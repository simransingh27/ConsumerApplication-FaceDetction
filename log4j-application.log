2020-01-05 19:48:41 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 57e30d96-dd48-4f58-8285-c88edb4759de
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-05 19:48:42 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-05 19:48:42 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-05 19:48:42 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-05 19:48:42 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=57e30d96-dd48-4f58-8285-c88edb4759de] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-05 19:48:42 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=57e30d96-dd48-4f58-8285-c88edb4759de] Revoking previously assigned partitions []
2020-01-05 19:48:42 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=57e30d96-dd48-4f58-8285-c88edb4759de] (Re-)joining group
2020-01-05 19:48:43 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=57e30d96-dd48-4f58-8285-c88edb4759de] Successfully joined group with generation 1
2020-01-05 19:48:43 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=57e30d96-dd48-4f58-8285-c88edb4759de] Setting newly assigned partitions [facedetection-0]
2020-01-05 19:48:43 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=57e30d96-dd48-4f58-8285-c88edb4759de] Resetting offset for partition facedetection-0 to offset 738.
2020-01-05 19:49:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8191fef8-2cca-4f5b-9865-12fa79ff5e73
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-05 19:49:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-05 19:49:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-05 19:49:01 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-05 19:49:01 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-2, groupId=8191fef8-2cca-4f5b-9865-12fa79ff5e73] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-05 19:49:01 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-2, groupId=8191fef8-2cca-4f5b-9865-12fa79ff5e73] Revoking previously assigned partitions []
2020-01-05 19:49:01 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-2, groupId=8191fef8-2cca-4f5b-9865-12fa79ff5e73] (Re-)joining group
2020-01-05 19:49:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-2, groupId=8191fef8-2cca-4f5b-9865-12fa79ff5e73] Successfully joined group with generation 1
2020-01-05 19:49:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-2, groupId=8191fef8-2cca-4f5b-9865-12fa79ff5e73] Setting newly assigned partitions [facedetection-0]
2020-01-05 19:49:02 INFO  Fetcher:583 - [Consumer clientId=consumer-2, groupId=8191fef8-2cca-4f5b-9865-12fa79ff5e73] Resetting offset for partition facedetection-0 to offset 1130.
2020-01-05 20:10:36 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 890dbb4d-1564-47c9-af08-e0aa7209c6f6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-05 20:10:36 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-05 20:10:36 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-05 20:10:36 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-05 20:10:36 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=890dbb4d-1564-47c9-af08-e0aa7209c6f6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-05 20:10:36 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=890dbb4d-1564-47c9-af08-e0aa7209c6f6] Revoking previously assigned partitions []
2020-01-05 20:10:36 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=890dbb4d-1564-47c9-af08-e0aa7209c6f6] (Re-)joining group
2020-01-05 20:10:36 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=890dbb4d-1564-47c9-af08-e0aa7209c6f6] Successfully joined group with generation 1
2020-01-05 20:10:36 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=890dbb4d-1564-47c9-af08-e0aa7209c6f6] Setting newly assigned partitions [facedetectiontest-0]
2020-01-05 20:10:36 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=890dbb4d-1564-47c9-af08-e0aa7209c6f6] Resetting offset for partition facedetectiontest-0 to offset 1390.
2020-01-05 21:05:14 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9c3b2979-6953-48f3-b4bc-89ac3cdaddff
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-05 21:05:14 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-05 21:05:14 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-05 21:05:15 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-05 21:05:15 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=9c3b2979-6953-48f3-b4bc-89ac3cdaddff] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-05 21:05:15 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=9c3b2979-6953-48f3-b4bc-89ac3cdaddff] Revoking previously assigned partitions []
2020-01-05 21:05:15 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=9c3b2979-6953-48f3-b4bc-89ac3cdaddff] (Re-)joining group
2020-01-05 21:05:15 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=9c3b2979-6953-48f3-b4bc-89ac3cdaddff] Successfully joined group with generation 1
2020-01-05 21:05:15 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=9c3b2979-6953-48f3-b4bc-89ac3cdaddff] Setting newly assigned partitions [facedetectiontest10-0]
2020-01-05 21:05:15 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=9c3b2979-6953-48f3-b4bc-89ac3cdaddff] Resetting offset for partition facedetectiontest10-0 to offset 0.
2020-01-05 21:06:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a9fda3fd-9559-4aa4-8067-11aec6b39331
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-05 21:06:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-05 21:06:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-05 21:06:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-05 21:06:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=a9fda3fd-9559-4aa4-8067-11aec6b39331] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-05 21:06:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=a9fda3fd-9559-4aa4-8067-11aec6b39331] Revoking previously assigned partitions []
2020-01-05 21:06:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=a9fda3fd-9559-4aa4-8067-11aec6b39331] (Re-)joining group
2020-01-05 21:06:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=a9fda3fd-9559-4aa4-8067-11aec6b39331] Successfully joined group with generation 1
2020-01-05 21:06:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=a9fda3fd-9559-4aa4-8067-11aec6b39331] Setting newly assigned partitions [facedetectiontest10-0]
2020-01-05 21:06:55 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=a9fda3fd-9559-4aa4-8067-11aec6b39331] Resetting offset for partition facedetectiontest10-0 to offset 0.
2020-01-07 17:34:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ff12f3bc-5a51-4bb5-89c2-eed9385af106
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-07 17:36:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4689dc6b-53f5-490c-b779-012307f65ea6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-07 17:38:47 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0e595c1a-ef60-47a7-8c06-1afbd295b650
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-07 17:39:39 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f396d380-a8b9-40f2-8c6f-b55f4d141d57
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-07 18:09:18 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1fc3eac0-5080-4245-aeef-22d9a05fd01a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-07 19:05:05 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 80cb1dde-2b49-4987-8764-e15c55b7156f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-07 19:06:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1763045d-5d38-4c14-895c-4d71d2ec9260
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-01-07 19:13:00 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e76faa1a-21df-41cd-a6e7-62ca7eb4cae0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:00 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:00 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:00 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:00 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=e76faa1a-21df-41cd-a6e7-62ca7eb4cae0] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:00 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=e76faa1a-21df-41cd-a6e7-62ca7eb4cae0] Revoking previously assigned partitions []
2020-01-07 19:13:00 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=e76faa1a-21df-41cd-a6e7-62ca7eb4cae0] (Re-)joining group
2020-01-07 19:13:00 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=e76faa1a-21df-41cd-a6e7-62ca7eb4cae0] Successfully joined group with generation 1
2020-01-07 19:13:00 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=e76faa1a-21df-41cd-a6e7-62ca7eb4cae0] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:00 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=e76faa1a-21df-41cd-a6e7-62ca7eb4cae0] Resetting offset for partition facedetectiontest101-0 to offset 17461.
2020-01-07 19:13:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c126d784-adee-4a57-a535-904b968cadc7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:01 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:01 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-2, groupId=c126d784-adee-4a57-a535-904b968cadc7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:01 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-2, groupId=c126d784-adee-4a57-a535-904b968cadc7] Revoking previously assigned partitions []
2020-01-07 19:13:01 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-2, groupId=c126d784-adee-4a57-a535-904b968cadc7] (Re-)joining group
2020-01-07 19:13:01 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-2, groupId=c126d784-adee-4a57-a535-904b968cadc7] Successfully joined group with generation 1
2020-01-07 19:13:01 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-2, groupId=c126d784-adee-4a57-a535-904b968cadc7] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:01 INFO  Fetcher:583 - [Consumer clientId=consumer-2, groupId=c126d784-adee-4a57-a535-904b968cadc7] Resetting offset for partition facedetectiontest101-0 to offset 17467.
2020-01-07 19:13:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 99e59722-5fdd-4df2-b2da-fc9893deca4c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:01 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:01 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-3, groupId=99e59722-5fdd-4df2-b2da-fc9893deca4c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:01 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-3, groupId=99e59722-5fdd-4df2-b2da-fc9893deca4c] Revoking previously assigned partitions []
2020-01-07 19:13:01 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-3, groupId=99e59722-5fdd-4df2-b2da-fc9893deca4c] (Re-)joining group
2020-01-07 19:13:01 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-3, groupId=99e59722-5fdd-4df2-b2da-fc9893deca4c] Successfully joined group with generation 1
2020-01-07 19:13:01 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-3, groupId=99e59722-5fdd-4df2-b2da-fc9893deca4c] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:01 INFO  Fetcher:583 - [Consumer clientId=consumer-3, groupId=99e59722-5fdd-4df2-b2da-fc9893deca4c] Resetting offset for partition facedetectiontest101-0 to offset 17468.
2020-01-07 19:13:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 45969616-4691-42f3-95e1-303ce4477b11
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:01 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:01 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-4, groupId=45969616-4691-42f3-95e1-303ce4477b11] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:01 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-4, groupId=45969616-4691-42f3-95e1-303ce4477b11] Revoking previously assigned partitions []
2020-01-07 19:13:01 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-4, groupId=45969616-4691-42f3-95e1-303ce4477b11] (Re-)joining group
2020-01-07 19:13:01 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-4, groupId=45969616-4691-42f3-95e1-303ce4477b11] Successfully joined group with generation 1
2020-01-07 19:13:01 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-4, groupId=45969616-4691-42f3-95e1-303ce4477b11] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:01 INFO  Fetcher:583 - [Consumer clientId=consumer-4, groupId=45969616-4691-42f3-95e1-303ce4477b11] Resetting offset for partition facedetectiontest101-0 to offset 17469.
2020-01-07 19:13:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c4da77d1-0ae5-4cbd-bbf8-fcf5fa8677f4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:01 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:01 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-5, groupId=c4da77d1-0ae5-4cbd-bbf8-fcf5fa8677f4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:01 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-5, groupId=c4da77d1-0ae5-4cbd-bbf8-fcf5fa8677f4] Revoking previously assigned partitions []
2020-01-07 19:13:01 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-5, groupId=c4da77d1-0ae5-4cbd-bbf8-fcf5fa8677f4] (Re-)joining group
2020-01-07 19:13:01 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-5, groupId=c4da77d1-0ae5-4cbd-bbf8-fcf5fa8677f4] Successfully joined group with generation 1
2020-01-07 19:13:01 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-5, groupId=c4da77d1-0ae5-4cbd-bbf8-fcf5fa8677f4] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:01 INFO  Fetcher:583 - [Consumer clientId=consumer-5, groupId=c4da77d1-0ae5-4cbd-bbf8-fcf5fa8677f4] Resetting offset for partition facedetectiontest101-0 to offset 17470.
2020-01-07 19:13:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 99d446a1-128b-4535-85de-90a65351e240
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:01 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:01 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-6, groupId=99d446a1-128b-4535-85de-90a65351e240] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:01 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-6, groupId=99d446a1-128b-4535-85de-90a65351e240] Revoking previously assigned partitions []
2020-01-07 19:13:01 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-6, groupId=99d446a1-128b-4535-85de-90a65351e240] (Re-)joining group
2020-01-07 19:13:01 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-6, groupId=99d446a1-128b-4535-85de-90a65351e240] Successfully joined group with generation 1
2020-01-07 19:13:01 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-6, groupId=99d446a1-128b-4535-85de-90a65351e240] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:01 INFO  Fetcher:583 - [Consumer clientId=consumer-6, groupId=99d446a1-128b-4535-85de-90a65351e240] Resetting offset for partition facedetectiontest101-0 to offset 17471.
2020-01-07 19:13:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ba396053-4a8c-4088-bad7-485b531e2339
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:01 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:01 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-7, groupId=ba396053-4a8c-4088-bad7-485b531e2339] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:01 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-7, groupId=ba396053-4a8c-4088-bad7-485b531e2339] Revoking previously assigned partitions []
2020-01-07 19:13:01 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-7, groupId=ba396053-4a8c-4088-bad7-485b531e2339] (Re-)joining group
2020-01-07 19:13:01 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-7, groupId=ba396053-4a8c-4088-bad7-485b531e2339] Successfully joined group with generation 1
2020-01-07 19:13:01 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-7, groupId=ba396053-4a8c-4088-bad7-485b531e2339] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:01 INFO  Fetcher:583 - [Consumer clientId=consumer-7, groupId=ba396053-4a8c-4088-bad7-485b531e2339] Resetting offset for partition facedetectiontest101-0 to offset 17472.
2020-01-07 19:13:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 944556b7-cf21-457e-b075-326a2036e657
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:01 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:01 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-8, groupId=944556b7-cf21-457e-b075-326a2036e657] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:01 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-8, groupId=944556b7-cf21-457e-b075-326a2036e657] Revoking previously assigned partitions []
2020-01-07 19:13:01 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-8, groupId=944556b7-cf21-457e-b075-326a2036e657] (Re-)joining group
2020-01-07 19:13:01 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-8, groupId=944556b7-cf21-457e-b075-326a2036e657] Successfully joined group with generation 1
2020-01-07 19:13:01 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-8, groupId=944556b7-cf21-457e-b075-326a2036e657] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:01 INFO  Fetcher:583 - [Consumer clientId=consumer-8, groupId=944556b7-cf21-457e-b075-326a2036e657] Resetting offset for partition facedetectiontest101-0 to offset 17474.
2020-01-07 19:13:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5d380a53-5b7b-4e16-8417-2ba84e572c6b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-9, groupId=5d380a53-5b7b-4e16-8417-2ba84e572c6b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-9, groupId=5d380a53-5b7b-4e16-8417-2ba84e572c6b] Revoking previously assigned partitions []
2020-01-07 19:13:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-9, groupId=5d380a53-5b7b-4e16-8417-2ba84e572c6b] (Re-)joining group
2020-01-07 19:13:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-9, groupId=5d380a53-5b7b-4e16-8417-2ba84e572c6b] Successfully joined group with generation 1
2020-01-07 19:13:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-9, groupId=5d380a53-5b7b-4e16-8417-2ba84e572c6b] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:02 INFO  Fetcher:583 - [Consumer clientId=consumer-9, groupId=5d380a53-5b7b-4e16-8417-2ba84e572c6b] Resetting offset for partition facedetectiontest101-0 to offset 17475.
2020-01-07 19:13:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e2889c7b-c4ff-4541-904d-fa6d4da9a641
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-10, groupId=e2889c7b-c4ff-4541-904d-fa6d4da9a641] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-10, groupId=e2889c7b-c4ff-4541-904d-fa6d4da9a641] Revoking previously assigned partitions []
2020-01-07 19:13:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-10, groupId=e2889c7b-c4ff-4541-904d-fa6d4da9a641] (Re-)joining group
2020-01-07 19:13:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-10, groupId=e2889c7b-c4ff-4541-904d-fa6d4da9a641] Successfully joined group with generation 1
2020-01-07 19:13:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-10, groupId=e2889c7b-c4ff-4541-904d-fa6d4da9a641] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:02 INFO  Fetcher:583 - [Consumer clientId=consumer-10, groupId=e2889c7b-c4ff-4541-904d-fa6d4da9a641] Resetting offset for partition facedetectiontest101-0 to offset 17476.
2020-01-07 19:13:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e3295a93-0723-48a3-bfb0-9c1823bbd9c6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-11, groupId=e3295a93-0723-48a3-bfb0-9c1823bbd9c6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-11, groupId=e3295a93-0723-48a3-bfb0-9c1823bbd9c6] Revoking previously assigned partitions []
2020-01-07 19:13:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-11, groupId=e3295a93-0723-48a3-bfb0-9c1823bbd9c6] (Re-)joining group
2020-01-07 19:13:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-11, groupId=e3295a93-0723-48a3-bfb0-9c1823bbd9c6] Successfully joined group with generation 1
2020-01-07 19:13:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-11, groupId=e3295a93-0723-48a3-bfb0-9c1823bbd9c6] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:02 INFO  Fetcher:583 - [Consumer clientId=consumer-11, groupId=e3295a93-0723-48a3-bfb0-9c1823bbd9c6] Resetting offset for partition facedetectiontest101-0 to offset 17477.
2020-01-07 19:13:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 811cbb6c-8a06-4484-bd80-a094f9154599
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-12, groupId=811cbb6c-8a06-4484-bd80-a094f9154599] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-12, groupId=811cbb6c-8a06-4484-bd80-a094f9154599] Revoking previously assigned partitions []
2020-01-07 19:13:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-12, groupId=811cbb6c-8a06-4484-bd80-a094f9154599] (Re-)joining group
2020-01-07 19:13:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-12, groupId=811cbb6c-8a06-4484-bd80-a094f9154599] Successfully joined group with generation 1
2020-01-07 19:13:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-12, groupId=811cbb6c-8a06-4484-bd80-a094f9154599] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:02 INFO  Fetcher:583 - [Consumer clientId=consumer-12, groupId=811cbb6c-8a06-4484-bd80-a094f9154599] Resetting offset for partition facedetectiontest101-0 to offset 17478.
2020-01-07 19:13:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e5f0be5a-1d22-459b-bbc2-5bee08e7cbb6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-13, groupId=e5f0be5a-1d22-459b-bbc2-5bee08e7cbb6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-13, groupId=e5f0be5a-1d22-459b-bbc2-5bee08e7cbb6] Revoking previously assigned partitions []
2020-01-07 19:13:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-13, groupId=e5f0be5a-1d22-459b-bbc2-5bee08e7cbb6] (Re-)joining group
2020-01-07 19:13:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-13, groupId=e5f0be5a-1d22-459b-bbc2-5bee08e7cbb6] Successfully joined group with generation 1
2020-01-07 19:13:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-13, groupId=e5f0be5a-1d22-459b-bbc2-5bee08e7cbb6] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:02 INFO  Fetcher:583 - [Consumer clientId=consumer-13, groupId=e5f0be5a-1d22-459b-bbc2-5bee08e7cbb6] Resetting offset for partition facedetectiontest101-0 to offset 17480.
2020-01-07 19:13:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = aafdcf19-b145-47bc-b08e-7801b35630aa
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-14, groupId=aafdcf19-b145-47bc-b08e-7801b35630aa] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-14, groupId=aafdcf19-b145-47bc-b08e-7801b35630aa] Revoking previously assigned partitions []
2020-01-07 19:13:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-14, groupId=aafdcf19-b145-47bc-b08e-7801b35630aa] (Re-)joining group
2020-01-07 19:13:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-14, groupId=aafdcf19-b145-47bc-b08e-7801b35630aa] Successfully joined group with generation 1
2020-01-07 19:13:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-14, groupId=aafdcf19-b145-47bc-b08e-7801b35630aa] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:02 INFO  Fetcher:583 - [Consumer clientId=consumer-14, groupId=aafdcf19-b145-47bc-b08e-7801b35630aa] Resetting offset for partition facedetectiontest101-0 to offset 17482.
2020-01-07 19:13:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9d053d73-332a-4654-aac6-19dcbc682730
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-15, groupId=9d053d73-332a-4654-aac6-19dcbc682730] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-15, groupId=9d053d73-332a-4654-aac6-19dcbc682730] Revoking previously assigned partitions []
2020-01-07 19:13:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-15, groupId=9d053d73-332a-4654-aac6-19dcbc682730] (Re-)joining group
2020-01-07 19:13:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-15, groupId=9d053d73-332a-4654-aac6-19dcbc682730] Successfully joined group with generation 1
2020-01-07 19:13:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-15, groupId=9d053d73-332a-4654-aac6-19dcbc682730] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:02 INFO  Fetcher:583 - [Consumer clientId=consumer-15, groupId=9d053d73-332a-4654-aac6-19dcbc682730] Resetting offset for partition facedetectiontest101-0 to offset 17483.
2020-01-07 19:13:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5f973417-4a50-4872-bcc9-5d5843cced9b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-16, groupId=5f973417-4a50-4872-bcc9-5d5843cced9b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-16, groupId=5f973417-4a50-4872-bcc9-5d5843cced9b] Revoking previously assigned partitions []
2020-01-07 19:13:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-16, groupId=5f973417-4a50-4872-bcc9-5d5843cced9b] (Re-)joining group
2020-01-07 19:13:03 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-16, groupId=5f973417-4a50-4872-bcc9-5d5843cced9b] Successfully joined group with generation 1
2020-01-07 19:13:03 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-16, groupId=5f973417-4a50-4872-bcc9-5d5843cced9b] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:03 INFO  Fetcher:583 - [Consumer clientId=consumer-16, groupId=5f973417-4a50-4872-bcc9-5d5843cced9b] Resetting offset for partition facedetectiontest101-0 to offset 17484.
2020-01-07 19:13:03 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 04504bb4-9bb0-4039-8612-ee04a45e7156
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:03 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:03 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:03 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:03 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-17, groupId=04504bb4-9bb0-4039-8612-ee04a45e7156] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:03 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-17, groupId=04504bb4-9bb0-4039-8612-ee04a45e7156] Revoking previously assigned partitions []
2020-01-07 19:13:03 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-17, groupId=04504bb4-9bb0-4039-8612-ee04a45e7156] (Re-)joining group
2020-01-07 19:13:03 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-17, groupId=04504bb4-9bb0-4039-8612-ee04a45e7156] Successfully joined group with generation 1
2020-01-07 19:13:03 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-17, groupId=04504bb4-9bb0-4039-8612-ee04a45e7156] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:03 INFO  Fetcher:583 - [Consumer clientId=consumer-17, groupId=04504bb4-9bb0-4039-8612-ee04a45e7156] Resetting offset for partition facedetectiontest101-0 to offset 17485.
2020-01-07 19:13:03 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 336882f4-e3fd-4628-9c15-11c1b11d18c9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:03 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:03 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:03 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:03 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-18, groupId=336882f4-e3fd-4628-9c15-11c1b11d18c9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:03 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-18, groupId=336882f4-e3fd-4628-9c15-11c1b11d18c9] Revoking previously assigned partitions []
2020-01-07 19:13:03 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-18, groupId=336882f4-e3fd-4628-9c15-11c1b11d18c9] (Re-)joining group
2020-01-07 19:13:03 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-18, groupId=336882f4-e3fd-4628-9c15-11c1b11d18c9] Successfully joined group with generation 1
2020-01-07 19:13:03 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-18, groupId=336882f4-e3fd-4628-9c15-11c1b11d18c9] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:03 INFO  Fetcher:583 - [Consumer clientId=consumer-18, groupId=336882f4-e3fd-4628-9c15-11c1b11d18c9] Resetting offset for partition facedetectiontest101-0 to offset 17486.
2020-01-07 19:13:03 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1925f29e-d4f0-4b21-a6f2-3539aee64ea1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:03 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:03 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:03 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:03 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-19, groupId=1925f29e-d4f0-4b21-a6f2-3539aee64ea1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:03 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-19, groupId=1925f29e-d4f0-4b21-a6f2-3539aee64ea1] Revoking previously assigned partitions []
2020-01-07 19:13:03 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-19, groupId=1925f29e-d4f0-4b21-a6f2-3539aee64ea1] (Re-)joining group
2020-01-07 19:13:03 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-19, groupId=1925f29e-d4f0-4b21-a6f2-3539aee64ea1] Successfully joined group with generation 1
2020-01-07 19:13:03 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-19, groupId=1925f29e-d4f0-4b21-a6f2-3539aee64ea1] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:03 INFO  Fetcher:583 - [Consumer clientId=consumer-19, groupId=1925f29e-d4f0-4b21-a6f2-3539aee64ea1] Resetting offset for partition facedetectiontest101-0 to offset 17487.
2020-01-07 19:13:03 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fa667be3-d060-47a8-96d7-85ddc82492e8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:03 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:03 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:03 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:03 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-20, groupId=fa667be3-d060-47a8-96d7-85ddc82492e8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:03 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-20, groupId=fa667be3-d060-47a8-96d7-85ddc82492e8] Revoking previously assigned partitions []
2020-01-07 19:13:03 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-20, groupId=fa667be3-d060-47a8-96d7-85ddc82492e8] (Re-)joining group
2020-01-07 19:13:03 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-20, groupId=fa667be3-d060-47a8-96d7-85ddc82492e8] Successfully joined group with generation 1
2020-01-07 19:13:03 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-20, groupId=fa667be3-d060-47a8-96d7-85ddc82492e8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:03 INFO  Fetcher:583 - [Consumer clientId=consumer-20, groupId=fa667be3-d060-47a8-96d7-85ddc82492e8] Resetting offset for partition facedetectiontest101-0 to offset 17488.
2020-01-07 19:13:03 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4e05d54c-bd74-4ae5-884e-b5b009b97d0b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:03 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:03 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:03 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:03 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-21, groupId=4e05d54c-bd74-4ae5-884e-b5b009b97d0b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:03 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-21, groupId=4e05d54c-bd74-4ae5-884e-b5b009b97d0b] Revoking previously assigned partitions []
2020-01-07 19:13:03 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-21, groupId=4e05d54c-bd74-4ae5-884e-b5b009b97d0b] (Re-)joining group
2020-01-07 19:13:03 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-21, groupId=4e05d54c-bd74-4ae5-884e-b5b009b97d0b] Successfully joined group with generation 1
2020-01-07 19:13:03 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-21, groupId=4e05d54c-bd74-4ae5-884e-b5b009b97d0b] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:03 INFO  Fetcher:583 - [Consumer clientId=consumer-21, groupId=4e05d54c-bd74-4ae5-884e-b5b009b97d0b] Resetting offset for partition facedetectiontest101-0 to offset 17489.
2020-01-07 19:13:03 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 762e24fc-7d56-4cc5-b085-d64a7a8c590d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:03 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:03 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:03 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:03 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-22, groupId=762e24fc-7d56-4cc5-b085-d64a7a8c590d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:03 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-22, groupId=762e24fc-7d56-4cc5-b085-d64a7a8c590d] Revoking previously assigned partitions []
2020-01-07 19:13:03 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-22, groupId=762e24fc-7d56-4cc5-b085-d64a7a8c590d] (Re-)joining group
2020-01-07 19:13:03 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-22, groupId=762e24fc-7d56-4cc5-b085-d64a7a8c590d] Successfully joined group with generation 1
2020-01-07 19:13:03 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-22, groupId=762e24fc-7d56-4cc5-b085-d64a7a8c590d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:03 INFO  Fetcher:583 - [Consumer clientId=consumer-22, groupId=762e24fc-7d56-4cc5-b085-d64a7a8c590d] Resetting offset for partition facedetectiontest101-0 to offset 17490.
2020-01-07 19:13:03 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7af4c2df-fdcc-477f-8c95-500d8d71b9b4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:03 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:03 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:03 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:03 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-23, groupId=7af4c2df-fdcc-477f-8c95-500d8d71b9b4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:03 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-23, groupId=7af4c2df-fdcc-477f-8c95-500d8d71b9b4] Revoking previously assigned partitions []
2020-01-07 19:13:03 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-23, groupId=7af4c2df-fdcc-477f-8c95-500d8d71b9b4] (Re-)joining group
2020-01-07 19:13:03 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-23, groupId=7af4c2df-fdcc-477f-8c95-500d8d71b9b4] Successfully joined group with generation 1
2020-01-07 19:13:03 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-23, groupId=7af4c2df-fdcc-477f-8c95-500d8d71b9b4] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:03 INFO  Fetcher:583 - [Consumer clientId=consumer-23, groupId=7af4c2df-fdcc-477f-8c95-500d8d71b9b4] Resetting offset for partition facedetectiontest101-0 to offset 17491.
2020-01-07 19:13:03 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d4e9b640-4252-433d-8d69-352d7807d365
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:03 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:03 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:03 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:03 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-24, groupId=d4e9b640-4252-433d-8d69-352d7807d365] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:03 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-24, groupId=d4e9b640-4252-433d-8d69-352d7807d365] Revoking previously assigned partitions []
2020-01-07 19:13:03 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-24, groupId=d4e9b640-4252-433d-8d69-352d7807d365] (Re-)joining group
2020-01-07 19:13:03 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-24, groupId=d4e9b640-4252-433d-8d69-352d7807d365] Successfully joined group with generation 1
2020-01-07 19:13:03 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-24, groupId=d4e9b640-4252-433d-8d69-352d7807d365] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:03 INFO  Fetcher:583 - [Consumer clientId=consumer-24, groupId=d4e9b640-4252-433d-8d69-352d7807d365] Resetting offset for partition facedetectiontest101-0 to offset 17492.
2020-01-07 19:13:03 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = cd59db16-274b-45cc-bc96-66372f7fc3e6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:03 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:03 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:03 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:03 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-25, groupId=cd59db16-274b-45cc-bc96-66372f7fc3e6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:03 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-25, groupId=cd59db16-274b-45cc-bc96-66372f7fc3e6] Revoking previously assigned partitions []
2020-01-07 19:13:03 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-25, groupId=cd59db16-274b-45cc-bc96-66372f7fc3e6] (Re-)joining group
2020-01-07 19:13:03 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-25, groupId=cd59db16-274b-45cc-bc96-66372f7fc3e6] Successfully joined group with generation 1
2020-01-07 19:13:03 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-25, groupId=cd59db16-274b-45cc-bc96-66372f7fc3e6] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:03 INFO  Fetcher:583 - [Consumer clientId=consumer-25, groupId=cd59db16-274b-45cc-bc96-66372f7fc3e6] Resetting offset for partition facedetectiontest101-0 to offset 17493.
2020-01-07 19:13:04 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 34a1602d-66ec-4b6c-b715-a2950a4f51c5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:04 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:04 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:04 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:04 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-26, groupId=34a1602d-66ec-4b6c-b715-a2950a4f51c5] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:04 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-26, groupId=34a1602d-66ec-4b6c-b715-a2950a4f51c5] Revoking previously assigned partitions []
2020-01-07 19:13:04 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-26, groupId=34a1602d-66ec-4b6c-b715-a2950a4f51c5] (Re-)joining group
2020-01-07 19:13:04 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-26, groupId=34a1602d-66ec-4b6c-b715-a2950a4f51c5] Successfully joined group with generation 1
2020-01-07 19:13:04 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-26, groupId=34a1602d-66ec-4b6c-b715-a2950a4f51c5] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:04 INFO  Fetcher:583 - [Consumer clientId=consumer-26, groupId=34a1602d-66ec-4b6c-b715-a2950a4f51c5] Resetting offset for partition facedetectiontest101-0 to offset 17494.
2020-01-07 19:13:04 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1b621491-33f6-438a-b6a5-b64a35748bad
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:04 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:04 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:04 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:04 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-27, groupId=1b621491-33f6-438a-b6a5-b64a35748bad] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:04 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-27, groupId=1b621491-33f6-438a-b6a5-b64a35748bad] Revoking previously assigned partitions []
2020-01-07 19:13:04 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-27, groupId=1b621491-33f6-438a-b6a5-b64a35748bad] (Re-)joining group
2020-01-07 19:13:04 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-27, groupId=1b621491-33f6-438a-b6a5-b64a35748bad] Successfully joined group with generation 1
2020-01-07 19:13:04 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-27, groupId=1b621491-33f6-438a-b6a5-b64a35748bad] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:04 INFO  Fetcher:583 - [Consumer clientId=consumer-27, groupId=1b621491-33f6-438a-b6a5-b64a35748bad] Resetting offset for partition facedetectiontest101-0 to offset 17495.
2020-01-07 19:13:04 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 70db0da9-97d2-4ad4-89d3-cf6287806085
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:04 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:04 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:04 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:04 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-28, groupId=70db0da9-97d2-4ad4-89d3-cf6287806085] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:04 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-28, groupId=70db0da9-97d2-4ad4-89d3-cf6287806085] Revoking previously assigned partitions []
2020-01-07 19:13:04 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-28, groupId=70db0da9-97d2-4ad4-89d3-cf6287806085] (Re-)joining group
2020-01-07 19:13:04 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-28, groupId=70db0da9-97d2-4ad4-89d3-cf6287806085] Successfully joined group with generation 1
2020-01-07 19:13:04 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-28, groupId=70db0da9-97d2-4ad4-89d3-cf6287806085] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:04 INFO  Fetcher:583 - [Consumer clientId=consumer-28, groupId=70db0da9-97d2-4ad4-89d3-cf6287806085] Resetting offset for partition facedetectiontest101-0 to offset 17496.
2020-01-07 19:13:04 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9e517f7d-aec3-4e90-b918-0572b8f5134a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:04 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:04 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:04 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:04 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-29, groupId=9e517f7d-aec3-4e90-b918-0572b8f5134a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:04 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-29, groupId=9e517f7d-aec3-4e90-b918-0572b8f5134a] Revoking previously assigned partitions []
2020-01-07 19:13:04 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-29, groupId=9e517f7d-aec3-4e90-b918-0572b8f5134a] (Re-)joining group
2020-01-07 19:13:04 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-29, groupId=9e517f7d-aec3-4e90-b918-0572b8f5134a] Successfully joined group with generation 1
2020-01-07 19:13:04 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-29, groupId=9e517f7d-aec3-4e90-b918-0572b8f5134a] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:04 INFO  Fetcher:583 - [Consumer clientId=consumer-29, groupId=9e517f7d-aec3-4e90-b918-0572b8f5134a] Resetting offset for partition facedetectiontest101-0 to offset 17498.
2020-01-07 19:13:04 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f21d532e-9c3b-4544-8a63-cb7d6ff30936
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:04 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:04 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:04 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:04 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-30, groupId=f21d532e-9c3b-4544-8a63-cb7d6ff30936] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:04 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-30, groupId=f21d532e-9c3b-4544-8a63-cb7d6ff30936] Revoking previously assigned partitions []
2020-01-07 19:13:04 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-30, groupId=f21d532e-9c3b-4544-8a63-cb7d6ff30936] (Re-)joining group
2020-01-07 19:13:04 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-30, groupId=f21d532e-9c3b-4544-8a63-cb7d6ff30936] Successfully joined group with generation 1
2020-01-07 19:13:04 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-30, groupId=f21d532e-9c3b-4544-8a63-cb7d6ff30936] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:04 INFO  Fetcher:583 - [Consumer clientId=consumer-30, groupId=f21d532e-9c3b-4544-8a63-cb7d6ff30936] Resetting offset for partition facedetectiontest101-0 to offset 17499.
2020-01-07 19:13:04 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b5e57efd-fdc9-461b-99d7-27fad212b7a4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:04 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:04 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:04 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:04 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-31, groupId=b5e57efd-fdc9-461b-99d7-27fad212b7a4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:04 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-31, groupId=b5e57efd-fdc9-461b-99d7-27fad212b7a4] Revoking previously assigned partitions []
2020-01-07 19:13:04 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-31, groupId=b5e57efd-fdc9-461b-99d7-27fad212b7a4] (Re-)joining group
2020-01-07 19:13:04 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-31, groupId=b5e57efd-fdc9-461b-99d7-27fad212b7a4] Successfully joined group with generation 1
2020-01-07 19:13:04 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-31, groupId=b5e57efd-fdc9-461b-99d7-27fad212b7a4] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:04 INFO  Fetcher:583 - [Consumer clientId=consumer-31, groupId=b5e57efd-fdc9-461b-99d7-27fad212b7a4] Resetting offset for partition facedetectiontest101-0 to offset 17500.
2020-01-07 19:13:04 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4e3206e4-9558-463f-96da-a23f5be2e08a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:04 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:04 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:04 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:04 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-32, groupId=4e3206e4-9558-463f-96da-a23f5be2e08a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:04 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-32, groupId=4e3206e4-9558-463f-96da-a23f5be2e08a] Revoking previously assigned partitions []
2020-01-07 19:13:04 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-32, groupId=4e3206e4-9558-463f-96da-a23f5be2e08a] (Re-)joining group
2020-01-07 19:13:04 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-32, groupId=4e3206e4-9558-463f-96da-a23f5be2e08a] Successfully joined group with generation 1
2020-01-07 19:13:04 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-32, groupId=4e3206e4-9558-463f-96da-a23f5be2e08a] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:04 INFO  Fetcher:583 - [Consumer clientId=consumer-32, groupId=4e3206e4-9558-463f-96da-a23f5be2e08a] Resetting offset for partition facedetectiontest101-0 to offset 17501.
2020-01-07 19:13:05 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e5dadacb-3529-43ab-9c66-24f201c755a1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:05 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:05 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:05 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:05 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-33, groupId=e5dadacb-3529-43ab-9c66-24f201c755a1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:05 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-33, groupId=e5dadacb-3529-43ab-9c66-24f201c755a1] Revoking previously assigned partitions []
2020-01-07 19:13:05 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-33, groupId=e5dadacb-3529-43ab-9c66-24f201c755a1] (Re-)joining group
2020-01-07 19:13:05 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-33, groupId=e5dadacb-3529-43ab-9c66-24f201c755a1] Successfully joined group with generation 1
2020-01-07 19:13:05 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-33, groupId=e5dadacb-3529-43ab-9c66-24f201c755a1] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:05 INFO  Fetcher:583 - [Consumer clientId=consumer-33, groupId=e5dadacb-3529-43ab-9c66-24f201c755a1] Resetting offset for partition facedetectiontest101-0 to offset 17502.
2020-01-07 19:13:05 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f94c32d6-da60-4855-be23-0ac11957033d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:05 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:05 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:05 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:05 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-34, groupId=f94c32d6-da60-4855-be23-0ac11957033d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:05 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-34, groupId=f94c32d6-da60-4855-be23-0ac11957033d] Revoking previously assigned partitions []
2020-01-07 19:13:05 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-34, groupId=f94c32d6-da60-4855-be23-0ac11957033d] (Re-)joining group
2020-01-07 19:13:05 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-34, groupId=f94c32d6-da60-4855-be23-0ac11957033d] Successfully joined group with generation 1
2020-01-07 19:13:05 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-34, groupId=f94c32d6-da60-4855-be23-0ac11957033d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:05 INFO  Fetcher:583 - [Consumer clientId=consumer-34, groupId=f94c32d6-da60-4855-be23-0ac11957033d] Resetting offset for partition facedetectiontest101-0 to offset 17504.
2020-01-07 19:13:05 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 77a3a117-0e14-47af-9f85-933a9892772d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:05 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:05 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:05 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:05 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-35, groupId=77a3a117-0e14-47af-9f85-933a9892772d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:05 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-35, groupId=77a3a117-0e14-47af-9f85-933a9892772d] Revoking previously assigned partitions []
2020-01-07 19:13:05 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-35, groupId=77a3a117-0e14-47af-9f85-933a9892772d] (Re-)joining group
2020-01-07 19:13:05 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-35, groupId=77a3a117-0e14-47af-9f85-933a9892772d] Successfully joined group with generation 1
2020-01-07 19:13:05 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-35, groupId=77a3a117-0e14-47af-9f85-933a9892772d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:05 INFO  Fetcher:583 - [Consumer clientId=consumer-35, groupId=77a3a117-0e14-47af-9f85-933a9892772d] Resetting offset for partition facedetectiontest101-0 to offset 17505.
2020-01-07 19:13:05 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 42269865-19a3-4c8f-b392-b4282f5dfc10
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:05 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:05 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:05 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:05 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-36, groupId=42269865-19a3-4c8f-b392-b4282f5dfc10] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:05 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-36, groupId=42269865-19a3-4c8f-b392-b4282f5dfc10] Revoking previously assigned partitions []
2020-01-07 19:13:05 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-36, groupId=42269865-19a3-4c8f-b392-b4282f5dfc10] (Re-)joining group
2020-01-07 19:13:05 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-36, groupId=42269865-19a3-4c8f-b392-b4282f5dfc10] Successfully joined group with generation 1
2020-01-07 19:13:05 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-36, groupId=42269865-19a3-4c8f-b392-b4282f5dfc10] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:05 INFO  Fetcher:583 - [Consumer clientId=consumer-36, groupId=42269865-19a3-4c8f-b392-b4282f5dfc10] Resetting offset for partition facedetectiontest101-0 to offset 17506.
2020-01-07 19:13:05 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 85f01c9c-cda6-48c2-97dc-e2eef666cbcd
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:05 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:05 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:05 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:05 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-37, groupId=85f01c9c-cda6-48c2-97dc-e2eef666cbcd] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:05 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-37, groupId=85f01c9c-cda6-48c2-97dc-e2eef666cbcd] Revoking previously assigned partitions []
2020-01-07 19:13:05 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-37, groupId=85f01c9c-cda6-48c2-97dc-e2eef666cbcd] (Re-)joining group
2020-01-07 19:13:05 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-37, groupId=85f01c9c-cda6-48c2-97dc-e2eef666cbcd] Successfully joined group with generation 1
2020-01-07 19:13:05 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-37, groupId=85f01c9c-cda6-48c2-97dc-e2eef666cbcd] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:05 INFO  Fetcher:583 - [Consumer clientId=consumer-37, groupId=85f01c9c-cda6-48c2-97dc-e2eef666cbcd] Resetting offset for partition facedetectiontest101-0 to offset 17507.
2020-01-07 19:13:05 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 99df77dd-7ab4-4fb7-af2e-bc91916aed00
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:05 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:05 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:05 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:05 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-38, groupId=99df77dd-7ab4-4fb7-af2e-bc91916aed00] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:05 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-38, groupId=99df77dd-7ab4-4fb7-af2e-bc91916aed00] Revoking previously assigned partitions []
2020-01-07 19:13:05 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-38, groupId=99df77dd-7ab4-4fb7-af2e-bc91916aed00] (Re-)joining group
2020-01-07 19:13:05 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-38, groupId=99df77dd-7ab4-4fb7-af2e-bc91916aed00] Successfully joined group with generation 1
2020-01-07 19:13:05 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-38, groupId=99df77dd-7ab4-4fb7-af2e-bc91916aed00] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:05 INFO  Fetcher:583 - [Consumer clientId=consumer-38, groupId=99df77dd-7ab4-4fb7-af2e-bc91916aed00] Resetting offset for partition facedetectiontest101-0 to offset 17508.
2020-01-07 19:13:05 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 169224be-3e44-4eb7-be5a-1d5573353970
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:05 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:05 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:05 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:05 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-39, groupId=169224be-3e44-4eb7-be5a-1d5573353970] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:05 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-39, groupId=169224be-3e44-4eb7-be5a-1d5573353970] Revoking previously assigned partitions []
2020-01-07 19:13:05 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-39, groupId=169224be-3e44-4eb7-be5a-1d5573353970] (Re-)joining group
2020-01-07 19:13:05 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-39, groupId=169224be-3e44-4eb7-be5a-1d5573353970] Successfully joined group with generation 1
2020-01-07 19:13:05 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-39, groupId=169224be-3e44-4eb7-be5a-1d5573353970] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:05 INFO  Fetcher:583 - [Consumer clientId=consumer-39, groupId=169224be-3e44-4eb7-be5a-1d5573353970] Resetting offset for partition facedetectiontest101-0 to offset 17509.
2020-01-07 19:13:05 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ea03264f-88dc-40ab-95d4-455e102ac22e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:05 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:05 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:05 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:05 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-40, groupId=ea03264f-88dc-40ab-95d4-455e102ac22e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:05 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-40, groupId=ea03264f-88dc-40ab-95d4-455e102ac22e] Revoking previously assigned partitions []
2020-01-07 19:13:05 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-40, groupId=ea03264f-88dc-40ab-95d4-455e102ac22e] (Re-)joining group
2020-01-07 19:13:05 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-40, groupId=ea03264f-88dc-40ab-95d4-455e102ac22e] Successfully joined group with generation 1
2020-01-07 19:13:05 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-40, groupId=ea03264f-88dc-40ab-95d4-455e102ac22e] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:05 INFO  Fetcher:583 - [Consumer clientId=consumer-40, groupId=ea03264f-88dc-40ab-95d4-455e102ac22e] Resetting offset for partition facedetectiontest101-0 to offset 17510.
2020-01-07 19:13:05 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 653244f5-974c-4202-9ccf-52222d0d5acd
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:05 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:05 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:05 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:05 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-41, groupId=653244f5-974c-4202-9ccf-52222d0d5acd] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:05 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-41, groupId=653244f5-974c-4202-9ccf-52222d0d5acd] Revoking previously assigned partitions []
2020-01-07 19:13:05 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-41, groupId=653244f5-974c-4202-9ccf-52222d0d5acd] (Re-)joining group
2020-01-07 19:13:05 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-41, groupId=653244f5-974c-4202-9ccf-52222d0d5acd] Successfully joined group with generation 1
2020-01-07 19:13:05 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-41, groupId=653244f5-974c-4202-9ccf-52222d0d5acd] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:05 INFO  Fetcher:583 - [Consumer clientId=consumer-41, groupId=653244f5-974c-4202-9ccf-52222d0d5acd] Resetting offset for partition facedetectiontest101-0 to offset 17511.
2020-01-07 19:13:05 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 31a67ad7-17a7-4dae-8a42-43281e5d5e08
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:05 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:05 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:05 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:05 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-42, groupId=31a67ad7-17a7-4dae-8a42-43281e5d5e08] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:05 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-42, groupId=31a67ad7-17a7-4dae-8a42-43281e5d5e08] Revoking previously assigned partitions []
2020-01-07 19:13:05 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-42, groupId=31a67ad7-17a7-4dae-8a42-43281e5d5e08] (Re-)joining group
2020-01-07 19:13:05 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-42, groupId=31a67ad7-17a7-4dae-8a42-43281e5d5e08] Successfully joined group with generation 1
2020-01-07 19:13:05 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-42, groupId=31a67ad7-17a7-4dae-8a42-43281e5d5e08] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:05 INFO  Fetcher:583 - [Consumer clientId=consumer-42, groupId=31a67ad7-17a7-4dae-8a42-43281e5d5e08] Resetting offset for partition facedetectiontest101-0 to offset 17512.
2020-01-07 19:13:06 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ff01a483-4787-466f-ad82-e31a36b87484
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:06 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:06 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:06 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:06 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-43, groupId=ff01a483-4787-466f-ad82-e31a36b87484] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:06 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-43, groupId=ff01a483-4787-466f-ad82-e31a36b87484] Revoking previously assigned partitions []
2020-01-07 19:13:06 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-43, groupId=ff01a483-4787-466f-ad82-e31a36b87484] (Re-)joining group
2020-01-07 19:13:06 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-43, groupId=ff01a483-4787-466f-ad82-e31a36b87484] Successfully joined group with generation 1
2020-01-07 19:13:06 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-43, groupId=ff01a483-4787-466f-ad82-e31a36b87484] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:06 INFO  Fetcher:583 - [Consumer clientId=consumer-43, groupId=ff01a483-4787-466f-ad82-e31a36b87484] Resetting offset for partition facedetectiontest101-0 to offset 17513.
2020-01-07 19:13:06 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 062c19b7-8d22-4f2c-a7c9-7eccbf9454cf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:06 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:06 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:06 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:06 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-44, groupId=062c19b7-8d22-4f2c-a7c9-7eccbf9454cf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:06 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-44, groupId=062c19b7-8d22-4f2c-a7c9-7eccbf9454cf] Revoking previously assigned partitions []
2020-01-07 19:13:06 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-44, groupId=062c19b7-8d22-4f2c-a7c9-7eccbf9454cf] (Re-)joining group
2020-01-07 19:13:06 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-44, groupId=062c19b7-8d22-4f2c-a7c9-7eccbf9454cf] Successfully joined group with generation 1
2020-01-07 19:13:06 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-44, groupId=062c19b7-8d22-4f2c-a7c9-7eccbf9454cf] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:06 INFO  Fetcher:583 - [Consumer clientId=consumer-44, groupId=062c19b7-8d22-4f2c-a7c9-7eccbf9454cf] Resetting offset for partition facedetectiontest101-0 to offset 17514.
2020-01-07 19:13:06 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c5078001-d94d-4200-bdf5-47f84614ee95
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:06 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:06 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:06 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:06 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-45, groupId=c5078001-d94d-4200-bdf5-47f84614ee95] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:06 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-45, groupId=c5078001-d94d-4200-bdf5-47f84614ee95] Revoking previously assigned partitions []
2020-01-07 19:13:06 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-45, groupId=c5078001-d94d-4200-bdf5-47f84614ee95] (Re-)joining group
2020-01-07 19:13:06 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-45, groupId=c5078001-d94d-4200-bdf5-47f84614ee95] Successfully joined group with generation 1
2020-01-07 19:13:06 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-45, groupId=c5078001-d94d-4200-bdf5-47f84614ee95] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:06 INFO  Fetcher:583 - [Consumer clientId=consumer-45, groupId=c5078001-d94d-4200-bdf5-47f84614ee95] Resetting offset for partition facedetectiontest101-0 to offset 17515.
2020-01-07 19:13:06 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 57587362-081e-48ab-8d7b-6be395ba2a99
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:06 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:06 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:06 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:06 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-46, groupId=57587362-081e-48ab-8d7b-6be395ba2a99] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:06 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-46, groupId=57587362-081e-48ab-8d7b-6be395ba2a99] Revoking previously assigned partitions []
2020-01-07 19:13:06 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-46, groupId=57587362-081e-48ab-8d7b-6be395ba2a99] (Re-)joining group
2020-01-07 19:13:06 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-46, groupId=57587362-081e-48ab-8d7b-6be395ba2a99] Successfully joined group with generation 1
2020-01-07 19:13:06 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-46, groupId=57587362-081e-48ab-8d7b-6be395ba2a99] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:06 INFO  Fetcher:583 - [Consumer clientId=consumer-46, groupId=57587362-081e-48ab-8d7b-6be395ba2a99] Resetting offset for partition facedetectiontest101-0 to offset 17516.
2020-01-07 19:13:06 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ba651f13-cd1a-4133-883e-440a546f7c4e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:06 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:06 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:06 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:06 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-47, groupId=ba651f13-cd1a-4133-883e-440a546f7c4e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:06 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-47, groupId=ba651f13-cd1a-4133-883e-440a546f7c4e] Revoking previously assigned partitions []
2020-01-07 19:13:06 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-47, groupId=ba651f13-cd1a-4133-883e-440a546f7c4e] (Re-)joining group
2020-01-07 19:13:06 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-47, groupId=ba651f13-cd1a-4133-883e-440a546f7c4e] Successfully joined group with generation 1
2020-01-07 19:13:06 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-47, groupId=ba651f13-cd1a-4133-883e-440a546f7c4e] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:06 INFO  Fetcher:583 - [Consumer clientId=consumer-47, groupId=ba651f13-cd1a-4133-883e-440a546f7c4e] Resetting offset for partition facedetectiontest101-0 to offset 17517.
2020-01-07 19:13:06 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9a210d15-6085-4286-ae44-5841dca37d4f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:06 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:06 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:06 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:06 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-48, groupId=9a210d15-6085-4286-ae44-5841dca37d4f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:06 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-48, groupId=9a210d15-6085-4286-ae44-5841dca37d4f] Revoking previously assigned partitions []
2020-01-07 19:13:06 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-48, groupId=9a210d15-6085-4286-ae44-5841dca37d4f] (Re-)joining group
2020-01-07 19:13:06 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-48, groupId=9a210d15-6085-4286-ae44-5841dca37d4f] Successfully joined group with generation 1
2020-01-07 19:13:06 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-48, groupId=9a210d15-6085-4286-ae44-5841dca37d4f] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:06 INFO  Fetcher:583 - [Consumer clientId=consumer-48, groupId=9a210d15-6085-4286-ae44-5841dca37d4f] Resetting offset for partition facedetectiontest101-0 to offset 17518.
2020-01-07 19:13:06 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = bb787a3d-d931-4f75-a1e9-6e37d99d075e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:06 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:06 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:06 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:06 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-49, groupId=bb787a3d-d931-4f75-a1e9-6e37d99d075e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:06 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-49, groupId=bb787a3d-d931-4f75-a1e9-6e37d99d075e] Revoking previously assigned partitions []
2020-01-07 19:13:06 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-49, groupId=bb787a3d-d931-4f75-a1e9-6e37d99d075e] (Re-)joining group
2020-01-07 19:13:06 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-49, groupId=bb787a3d-d931-4f75-a1e9-6e37d99d075e] Successfully joined group with generation 1
2020-01-07 19:13:06 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-49, groupId=bb787a3d-d931-4f75-a1e9-6e37d99d075e] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:06 INFO  Fetcher:583 - [Consumer clientId=consumer-49, groupId=bb787a3d-d931-4f75-a1e9-6e37d99d075e] Resetting offset for partition facedetectiontest101-0 to offset 17519.
2020-01-07 19:13:06 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2cd078a5-af77-41ca-b230-5a4e3702b502
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:06 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:06 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:06 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:06 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-50, groupId=2cd078a5-af77-41ca-b230-5a4e3702b502] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:06 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-50, groupId=2cd078a5-af77-41ca-b230-5a4e3702b502] Revoking previously assigned partitions []
2020-01-07 19:13:06 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-50, groupId=2cd078a5-af77-41ca-b230-5a4e3702b502] (Re-)joining group
2020-01-07 19:13:06 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-50, groupId=2cd078a5-af77-41ca-b230-5a4e3702b502] Successfully joined group with generation 1
2020-01-07 19:13:06 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-50, groupId=2cd078a5-af77-41ca-b230-5a4e3702b502] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:06 INFO  Fetcher:583 - [Consumer clientId=consumer-50, groupId=2cd078a5-af77-41ca-b230-5a4e3702b502] Resetting offset for partition facedetectiontest101-0 to offset 17520.
2020-01-07 19:13:07 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 85a07310-96df-44b4-9a1f-65adc9fed358
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:07 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:07 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:07 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:07 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-51, groupId=85a07310-96df-44b4-9a1f-65adc9fed358] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:07 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-51, groupId=85a07310-96df-44b4-9a1f-65adc9fed358] Revoking previously assigned partitions []
2020-01-07 19:13:07 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-51, groupId=85a07310-96df-44b4-9a1f-65adc9fed358] (Re-)joining group
2020-01-07 19:13:07 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-51, groupId=85a07310-96df-44b4-9a1f-65adc9fed358] Successfully joined group with generation 1
2020-01-07 19:13:07 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-51, groupId=85a07310-96df-44b4-9a1f-65adc9fed358] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:07 INFO  Fetcher:583 - [Consumer clientId=consumer-51, groupId=85a07310-96df-44b4-9a1f-65adc9fed358] Resetting offset for partition facedetectiontest101-0 to offset 17521.
2020-01-07 19:13:07 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 38be8399-8213-4488-b5bd-aca48cbf374c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:07 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:07 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:07 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:07 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-52, groupId=38be8399-8213-4488-b5bd-aca48cbf374c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:07 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-52, groupId=38be8399-8213-4488-b5bd-aca48cbf374c] Revoking previously assigned partitions []
2020-01-07 19:13:07 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-52, groupId=38be8399-8213-4488-b5bd-aca48cbf374c] (Re-)joining group
2020-01-07 19:13:07 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-52, groupId=38be8399-8213-4488-b5bd-aca48cbf374c] Successfully joined group with generation 1
2020-01-07 19:13:07 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-52, groupId=38be8399-8213-4488-b5bd-aca48cbf374c] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:07 INFO  Fetcher:583 - [Consumer clientId=consumer-52, groupId=38be8399-8213-4488-b5bd-aca48cbf374c] Resetting offset for partition facedetectiontest101-0 to offset 17522.
2020-01-07 19:13:07 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7d896632-5dc4-4718-ac06-0358019774a8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:07 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:07 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:07 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:07 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-53, groupId=7d896632-5dc4-4718-ac06-0358019774a8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:07 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-53, groupId=7d896632-5dc4-4718-ac06-0358019774a8] Revoking previously assigned partitions []
2020-01-07 19:13:07 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-53, groupId=7d896632-5dc4-4718-ac06-0358019774a8] (Re-)joining group
2020-01-07 19:13:07 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-53, groupId=7d896632-5dc4-4718-ac06-0358019774a8] Successfully joined group with generation 1
2020-01-07 19:13:07 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-53, groupId=7d896632-5dc4-4718-ac06-0358019774a8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:07 INFO  Fetcher:583 - [Consumer clientId=consumer-53, groupId=7d896632-5dc4-4718-ac06-0358019774a8] Resetting offset for partition facedetectiontest101-0 to offset 17523.
2020-01-07 19:13:07 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = cd335f43-2e34-4e39-b9b9-ce9ef9a1f83a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:07 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:07 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:07 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:07 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-54, groupId=cd335f43-2e34-4e39-b9b9-ce9ef9a1f83a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:07 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-54, groupId=cd335f43-2e34-4e39-b9b9-ce9ef9a1f83a] Revoking previously assigned partitions []
2020-01-07 19:13:07 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-54, groupId=cd335f43-2e34-4e39-b9b9-ce9ef9a1f83a] (Re-)joining group
2020-01-07 19:13:07 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-54, groupId=cd335f43-2e34-4e39-b9b9-ce9ef9a1f83a] Successfully joined group with generation 1
2020-01-07 19:13:07 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-54, groupId=cd335f43-2e34-4e39-b9b9-ce9ef9a1f83a] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:07 INFO  Fetcher:583 - [Consumer clientId=consumer-54, groupId=cd335f43-2e34-4e39-b9b9-ce9ef9a1f83a] Resetting offset for partition facedetectiontest101-0 to offset 17524.
2020-01-07 19:13:07 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8c919078-584b-4dcd-98be-ace86e345feb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:07 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:07 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:07 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:07 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-55, groupId=8c919078-584b-4dcd-98be-ace86e345feb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:07 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-55, groupId=8c919078-584b-4dcd-98be-ace86e345feb] Revoking previously assigned partitions []
2020-01-07 19:13:07 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-55, groupId=8c919078-584b-4dcd-98be-ace86e345feb] (Re-)joining group
2020-01-07 19:13:07 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-55, groupId=8c919078-584b-4dcd-98be-ace86e345feb] Successfully joined group with generation 1
2020-01-07 19:13:07 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-55, groupId=8c919078-584b-4dcd-98be-ace86e345feb] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:07 INFO  Fetcher:583 - [Consumer clientId=consumer-55, groupId=8c919078-584b-4dcd-98be-ace86e345feb] Resetting offset for partition facedetectiontest101-0 to offset 17525.
2020-01-07 19:13:07 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9c6837bb-af21-4d3e-84d4-c8204098ca37
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:07 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:07 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:07 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:07 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-56, groupId=9c6837bb-af21-4d3e-84d4-c8204098ca37] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:07 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-56, groupId=9c6837bb-af21-4d3e-84d4-c8204098ca37] Revoking previously assigned partitions []
2020-01-07 19:13:07 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-56, groupId=9c6837bb-af21-4d3e-84d4-c8204098ca37] (Re-)joining group
2020-01-07 19:13:07 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-56, groupId=9c6837bb-af21-4d3e-84d4-c8204098ca37] Successfully joined group with generation 1
2020-01-07 19:13:07 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-56, groupId=9c6837bb-af21-4d3e-84d4-c8204098ca37] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:07 INFO  Fetcher:583 - [Consumer clientId=consumer-56, groupId=9c6837bb-af21-4d3e-84d4-c8204098ca37] Resetting offset for partition facedetectiontest101-0 to offset 17526.
2020-01-07 19:13:07 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d9010a3a-46ba-4123-b94e-7803c8323e88
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:07 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:07 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:07 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:07 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-57, groupId=d9010a3a-46ba-4123-b94e-7803c8323e88] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:07 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-57, groupId=d9010a3a-46ba-4123-b94e-7803c8323e88] Revoking previously assigned partitions []
2020-01-07 19:13:07 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-57, groupId=d9010a3a-46ba-4123-b94e-7803c8323e88] (Re-)joining group
2020-01-07 19:13:07 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-57, groupId=d9010a3a-46ba-4123-b94e-7803c8323e88] Successfully joined group with generation 1
2020-01-07 19:13:07 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-57, groupId=d9010a3a-46ba-4123-b94e-7803c8323e88] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:07 INFO  Fetcher:583 - [Consumer clientId=consumer-57, groupId=d9010a3a-46ba-4123-b94e-7803c8323e88] Resetting offset for partition facedetectiontest101-0 to offset 17527.
2020-01-07 19:13:07 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fb3f25f9-dbc4-42ab-9db1-47abea10515d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:07 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:07 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:07 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:07 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-58, groupId=fb3f25f9-dbc4-42ab-9db1-47abea10515d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:07 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-58, groupId=fb3f25f9-dbc4-42ab-9db1-47abea10515d] Revoking previously assigned partitions []
2020-01-07 19:13:07 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-58, groupId=fb3f25f9-dbc4-42ab-9db1-47abea10515d] (Re-)joining group
2020-01-07 19:13:07 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-58, groupId=fb3f25f9-dbc4-42ab-9db1-47abea10515d] Successfully joined group with generation 1
2020-01-07 19:13:07 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-58, groupId=fb3f25f9-dbc4-42ab-9db1-47abea10515d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:07 INFO  Fetcher:583 - [Consumer clientId=consumer-58, groupId=fb3f25f9-dbc4-42ab-9db1-47abea10515d] Resetting offset for partition facedetectiontest101-0 to offset 17528.
2020-01-07 19:13:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7a17bfb6-8663-4114-a345-9ebac36c6495
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-59, groupId=7a17bfb6-8663-4114-a345-9ebac36c6495] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:08 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-59, groupId=7a17bfb6-8663-4114-a345-9ebac36c6495] Revoking previously assigned partitions []
2020-01-07 19:13:08 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-59, groupId=7a17bfb6-8663-4114-a345-9ebac36c6495] (Re-)joining group
2020-01-07 19:13:08 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-59, groupId=7a17bfb6-8663-4114-a345-9ebac36c6495] Successfully joined group with generation 1
2020-01-07 19:13:08 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-59, groupId=7a17bfb6-8663-4114-a345-9ebac36c6495] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:08 INFO  Fetcher:583 - [Consumer clientId=consumer-59, groupId=7a17bfb6-8663-4114-a345-9ebac36c6495] Resetting offset for partition facedetectiontest101-0 to offset 17529.
2020-01-07 19:13:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 85774dea-3804-417b-b584-62239f338042
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-60, groupId=85774dea-3804-417b-b584-62239f338042] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:08 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-60, groupId=85774dea-3804-417b-b584-62239f338042] Revoking previously assigned partitions []
2020-01-07 19:13:08 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-60, groupId=85774dea-3804-417b-b584-62239f338042] (Re-)joining group
2020-01-07 19:13:08 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-60, groupId=85774dea-3804-417b-b584-62239f338042] Successfully joined group with generation 1
2020-01-07 19:13:08 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-60, groupId=85774dea-3804-417b-b584-62239f338042] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:08 INFO  Fetcher:583 - [Consumer clientId=consumer-60, groupId=85774dea-3804-417b-b584-62239f338042] Resetting offset for partition facedetectiontest101-0 to offset 17530.
2020-01-07 19:13:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2f35a17b-1305-4739-b335-3102a55b0a78
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-61, groupId=2f35a17b-1305-4739-b335-3102a55b0a78] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:08 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-61, groupId=2f35a17b-1305-4739-b335-3102a55b0a78] Revoking previously assigned partitions []
2020-01-07 19:13:08 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-61, groupId=2f35a17b-1305-4739-b335-3102a55b0a78] (Re-)joining group
2020-01-07 19:13:08 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-61, groupId=2f35a17b-1305-4739-b335-3102a55b0a78] Successfully joined group with generation 1
2020-01-07 19:13:08 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-61, groupId=2f35a17b-1305-4739-b335-3102a55b0a78] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:08 INFO  Fetcher:583 - [Consumer clientId=consumer-61, groupId=2f35a17b-1305-4739-b335-3102a55b0a78] Resetting offset for partition facedetectiontest101-0 to offset 17532.
2020-01-07 19:13:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4dc57523-d59f-4661-81b6-8c45d0b87424
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-62, groupId=4dc57523-d59f-4661-81b6-8c45d0b87424] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:08 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-62, groupId=4dc57523-d59f-4661-81b6-8c45d0b87424] Revoking previously assigned partitions []
2020-01-07 19:13:08 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-62, groupId=4dc57523-d59f-4661-81b6-8c45d0b87424] (Re-)joining group
2020-01-07 19:13:08 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-62, groupId=4dc57523-d59f-4661-81b6-8c45d0b87424] Successfully joined group with generation 1
2020-01-07 19:13:08 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-62, groupId=4dc57523-d59f-4661-81b6-8c45d0b87424] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:08 INFO  Fetcher:583 - [Consumer clientId=consumer-62, groupId=4dc57523-d59f-4661-81b6-8c45d0b87424] Resetting offset for partition facedetectiontest101-0 to offset 17533.
2020-01-07 19:13:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 62404539-a644-4476-a411-1f888d6c3b61
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-63, groupId=62404539-a644-4476-a411-1f888d6c3b61] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:08 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-63, groupId=62404539-a644-4476-a411-1f888d6c3b61] Revoking previously assigned partitions []
2020-01-07 19:13:08 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-63, groupId=62404539-a644-4476-a411-1f888d6c3b61] (Re-)joining group
2020-01-07 19:13:08 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-63, groupId=62404539-a644-4476-a411-1f888d6c3b61] Successfully joined group with generation 1
2020-01-07 19:13:08 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-63, groupId=62404539-a644-4476-a411-1f888d6c3b61] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:08 INFO  Fetcher:583 - [Consumer clientId=consumer-63, groupId=62404539-a644-4476-a411-1f888d6c3b61] Resetting offset for partition facedetectiontest101-0 to offset 17534.
2020-01-07 19:13:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ab5cddee-5855-4476-b5ed-f58ed9457e6d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-64, groupId=ab5cddee-5855-4476-b5ed-f58ed9457e6d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:08 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-64, groupId=ab5cddee-5855-4476-b5ed-f58ed9457e6d] Revoking previously assigned partitions []
2020-01-07 19:13:08 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-64, groupId=ab5cddee-5855-4476-b5ed-f58ed9457e6d] (Re-)joining group
2020-01-07 19:13:08 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-64, groupId=ab5cddee-5855-4476-b5ed-f58ed9457e6d] Successfully joined group with generation 1
2020-01-07 19:13:08 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-64, groupId=ab5cddee-5855-4476-b5ed-f58ed9457e6d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:08 INFO  Fetcher:583 - [Consumer clientId=consumer-64, groupId=ab5cddee-5855-4476-b5ed-f58ed9457e6d] Resetting offset for partition facedetectiontest101-0 to offset 17535.
2020-01-07 19:13:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d7426393-212c-4a3d-9dd2-c61ed79e89bf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-65, groupId=d7426393-212c-4a3d-9dd2-c61ed79e89bf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:08 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-65, groupId=d7426393-212c-4a3d-9dd2-c61ed79e89bf] Revoking previously assigned partitions []
2020-01-07 19:13:08 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-65, groupId=d7426393-212c-4a3d-9dd2-c61ed79e89bf] (Re-)joining group
2020-01-07 19:13:08 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-65, groupId=d7426393-212c-4a3d-9dd2-c61ed79e89bf] Successfully joined group with generation 1
2020-01-07 19:13:08 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-65, groupId=d7426393-212c-4a3d-9dd2-c61ed79e89bf] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:08 INFO  Fetcher:583 - [Consumer clientId=consumer-65, groupId=d7426393-212c-4a3d-9dd2-c61ed79e89bf] Resetting offset for partition facedetectiontest101-0 to offset 17536.
2020-01-07 19:13:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f148df82-09bf-4c18-a5a8-a096570b1e69
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-66, groupId=f148df82-09bf-4c18-a5a8-a096570b1e69] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:08 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-66, groupId=f148df82-09bf-4c18-a5a8-a096570b1e69] Revoking previously assigned partitions []
2020-01-07 19:13:08 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-66, groupId=f148df82-09bf-4c18-a5a8-a096570b1e69] (Re-)joining group
2020-01-07 19:13:08 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-66, groupId=f148df82-09bf-4c18-a5a8-a096570b1e69] Successfully joined group with generation 1
2020-01-07 19:13:08 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-66, groupId=f148df82-09bf-4c18-a5a8-a096570b1e69] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:08 INFO  Fetcher:583 - [Consumer clientId=consumer-66, groupId=f148df82-09bf-4c18-a5a8-a096570b1e69] Resetting offset for partition facedetectiontest101-0 to offset 17537.
2020-01-07 19:13:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 64891b4f-ea77-4bbe-a6dd-357cf4c0ffdc
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-67, groupId=64891b4f-ea77-4bbe-a6dd-357cf4c0ffdc] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:08 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-67, groupId=64891b4f-ea77-4bbe-a6dd-357cf4c0ffdc] Revoking previously assigned partitions []
2020-01-07 19:13:08 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-67, groupId=64891b4f-ea77-4bbe-a6dd-357cf4c0ffdc] (Re-)joining group
2020-01-07 19:13:08 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-67, groupId=64891b4f-ea77-4bbe-a6dd-357cf4c0ffdc] Successfully joined group with generation 1
2020-01-07 19:13:08 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-67, groupId=64891b4f-ea77-4bbe-a6dd-357cf4c0ffdc] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:08 INFO  Fetcher:583 - [Consumer clientId=consumer-67, groupId=64891b4f-ea77-4bbe-a6dd-357cf4c0ffdc] Resetting offset for partition facedetectiontest101-0 to offset 17538.
2020-01-07 19:13:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 42fef35b-4b4c-43f5-b500-a8888fda8703
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-68, groupId=42fef35b-4b4c-43f5-b500-a8888fda8703] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:08 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-68, groupId=42fef35b-4b4c-43f5-b500-a8888fda8703] Revoking previously assigned partitions []
2020-01-07 19:13:08 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-68, groupId=42fef35b-4b4c-43f5-b500-a8888fda8703] (Re-)joining group
2020-01-07 19:13:08 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-68, groupId=42fef35b-4b4c-43f5-b500-a8888fda8703] Successfully joined group with generation 1
2020-01-07 19:13:08 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-68, groupId=42fef35b-4b4c-43f5-b500-a8888fda8703] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:08 INFO  Fetcher:583 - [Consumer clientId=consumer-68, groupId=42fef35b-4b4c-43f5-b500-a8888fda8703] Resetting offset for partition facedetectiontest101-0 to offset 17539.
2020-01-07 19:13:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2ac96f7e-58fe-4141-8333-8fd65406e7b1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-69, groupId=2ac96f7e-58fe-4141-8333-8fd65406e7b1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:08 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-69, groupId=2ac96f7e-58fe-4141-8333-8fd65406e7b1] Revoking previously assigned partitions []
2020-01-07 19:13:08 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-69, groupId=2ac96f7e-58fe-4141-8333-8fd65406e7b1] (Re-)joining group
2020-01-07 19:13:08 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-69, groupId=2ac96f7e-58fe-4141-8333-8fd65406e7b1] Successfully joined group with generation 1
2020-01-07 19:13:08 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-69, groupId=2ac96f7e-58fe-4141-8333-8fd65406e7b1] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:08 INFO  Fetcher:583 - [Consumer clientId=consumer-69, groupId=2ac96f7e-58fe-4141-8333-8fd65406e7b1] Resetting offset for partition facedetectiontest101-0 to offset 17541.
2020-01-07 19:13:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 944d7965-b5c6-4a19-88f1-5621a01d5678
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-70, groupId=944d7965-b5c6-4a19-88f1-5621a01d5678] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:08 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-70, groupId=944d7965-b5c6-4a19-88f1-5621a01d5678] Revoking previously assigned partitions []
2020-01-07 19:13:08 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-70, groupId=944d7965-b5c6-4a19-88f1-5621a01d5678] (Re-)joining group
2020-01-07 19:13:08 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-70, groupId=944d7965-b5c6-4a19-88f1-5621a01d5678] Successfully joined group with generation 1
2020-01-07 19:13:08 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-70, groupId=944d7965-b5c6-4a19-88f1-5621a01d5678] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:08 INFO  Fetcher:583 - [Consumer clientId=consumer-70, groupId=944d7965-b5c6-4a19-88f1-5621a01d5678] Resetting offset for partition facedetectiontest101-0 to offset 17542.
2020-01-07 19:13:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f9ff0f27-fb44-483c-acbc-a74f74846675
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:09 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:09 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-71, groupId=f9ff0f27-fb44-483c-acbc-a74f74846675] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-71, groupId=f9ff0f27-fb44-483c-acbc-a74f74846675] Revoking previously assigned partitions []
2020-01-07 19:13:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-71, groupId=f9ff0f27-fb44-483c-acbc-a74f74846675] (Re-)joining group
2020-01-07 19:13:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-71, groupId=f9ff0f27-fb44-483c-acbc-a74f74846675] Successfully joined group with generation 1
2020-01-07 19:13:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-71, groupId=f9ff0f27-fb44-483c-acbc-a74f74846675] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:09 INFO  Fetcher:583 - [Consumer clientId=consumer-71, groupId=f9ff0f27-fb44-483c-acbc-a74f74846675] Resetting offset for partition facedetectiontest101-0 to offset 17543.
2020-01-07 19:13:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 41a62e99-ac96-4c9a-b58d-af07b482f596
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:09 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:09 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-72, groupId=41a62e99-ac96-4c9a-b58d-af07b482f596] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-72, groupId=41a62e99-ac96-4c9a-b58d-af07b482f596] Revoking previously assigned partitions []
2020-01-07 19:13:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-72, groupId=41a62e99-ac96-4c9a-b58d-af07b482f596] (Re-)joining group
2020-01-07 19:13:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-72, groupId=41a62e99-ac96-4c9a-b58d-af07b482f596] Successfully joined group with generation 1
2020-01-07 19:13:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-72, groupId=41a62e99-ac96-4c9a-b58d-af07b482f596] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:09 INFO  Fetcher:583 - [Consumer clientId=consumer-72, groupId=41a62e99-ac96-4c9a-b58d-af07b482f596] Resetting offset for partition facedetectiontest101-0 to offset 17544.
2020-01-07 19:13:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a841b7ea-6217-412c-9c2d-37d8f3fbce75
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:09 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:09 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-73, groupId=a841b7ea-6217-412c-9c2d-37d8f3fbce75] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-73, groupId=a841b7ea-6217-412c-9c2d-37d8f3fbce75] Revoking previously assigned partitions []
2020-01-07 19:13:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-73, groupId=a841b7ea-6217-412c-9c2d-37d8f3fbce75] (Re-)joining group
2020-01-07 19:13:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-73, groupId=a841b7ea-6217-412c-9c2d-37d8f3fbce75] Successfully joined group with generation 1
2020-01-07 19:13:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-73, groupId=a841b7ea-6217-412c-9c2d-37d8f3fbce75] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:09 INFO  Fetcher:583 - [Consumer clientId=consumer-73, groupId=a841b7ea-6217-412c-9c2d-37d8f3fbce75] Resetting offset for partition facedetectiontest101-0 to offset 17545.
2020-01-07 19:13:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 17e065e5-6130-4cb0-ba99-b1b8a5d6842c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:09 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:09 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-74, groupId=17e065e5-6130-4cb0-ba99-b1b8a5d6842c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-74, groupId=17e065e5-6130-4cb0-ba99-b1b8a5d6842c] Revoking previously assigned partitions []
2020-01-07 19:13:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-74, groupId=17e065e5-6130-4cb0-ba99-b1b8a5d6842c] (Re-)joining group
2020-01-07 19:13:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-74, groupId=17e065e5-6130-4cb0-ba99-b1b8a5d6842c] Successfully joined group with generation 1
2020-01-07 19:13:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-74, groupId=17e065e5-6130-4cb0-ba99-b1b8a5d6842c] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:09 INFO  Fetcher:583 - [Consumer clientId=consumer-74, groupId=17e065e5-6130-4cb0-ba99-b1b8a5d6842c] Resetting offset for partition facedetectiontest101-0 to offset 17546.
2020-01-07 19:13:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b90a8b92-fe5e-48bd-b28f-354974e5a42f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:09 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:09 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-75, groupId=b90a8b92-fe5e-48bd-b28f-354974e5a42f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-75, groupId=b90a8b92-fe5e-48bd-b28f-354974e5a42f] Revoking previously assigned partitions []
2020-01-07 19:13:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-75, groupId=b90a8b92-fe5e-48bd-b28f-354974e5a42f] (Re-)joining group
2020-01-07 19:13:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-75, groupId=b90a8b92-fe5e-48bd-b28f-354974e5a42f] Successfully joined group with generation 1
2020-01-07 19:13:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-75, groupId=b90a8b92-fe5e-48bd-b28f-354974e5a42f] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:09 INFO  Fetcher:583 - [Consumer clientId=consumer-75, groupId=b90a8b92-fe5e-48bd-b28f-354974e5a42f] Resetting offset for partition facedetectiontest101-0 to offset 17548.
2020-01-07 19:13:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = de0ef18b-b5ff-4270-8d03-f6617ac8c339
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:09 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:09 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-76, groupId=de0ef18b-b5ff-4270-8d03-f6617ac8c339] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-76, groupId=de0ef18b-b5ff-4270-8d03-f6617ac8c339] Revoking previously assigned partitions []
2020-01-07 19:13:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-76, groupId=de0ef18b-b5ff-4270-8d03-f6617ac8c339] (Re-)joining group
2020-01-07 19:13:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-76, groupId=de0ef18b-b5ff-4270-8d03-f6617ac8c339] Successfully joined group with generation 1
2020-01-07 19:13:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-76, groupId=de0ef18b-b5ff-4270-8d03-f6617ac8c339] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:09 INFO  Fetcher:583 - [Consumer clientId=consumer-76, groupId=de0ef18b-b5ff-4270-8d03-f6617ac8c339] Resetting offset for partition facedetectiontest101-0 to offset 17549.
2020-01-07 19:13:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 41cc0341-48fb-4d03-a2c1-c83358d5d714
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:09 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:09 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-77, groupId=41cc0341-48fb-4d03-a2c1-c83358d5d714] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-77, groupId=41cc0341-48fb-4d03-a2c1-c83358d5d714] Revoking previously assigned partitions []
2020-01-07 19:13:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-77, groupId=41cc0341-48fb-4d03-a2c1-c83358d5d714] (Re-)joining group
2020-01-07 19:13:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-77, groupId=41cc0341-48fb-4d03-a2c1-c83358d5d714] Successfully joined group with generation 1
2020-01-07 19:13:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-77, groupId=41cc0341-48fb-4d03-a2c1-c83358d5d714] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:09 INFO  Fetcher:583 - [Consumer clientId=consumer-77, groupId=41cc0341-48fb-4d03-a2c1-c83358d5d714] Resetting offset for partition facedetectiontest101-0 to offset 17551.
2020-01-07 19:13:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1d6e149a-fb75-4e1a-8cdc-d114ff595d1d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:09 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:09 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-78, groupId=1d6e149a-fb75-4e1a-8cdc-d114ff595d1d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-78, groupId=1d6e149a-fb75-4e1a-8cdc-d114ff595d1d] Revoking previously assigned partitions []
2020-01-07 19:13:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-78, groupId=1d6e149a-fb75-4e1a-8cdc-d114ff595d1d] (Re-)joining group
2020-01-07 19:13:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-78, groupId=1d6e149a-fb75-4e1a-8cdc-d114ff595d1d] Successfully joined group with generation 1
2020-01-07 19:13:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-78, groupId=1d6e149a-fb75-4e1a-8cdc-d114ff595d1d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:09 INFO  Fetcher:583 - [Consumer clientId=consumer-78, groupId=1d6e149a-fb75-4e1a-8cdc-d114ff595d1d] Resetting offset for partition facedetectiontest101-0 to offset 17552.
2020-01-07 19:13:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1f65aa2e-8565-4225-8e5a-108cb773cf89
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:09 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:09 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-79, groupId=1f65aa2e-8565-4225-8e5a-108cb773cf89] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-79, groupId=1f65aa2e-8565-4225-8e5a-108cb773cf89] Revoking previously assigned partitions []
2020-01-07 19:13:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-79, groupId=1f65aa2e-8565-4225-8e5a-108cb773cf89] (Re-)joining group
2020-01-07 19:13:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-79, groupId=1f65aa2e-8565-4225-8e5a-108cb773cf89] Successfully joined group with generation 1
2020-01-07 19:13:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-79, groupId=1f65aa2e-8565-4225-8e5a-108cb773cf89] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:09 INFO  Fetcher:583 - [Consumer clientId=consumer-79, groupId=1f65aa2e-8565-4225-8e5a-108cb773cf89] Resetting offset for partition facedetectiontest101-0 to offset 17554.
2020-01-07 19:13:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ea11a288-1ff1-4823-a9ff-89f2ee8b4be8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:09 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:09 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-80, groupId=ea11a288-1ff1-4823-a9ff-89f2ee8b4be8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-80, groupId=ea11a288-1ff1-4823-a9ff-89f2ee8b4be8] Revoking previously assigned partitions []
2020-01-07 19:13:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-80, groupId=ea11a288-1ff1-4823-a9ff-89f2ee8b4be8] (Re-)joining group
2020-01-07 19:13:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-80, groupId=ea11a288-1ff1-4823-a9ff-89f2ee8b4be8] Successfully joined group with generation 1
2020-01-07 19:13:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-80, groupId=ea11a288-1ff1-4823-a9ff-89f2ee8b4be8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:09 INFO  Fetcher:583 - [Consumer clientId=consumer-80, groupId=ea11a288-1ff1-4823-a9ff-89f2ee8b4be8] Resetting offset for partition facedetectiontest101-0 to offset 17555.
2020-01-07 19:13:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9684854d-3f81-45dc-81d9-376c9ba68291
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:09 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:09 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-81, groupId=9684854d-3f81-45dc-81d9-376c9ba68291] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-81, groupId=9684854d-3f81-45dc-81d9-376c9ba68291] Revoking previously assigned partitions []
2020-01-07 19:13:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-81, groupId=9684854d-3f81-45dc-81d9-376c9ba68291] (Re-)joining group
2020-01-07 19:13:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-81, groupId=9684854d-3f81-45dc-81d9-376c9ba68291] Successfully joined group with generation 1
2020-01-07 19:13:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-81, groupId=9684854d-3f81-45dc-81d9-376c9ba68291] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:10 INFO  Fetcher:583 - [Consumer clientId=consumer-81, groupId=9684854d-3f81-45dc-81d9-376c9ba68291] Resetting offset for partition facedetectiontest101-0 to offset 17556.
2020-01-07 19:13:10 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 58676cce-2be8-473d-b2c3-de6fcffb5153
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:10 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:10 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:10 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:10 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-82, groupId=58676cce-2be8-473d-b2c3-de6fcffb5153] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:10 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-82, groupId=58676cce-2be8-473d-b2c3-de6fcffb5153] Revoking previously assigned partitions []
2020-01-07 19:13:10 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-82, groupId=58676cce-2be8-473d-b2c3-de6fcffb5153] (Re-)joining group
2020-01-07 19:13:10 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-82, groupId=58676cce-2be8-473d-b2c3-de6fcffb5153] Successfully joined group with generation 1
2020-01-07 19:13:10 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-82, groupId=58676cce-2be8-473d-b2c3-de6fcffb5153] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:10 INFO  Fetcher:583 - [Consumer clientId=consumer-82, groupId=58676cce-2be8-473d-b2c3-de6fcffb5153] Resetting offset for partition facedetectiontest101-0 to offset 17557.
2020-01-07 19:13:10 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 77e451b0-bdd9-49a4-9af1-b033d685b28d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:10 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:10 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:10 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:10 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-83, groupId=77e451b0-bdd9-49a4-9af1-b033d685b28d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:10 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-83, groupId=77e451b0-bdd9-49a4-9af1-b033d685b28d] Revoking previously assigned partitions []
2020-01-07 19:13:10 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-83, groupId=77e451b0-bdd9-49a4-9af1-b033d685b28d] (Re-)joining group
2020-01-07 19:13:10 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-83, groupId=77e451b0-bdd9-49a4-9af1-b033d685b28d] Successfully joined group with generation 1
2020-01-07 19:13:10 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-83, groupId=77e451b0-bdd9-49a4-9af1-b033d685b28d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:10 INFO  Fetcher:583 - [Consumer clientId=consumer-83, groupId=77e451b0-bdd9-49a4-9af1-b033d685b28d] Resetting offset for partition facedetectiontest101-0 to offset 17558.
2020-01-07 19:13:10 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1d497cdb-19c3-48c8-9f7f-845eccfc530f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:10 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:10 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:10 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:10 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-84, groupId=1d497cdb-19c3-48c8-9f7f-845eccfc530f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:10 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-84, groupId=1d497cdb-19c3-48c8-9f7f-845eccfc530f] Revoking previously assigned partitions []
2020-01-07 19:13:10 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-84, groupId=1d497cdb-19c3-48c8-9f7f-845eccfc530f] (Re-)joining group
2020-01-07 19:13:10 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-84, groupId=1d497cdb-19c3-48c8-9f7f-845eccfc530f] Successfully joined group with generation 1
2020-01-07 19:13:10 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-84, groupId=1d497cdb-19c3-48c8-9f7f-845eccfc530f] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:10 INFO  Fetcher:583 - [Consumer clientId=consumer-84, groupId=1d497cdb-19c3-48c8-9f7f-845eccfc530f] Resetting offset for partition facedetectiontest101-0 to offset 17559.
2020-01-07 19:13:10 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0b8f1afb-aaac-445b-904f-4a7f8b270ede
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:10 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:10 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:10 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:10 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-85, groupId=0b8f1afb-aaac-445b-904f-4a7f8b270ede] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:10 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-85, groupId=0b8f1afb-aaac-445b-904f-4a7f8b270ede] Revoking previously assigned partitions []
2020-01-07 19:13:10 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-85, groupId=0b8f1afb-aaac-445b-904f-4a7f8b270ede] (Re-)joining group
2020-01-07 19:13:10 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-85, groupId=0b8f1afb-aaac-445b-904f-4a7f8b270ede] Successfully joined group with generation 1
2020-01-07 19:13:10 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-85, groupId=0b8f1afb-aaac-445b-904f-4a7f8b270ede] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:10 INFO  Fetcher:583 - [Consumer clientId=consumer-85, groupId=0b8f1afb-aaac-445b-904f-4a7f8b270ede] Resetting offset for partition facedetectiontest101-0 to offset 17560.
2020-01-07 19:13:10 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e5b8bb9e-286d-47fe-8f75-66fd373587f5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:10 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:10 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:10 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:10 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-86, groupId=e5b8bb9e-286d-47fe-8f75-66fd373587f5] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:10 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-86, groupId=e5b8bb9e-286d-47fe-8f75-66fd373587f5] Revoking previously assigned partitions []
2020-01-07 19:13:10 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-86, groupId=e5b8bb9e-286d-47fe-8f75-66fd373587f5] (Re-)joining group
2020-01-07 19:13:10 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-86, groupId=e5b8bb9e-286d-47fe-8f75-66fd373587f5] Successfully joined group with generation 1
2020-01-07 19:13:10 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-86, groupId=e5b8bb9e-286d-47fe-8f75-66fd373587f5] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:10 INFO  Fetcher:583 - [Consumer clientId=consumer-86, groupId=e5b8bb9e-286d-47fe-8f75-66fd373587f5] Resetting offset for partition facedetectiontest101-0 to offset 17561.
2020-01-07 19:13:10 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4a16af9b-35da-4f79-9301-81a95ca3aad8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:10 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:10 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:10 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:10 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-87, groupId=4a16af9b-35da-4f79-9301-81a95ca3aad8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:10 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-87, groupId=4a16af9b-35da-4f79-9301-81a95ca3aad8] Revoking previously assigned partitions []
2020-01-07 19:13:10 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-87, groupId=4a16af9b-35da-4f79-9301-81a95ca3aad8] (Re-)joining group
2020-01-07 19:13:10 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-87, groupId=4a16af9b-35da-4f79-9301-81a95ca3aad8] Successfully joined group with generation 1
2020-01-07 19:13:10 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-87, groupId=4a16af9b-35da-4f79-9301-81a95ca3aad8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:10 INFO  Fetcher:583 - [Consumer clientId=consumer-87, groupId=4a16af9b-35da-4f79-9301-81a95ca3aad8] Resetting offset for partition facedetectiontest101-0 to offset 17562.
2020-01-07 19:13:10 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = def9761e-576f-492e-b7a6-8fa4a4d3b98e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:10 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:10 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:10 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:10 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-88, groupId=def9761e-576f-492e-b7a6-8fa4a4d3b98e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:10 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-88, groupId=def9761e-576f-492e-b7a6-8fa4a4d3b98e] Revoking previously assigned partitions []
2020-01-07 19:13:10 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-88, groupId=def9761e-576f-492e-b7a6-8fa4a4d3b98e] (Re-)joining group
2020-01-07 19:13:10 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-88, groupId=def9761e-576f-492e-b7a6-8fa4a4d3b98e] Successfully joined group with generation 1
2020-01-07 19:13:10 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-88, groupId=def9761e-576f-492e-b7a6-8fa4a4d3b98e] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:10 INFO  Fetcher:583 - [Consumer clientId=consumer-88, groupId=def9761e-576f-492e-b7a6-8fa4a4d3b98e] Resetting offset for partition facedetectiontest101-0 to offset 17564.
2020-01-07 19:13:10 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = abeadc0a-9a25-4619-9669-18335c70a64a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:10 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:10 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:10 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:10 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-89, groupId=abeadc0a-9a25-4619-9669-18335c70a64a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:10 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-89, groupId=abeadc0a-9a25-4619-9669-18335c70a64a] Revoking previously assigned partitions []
2020-01-07 19:13:10 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-89, groupId=abeadc0a-9a25-4619-9669-18335c70a64a] (Re-)joining group
2020-01-07 19:13:10 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-89, groupId=abeadc0a-9a25-4619-9669-18335c70a64a] Successfully joined group with generation 1
2020-01-07 19:13:10 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-89, groupId=abeadc0a-9a25-4619-9669-18335c70a64a] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:10 INFO  Fetcher:583 - [Consumer clientId=consumer-89, groupId=abeadc0a-9a25-4619-9669-18335c70a64a] Resetting offset for partition facedetectiontest101-0 to offset 17565.
2020-01-07 19:13:11 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d0939761-b6d8-4bb2-8a0d-128a2b519489
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:11 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:11 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:11 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:11 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-90, groupId=d0939761-b6d8-4bb2-8a0d-128a2b519489] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:11 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-90, groupId=d0939761-b6d8-4bb2-8a0d-128a2b519489] Revoking previously assigned partitions []
2020-01-07 19:13:11 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-90, groupId=d0939761-b6d8-4bb2-8a0d-128a2b519489] (Re-)joining group
2020-01-07 19:13:11 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-90, groupId=d0939761-b6d8-4bb2-8a0d-128a2b519489] Successfully joined group with generation 1
2020-01-07 19:13:11 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-90, groupId=d0939761-b6d8-4bb2-8a0d-128a2b519489] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:11 INFO  Fetcher:583 - [Consumer clientId=consumer-90, groupId=d0939761-b6d8-4bb2-8a0d-128a2b519489] Resetting offset for partition facedetectiontest101-0 to offset 17567.
2020-01-07 19:13:11 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6c7620bd-3d04-4933-a600-26408c6d9e3c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:11 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:11 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:11 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:11 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-91, groupId=6c7620bd-3d04-4933-a600-26408c6d9e3c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:11 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-91, groupId=6c7620bd-3d04-4933-a600-26408c6d9e3c] Revoking previously assigned partitions []
2020-01-07 19:13:11 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-91, groupId=6c7620bd-3d04-4933-a600-26408c6d9e3c] (Re-)joining group
2020-01-07 19:13:11 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-91, groupId=6c7620bd-3d04-4933-a600-26408c6d9e3c] Successfully joined group with generation 1
2020-01-07 19:13:11 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-91, groupId=6c7620bd-3d04-4933-a600-26408c6d9e3c] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:11 INFO  Fetcher:583 - [Consumer clientId=consumer-91, groupId=6c7620bd-3d04-4933-a600-26408c6d9e3c] Resetting offset for partition facedetectiontest101-0 to offset 17568.
2020-01-07 19:13:11 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 564261c5-d97c-483a-98ba-90071e2bf5a5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:11 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:11 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:11 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:11 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-92, groupId=564261c5-d97c-483a-98ba-90071e2bf5a5] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:11 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-92, groupId=564261c5-d97c-483a-98ba-90071e2bf5a5] Revoking previously assigned partitions []
2020-01-07 19:13:11 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-92, groupId=564261c5-d97c-483a-98ba-90071e2bf5a5] (Re-)joining group
2020-01-07 19:13:11 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-92, groupId=564261c5-d97c-483a-98ba-90071e2bf5a5] Successfully joined group with generation 1
2020-01-07 19:13:11 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-92, groupId=564261c5-d97c-483a-98ba-90071e2bf5a5] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:11 INFO  Fetcher:583 - [Consumer clientId=consumer-92, groupId=564261c5-d97c-483a-98ba-90071e2bf5a5] Resetting offset for partition facedetectiontest101-0 to offset 17569.
2020-01-07 19:13:11 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d95d6dfb-8884-4bb8-b11c-4808a3d6c4bb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:11 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:11 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:11 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:11 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-93, groupId=d95d6dfb-8884-4bb8-b11c-4808a3d6c4bb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:11 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-93, groupId=d95d6dfb-8884-4bb8-b11c-4808a3d6c4bb] Revoking previously assigned partitions []
2020-01-07 19:13:11 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-93, groupId=d95d6dfb-8884-4bb8-b11c-4808a3d6c4bb] (Re-)joining group
2020-01-07 19:13:11 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-93, groupId=d95d6dfb-8884-4bb8-b11c-4808a3d6c4bb] Successfully joined group with generation 1
2020-01-07 19:13:11 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-93, groupId=d95d6dfb-8884-4bb8-b11c-4808a3d6c4bb] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:11 INFO  Fetcher:583 - [Consumer clientId=consumer-93, groupId=d95d6dfb-8884-4bb8-b11c-4808a3d6c4bb] Resetting offset for partition facedetectiontest101-0 to offset 17570.
2020-01-07 19:13:11 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9354028e-2427-4fde-815e-3bc69f548987
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:11 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:11 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:11 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:11 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-94, groupId=9354028e-2427-4fde-815e-3bc69f548987] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:11 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-94, groupId=9354028e-2427-4fde-815e-3bc69f548987] Revoking previously assigned partitions []
2020-01-07 19:13:11 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-94, groupId=9354028e-2427-4fde-815e-3bc69f548987] (Re-)joining group
2020-01-07 19:13:11 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-94, groupId=9354028e-2427-4fde-815e-3bc69f548987] Successfully joined group with generation 1
2020-01-07 19:13:11 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-94, groupId=9354028e-2427-4fde-815e-3bc69f548987] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:11 INFO  Fetcher:583 - [Consumer clientId=consumer-94, groupId=9354028e-2427-4fde-815e-3bc69f548987] Resetting offset for partition facedetectiontest101-0 to offset 17571.
2020-01-07 19:13:11 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 03409a67-ab77-4d92-8b69-0163469fc20f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:11 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:11 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:11 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:11 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-95, groupId=03409a67-ab77-4d92-8b69-0163469fc20f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:11 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-95, groupId=03409a67-ab77-4d92-8b69-0163469fc20f] Revoking previously assigned partitions []
2020-01-07 19:13:11 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-95, groupId=03409a67-ab77-4d92-8b69-0163469fc20f] (Re-)joining group
2020-01-07 19:13:11 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-95, groupId=03409a67-ab77-4d92-8b69-0163469fc20f] Successfully joined group with generation 1
2020-01-07 19:13:11 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-95, groupId=03409a67-ab77-4d92-8b69-0163469fc20f] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:11 INFO  Fetcher:583 - [Consumer clientId=consumer-95, groupId=03409a67-ab77-4d92-8b69-0163469fc20f] Resetting offset for partition facedetectiontest101-0 to offset 17572.
2020-01-07 19:13:11 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0c2b51df-1fb1-4856-b388-841bc7a3f61a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:11 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:11 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:11 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:11 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-96, groupId=0c2b51df-1fb1-4856-b388-841bc7a3f61a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:11 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-96, groupId=0c2b51df-1fb1-4856-b388-841bc7a3f61a] Revoking previously assigned partitions []
2020-01-07 19:13:11 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-96, groupId=0c2b51df-1fb1-4856-b388-841bc7a3f61a] (Re-)joining group
2020-01-07 19:13:11 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-96, groupId=0c2b51df-1fb1-4856-b388-841bc7a3f61a] Successfully joined group with generation 1
2020-01-07 19:13:11 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-96, groupId=0c2b51df-1fb1-4856-b388-841bc7a3f61a] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:11 INFO  Fetcher:583 - [Consumer clientId=consumer-96, groupId=0c2b51df-1fb1-4856-b388-841bc7a3f61a] Resetting offset for partition facedetectiontest101-0 to offset 17573.
2020-01-07 19:13:12 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = acb7e1b4-07fa-4d09-81ef-ec08751901e3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:12 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:12 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:12 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:12 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-97, groupId=acb7e1b4-07fa-4d09-81ef-ec08751901e3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:12 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-97, groupId=acb7e1b4-07fa-4d09-81ef-ec08751901e3] Revoking previously assigned partitions []
2020-01-07 19:13:12 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-97, groupId=acb7e1b4-07fa-4d09-81ef-ec08751901e3] (Re-)joining group
2020-01-07 19:13:12 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-97, groupId=acb7e1b4-07fa-4d09-81ef-ec08751901e3] Successfully joined group with generation 1
2020-01-07 19:13:12 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-97, groupId=acb7e1b4-07fa-4d09-81ef-ec08751901e3] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:12 INFO  Fetcher:583 - [Consumer clientId=consumer-97, groupId=acb7e1b4-07fa-4d09-81ef-ec08751901e3] Resetting offset for partition facedetectiontest101-0 to offset 17574.
2020-01-07 19:13:12 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dd39b71e-fa8f-4f29-9a49-70bad533c5fa
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:12 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:12 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:12 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:12 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-98, groupId=dd39b71e-fa8f-4f29-9a49-70bad533c5fa] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:12 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-98, groupId=dd39b71e-fa8f-4f29-9a49-70bad533c5fa] Revoking previously assigned partitions []
2020-01-07 19:13:12 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-98, groupId=dd39b71e-fa8f-4f29-9a49-70bad533c5fa] (Re-)joining group
2020-01-07 19:13:12 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-98, groupId=dd39b71e-fa8f-4f29-9a49-70bad533c5fa] Successfully joined group with generation 1
2020-01-07 19:13:12 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-98, groupId=dd39b71e-fa8f-4f29-9a49-70bad533c5fa] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:12 INFO  Fetcher:583 - [Consumer clientId=consumer-98, groupId=dd39b71e-fa8f-4f29-9a49-70bad533c5fa] Resetting offset for partition facedetectiontest101-0 to offset 17575.
2020-01-07 19:13:12 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1cab4536-0743-42be-bb23-38951e9f6b41
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:12 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:12 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:12 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:12 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-99, groupId=1cab4536-0743-42be-bb23-38951e9f6b41] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:12 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-99, groupId=1cab4536-0743-42be-bb23-38951e9f6b41] Revoking previously assigned partitions []
2020-01-07 19:13:12 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-99, groupId=1cab4536-0743-42be-bb23-38951e9f6b41] (Re-)joining group
2020-01-07 19:13:12 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-99, groupId=1cab4536-0743-42be-bb23-38951e9f6b41] Successfully joined group with generation 1
2020-01-07 19:13:12 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-99, groupId=1cab4536-0743-42be-bb23-38951e9f6b41] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:12 INFO  Fetcher:583 - [Consumer clientId=consumer-99, groupId=1cab4536-0743-42be-bb23-38951e9f6b41] Resetting offset for partition facedetectiontest101-0 to offset 17576.
2020-01-07 19:13:12 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2bb7cc07-5eac-4a57-8fb8-178beb208425
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:12 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:12 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:12 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:12 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-100, groupId=2bb7cc07-5eac-4a57-8fb8-178beb208425] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:12 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-100, groupId=2bb7cc07-5eac-4a57-8fb8-178beb208425] Revoking previously assigned partitions []
2020-01-07 19:13:12 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-100, groupId=2bb7cc07-5eac-4a57-8fb8-178beb208425] (Re-)joining group
2020-01-07 19:13:12 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-100, groupId=2bb7cc07-5eac-4a57-8fb8-178beb208425] Successfully joined group with generation 1
2020-01-07 19:13:12 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-100, groupId=2bb7cc07-5eac-4a57-8fb8-178beb208425] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:12 INFO  Fetcher:583 - [Consumer clientId=consumer-100, groupId=2bb7cc07-5eac-4a57-8fb8-178beb208425] Resetting offset for partition facedetectiontest101-0 to offset 17577.
2020-01-07 19:13:12 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a4cfb73f-72a2-4889-b08a-0995da25d8be
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:12 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:12 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:12 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:12 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-101, groupId=a4cfb73f-72a2-4889-b08a-0995da25d8be] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:12 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-101, groupId=a4cfb73f-72a2-4889-b08a-0995da25d8be] Revoking previously assigned partitions []
2020-01-07 19:13:12 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-101, groupId=a4cfb73f-72a2-4889-b08a-0995da25d8be] (Re-)joining group
2020-01-07 19:13:12 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-101, groupId=a4cfb73f-72a2-4889-b08a-0995da25d8be] Successfully joined group with generation 1
2020-01-07 19:13:12 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-101, groupId=a4cfb73f-72a2-4889-b08a-0995da25d8be] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:12 INFO  Fetcher:583 - [Consumer clientId=consumer-101, groupId=a4cfb73f-72a2-4889-b08a-0995da25d8be] Resetting offset for partition facedetectiontest101-0 to offset 17579.
2020-01-07 19:13:12 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ee325fd7-2a98-4945-bb59-5d2f2a88f85b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:12 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:12 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:12 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:12 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-102, groupId=ee325fd7-2a98-4945-bb59-5d2f2a88f85b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:12 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-102, groupId=ee325fd7-2a98-4945-bb59-5d2f2a88f85b] Revoking previously assigned partitions []
2020-01-07 19:13:12 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-102, groupId=ee325fd7-2a98-4945-bb59-5d2f2a88f85b] (Re-)joining group
2020-01-07 19:13:12 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-102, groupId=ee325fd7-2a98-4945-bb59-5d2f2a88f85b] Successfully joined group with generation 1
2020-01-07 19:13:12 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-102, groupId=ee325fd7-2a98-4945-bb59-5d2f2a88f85b] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:12 INFO  Fetcher:583 - [Consumer clientId=consumer-102, groupId=ee325fd7-2a98-4945-bb59-5d2f2a88f85b] Resetting offset for partition facedetectiontest101-0 to offset 17580.
2020-01-07 19:13:12 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7294712c-4ab3-4b79-99ac-8184f8edfec8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:12 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:12 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:12 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:12 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-103, groupId=7294712c-4ab3-4b79-99ac-8184f8edfec8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:12 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-103, groupId=7294712c-4ab3-4b79-99ac-8184f8edfec8] Revoking previously assigned partitions []
2020-01-07 19:13:12 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-103, groupId=7294712c-4ab3-4b79-99ac-8184f8edfec8] (Re-)joining group
2020-01-07 19:13:12 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-103, groupId=7294712c-4ab3-4b79-99ac-8184f8edfec8] Successfully joined group with generation 1
2020-01-07 19:13:12 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-103, groupId=7294712c-4ab3-4b79-99ac-8184f8edfec8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:12 INFO  Fetcher:583 - [Consumer clientId=consumer-103, groupId=7294712c-4ab3-4b79-99ac-8184f8edfec8] Resetting offset for partition facedetectiontest101-0 to offset 17581.
2020-01-07 19:13:12 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8671b289-7056-49a7-bd67-4b0d2eb50efc
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:12 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:12 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:12 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:12 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-104, groupId=8671b289-7056-49a7-bd67-4b0d2eb50efc] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:12 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-104, groupId=8671b289-7056-49a7-bd67-4b0d2eb50efc] Revoking previously assigned partitions []
2020-01-07 19:13:12 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-104, groupId=8671b289-7056-49a7-bd67-4b0d2eb50efc] (Re-)joining group
2020-01-07 19:13:12 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-104, groupId=8671b289-7056-49a7-bd67-4b0d2eb50efc] Successfully joined group with generation 1
2020-01-07 19:13:12 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-104, groupId=8671b289-7056-49a7-bd67-4b0d2eb50efc] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:12 INFO  Fetcher:583 - [Consumer clientId=consumer-104, groupId=8671b289-7056-49a7-bd67-4b0d2eb50efc] Resetting offset for partition facedetectiontest101-0 to offset 17582.
2020-01-07 19:13:12 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2a24b26e-fb33-411c-bd0a-590959add335
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:12 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:12 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:12 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:12 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-105, groupId=2a24b26e-fb33-411c-bd0a-590959add335] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:12 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-105, groupId=2a24b26e-fb33-411c-bd0a-590959add335] Revoking previously assigned partitions []
2020-01-07 19:13:12 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-105, groupId=2a24b26e-fb33-411c-bd0a-590959add335] (Re-)joining group
2020-01-07 19:13:12 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-105, groupId=2a24b26e-fb33-411c-bd0a-590959add335] Successfully joined group with generation 1
2020-01-07 19:13:12 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-105, groupId=2a24b26e-fb33-411c-bd0a-590959add335] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:12 INFO  Fetcher:583 - [Consumer clientId=consumer-105, groupId=2a24b26e-fb33-411c-bd0a-590959add335] Resetting offset for partition facedetectiontest101-0 to offset 17584.
2020-01-07 19:13:12 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9e0dbaf2-353c-4cce-a355-1f65980cd3b4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:12 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:12 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:12 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:12 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-106, groupId=9e0dbaf2-353c-4cce-a355-1f65980cd3b4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:12 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-106, groupId=9e0dbaf2-353c-4cce-a355-1f65980cd3b4] Revoking previously assigned partitions []
2020-01-07 19:13:12 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-106, groupId=9e0dbaf2-353c-4cce-a355-1f65980cd3b4] (Re-)joining group
2020-01-07 19:13:12 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-106, groupId=9e0dbaf2-353c-4cce-a355-1f65980cd3b4] Successfully joined group with generation 1
2020-01-07 19:13:12 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-106, groupId=9e0dbaf2-353c-4cce-a355-1f65980cd3b4] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:12 INFO  Fetcher:583 - [Consumer clientId=consumer-106, groupId=9e0dbaf2-353c-4cce-a355-1f65980cd3b4] Resetting offset for partition facedetectiontest101-0 to offset 17585.
2020-01-07 19:13:12 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 642bc4a4-81f2-4c16-a39f-eceb40019da2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:12 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:12 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:12 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:12 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-107, groupId=642bc4a4-81f2-4c16-a39f-eceb40019da2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:12 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-107, groupId=642bc4a4-81f2-4c16-a39f-eceb40019da2] Revoking previously assigned partitions []
2020-01-07 19:13:12 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-107, groupId=642bc4a4-81f2-4c16-a39f-eceb40019da2] (Re-)joining group
2020-01-07 19:13:12 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-107, groupId=642bc4a4-81f2-4c16-a39f-eceb40019da2] Successfully joined group with generation 1
2020-01-07 19:13:12 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-107, groupId=642bc4a4-81f2-4c16-a39f-eceb40019da2] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:12 INFO  Fetcher:583 - [Consumer clientId=consumer-107, groupId=642bc4a4-81f2-4c16-a39f-eceb40019da2] Resetting offset for partition facedetectiontest101-0 to offset 17586.
2020-01-07 19:13:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 89bd3b32-137d-47a1-8f2b-26ef735e7bae
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:13 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-108, groupId=89bd3b32-137d-47a1-8f2b-26ef735e7bae] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-108, groupId=89bd3b32-137d-47a1-8f2b-26ef735e7bae] Revoking previously assigned partitions []
2020-01-07 19:13:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-108, groupId=89bd3b32-137d-47a1-8f2b-26ef735e7bae] (Re-)joining group
2020-01-07 19:13:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-108, groupId=89bd3b32-137d-47a1-8f2b-26ef735e7bae] Successfully joined group with generation 1
2020-01-07 19:13:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-108, groupId=89bd3b32-137d-47a1-8f2b-26ef735e7bae] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:13 INFO  Fetcher:583 - [Consumer clientId=consumer-108, groupId=89bd3b32-137d-47a1-8f2b-26ef735e7bae] Resetting offset for partition facedetectiontest101-0 to offset 17587.
2020-01-07 19:13:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = af1cfb16-c80d-4499-8f75-b4b0740be1f7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:13 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-109, groupId=af1cfb16-c80d-4499-8f75-b4b0740be1f7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-109, groupId=af1cfb16-c80d-4499-8f75-b4b0740be1f7] Revoking previously assigned partitions []
2020-01-07 19:13:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-109, groupId=af1cfb16-c80d-4499-8f75-b4b0740be1f7] (Re-)joining group
2020-01-07 19:13:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-109, groupId=af1cfb16-c80d-4499-8f75-b4b0740be1f7] Successfully joined group with generation 1
2020-01-07 19:13:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-109, groupId=af1cfb16-c80d-4499-8f75-b4b0740be1f7] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:13 INFO  Fetcher:583 - [Consumer clientId=consumer-109, groupId=af1cfb16-c80d-4499-8f75-b4b0740be1f7] Resetting offset for partition facedetectiontest101-0 to offset 17588.
2020-01-07 19:13:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 48f9726d-a21b-4298-a954-05def9958fb8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:13 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-110, groupId=48f9726d-a21b-4298-a954-05def9958fb8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-110, groupId=48f9726d-a21b-4298-a954-05def9958fb8] Revoking previously assigned partitions []
2020-01-07 19:13:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-110, groupId=48f9726d-a21b-4298-a954-05def9958fb8] (Re-)joining group
2020-01-07 19:13:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-110, groupId=48f9726d-a21b-4298-a954-05def9958fb8] Successfully joined group with generation 1
2020-01-07 19:13:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-110, groupId=48f9726d-a21b-4298-a954-05def9958fb8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:13 INFO  Fetcher:583 - [Consumer clientId=consumer-110, groupId=48f9726d-a21b-4298-a954-05def9958fb8] Resetting offset for partition facedetectiontest101-0 to offset 17589.
2020-01-07 19:13:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 85426534-b5d9-4cc8-a212-9762395cfc8c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:13 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-111, groupId=85426534-b5d9-4cc8-a212-9762395cfc8c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-111, groupId=85426534-b5d9-4cc8-a212-9762395cfc8c] Revoking previously assigned partitions []
2020-01-07 19:13:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-111, groupId=85426534-b5d9-4cc8-a212-9762395cfc8c] (Re-)joining group
2020-01-07 19:13:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-111, groupId=85426534-b5d9-4cc8-a212-9762395cfc8c] Successfully joined group with generation 1
2020-01-07 19:13:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-111, groupId=85426534-b5d9-4cc8-a212-9762395cfc8c] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:13 INFO  Fetcher:583 - [Consumer clientId=consumer-111, groupId=85426534-b5d9-4cc8-a212-9762395cfc8c] Resetting offset for partition facedetectiontest101-0 to offset 17590.
2020-01-07 19:13:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2d0987dc-1f59-4a0a-a473-a9986fdf8337
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:13 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-112, groupId=2d0987dc-1f59-4a0a-a473-a9986fdf8337] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-112, groupId=2d0987dc-1f59-4a0a-a473-a9986fdf8337] Revoking previously assigned partitions []
2020-01-07 19:13:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-112, groupId=2d0987dc-1f59-4a0a-a473-a9986fdf8337] (Re-)joining group
2020-01-07 19:13:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-112, groupId=2d0987dc-1f59-4a0a-a473-a9986fdf8337] Successfully joined group with generation 1
2020-01-07 19:13:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-112, groupId=2d0987dc-1f59-4a0a-a473-a9986fdf8337] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:13 INFO  Fetcher:583 - [Consumer clientId=consumer-112, groupId=2d0987dc-1f59-4a0a-a473-a9986fdf8337] Resetting offset for partition facedetectiontest101-0 to offset 17591.
2020-01-07 19:13:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4bc41b5a-843a-43bc-8b36-b56fb21f0c7a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:13 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-113, groupId=4bc41b5a-843a-43bc-8b36-b56fb21f0c7a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-113, groupId=4bc41b5a-843a-43bc-8b36-b56fb21f0c7a] Revoking previously assigned partitions []
2020-01-07 19:13:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-113, groupId=4bc41b5a-843a-43bc-8b36-b56fb21f0c7a] (Re-)joining group
2020-01-07 19:13:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-113, groupId=4bc41b5a-843a-43bc-8b36-b56fb21f0c7a] Successfully joined group with generation 1
2020-01-07 19:13:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-113, groupId=4bc41b5a-843a-43bc-8b36-b56fb21f0c7a] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:13 INFO  Fetcher:583 - [Consumer clientId=consumer-113, groupId=4bc41b5a-843a-43bc-8b36-b56fb21f0c7a] Resetting offset for partition facedetectiontest101-0 to offset 17592.
2020-01-07 19:13:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4290d0b5-5162-41e2-9d74-9be60ed638f7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:13 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-114, groupId=4290d0b5-5162-41e2-9d74-9be60ed638f7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-114, groupId=4290d0b5-5162-41e2-9d74-9be60ed638f7] Revoking previously assigned partitions []
2020-01-07 19:13:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-114, groupId=4290d0b5-5162-41e2-9d74-9be60ed638f7] (Re-)joining group
2020-01-07 19:13:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-114, groupId=4290d0b5-5162-41e2-9d74-9be60ed638f7] Successfully joined group with generation 1
2020-01-07 19:13:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-114, groupId=4290d0b5-5162-41e2-9d74-9be60ed638f7] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:13 INFO  Fetcher:583 - [Consumer clientId=consumer-114, groupId=4290d0b5-5162-41e2-9d74-9be60ed638f7] Resetting offset for partition facedetectiontest101-0 to offset 17593.
2020-01-07 19:13:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5be72fa9-5bba-47e5-9622-7e04168c6f2f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:13 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-115, groupId=5be72fa9-5bba-47e5-9622-7e04168c6f2f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-115, groupId=5be72fa9-5bba-47e5-9622-7e04168c6f2f] Revoking previously assigned partitions []
2020-01-07 19:13:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-115, groupId=5be72fa9-5bba-47e5-9622-7e04168c6f2f] (Re-)joining group
2020-01-07 19:13:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-115, groupId=5be72fa9-5bba-47e5-9622-7e04168c6f2f] Successfully joined group with generation 1
2020-01-07 19:13:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-115, groupId=5be72fa9-5bba-47e5-9622-7e04168c6f2f] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:13 INFO  Fetcher:583 - [Consumer clientId=consumer-115, groupId=5be72fa9-5bba-47e5-9622-7e04168c6f2f] Resetting offset for partition facedetectiontest101-0 to offset 17594.
2020-01-07 19:13:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9fa7641f-025e-414f-b371-7d3d79fad9ec
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:13 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-116, groupId=9fa7641f-025e-414f-b371-7d3d79fad9ec] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-116, groupId=9fa7641f-025e-414f-b371-7d3d79fad9ec] Revoking previously assigned partitions []
2020-01-07 19:13:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-116, groupId=9fa7641f-025e-414f-b371-7d3d79fad9ec] (Re-)joining group
2020-01-07 19:13:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-116, groupId=9fa7641f-025e-414f-b371-7d3d79fad9ec] Successfully joined group with generation 1
2020-01-07 19:13:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-116, groupId=9fa7641f-025e-414f-b371-7d3d79fad9ec] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:13 INFO  Fetcher:583 - [Consumer clientId=consumer-116, groupId=9fa7641f-025e-414f-b371-7d3d79fad9ec] Resetting offset for partition facedetectiontest101-0 to offset 17595.
2020-01-07 19:13:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 792bffcc-23d3-4d92-bb9b-24aad7a08ba7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:13 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-117, groupId=792bffcc-23d3-4d92-bb9b-24aad7a08ba7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-117, groupId=792bffcc-23d3-4d92-bb9b-24aad7a08ba7] Revoking previously assigned partitions []
2020-01-07 19:13:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-117, groupId=792bffcc-23d3-4d92-bb9b-24aad7a08ba7] (Re-)joining group
2020-01-07 19:13:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-117, groupId=792bffcc-23d3-4d92-bb9b-24aad7a08ba7] Successfully joined group with generation 1
2020-01-07 19:13:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-117, groupId=792bffcc-23d3-4d92-bb9b-24aad7a08ba7] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:13 INFO  Fetcher:583 - [Consumer clientId=consumer-117, groupId=792bffcc-23d3-4d92-bb9b-24aad7a08ba7] Resetting offset for partition facedetectiontest101-0 to offset 17596.
2020-01-07 19:13:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ea8a6cdd-0b25-4881-92e3-d4ebc2b4cf81
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:13 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-118, groupId=ea8a6cdd-0b25-4881-92e3-d4ebc2b4cf81] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-118, groupId=ea8a6cdd-0b25-4881-92e3-d4ebc2b4cf81] Revoking previously assigned partitions []
2020-01-07 19:13:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-118, groupId=ea8a6cdd-0b25-4881-92e3-d4ebc2b4cf81] (Re-)joining group
2020-01-07 19:13:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-118, groupId=ea8a6cdd-0b25-4881-92e3-d4ebc2b4cf81] Successfully joined group with generation 1
2020-01-07 19:13:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-118, groupId=ea8a6cdd-0b25-4881-92e3-d4ebc2b4cf81] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:13 INFO  Fetcher:583 - [Consumer clientId=consumer-118, groupId=ea8a6cdd-0b25-4881-92e3-d4ebc2b4cf81] Resetting offset for partition facedetectiontest101-0 to offset 17597.
2020-01-07 19:13:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5e46b2df-6c5c-475f-a61d-364ed4af006c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:13 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-119, groupId=5e46b2df-6c5c-475f-a61d-364ed4af006c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-119, groupId=5e46b2df-6c5c-475f-a61d-364ed4af006c] Revoking previously assigned partitions []
2020-01-07 19:13:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-119, groupId=5e46b2df-6c5c-475f-a61d-364ed4af006c] (Re-)joining group
2020-01-07 19:13:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-119, groupId=5e46b2df-6c5c-475f-a61d-364ed4af006c] Successfully joined group with generation 1
2020-01-07 19:13:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-119, groupId=5e46b2df-6c5c-475f-a61d-364ed4af006c] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:13 INFO  Fetcher:583 - [Consumer clientId=consumer-119, groupId=5e46b2df-6c5c-475f-a61d-364ed4af006c] Resetting offset for partition facedetectiontest101-0 to offset 17598.
2020-01-07 19:13:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1d1bc9a1-5ece-4881-a7f7-71acffb6e3f6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:13 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-120, groupId=1d1bc9a1-5ece-4881-a7f7-71acffb6e3f6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-120, groupId=1d1bc9a1-5ece-4881-a7f7-71acffb6e3f6] Revoking previously assigned partitions []
2020-01-07 19:13:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-120, groupId=1d1bc9a1-5ece-4881-a7f7-71acffb6e3f6] (Re-)joining group
2020-01-07 19:13:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-120, groupId=1d1bc9a1-5ece-4881-a7f7-71acffb6e3f6] Successfully joined group with generation 1
2020-01-07 19:13:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-120, groupId=1d1bc9a1-5ece-4881-a7f7-71acffb6e3f6] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:13 INFO  Fetcher:583 - [Consumer clientId=consumer-120, groupId=1d1bc9a1-5ece-4881-a7f7-71acffb6e3f6] Resetting offset for partition facedetectiontest101-0 to offset 17599.
2020-01-07 19:13:14 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c6153a1a-d319-48bc-bf29-55452f42ccd1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:14 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:14 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:14 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:14 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-121, groupId=c6153a1a-d319-48bc-bf29-55452f42ccd1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:14 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-121, groupId=c6153a1a-d319-48bc-bf29-55452f42ccd1] Revoking previously assigned partitions []
2020-01-07 19:13:14 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-121, groupId=c6153a1a-d319-48bc-bf29-55452f42ccd1] (Re-)joining group
2020-01-07 19:13:14 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-121, groupId=c6153a1a-d319-48bc-bf29-55452f42ccd1] Successfully joined group with generation 1
2020-01-07 19:13:14 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-121, groupId=c6153a1a-d319-48bc-bf29-55452f42ccd1] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:14 INFO  Fetcher:583 - [Consumer clientId=consumer-121, groupId=c6153a1a-d319-48bc-bf29-55452f42ccd1] Resetting offset for partition facedetectiontest101-0 to offset 17601.
2020-01-07 19:13:14 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0dddbdf2-eae4-47a6-94ee-c2e97a6db425
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:14 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:14 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:14 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:14 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-122, groupId=0dddbdf2-eae4-47a6-94ee-c2e97a6db425] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:14 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-122, groupId=0dddbdf2-eae4-47a6-94ee-c2e97a6db425] Revoking previously assigned partitions []
2020-01-07 19:13:14 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-122, groupId=0dddbdf2-eae4-47a6-94ee-c2e97a6db425] (Re-)joining group
2020-01-07 19:13:14 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-122, groupId=0dddbdf2-eae4-47a6-94ee-c2e97a6db425] Successfully joined group with generation 1
2020-01-07 19:13:14 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-122, groupId=0dddbdf2-eae4-47a6-94ee-c2e97a6db425] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:14 INFO  Fetcher:583 - [Consumer clientId=consumer-122, groupId=0dddbdf2-eae4-47a6-94ee-c2e97a6db425] Resetting offset for partition facedetectiontest101-0 to offset 17602.
2020-01-07 19:13:14 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 354d1d32-df65-4cf8-87b4-dda190dd7f4c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:14 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:14 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:14 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:14 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-123, groupId=354d1d32-df65-4cf8-87b4-dda190dd7f4c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:14 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-123, groupId=354d1d32-df65-4cf8-87b4-dda190dd7f4c] Revoking previously assigned partitions []
2020-01-07 19:13:14 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-123, groupId=354d1d32-df65-4cf8-87b4-dda190dd7f4c] (Re-)joining group
2020-01-07 19:13:14 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-123, groupId=354d1d32-df65-4cf8-87b4-dda190dd7f4c] Successfully joined group with generation 1
2020-01-07 19:13:14 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-123, groupId=354d1d32-df65-4cf8-87b4-dda190dd7f4c] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:14 INFO  Fetcher:583 - [Consumer clientId=consumer-123, groupId=354d1d32-df65-4cf8-87b4-dda190dd7f4c] Resetting offset for partition facedetectiontest101-0 to offset 17603.
2020-01-07 19:13:14 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5277148a-96e7-4fdb-92a1-1d89b9964773
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:14 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:14 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:14 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:14 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-124, groupId=5277148a-96e7-4fdb-92a1-1d89b9964773] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:14 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-124, groupId=5277148a-96e7-4fdb-92a1-1d89b9964773] Revoking previously assigned partitions []
2020-01-07 19:13:14 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-124, groupId=5277148a-96e7-4fdb-92a1-1d89b9964773] (Re-)joining group
2020-01-07 19:13:14 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-124, groupId=5277148a-96e7-4fdb-92a1-1d89b9964773] Successfully joined group with generation 1
2020-01-07 19:13:14 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-124, groupId=5277148a-96e7-4fdb-92a1-1d89b9964773] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:14 INFO  Fetcher:583 - [Consumer clientId=consumer-124, groupId=5277148a-96e7-4fdb-92a1-1d89b9964773] Resetting offset for partition facedetectiontest101-0 to offset 17604.
2020-01-07 19:13:14 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dccf015a-3d29-45b2-9e3f-4f6fa70bd873
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:14 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:14 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:14 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:14 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-125, groupId=dccf015a-3d29-45b2-9e3f-4f6fa70bd873] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:14 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-125, groupId=dccf015a-3d29-45b2-9e3f-4f6fa70bd873] Revoking previously assigned partitions []
2020-01-07 19:13:14 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-125, groupId=dccf015a-3d29-45b2-9e3f-4f6fa70bd873] (Re-)joining group
2020-01-07 19:13:14 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-125, groupId=dccf015a-3d29-45b2-9e3f-4f6fa70bd873] Successfully joined group with generation 1
2020-01-07 19:13:14 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-125, groupId=dccf015a-3d29-45b2-9e3f-4f6fa70bd873] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:14 INFO  Fetcher:583 - [Consumer clientId=consumer-125, groupId=dccf015a-3d29-45b2-9e3f-4f6fa70bd873] Resetting offset for partition facedetectiontest101-0 to offset 17605.
2020-01-07 19:13:14 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4a562d4a-e6ee-4eb2-aa7e-20429f2dea7a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:14 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:14 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:14 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:14 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-126, groupId=4a562d4a-e6ee-4eb2-aa7e-20429f2dea7a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:14 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-126, groupId=4a562d4a-e6ee-4eb2-aa7e-20429f2dea7a] Revoking previously assigned partitions []
2020-01-07 19:13:14 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-126, groupId=4a562d4a-e6ee-4eb2-aa7e-20429f2dea7a] (Re-)joining group
2020-01-07 19:13:14 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-126, groupId=4a562d4a-e6ee-4eb2-aa7e-20429f2dea7a] Successfully joined group with generation 1
2020-01-07 19:13:14 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-126, groupId=4a562d4a-e6ee-4eb2-aa7e-20429f2dea7a] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:14 INFO  Fetcher:583 - [Consumer clientId=consumer-126, groupId=4a562d4a-e6ee-4eb2-aa7e-20429f2dea7a] Resetting offset for partition facedetectiontest101-0 to offset 17606.
2020-01-07 19:13:14 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b2c8fb97-49d9-412b-aac1-0b89811eff2b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:14 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:14 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:14 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:14 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-127, groupId=b2c8fb97-49d9-412b-aac1-0b89811eff2b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:14 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-127, groupId=b2c8fb97-49d9-412b-aac1-0b89811eff2b] Revoking previously assigned partitions []
2020-01-07 19:13:14 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-127, groupId=b2c8fb97-49d9-412b-aac1-0b89811eff2b] (Re-)joining group
2020-01-07 19:13:14 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-127, groupId=b2c8fb97-49d9-412b-aac1-0b89811eff2b] Successfully joined group with generation 1
2020-01-07 19:13:14 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-127, groupId=b2c8fb97-49d9-412b-aac1-0b89811eff2b] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:14 INFO  Fetcher:583 - [Consumer clientId=consumer-127, groupId=b2c8fb97-49d9-412b-aac1-0b89811eff2b] Resetting offset for partition facedetectiontest101-0 to offset 17607.
2020-01-07 19:13:14 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 26989b90-3665-477c-9f4e-9b9388fb6863
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:14 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:14 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:14 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:14 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-128, groupId=26989b90-3665-477c-9f4e-9b9388fb6863] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:14 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-128, groupId=26989b90-3665-477c-9f4e-9b9388fb6863] Revoking previously assigned partitions []
2020-01-07 19:13:14 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-128, groupId=26989b90-3665-477c-9f4e-9b9388fb6863] (Re-)joining group
2020-01-07 19:13:14 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-128, groupId=26989b90-3665-477c-9f4e-9b9388fb6863] Successfully joined group with generation 1
2020-01-07 19:13:14 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-128, groupId=26989b90-3665-477c-9f4e-9b9388fb6863] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:14 INFO  Fetcher:583 - [Consumer clientId=consumer-128, groupId=26989b90-3665-477c-9f4e-9b9388fb6863] Resetting offset for partition facedetectiontest101-0 to offset 17608.
2020-01-07 19:13:14 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = acd66946-e887-4985-baa9-6e47a9562d22
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:14 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:14 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:14 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:14 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-129, groupId=acd66946-e887-4985-baa9-6e47a9562d22] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:14 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-129, groupId=acd66946-e887-4985-baa9-6e47a9562d22] Revoking previously assigned partitions []
2020-01-07 19:13:14 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-129, groupId=acd66946-e887-4985-baa9-6e47a9562d22] (Re-)joining group
2020-01-07 19:13:14 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-129, groupId=acd66946-e887-4985-baa9-6e47a9562d22] Successfully joined group with generation 1
2020-01-07 19:13:14 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-129, groupId=acd66946-e887-4985-baa9-6e47a9562d22] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:14 INFO  Fetcher:583 - [Consumer clientId=consumer-129, groupId=acd66946-e887-4985-baa9-6e47a9562d22] Resetting offset for partition facedetectiontest101-0 to offset 17609.
2020-01-07 19:13:14 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 132c38f6-4523-4189-88d5-44450269ae8f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:14 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:14 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:14 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:14 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-130, groupId=132c38f6-4523-4189-88d5-44450269ae8f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:14 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-130, groupId=132c38f6-4523-4189-88d5-44450269ae8f] Revoking previously assigned partitions []
2020-01-07 19:13:14 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-130, groupId=132c38f6-4523-4189-88d5-44450269ae8f] (Re-)joining group
2020-01-07 19:13:15 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-130, groupId=132c38f6-4523-4189-88d5-44450269ae8f] Successfully joined group with generation 1
2020-01-07 19:13:15 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-130, groupId=132c38f6-4523-4189-88d5-44450269ae8f] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:15 INFO  Fetcher:583 - [Consumer clientId=consumer-130, groupId=132c38f6-4523-4189-88d5-44450269ae8f] Resetting offset for partition facedetectiontest101-0 to offset 17610.
2020-01-07 19:13:15 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8a9579d2-ec6c-40e0-8304-50a7f044e97b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:15 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:15 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:15 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:15 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-131, groupId=8a9579d2-ec6c-40e0-8304-50a7f044e97b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:15 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-131, groupId=8a9579d2-ec6c-40e0-8304-50a7f044e97b] Revoking previously assigned partitions []
2020-01-07 19:13:15 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-131, groupId=8a9579d2-ec6c-40e0-8304-50a7f044e97b] (Re-)joining group
2020-01-07 19:13:15 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-131, groupId=8a9579d2-ec6c-40e0-8304-50a7f044e97b] Successfully joined group with generation 1
2020-01-07 19:13:15 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-131, groupId=8a9579d2-ec6c-40e0-8304-50a7f044e97b] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:15 INFO  Fetcher:583 - [Consumer clientId=consumer-131, groupId=8a9579d2-ec6c-40e0-8304-50a7f044e97b] Resetting offset for partition facedetectiontest101-0 to offset 17611.
2020-01-07 19:13:15 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 62fc9b2a-5425-4397-ab9d-dc1e95998129
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:15 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:15 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:15 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:15 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-132, groupId=62fc9b2a-5425-4397-ab9d-dc1e95998129] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:15 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-132, groupId=62fc9b2a-5425-4397-ab9d-dc1e95998129] Revoking previously assigned partitions []
2020-01-07 19:13:15 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-132, groupId=62fc9b2a-5425-4397-ab9d-dc1e95998129] (Re-)joining group
2020-01-07 19:13:15 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-132, groupId=62fc9b2a-5425-4397-ab9d-dc1e95998129] Successfully joined group with generation 1
2020-01-07 19:13:15 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-132, groupId=62fc9b2a-5425-4397-ab9d-dc1e95998129] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:15 INFO  Fetcher:583 - [Consumer clientId=consumer-132, groupId=62fc9b2a-5425-4397-ab9d-dc1e95998129] Resetting offset for partition facedetectiontest101-0 to offset 17612.
2020-01-07 19:13:15 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b685668a-699e-4c37-81db-11cc896efcdf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:15 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:15 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:15 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:15 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-133, groupId=b685668a-699e-4c37-81db-11cc896efcdf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:15 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-133, groupId=b685668a-699e-4c37-81db-11cc896efcdf] Revoking previously assigned partitions []
2020-01-07 19:13:15 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-133, groupId=b685668a-699e-4c37-81db-11cc896efcdf] (Re-)joining group
2020-01-07 19:13:15 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-133, groupId=b685668a-699e-4c37-81db-11cc896efcdf] Successfully joined group with generation 1
2020-01-07 19:13:15 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-133, groupId=b685668a-699e-4c37-81db-11cc896efcdf] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:15 INFO  Fetcher:583 - [Consumer clientId=consumer-133, groupId=b685668a-699e-4c37-81db-11cc896efcdf] Resetting offset for partition facedetectiontest101-0 to offset 17613.
2020-01-07 19:13:15 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 931f1833-07a6-4366-8bc6-dcef62b08537
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:15 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:15 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:15 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:15 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-134, groupId=931f1833-07a6-4366-8bc6-dcef62b08537] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:15 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-134, groupId=931f1833-07a6-4366-8bc6-dcef62b08537] Revoking previously assigned partitions []
2020-01-07 19:13:15 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-134, groupId=931f1833-07a6-4366-8bc6-dcef62b08537] (Re-)joining group
2020-01-07 19:13:15 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-134, groupId=931f1833-07a6-4366-8bc6-dcef62b08537] Successfully joined group with generation 1
2020-01-07 19:13:15 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-134, groupId=931f1833-07a6-4366-8bc6-dcef62b08537] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:15 INFO  Fetcher:583 - [Consumer clientId=consumer-134, groupId=931f1833-07a6-4366-8bc6-dcef62b08537] Resetting offset for partition facedetectiontest101-0 to offset 17614.
2020-01-07 19:13:15 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7e89c565-5f0a-4726-8842-68fe7c2944a6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:15 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:15 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:15 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:15 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-135, groupId=7e89c565-5f0a-4726-8842-68fe7c2944a6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:15 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-135, groupId=7e89c565-5f0a-4726-8842-68fe7c2944a6] Revoking previously assigned partitions []
2020-01-07 19:13:15 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-135, groupId=7e89c565-5f0a-4726-8842-68fe7c2944a6] (Re-)joining group
2020-01-07 19:13:15 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-135, groupId=7e89c565-5f0a-4726-8842-68fe7c2944a6] Successfully joined group with generation 1
2020-01-07 19:13:15 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-135, groupId=7e89c565-5f0a-4726-8842-68fe7c2944a6] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:15 INFO  Fetcher:583 - [Consumer clientId=consumer-135, groupId=7e89c565-5f0a-4726-8842-68fe7c2944a6] Resetting offset for partition facedetectiontest101-0 to offset 17615.
2020-01-07 19:13:15 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c616b30c-42fc-41aa-b6c7-bd770d87abb8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:15 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:15 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:15 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:15 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-136, groupId=c616b30c-42fc-41aa-b6c7-bd770d87abb8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:15 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-136, groupId=c616b30c-42fc-41aa-b6c7-bd770d87abb8] Revoking previously assigned partitions []
2020-01-07 19:13:15 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-136, groupId=c616b30c-42fc-41aa-b6c7-bd770d87abb8] (Re-)joining group
2020-01-07 19:13:15 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-136, groupId=c616b30c-42fc-41aa-b6c7-bd770d87abb8] Successfully joined group with generation 1
2020-01-07 19:13:15 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-136, groupId=c616b30c-42fc-41aa-b6c7-bd770d87abb8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:15 INFO  Fetcher:583 - [Consumer clientId=consumer-136, groupId=c616b30c-42fc-41aa-b6c7-bd770d87abb8] Resetting offset for partition facedetectiontest101-0 to offset 17616.
2020-01-07 19:13:15 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 96991e92-5e86-46a9-a261-c301f82490c2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:15 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:15 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:15 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:15 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-137, groupId=96991e92-5e86-46a9-a261-c301f82490c2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:15 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-137, groupId=96991e92-5e86-46a9-a261-c301f82490c2] Revoking previously assigned partitions []
2020-01-07 19:13:15 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-137, groupId=96991e92-5e86-46a9-a261-c301f82490c2] (Re-)joining group
2020-01-07 19:13:15 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-137, groupId=96991e92-5e86-46a9-a261-c301f82490c2] Successfully joined group with generation 1
2020-01-07 19:13:15 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-137, groupId=96991e92-5e86-46a9-a261-c301f82490c2] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:15 INFO  Fetcher:583 - [Consumer clientId=consumer-137, groupId=96991e92-5e86-46a9-a261-c301f82490c2] Resetting offset for partition facedetectiontest101-0 to offset 17617.
2020-01-07 19:13:15 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 55396332-0731-4a13-8f57-71f0e0403350
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:15 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:15 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:15 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:15 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-138, groupId=55396332-0731-4a13-8f57-71f0e0403350] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:15 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-138, groupId=55396332-0731-4a13-8f57-71f0e0403350] Revoking previously assigned partitions []
2020-01-07 19:13:15 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-138, groupId=55396332-0731-4a13-8f57-71f0e0403350] (Re-)joining group
2020-01-07 19:13:15 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-138, groupId=55396332-0731-4a13-8f57-71f0e0403350] Successfully joined group with generation 1
2020-01-07 19:13:15 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-138, groupId=55396332-0731-4a13-8f57-71f0e0403350] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:15 INFO  Fetcher:583 - [Consumer clientId=consumer-138, groupId=55396332-0731-4a13-8f57-71f0e0403350] Resetting offset for partition facedetectiontest101-0 to offset 17618.
2020-01-07 19:13:15 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = bde8b92b-8858-4f56-86ce-40ab66c49e4e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:15 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:15 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:15 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:15 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-139, groupId=bde8b92b-8858-4f56-86ce-40ab66c49e4e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:15 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-139, groupId=bde8b92b-8858-4f56-86ce-40ab66c49e4e] Revoking previously assigned partitions []
2020-01-07 19:13:15 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-139, groupId=bde8b92b-8858-4f56-86ce-40ab66c49e4e] (Re-)joining group
2020-01-07 19:13:15 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-139, groupId=bde8b92b-8858-4f56-86ce-40ab66c49e4e] Successfully joined group with generation 1
2020-01-07 19:13:15 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-139, groupId=bde8b92b-8858-4f56-86ce-40ab66c49e4e] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:15 INFO  Fetcher:583 - [Consumer clientId=consumer-139, groupId=bde8b92b-8858-4f56-86ce-40ab66c49e4e] Resetting offset for partition facedetectiontest101-0 to offset 17619.
2020-01-07 19:13:15 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3917528f-264a-480d-b83e-beece34bfef2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:15 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:15 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:15 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:15 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-140, groupId=3917528f-264a-480d-b83e-beece34bfef2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:15 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-140, groupId=3917528f-264a-480d-b83e-beece34bfef2] Revoking previously assigned partitions []
2020-01-07 19:13:15 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-140, groupId=3917528f-264a-480d-b83e-beece34bfef2] (Re-)joining group
2020-01-07 19:13:15 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-140, groupId=3917528f-264a-480d-b83e-beece34bfef2] Successfully joined group with generation 1
2020-01-07 19:13:15 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-140, groupId=3917528f-264a-480d-b83e-beece34bfef2] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:15 INFO  Fetcher:583 - [Consumer clientId=consumer-140, groupId=3917528f-264a-480d-b83e-beece34bfef2] Resetting offset for partition facedetectiontest101-0 to offset 17620.
2020-01-07 19:13:16 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 19710ad9-8f27-433c-ab3c-0deaefd172f2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:16 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:16 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:16 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:16 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-141, groupId=19710ad9-8f27-433c-ab3c-0deaefd172f2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:16 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-141, groupId=19710ad9-8f27-433c-ab3c-0deaefd172f2] Revoking previously assigned partitions []
2020-01-07 19:13:16 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-141, groupId=19710ad9-8f27-433c-ab3c-0deaefd172f2] (Re-)joining group
2020-01-07 19:13:16 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-141, groupId=19710ad9-8f27-433c-ab3c-0deaefd172f2] Successfully joined group with generation 1
2020-01-07 19:13:16 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-141, groupId=19710ad9-8f27-433c-ab3c-0deaefd172f2] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:16 INFO  Fetcher:583 - [Consumer clientId=consumer-141, groupId=19710ad9-8f27-433c-ab3c-0deaefd172f2] Resetting offset for partition facedetectiontest101-0 to offset 17621.
2020-01-07 19:13:16 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0d646b5f-09f0-4cd2-b0c8-f9f5c33a0bb7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:16 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:16 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:16 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:16 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-142, groupId=0d646b5f-09f0-4cd2-b0c8-f9f5c33a0bb7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:16 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-142, groupId=0d646b5f-09f0-4cd2-b0c8-f9f5c33a0bb7] Revoking previously assigned partitions []
2020-01-07 19:13:16 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-142, groupId=0d646b5f-09f0-4cd2-b0c8-f9f5c33a0bb7] (Re-)joining group
2020-01-07 19:13:16 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-142, groupId=0d646b5f-09f0-4cd2-b0c8-f9f5c33a0bb7] Successfully joined group with generation 1
2020-01-07 19:13:16 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-142, groupId=0d646b5f-09f0-4cd2-b0c8-f9f5c33a0bb7] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:16 INFO  Fetcher:583 - [Consumer clientId=consumer-142, groupId=0d646b5f-09f0-4cd2-b0c8-f9f5c33a0bb7] Resetting offset for partition facedetectiontest101-0 to offset 17622.
2020-01-07 19:13:16 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 78d745bb-239e-4d24-96e9-b4b2b14c5409
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:16 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:16 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:16 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:16 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-143, groupId=78d745bb-239e-4d24-96e9-b4b2b14c5409] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:16 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-143, groupId=78d745bb-239e-4d24-96e9-b4b2b14c5409] Revoking previously assigned partitions []
2020-01-07 19:13:16 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-143, groupId=78d745bb-239e-4d24-96e9-b4b2b14c5409] (Re-)joining group
2020-01-07 19:13:16 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-143, groupId=78d745bb-239e-4d24-96e9-b4b2b14c5409] Successfully joined group with generation 1
2020-01-07 19:13:16 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-143, groupId=78d745bb-239e-4d24-96e9-b4b2b14c5409] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:16 INFO  Fetcher:583 - [Consumer clientId=consumer-143, groupId=78d745bb-239e-4d24-96e9-b4b2b14c5409] Resetting offset for partition facedetectiontest101-0 to offset 17623.
2020-01-07 19:13:16 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 042529ed-84a1-41bb-b840-462119b696e8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:16 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:16 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:16 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:16 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-144, groupId=042529ed-84a1-41bb-b840-462119b696e8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:16 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-144, groupId=042529ed-84a1-41bb-b840-462119b696e8] Revoking previously assigned partitions []
2020-01-07 19:13:16 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-144, groupId=042529ed-84a1-41bb-b840-462119b696e8] (Re-)joining group
2020-01-07 19:13:16 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-144, groupId=042529ed-84a1-41bb-b840-462119b696e8] Successfully joined group with generation 1
2020-01-07 19:13:16 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-144, groupId=042529ed-84a1-41bb-b840-462119b696e8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:16 INFO  Fetcher:583 - [Consumer clientId=consumer-144, groupId=042529ed-84a1-41bb-b840-462119b696e8] Resetting offset for partition facedetectiontest101-0 to offset 17624.
2020-01-07 19:13:16 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 80d9f179-8b8e-4128-b056-4487bb8ae0f9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:16 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:16 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:16 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:16 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-145, groupId=80d9f179-8b8e-4128-b056-4487bb8ae0f9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:16 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-145, groupId=80d9f179-8b8e-4128-b056-4487bb8ae0f9] Revoking previously assigned partitions []
2020-01-07 19:13:16 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-145, groupId=80d9f179-8b8e-4128-b056-4487bb8ae0f9] (Re-)joining group
2020-01-07 19:13:16 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-145, groupId=80d9f179-8b8e-4128-b056-4487bb8ae0f9] Successfully joined group with generation 1
2020-01-07 19:13:16 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-145, groupId=80d9f179-8b8e-4128-b056-4487bb8ae0f9] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:16 INFO  Fetcher:583 - [Consumer clientId=consumer-145, groupId=80d9f179-8b8e-4128-b056-4487bb8ae0f9] Resetting offset for partition facedetectiontest101-0 to offset 17625.
2020-01-07 19:13:16 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 318c19ca-4987-4804-992b-9d06c7c4c42d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:16 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:16 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:16 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:16 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-146, groupId=318c19ca-4987-4804-992b-9d06c7c4c42d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:16 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-146, groupId=318c19ca-4987-4804-992b-9d06c7c4c42d] Revoking previously assigned partitions []
2020-01-07 19:13:16 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-146, groupId=318c19ca-4987-4804-992b-9d06c7c4c42d] (Re-)joining group
2020-01-07 19:13:16 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-146, groupId=318c19ca-4987-4804-992b-9d06c7c4c42d] Successfully joined group with generation 1
2020-01-07 19:13:16 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-146, groupId=318c19ca-4987-4804-992b-9d06c7c4c42d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:16 INFO  Fetcher:583 - [Consumer clientId=consumer-146, groupId=318c19ca-4987-4804-992b-9d06c7c4c42d] Resetting offset for partition facedetectiontest101-0 to offset 17626.
2020-01-07 19:13:16 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f427db42-ac85-4264-b4bc-63dc62200c85
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:16 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:16 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:16 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:16 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-147, groupId=f427db42-ac85-4264-b4bc-63dc62200c85] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:16 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-147, groupId=f427db42-ac85-4264-b4bc-63dc62200c85] Revoking previously assigned partitions []
2020-01-07 19:13:16 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-147, groupId=f427db42-ac85-4264-b4bc-63dc62200c85] (Re-)joining group
2020-01-07 19:13:16 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-147, groupId=f427db42-ac85-4264-b4bc-63dc62200c85] Successfully joined group with generation 1
2020-01-07 19:13:16 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-147, groupId=f427db42-ac85-4264-b4bc-63dc62200c85] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:16 INFO  Fetcher:583 - [Consumer clientId=consumer-147, groupId=f427db42-ac85-4264-b4bc-63dc62200c85] Resetting offset for partition facedetectiontest101-0 to offset 17627.
2020-01-07 19:13:16 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8878c8d0-42ff-4858-a87e-ace72db9f498
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:16 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:16 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:16 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:16 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-148, groupId=8878c8d0-42ff-4858-a87e-ace72db9f498] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:16 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-148, groupId=8878c8d0-42ff-4858-a87e-ace72db9f498] Revoking previously assigned partitions []
2020-01-07 19:13:16 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-148, groupId=8878c8d0-42ff-4858-a87e-ace72db9f498] (Re-)joining group
2020-01-07 19:13:16 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-148, groupId=8878c8d0-42ff-4858-a87e-ace72db9f498] Successfully joined group with generation 1
2020-01-07 19:13:16 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-148, groupId=8878c8d0-42ff-4858-a87e-ace72db9f498] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:16 INFO  Fetcher:583 - [Consumer clientId=consumer-148, groupId=8878c8d0-42ff-4858-a87e-ace72db9f498] Resetting offset for partition facedetectiontest101-0 to offset 17628.
2020-01-07 19:13:16 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f2afefe7-e140-464f-94de-ee5894a44135
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:16 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:16 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:16 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:16 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-149, groupId=f2afefe7-e140-464f-94de-ee5894a44135] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:16 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-149, groupId=f2afefe7-e140-464f-94de-ee5894a44135] Revoking previously assigned partitions []
2020-01-07 19:13:16 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-149, groupId=f2afefe7-e140-464f-94de-ee5894a44135] (Re-)joining group
2020-01-07 19:13:16 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-149, groupId=f2afefe7-e140-464f-94de-ee5894a44135] Successfully joined group with generation 1
2020-01-07 19:13:16 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-149, groupId=f2afefe7-e140-464f-94de-ee5894a44135] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:16 INFO  Fetcher:583 - [Consumer clientId=consumer-149, groupId=f2afefe7-e140-464f-94de-ee5894a44135] Resetting offset for partition facedetectiontest101-0 to offset 17629.
2020-01-07 19:13:16 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ee4f7088-2ab0-4231-84e8-f9afbaaad65a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:16 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:16 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:16 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:16 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-150, groupId=ee4f7088-2ab0-4231-84e8-f9afbaaad65a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:16 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-150, groupId=ee4f7088-2ab0-4231-84e8-f9afbaaad65a] Revoking previously assigned partitions []
2020-01-07 19:13:16 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-150, groupId=ee4f7088-2ab0-4231-84e8-f9afbaaad65a] (Re-)joining group
2020-01-07 19:13:16 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-150, groupId=ee4f7088-2ab0-4231-84e8-f9afbaaad65a] Successfully joined group with generation 1
2020-01-07 19:13:16 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-150, groupId=ee4f7088-2ab0-4231-84e8-f9afbaaad65a] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:16 INFO  Fetcher:583 - [Consumer clientId=consumer-150, groupId=ee4f7088-2ab0-4231-84e8-f9afbaaad65a] Resetting offset for partition facedetectiontest101-0 to offset 17630.
2020-01-07 19:13:16 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e277c313-d4a9-473d-8d9a-cd30ef6619b3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:16 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:16 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:16 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:16 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-151, groupId=e277c313-d4a9-473d-8d9a-cd30ef6619b3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:16 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-151, groupId=e277c313-d4a9-473d-8d9a-cd30ef6619b3] Revoking previously assigned partitions []
2020-01-07 19:13:16 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-151, groupId=e277c313-d4a9-473d-8d9a-cd30ef6619b3] (Re-)joining group
2020-01-07 19:13:16 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-151, groupId=e277c313-d4a9-473d-8d9a-cd30ef6619b3] Successfully joined group with generation 1
2020-01-07 19:13:16 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-151, groupId=e277c313-d4a9-473d-8d9a-cd30ef6619b3] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:16 INFO  Fetcher:583 - [Consumer clientId=consumer-151, groupId=e277c313-d4a9-473d-8d9a-cd30ef6619b3] Resetting offset for partition facedetectiontest101-0 to offset 17631.
2020-01-07 19:13:16 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 831b31ba-cee7-4cfe-94a0-abac170d892f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:16 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:16 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:16 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:16 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-152, groupId=831b31ba-cee7-4cfe-94a0-abac170d892f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:16 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-152, groupId=831b31ba-cee7-4cfe-94a0-abac170d892f] Revoking previously assigned partitions []
2020-01-07 19:13:16 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-152, groupId=831b31ba-cee7-4cfe-94a0-abac170d892f] (Re-)joining group
2020-01-07 19:13:16 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-152, groupId=831b31ba-cee7-4cfe-94a0-abac170d892f] Successfully joined group with generation 1
2020-01-07 19:13:16 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-152, groupId=831b31ba-cee7-4cfe-94a0-abac170d892f] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:16 INFO  Fetcher:583 - [Consumer clientId=consumer-152, groupId=831b31ba-cee7-4cfe-94a0-abac170d892f] Resetting offset for partition facedetectiontest101-0 to offset 17632.
2020-01-07 19:13:16 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b70b1357-3171-4c9a-ad62-c4964b7840ef
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:16 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:16 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:16 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:16 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-153, groupId=b70b1357-3171-4c9a-ad62-c4964b7840ef] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:16 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-153, groupId=b70b1357-3171-4c9a-ad62-c4964b7840ef] Revoking previously assigned partitions []
2020-01-07 19:13:16 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-153, groupId=b70b1357-3171-4c9a-ad62-c4964b7840ef] (Re-)joining group
2020-01-07 19:13:16 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-153, groupId=b70b1357-3171-4c9a-ad62-c4964b7840ef] Successfully joined group with generation 1
2020-01-07 19:13:16 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-153, groupId=b70b1357-3171-4c9a-ad62-c4964b7840ef] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:16 INFO  Fetcher:583 - [Consumer clientId=consumer-153, groupId=b70b1357-3171-4c9a-ad62-c4964b7840ef] Resetting offset for partition facedetectiontest101-0 to offset 17633.
2020-01-07 19:13:16 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 87dc2499-c867-47e9-85dc-b9206937e09c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:16 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:16 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:16 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:16 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-154, groupId=87dc2499-c867-47e9-85dc-b9206937e09c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:16 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-154, groupId=87dc2499-c867-47e9-85dc-b9206937e09c] Revoking previously assigned partitions []
2020-01-07 19:13:16 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-154, groupId=87dc2499-c867-47e9-85dc-b9206937e09c] (Re-)joining group
2020-01-07 19:13:16 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-154, groupId=87dc2499-c867-47e9-85dc-b9206937e09c] Successfully joined group with generation 1
2020-01-07 19:13:16 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-154, groupId=87dc2499-c867-47e9-85dc-b9206937e09c] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:16 INFO  Fetcher:583 - [Consumer clientId=consumer-154, groupId=87dc2499-c867-47e9-85dc-b9206937e09c] Resetting offset for partition facedetectiontest101-0 to offset 17634.
2020-01-07 19:13:17 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = eece7e0a-8c94-4741-a61c-e482ad5983db
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:17 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:17 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:17 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:17 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-155, groupId=eece7e0a-8c94-4741-a61c-e482ad5983db] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:17 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-155, groupId=eece7e0a-8c94-4741-a61c-e482ad5983db] Revoking previously assigned partitions []
2020-01-07 19:13:17 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-155, groupId=eece7e0a-8c94-4741-a61c-e482ad5983db] (Re-)joining group
2020-01-07 19:13:17 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-155, groupId=eece7e0a-8c94-4741-a61c-e482ad5983db] Successfully joined group with generation 1
2020-01-07 19:13:17 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-155, groupId=eece7e0a-8c94-4741-a61c-e482ad5983db] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:17 INFO  Fetcher:583 - [Consumer clientId=consumer-155, groupId=eece7e0a-8c94-4741-a61c-e482ad5983db] Resetting offset for partition facedetectiontest101-0 to offset 17635.
2020-01-07 19:13:17 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7f0d610e-0cb4-4f10-bee8-805a10739a53
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:17 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:17 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:17 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:17 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-156, groupId=7f0d610e-0cb4-4f10-bee8-805a10739a53] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:17 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-156, groupId=7f0d610e-0cb4-4f10-bee8-805a10739a53] Revoking previously assigned partitions []
2020-01-07 19:13:17 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-156, groupId=7f0d610e-0cb4-4f10-bee8-805a10739a53] (Re-)joining group
2020-01-07 19:13:17 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-156, groupId=7f0d610e-0cb4-4f10-bee8-805a10739a53] Successfully joined group with generation 1
2020-01-07 19:13:17 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-156, groupId=7f0d610e-0cb4-4f10-bee8-805a10739a53] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:17 INFO  Fetcher:583 - [Consumer clientId=consumer-156, groupId=7f0d610e-0cb4-4f10-bee8-805a10739a53] Resetting offset for partition facedetectiontest101-0 to offset 17636.
2020-01-07 19:13:17 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8df0907a-4842-4441-8af8-ec7829d6ea92
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:17 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:17 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:17 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:17 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-157, groupId=8df0907a-4842-4441-8af8-ec7829d6ea92] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:17 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-157, groupId=8df0907a-4842-4441-8af8-ec7829d6ea92] Revoking previously assigned partitions []
2020-01-07 19:13:17 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-157, groupId=8df0907a-4842-4441-8af8-ec7829d6ea92] (Re-)joining group
2020-01-07 19:13:17 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-157, groupId=8df0907a-4842-4441-8af8-ec7829d6ea92] Successfully joined group with generation 1
2020-01-07 19:13:17 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-157, groupId=8df0907a-4842-4441-8af8-ec7829d6ea92] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:17 INFO  Fetcher:583 - [Consumer clientId=consumer-157, groupId=8df0907a-4842-4441-8af8-ec7829d6ea92] Resetting offset for partition facedetectiontest101-0 to offset 17638.
2020-01-07 19:13:17 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0b22ff6b-38a8-4de2-84ff-bddca7badab5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:17 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:17 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:17 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:17 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-158, groupId=0b22ff6b-38a8-4de2-84ff-bddca7badab5] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:17 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-158, groupId=0b22ff6b-38a8-4de2-84ff-bddca7badab5] Revoking previously assigned partitions []
2020-01-07 19:13:17 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-158, groupId=0b22ff6b-38a8-4de2-84ff-bddca7badab5] (Re-)joining group
2020-01-07 19:13:17 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-158, groupId=0b22ff6b-38a8-4de2-84ff-bddca7badab5] Successfully joined group with generation 1
2020-01-07 19:13:17 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-158, groupId=0b22ff6b-38a8-4de2-84ff-bddca7badab5] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:17 INFO  Fetcher:583 - [Consumer clientId=consumer-158, groupId=0b22ff6b-38a8-4de2-84ff-bddca7badab5] Resetting offset for partition facedetectiontest101-0 to offset 17639.
2020-01-07 19:13:17 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0b3bc883-00f7-4f5a-89ce-69bfee575c2c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:17 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:17 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:17 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:17 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-159, groupId=0b3bc883-00f7-4f5a-89ce-69bfee575c2c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:17 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-159, groupId=0b3bc883-00f7-4f5a-89ce-69bfee575c2c] Revoking previously assigned partitions []
2020-01-07 19:13:17 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-159, groupId=0b3bc883-00f7-4f5a-89ce-69bfee575c2c] (Re-)joining group
2020-01-07 19:13:17 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-159, groupId=0b3bc883-00f7-4f5a-89ce-69bfee575c2c] Successfully joined group with generation 1
2020-01-07 19:13:17 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-159, groupId=0b3bc883-00f7-4f5a-89ce-69bfee575c2c] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:17 INFO  Fetcher:583 - [Consumer clientId=consumer-159, groupId=0b3bc883-00f7-4f5a-89ce-69bfee575c2c] Resetting offset for partition facedetectiontest101-0 to offset 17640.
2020-01-07 19:13:17 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e956ef3a-56d3-4b04-9e1f-415f27ddbb1d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:17 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:17 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:17 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:17 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-160, groupId=e956ef3a-56d3-4b04-9e1f-415f27ddbb1d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:17 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-160, groupId=e956ef3a-56d3-4b04-9e1f-415f27ddbb1d] Revoking previously assigned partitions []
2020-01-07 19:13:17 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-160, groupId=e956ef3a-56d3-4b04-9e1f-415f27ddbb1d] (Re-)joining group
2020-01-07 19:13:17 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-160, groupId=e956ef3a-56d3-4b04-9e1f-415f27ddbb1d] Successfully joined group with generation 1
2020-01-07 19:13:17 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-160, groupId=e956ef3a-56d3-4b04-9e1f-415f27ddbb1d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:17 INFO  Fetcher:583 - [Consumer clientId=consumer-160, groupId=e956ef3a-56d3-4b04-9e1f-415f27ddbb1d] Resetting offset for partition facedetectiontest101-0 to offset 17642.
2020-01-07 19:13:17 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4107d643-4271-4093-bead-6d61391f917e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:17 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:17 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:17 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:17 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-161, groupId=4107d643-4271-4093-bead-6d61391f917e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:17 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-161, groupId=4107d643-4271-4093-bead-6d61391f917e] Revoking previously assigned partitions []
2020-01-07 19:13:17 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-161, groupId=4107d643-4271-4093-bead-6d61391f917e] (Re-)joining group
2020-01-07 19:13:17 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-161, groupId=4107d643-4271-4093-bead-6d61391f917e] Successfully joined group with generation 1
2020-01-07 19:13:17 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-161, groupId=4107d643-4271-4093-bead-6d61391f917e] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:17 INFO  Fetcher:583 - [Consumer clientId=consumer-161, groupId=4107d643-4271-4093-bead-6d61391f917e] Resetting offset for partition facedetectiontest101-0 to offset 17643.
2020-01-07 19:13:17 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 54310eea-f650-4765-bc95-7cd315879c8f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:17 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:17 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:17 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:17 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-162, groupId=54310eea-f650-4765-bc95-7cd315879c8f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:17 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-162, groupId=54310eea-f650-4765-bc95-7cd315879c8f] Revoking previously assigned partitions []
2020-01-07 19:13:17 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-162, groupId=54310eea-f650-4765-bc95-7cd315879c8f] (Re-)joining group
2020-01-07 19:13:17 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-162, groupId=54310eea-f650-4765-bc95-7cd315879c8f] Successfully joined group with generation 1
2020-01-07 19:13:17 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-162, groupId=54310eea-f650-4765-bc95-7cd315879c8f] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:17 INFO  Fetcher:583 - [Consumer clientId=consumer-162, groupId=54310eea-f650-4765-bc95-7cd315879c8f] Resetting offset for partition facedetectiontest101-0 to offset 17645.
2020-01-07 19:13:17 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 77ce23ef-bfb9-44fe-a7a3-b70d6bb01202
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:17 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:17 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:17 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:17 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-163, groupId=77ce23ef-bfb9-44fe-a7a3-b70d6bb01202] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:17 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-163, groupId=77ce23ef-bfb9-44fe-a7a3-b70d6bb01202] Revoking previously assigned partitions []
2020-01-07 19:13:17 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-163, groupId=77ce23ef-bfb9-44fe-a7a3-b70d6bb01202] (Re-)joining group
2020-01-07 19:13:17 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-163, groupId=77ce23ef-bfb9-44fe-a7a3-b70d6bb01202] Successfully joined group with generation 1
2020-01-07 19:13:17 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-163, groupId=77ce23ef-bfb9-44fe-a7a3-b70d6bb01202] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:17 INFO  Fetcher:583 - [Consumer clientId=consumer-163, groupId=77ce23ef-bfb9-44fe-a7a3-b70d6bb01202] Resetting offset for partition facedetectiontest101-0 to offset 17646.
2020-01-07 19:13:17 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 93b9a8db-483d-45e3-9426-0725354adcf3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:17 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:17 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:17 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:17 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-164, groupId=93b9a8db-483d-45e3-9426-0725354adcf3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:17 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-164, groupId=93b9a8db-483d-45e3-9426-0725354adcf3] Revoking previously assigned partitions []
2020-01-07 19:13:17 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-164, groupId=93b9a8db-483d-45e3-9426-0725354adcf3] (Re-)joining group
2020-01-07 19:13:17 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-164, groupId=93b9a8db-483d-45e3-9426-0725354adcf3] Successfully joined group with generation 1
2020-01-07 19:13:17 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-164, groupId=93b9a8db-483d-45e3-9426-0725354adcf3] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:17 INFO  Fetcher:583 - [Consumer clientId=consumer-164, groupId=93b9a8db-483d-45e3-9426-0725354adcf3] Resetting offset for partition facedetectiontest101-0 to offset 17647.
2020-01-07 19:13:17 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ea3f5fe2-5329-45fc-9b31-0fcc4fc91db7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:17 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:17 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:17 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:17 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-165, groupId=ea3f5fe2-5329-45fc-9b31-0fcc4fc91db7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:17 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-165, groupId=ea3f5fe2-5329-45fc-9b31-0fcc4fc91db7] Revoking previously assigned partitions []
2020-01-07 19:13:17 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-165, groupId=ea3f5fe2-5329-45fc-9b31-0fcc4fc91db7] (Re-)joining group
2020-01-07 19:13:17 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-165, groupId=ea3f5fe2-5329-45fc-9b31-0fcc4fc91db7] Successfully joined group with generation 1
2020-01-07 19:13:17 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-165, groupId=ea3f5fe2-5329-45fc-9b31-0fcc4fc91db7] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:17 INFO  Fetcher:583 - [Consumer clientId=consumer-165, groupId=ea3f5fe2-5329-45fc-9b31-0fcc4fc91db7] Resetting offset for partition facedetectiontest101-0 to offset 17649.
2020-01-07 19:13:18 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c44c315c-45a9-4e27-970c-e22ab72b60c7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:18 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:18 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:18 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:18 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-166, groupId=c44c315c-45a9-4e27-970c-e22ab72b60c7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:18 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-166, groupId=c44c315c-45a9-4e27-970c-e22ab72b60c7] Revoking previously assigned partitions []
2020-01-07 19:13:18 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-166, groupId=c44c315c-45a9-4e27-970c-e22ab72b60c7] (Re-)joining group
2020-01-07 19:13:18 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-166, groupId=c44c315c-45a9-4e27-970c-e22ab72b60c7] Successfully joined group with generation 1
2020-01-07 19:13:18 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-166, groupId=c44c315c-45a9-4e27-970c-e22ab72b60c7] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:18 INFO  Fetcher:583 - [Consumer clientId=consumer-166, groupId=c44c315c-45a9-4e27-970c-e22ab72b60c7] Resetting offset for partition facedetectiontest101-0 to offset 17650.
2020-01-07 19:13:18 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1b1e241c-c02b-48cb-a59e-89a92716de93
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:18 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:18 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:18 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:18 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-167, groupId=1b1e241c-c02b-48cb-a59e-89a92716de93] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:18 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-167, groupId=1b1e241c-c02b-48cb-a59e-89a92716de93] Revoking previously assigned partitions []
2020-01-07 19:13:18 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-167, groupId=1b1e241c-c02b-48cb-a59e-89a92716de93] (Re-)joining group
2020-01-07 19:13:18 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-167, groupId=1b1e241c-c02b-48cb-a59e-89a92716de93] Successfully joined group with generation 1
2020-01-07 19:13:18 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-167, groupId=1b1e241c-c02b-48cb-a59e-89a92716de93] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:18 INFO  Fetcher:583 - [Consumer clientId=consumer-167, groupId=1b1e241c-c02b-48cb-a59e-89a92716de93] Resetting offset for partition facedetectiontest101-0 to offset 17652.
2020-01-07 19:13:18 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dfcaf514-1821-4904-bfa6-b5aa01f08a67
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:18 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:18 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:18 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:18 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-168, groupId=dfcaf514-1821-4904-bfa6-b5aa01f08a67] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:18 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-168, groupId=dfcaf514-1821-4904-bfa6-b5aa01f08a67] Revoking previously assigned partitions []
2020-01-07 19:13:18 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-168, groupId=dfcaf514-1821-4904-bfa6-b5aa01f08a67] (Re-)joining group
2020-01-07 19:13:18 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-168, groupId=dfcaf514-1821-4904-bfa6-b5aa01f08a67] Successfully joined group with generation 1
2020-01-07 19:13:18 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-168, groupId=dfcaf514-1821-4904-bfa6-b5aa01f08a67] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:18 INFO  Fetcher:583 - [Consumer clientId=consumer-168, groupId=dfcaf514-1821-4904-bfa6-b5aa01f08a67] Resetting offset for partition facedetectiontest101-0 to offset 17653.
2020-01-07 19:13:18 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = edda6beb-17fc-46bb-9d03-f72bc64ed605
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:18 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:18 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:18 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:18 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-169, groupId=edda6beb-17fc-46bb-9d03-f72bc64ed605] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:18 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-169, groupId=edda6beb-17fc-46bb-9d03-f72bc64ed605] Revoking previously assigned partitions []
2020-01-07 19:13:18 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-169, groupId=edda6beb-17fc-46bb-9d03-f72bc64ed605] (Re-)joining group
2020-01-07 19:13:18 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-169, groupId=edda6beb-17fc-46bb-9d03-f72bc64ed605] Successfully joined group with generation 1
2020-01-07 19:13:18 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-169, groupId=edda6beb-17fc-46bb-9d03-f72bc64ed605] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:18 INFO  Fetcher:583 - [Consumer clientId=consumer-169, groupId=edda6beb-17fc-46bb-9d03-f72bc64ed605] Resetting offset for partition facedetectiontest101-0 to offset 17654.
2020-01-07 19:13:18 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f9e83dad-810f-458a-89fd-418944799eaf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:18 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:18 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:18 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:18 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-170, groupId=f9e83dad-810f-458a-89fd-418944799eaf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:18 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-170, groupId=f9e83dad-810f-458a-89fd-418944799eaf] Revoking previously assigned partitions []
2020-01-07 19:13:18 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-170, groupId=f9e83dad-810f-458a-89fd-418944799eaf] (Re-)joining group
2020-01-07 19:13:18 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-170, groupId=f9e83dad-810f-458a-89fd-418944799eaf] Successfully joined group with generation 1
2020-01-07 19:13:18 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-170, groupId=f9e83dad-810f-458a-89fd-418944799eaf] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:18 INFO  Fetcher:583 - [Consumer clientId=consumer-170, groupId=f9e83dad-810f-458a-89fd-418944799eaf] Resetting offset for partition facedetectiontest101-0 to offset 17655.
2020-01-07 19:13:18 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 32e51b5a-e28f-4403-a10d-14c5468b818b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:18 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:18 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:18 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:18 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-171, groupId=32e51b5a-e28f-4403-a10d-14c5468b818b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:18 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-171, groupId=32e51b5a-e28f-4403-a10d-14c5468b818b] Revoking previously assigned partitions []
2020-01-07 19:13:18 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-171, groupId=32e51b5a-e28f-4403-a10d-14c5468b818b] (Re-)joining group
2020-01-07 19:13:18 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-171, groupId=32e51b5a-e28f-4403-a10d-14c5468b818b] Successfully joined group with generation 1
2020-01-07 19:13:18 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-171, groupId=32e51b5a-e28f-4403-a10d-14c5468b818b] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:18 INFO  Fetcher:583 - [Consumer clientId=consumer-171, groupId=32e51b5a-e28f-4403-a10d-14c5468b818b] Resetting offset for partition facedetectiontest101-0 to offset 17656.
2020-01-07 19:13:18 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3fe4f3f2-fe9b-49f2-8794-2a42432f0de8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:18 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:18 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:18 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:18 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-172, groupId=3fe4f3f2-fe9b-49f2-8794-2a42432f0de8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:18 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-172, groupId=3fe4f3f2-fe9b-49f2-8794-2a42432f0de8] Revoking previously assigned partitions []
2020-01-07 19:13:18 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-172, groupId=3fe4f3f2-fe9b-49f2-8794-2a42432f0de8] (Re-)joining group
2020-01-07 19:13:18 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-172, groupId=3fe4f3f2-fe9b-49f2-8794-2a42432f0de8] Successfully joined group with generation 1
2020-01-07 19:13:18 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-172, groupId=3fe4f3f2-fe9b-49f2-8794-2a42432f0de8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:18 INFO  Fetcher:583 - [Consumer clientId=consumer-172, groupId=3fe4f3f2-fe9b-49f2-8794-2a42432f0de8] Resetting offset for partition facedetectiontest101-0 to offset 17658.
2020-01-07 19:13:18 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ae49f8d6-fdee-4dd1-824b-6809c8da75aa
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:18 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:18 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:18 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:18 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-173, groupId=ae49f8d6-fdee-4dd1-824b-6809c8da75aa] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:18 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-173, groupId=ae49f8d6-fdee-4dd1-824b-6809c8da75aa] Revoking previously assigned partitions []
2020-01-07 19:13:18 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-173, groupId=ae49f8d6-fdee-4dd1-824b-6809c8da75aa] (Re-)joining group
2020-01-07 19:13:18 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-173, groupId=ae49f8d6-fdee-4dd1-824b-6809c8da75aa] Successfully joined group with generation 1
2020-01-07 19:13:18 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-173, groupId=ae49f8d6-fdee-4dd1-824b-6809c8da75aa] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:18 INFO  Fetcher:583 - [Consumer clientId=consumer-173, groupId=ae49f8d6-fdee-4dd1-824b-6809c8da75aa] Resetting offset for partition facedetectiontest101-0 to offset 17659.
2020-01-07 19:13:18 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 737b3583-58ea-4c17-bfe9-a6ea6fed8dfc
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:18 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:18 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:18 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:18 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-174, groupId=737b3583-58ea-4c17-bfe9-a6ea6fed8dfc] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:18 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-174, groupId=737b3583-58ea-4c17-bfe9-a6ea6fed8dfc] Revoking previously assigned partitions []
2020-01-07 19:13:18 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-174, groupId=737b3583-58ea-4c17-bfe9-a6ea6fed8dfc] (Re-)joining group
2020-01-07 19:13:18 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-174, groupId=737b3583-58ea-4c17-bfe9-a6ea6fed8dfc] Successfully joined group with generation 1
2020-01-07 19:13:18 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-174, groupId=737b3583-58ea-4c17-bfe9-a6ea6fed8dfc] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:18 INFO  Fetcher:583 - [Consumer clientId=consumer-174, groupId=737b3583-58ea-4c17-bfe9-a6ea6fed8dfc] Resetting offset for partition facedetectiontest101-0 to offset 17660.
2020-01-07 19:13:18 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e5ee512c-db26-421d-807d-ebd066529a62
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:18 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:18 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:18 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:18 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-175, groupId=e5ee512c-db26-421d-807d-ebd066529a62] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:18 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-175, groupId=e5ee512c-db26-421d-807d-ebd066529a62] Revoking previously assigned partitions []
2020-01-07 19:13:18 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-175, groupId=e5ee512c-db26-421d-807d-ebd066529a62] (Re-)joining group
2020-01-07 19:13:18 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-175, groupId=e5ee512c-db26-421d-807d-ebd066529a62] Successfully joined group with generation 1
2020-01-07 19:13:18 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-175, groupId=e5ee512c-db26-421d-807d-ebd066529a62] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:18 INFO  Fetcher:583 - [Consumer clientId=consumer-175, groupId=e5ee512c-db26-421d-807d-ebd066529a62] Resetting offset for partition facedetectiontest101-0 to offset 17661.
2020-01-07 19:13:19 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5c880edb-0df3-4eb4-9456-3340706f4b16
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:19 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:19 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:19 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:19 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-176, groupId=5c880edb-0df3-4eb4-9456-3340706f4b16] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:19 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-176, groupId=5c880edb-0df3-4eb4-9456-3340706f4b16] Revoking previously assigned partitions []
2020-01-07 19:13:19 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-176, groupId=5c880edb-0df3-4eb4-9456-3340706f4b16] (Re-)joining group
2020-01-07 19:13:19 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-176, groupId=5c880edb-0df3-4eb4-9456-3340706f4b16] Successfully joined group with generation 1
2020-01-07 19:13:19 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-176, groupId=5c880edb-0df3-4eb4-9456-3340706f4b16] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:19 INFO  Fetcher:583 - [Consumer clientId=consumer-176, groupId=5c880edb-0df3-4eb4-9456-3340706f4b16] Resetting offset for partition facedetectiontest101-0 to offset 17662.
2020-01-07 19:13:19 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2547b9d7-ff81-44b7-a116-ebed91756198
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:19 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:19 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:19 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:19 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-177, groupId=2547b9d7-ff81-44b7-a116-ebed91756198] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:19 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-177, groupId=2547b9d7-ff81-44b7-a116-ebed91756198] Revoking previously assigned partitions []
2020-01-07 19:13:19 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-177, groupId=2547b9d7-ff81-44b7-a116-ebed91756198] (Re-)joining group
2020-01-07 19:13:19 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-177, groupId=2547b9d7-ff81-44b7-a116-ebed91756198] Successfully joined group with generation 1
2020-01-07 19:13:19 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-177, groupId=2547b9d7-ff81-44b7-a116-ebed91756198] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:19 INFO  Fetcher:583 - [Consumer clientId=consumer-177, groupId=2547b9d7-ff81-44b7-a116-ebed91756198] Resetting offset for partition facedetectiontest101-0 to offset 17663.
2020-01-07 19:13:19 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1f959eeb-5c20-432c-8ae9-d8af3e5b1924
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:19 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:19 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:19 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:19 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-178, groupId=1f959eeb-5c20-432c-8ae9-d8af3e5b1924] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:19 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-178, groupId=1f959eeb-5c20-432c-8ae9-d8af3e5b1924] Revoking previously assigned partitions []
2020-01-07 19:13:19 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-178, groupId=1f959eeb-5c20-432c-8ae9-d8af3e5b1924] (Re-)joining group
2020-01-07 19:13:19 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-178, groupId=1f959eeb-5c20-432c-8ae9-d8af3e5b1924] Successfully joined group with generation 1
2020-01-07 19:13:19 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-178, groupId=1f959eeb-5c20-432c-8ae9-d8af3e5b1924] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:19 INFO  Fetcher:583 - [Consumer clientId=consumer-178, groupId=1f959eeb-5c20-432c-8ae9-d8af3e5b1924] Resetting offset for partition facedetectiontest101-0 to offset 17664.
2020-01-07 19:13:19 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8c8bb57b-04b7-4370-8eae-6977ce526818
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:19 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:19 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:19 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:19 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-179, groupId=8c8bb57b-04b7-4370-8eae-6977ce526818] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:19 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-179, groupId=8c8bb57b-04b7-4370-8eae-6977ce526818] Revoking previously assigned partitions []
2020-01-07 19:13:19 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-179, groupId=8c8bb57b-04b7-4370-8eae-6977ce526818] (Re-)joining group
2020-01-07 19:13:19 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-179, groupId=8c8bb57b-04b7-4370-8eae-6977ce526818] Successfully joined group with generation 1
2020-01-07 19:13:19 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-179, groupId=8c8bb57b-04b7-4370-8eae-6977ce526818] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:19 INFO  Fetcher:583 - [Consumer clientId=consumer-179, groupId=8c8bb57b-04b7-4370-8eae-6977ce526818] Resetting offset for partition facedetectiontest101-0 to offset 17665.
2020-01-07 19:13:19 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7242706f-722a-4997-b261-6b54595747ee
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:19 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:19 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:19 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:19 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-180, groupId=7242706f-722a-4997-b261-6b54595747ee] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:19 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-180, groupId=7242706f-722a-4997-b261-6b54595747ee] Revoking previously assigned partitions []
2020-01-07 19:13:19 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-180, groupId=7242706f-722a-4997-b261-6b54595747ee] (Re-)joining group
2020-01-07 19:13:19 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-180, groupId=7242706f-722a-4997-b261-6b54595747ee] Successfully joined group with generation 1
2020-01-07 19:13:19 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-180, groupId=7242706f-722a-4997-b261-6b54595747ee] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:19 INFO  Fetcher:583 - [Consumer clientId=consumer-180, groupId=7242706f-722a-4997-b261-6b54595747ee] Resetting offset for partition facedetectiontest101-0 to offset 17666.
2020-01-07 19:13:19 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c35474bd-e45d-4883-990d-2fd12a3a23f8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:19 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:19 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:19 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:19 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-181, groupId=c35474bd-e45d-4883-990d-2fd12a3a23f8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:19 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-181, groupId=c35474bd-e45d-4883-990d-2fd12a3a23f8] Revoking previously assigned partitions []
2020-01-07 19:13:19 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-181, groupId=c35474bd-e45d-4883-990d-2fd12a3a23f8] (Re-)joining group
2020-01-07 19:13:19 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-181, groupId=c35474bd-e45d-4883-990d-2fd12a3a23f8] Successfully joined group with generation 1
2020-01-07 19:13:19 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-181, groupId=c35474bd-e45d-4883-990d-2fd12a3a23f8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:19 INFO  Fetcher:583 - [Consumer clientId=consumer-181, groupId=c35474bd-e45d-4883-990d-2fd12a3a23f8] Resetting offset for partition facedetectiontest101-0 to offset 17667.
2020-01-07 19:13:19 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f4cf0f86-6c82-499a-a026-ff7ab78d8682
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:19 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:19 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:19 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:19 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-182, groupId=f4cf0f86-6c82-499a-a026-ff7ab78d8682] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:19 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-182, groupId=f4cf0f86-6c82-499a-a026-ff7ab78d8682] Revoking previously assigned partitions []
2020-01-07 19:13:19 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-182, groupId=f4cf0f86-6c82-499a-a026-ff7ab78d8682] (Re-)joining group
2020-01-07 19:13:19 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-182, groupId=f4cf0f86-6c82-499a-a026-ff7ab78d8682] Successfully joined group with generation 1
2020-01-07 19:13:19 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-182, groupId=f4cf0f86-6c82-499a-a026-ff7ab78d8682] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:19 INFO  Fetcher:583 - [Consumer clientId=consumer-182, groupId=f4cf0f86-6c82-499a-a026-ff7ab78d8682] Resetting offset for partition facedetectiontest101-0 to offset 17668.
2020-01-07 19:13:19 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3087ba22-b495-4ba3-95f7-1a20753e8ebf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:19 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:19 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:19 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:19 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-183, groupId=3087ba22-b495-4ba3-95f7-1a20753e8ebf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:19 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-183, groupId=3087ba22-b495-4ba3-95f7-1a20753e8ebf] Revoking previously assigned partitions []
2020-01-07 19:13:19 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-183, groupId=3087ba22-b495-4ba3-95f7-1a20753e8ebf] (Re-)joining group
2020-01-07 19:13:19 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-183, groupId=3087ba22-b495-4ba3-95f7-1a20753e8ebf] Successfully joined group with generation 1
2020-01-07 19:13:19 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-183, groupId=3087ba22-b495-4ba3-95f7-1a20753e8ebf] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:19 INFO  Fetcher:583 - [Consumer clientId=consumer-183, groupId=3087ba22-b495-4ba3-95f7-1a20753e8ebf] Resetting offset for partition facedetectiontest101-0 to offset 17669.
2020-01-07 19:13:19 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 861343ee-7eea-410d-81db-ba97d01ddcf9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:19 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:19 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:19 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:19 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-184, groupId=861343ee-7eea-410d-81db-ba97d01ddcf9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:19 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-184, groupId=861343ee-7eea-410d-81db-ba97d01ddcf9] Revoking previously assigned partitions []
2020-01-07 19:13:19 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-184, groupId=861343ee-7eea-410d-81db-ba97d01ddcf9] (Re-)joining group
2020-01-07 19:13:19 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-184, groupId=861343ee-7eea-410d-81db-ba97d01ddcf9] Successfully joined group with generation 1
2020-01-07 19:13:19 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-184, groupId=861343ee-7eea-410d-81db-ba97d01ddcf9] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:19 INFO  Fetcher:583 - [Consumer clientId=consumer-184, groupId=861343ee-7eea-410d-81db-ba97d01ddcf9] Resetting offset for partition facedetectiontest101-0 to offset 17670.
2020-01-07 19:13:19 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = cb51ba92-3e3c-48e3-bb8c-3e9b1fa4a3a3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:19 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:19 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:19 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:19 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-185, groupId=cb51ba92-3e3c-48e3-bb8c-3e9b1fa4a3a3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:19 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-185, groupId=cb51ba92-3e3c-48e3-bb8c-3e9b1fa4a3a3] Revoking previously assigned partitions []
2020-01-07 19:13:19 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-185, groupId=cb51ba92-3e3c-48e3-bb8c-3e9b1fa4a3a3] (Re-)joining group
2020-01-07 19:13:19 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-185, groupId=cb51ba92-3e3c-48e3-bb8c-3e9b1fa4a3a3] Successfully joined group with generation 1
2020-01-07 19:13:19 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-185, groupId=cb51ba92-3e3c-48e3-bb8c-3e9b1fa4a3a3] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:19 INFO  Fetcher:583 - [Consumer clientId=consumer-185, groupId=cb51ba92-3e3c-48e3-bb8c-3e9b1fa4a3a3] Resetting offset for partition facedetectiontest101-0 to offset 17671.
2020-01-07 19:13:19 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = aad15458-7ef2-4d7e-89f3-85636b6ec639
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:19 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:19 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:19 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:19 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-186, groupId=aad15458-7ef2-4d7e-89f3-85636b6ec639] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:19 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-186, groupId=aad15458-7ef2-4d7e-89f3-85636b6ec639] Revoking previously assigned partitions []
2020-01-07 19:13:19 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-186, groupId=aad15458-7ef2-4d7e-89f3-85636b6ec639] (Re-)joining group
2020-01-07 19:13:19 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-186, groupId=aad15458-7ef2-4d7e-89f3-85636b6ec639] Successfully joined group with generation 1
2020-01-07 19:13:19 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-186, groupId=aad15458-7ef2-4d7e-89f3-85636b6ec639] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:19 INFO  Fetcher:583 - [Consumer clientId=consumer-186, groupId=aad15458-7ef2-4d7e-89f3-85636b6ec639] Resetting offset for partition facedetectiontest101-0 to offset 17672.
2020-01-07 19:13:19 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 051b684f-9ef8-4515-9104-41550fa225cb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:19 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:19 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:19 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:19 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-187, groupId=051b684f-9ef8-4515-9104-41550fa225cb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:19 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-187, groupId=051b684f-9ef8-4515-9104-41550fa225cb] Revoking previously assigned partitions []
2020-01-07 19:13:19 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-187, groupId=051b684f-9ef8-4515-9104-41550fa225cb] (Re-)joining group
2020-01-07 19:13:20 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-187, groupId=051b684f-9ef8-4515-9104-41550fa225cb] Successfully joined group with generation 1
2020-01-07 19:13:20 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-187, groupId=051b684f-9ef8-4515-9104-41550fa225cb] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:20 INFO  Fetcher:583 - [Consumer clientId=consumer-187, groupId=051b684f-9ef8-4515-9104-41550fa225cb] Resetting offset for partition facedetectiontest101-0 to offset 17673.
2020-01-07 19:13:20 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4ad40c20-ce8a-4119-af0b-d3f49c88406e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:20 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:20 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:20 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:20 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-188, groupId=4ad40c20-ce8a-4119-af0b-d3f49c88406e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:20 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-188, groupId=4ad40c20-ce8a-4119-af0b-d3f49c88406e] Revoking previously assigned partitions []
2020-01-07 19:13:20 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-188, groupId=4ad40c20-ce8a-4119-af0b-d3f49c88406e] (Re-)joining group
2020-01-07 19:13:20 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-188, groupId=4ad40c20-ce8a-4119-af0b-d3f49c88406e] Successfully joined group with generation 1
2020-01-07 19:13:20 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-188, groupId=4ad40c20-ce8a-4119-af0b-d3f49c88406e] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:20 INFO  Fetcher:583 - [Consumer clientId=consumer-188, groupId=4ad40c20-ce8a-4119-af0b-d3f49c88406e] Resetting offset for partition facedetectiontest101-0 to offset 17674.
2020-01-07 19:13:20 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9714ba5d-e012-4d7c-8cc3-7c68e8e1335b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:20 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:20 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:20 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:20 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-189, groupId=9714ba5d-e012-4d7c-8cc3-7c68e8e1335b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:20 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-189, groupId=9714ba5d-e012-4d7c-8cc3-7c68e8e1335b] Revoking previously assigned partitions []
2020-01-07 19:13:20 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-189, groupId=9714ba5d-e012-4d7c-8cc3-7c68e8e1335b] (Re-)joining group
2020-01-07 19:13:20 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-189, groupId=9714ba5d-e012-4d7c-8cc3-7c68e8e1335b] Successfully joined group with generation 1
2020-01-07 19:13:20 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-189, groupId=9714ba5d-e012-4d7c-8cc3-7c68e8e1335b] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:20 INFO  Fetcher:583 - [Consumer clientId=consumer-189, groupId=9714ba5d-e012-4d7c-8cc3-7c68e8e1335b] Resetting offset for partition facedetectiontest101-0 to offset 17675.
2020-01-07 19:13:20 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = aed17548-dd8e-4651-8b46-659065305c70
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:20 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:20 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:20 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:20 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-190, groupId=aed17548-dd8e-4651-8b46-659065305c70] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:20 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-190, groupId=aed17548-dd8e-4651-8b46-659065305c70] Revoking previously assigned partitions []
2020-01-07 19:13:20 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-190, groupId=aed17548-dd8e-4651-8b46-659065305c70] (Re-)joining group
2020-01-07 19:13:20 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-190, groupId=aed17548-dd8e-4651-8b46-659065305c70] Successfully joined group with generation 1
2020-01-07 19:13:20 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-190, groupId=aed17548-dd8e-4651-8b46-659065305c70] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:20 INFO  Fetcher:583 - [Consumer clientId=consumer-190, groupId=aed17548-dd8e-4651-8b46-659065305c70] Resetting offset for partition facedetectiontest101-0 to offset 17676.
2020-01-07 19:13:20 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 10f7edc9-a7f7-4324-8085-0167e69f8b5d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:20 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:20 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:20 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:20 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-191, groupId=10f7edc9-a7f7-4324-8085-0167e69f8b5d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:20 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-191, groupId=10f7edc9-a7f7-4324-8085-0167e69f8b5d] Revoking previously assigned partitions []
2020-01-07 19:13:20 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-191, groupId=10f7edc9-a7f7-4324-8085-0167e69f8b5d] (Re-)joining group
2020-01-07 19:13:20 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-191, groupId=10f7edc9-a7f7-4324-8085-0167e69f8b5d] Successfully joined group with generation 1
2020-01-07 19:13:20 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-191, groupId=10f7edc9-a7f7-4324-8085-0167e69f8b5d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:20 INFO  Fetcher:583 - [Consumer clientId=consumer-191, groupId=10f7edc9-a7f7-4324-8085-0167e69f8b5d] Resetting offset for partition facedetectiontest101-0 to offset 17677.
2020-01-07 19:13:20 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d6ffff3c-aefc-4857-bdfe-a8d98ef57b37
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:20 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:20 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:20 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:20 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-192, groupId=d6ffff3c-aefc-4857-bdfe-a8d98ef57b37] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:20 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-192, groupId=d6ffff3c-aefc-4857-bdfe-a8d98ef57b37] Revoking previously assigned partitions []
2020-01-07 19:13:20 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-192, groupId=d6ffff3c-aefc-4857-bdfe-a8d98ef57b37] (Re-)joining group
2020-01-07 19:13:20 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-192, groupId=d6ffff3c-aefc-4857-bdfe-a8d98ef57b37] Successfully joined group with generation 1
2020-01-07 19:13:20 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-192, groupId=d6ffff3c-aefc-4857-bdfe-a8d98ef57b37] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:20 INFO  Fetcher:583 - [Consumer clientId=consumer-192, groupId=d6ffff3c-aefc-4857-bdfe-a8d98ef57b37] Resetting offset for partition facedetectiontest101-0 to offset 17678.
2020-01-07 19:13:20 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d14faab0-eef6-448d-adb5-678485956e66
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:20 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:20 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:20 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:20 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-193, groupId=d14faab0-eef6-448d-adb5-678485956e66] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:20 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-193, groupId=d14faab0-eef6-448d-adb5-678485956e66] Revoking previously assigned partitions []
2020-01-07 19:13:20 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-193, groupId=d14faab0-eef6-448d-adb5-678485956e66] (Re-)joining group
2020-01-07 19:13:20 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-193, groupId=d14faab0-eef6-448d-adb5-678485956e66] Successfully joined group with generation 1
2020-01-07 19:13:20 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-193, groupId=d14faab0-eef6-448d-adb5-678485956e66] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:20 INFO  Fetcher:583 - [Consumer clientId=consumer-193, groupId=d14faab0-eef6-448d-adb5-678485956e66] Resetting offset for partition facedetectiontest101-0 to offset 17679.
2020-01-07 19:13:20 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 42425f09-8ae7-4f90-add5-6efa4b3edf26
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:20 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:20 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:20 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:20 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-194, groupId=42425f09-8ae7-4f90-add5-6efa4b3edf26] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:20 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-194, groupId=42425f09-8ae7-4f90-add5-6efa4b3edf26] Revoking previously assigned partitions []
2020-01-07 19:13:20 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-194, groupId=42425f09-8ae7-4f90-add5-6efa4b3edf26] (Re-)joining group
2020-01-07 19:13:20 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-194, groupId=42425f09-8ae7-4f90-add5-6efa4b3edf26] Successfully joined group with generation 1
2020-01-07 19:13:20 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-194, groupId=42425f09-8ae7-4f90-add5-6efa4b3edf26] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:20 INFO  Fetcher:583 - [Consumer clientId=consumer-194, groupId=42425f09-8ae7-4f90-add5-6efa4b3edf26] Resetting offset for partition facedetectiontest101-0 to offset 17680.
2020-01-07 19:13:20 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e7a43e20-69df-4a85-868a-7d50a28812c9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:20 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:20 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:20 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:20 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-195, groupId=e7a43e20-69df-4a85-868a-7d50a28812c9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:20 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-195, groupId=e7a43e20-69df-4a85-868a-7d50a28812c9] Revoking previously assigned partitions []
2020-01-07 19:13:20 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-195, groupId=e7a43e20-69df-4a85-868a-7d50a28812c9] (Re-)joining group
2020-01-07 19:13:20 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-195, groupId=e7a43e20-69df-4a85-868a-7d50a28812c9] Successfully joined group with generation 1
2020-01-07 19:13:20 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-195, groupId=e7a43e20-69df-4a85-868a-7d50a28812c9] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:20 INFO  Fetcher:583 - [Consumer clientId=consumer-195, groupId=e7a43e20-69df-4a85-868a-7d50a28812c9] Resetting offset for partition facedetectiontest101-0 to offset 17681.
2020-01-07 19:13:21 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 747d2d86-945d-4abc-8453-0455409256fb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:21 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:21 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:21 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:21 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-196, groupId=747d2d86-945d-4abc-8453-0455409256fb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:21 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-196, groupId=747d2d86-945d-4abc-8453-0455409256fb] Revoking previously assigned partitions []
2020-01-07 19:13:21 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-196, groupId=747d2d86-945d-4abc-8453-0455409256fb] (Re-)joining group
2020-01-07 19:13:21 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-196, groupId=747d2d86-945d-4abc-8453-0455409256fb] Successfully joined group with generation 1
2020-01-07 19:13:21 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-196, groupId=747d2d86-945d-4abc-8453-0455409256fb] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:21 INFO  Fetcher:583 - [Consumer clientId=consumer-196, groupId=747d2d86-945d-4abc-8453-0455409256fb] Resetting offset for partition facedetectiontest101-0 to offset 17682.
2020-01-07 19:13:21 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 53546703-d515-4b85-8e3e-8e5d9395cbc1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:21 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:21 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:21 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:21 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-197, groupId=53546703-d515-4b85-8e3e-8e5d9395cbc1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:21 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-197, groupId=53546703-d515-4b85-8e3e-8e5d9395cbc1] Revoking previously assigned partitions []
2020-01-07 19:13:21 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-197, groupId=53546703-d515-4b85-8e3e-8e5d9395cbc1] (Re-)joining group
2020-01-07 19:13:21 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-197, groupId=53546703-d515-4b85-8e3e-8e5d9395cbc1] Successfully joined group with generation 1
2020-01-07 19:13:21 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-197, groupId=53546703-d515-4b85-8e3e-8e5d9395cbc1] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:21 INFO  Fetcher:583 - [Consumer clientId=consumer-197, groupId=53546703-d515-4b85-8e3e-8e5d9395cbc1] Resetting offset for partition facedetectiontest101-0 to offset 17683.
2020-01-07 19:13:21 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5ea061b3-79b7-400c-884f-6f7787810d42
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:21 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:21 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:21 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:21 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-198, groupId=5ea061b3-79b7-400c-884f-6f7787810d42] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:21 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-198, groupId=5ea061b3-79b7-400c-884f-6f7787810d42] Revoking previously assigned partitions []
2020-01-07 19:13:21 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-198, groupId=5ea061b3-79b7-400c-884f-6f7787810d42] (Re-)joining group
2020-01-07 19:13:21 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-198, groupId=5ea061b3-79b7-400c-884f-6f7787810d42] Successfully joined group with generation 1
2020-01-07 19:13:21 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-198, groupId=5ea061b3-79b7-400c-884f-6f7787810d42] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:21 INFO  Fetcher:583 - [Consumer clientId=consumer-198, groupId=5ea061b3-79b7-400c-884f-6f7787810d42] Resetting offset for partition facedetectiontest101-0 to offset 17684.
2020-01-07 19:13:21 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 031e845e-f54f-41a7-ae4c-ba5bf7fd8004
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:21 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:21 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:21 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:21 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-199, groupId=031e845e-f54f-41a7-ae4c-ba5bf7fd8004] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:21 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-199, groupId=031e845e-f54f-41a7-ae4c-ba5bf7fd8004] Revoking previously assigned partitions []
2020-01-07 19:13:21 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-199, groupId=031e845e-f54f-41a7-ae4c-ba5bf7fd8004] (Re-)joining group
2020-01-07 19:13:21 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-199, groupId=031e845e-f54f-41a7-ae4c-ba5bf7fd8004] Successfully joined group with generation 1
2020-01-07 19:13:21 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-199, groupId=031e845e-f54f-41a7-ae4c-ba5bf7fd8004] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:21 INFO  Fetcher:583 - [Consumer clientId=consumer-199, groupId=031e845e-f54f-41a7-ae4c-ba5bf7fd8004] Resetting offset for partition facedetectiontest101-0 to offset 17685.
2020-01-07 19:13:21 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e114c876-dacd-4b7b-9483-a42a74de7e08
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:21 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:21 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:21 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:21 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-200, groupId=e114c876-dacd-4b7b-9483-a42a74de7e08] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:21 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-200, groupId=e114c876-dacd-4b7b-9483-a42a74de7e08] Revoking previously assigned partitions []
2020-01-07 19:13:21 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-200, groupId=e114c876-dacd-4b7b-9483-a42a74de7e08] (Re-)joining group
2020-01-07 19:13:21 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-200, groupId=e114c876-dacd-4b7b-9483-a42a74de7e08] Successfully joined group with generation 1
2020-01-07 19:13:21 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-200, groupId=e114c876-dacd-4b7b-9483-a42a74de7e08] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:21 INFO  Fetcher:583 - [Consumer clientId=consumer-200, groupId=e114c876-dacd-4b7b-9483-a42a74de7e08] Resetting offset for partition facedetectiontest101-0 to offset 17686.
2020-01-07 19:13:21 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 81a4a327-7c9a-4529-9540-b85f2e0cf9c4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:21 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:21 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:21 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:21 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-201, groupId=81a4a327-7c9a-4529-9540-b85f2e0cf9c4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:21 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-201, groupId=81a4a327-7c9a-4529-9540-b85f2e0cf9c4] Revoking previously assigned partitions []
2020-01-07 19:13:21 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-201, groupId=81a4a327-7c9a-4529-9540-b85f2e0cf9c4] (Re-)joining group
2020-01-07 19:13:21 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-201, groupId=81a4a327-7c9a-4529-9540-b85f2e0cf9c4] Successfully joined group with generation 1
2020-01-07 19:13:21 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-201, groupId=81a4a327-7c9a-4529-9540-b85f2e0cf9c4] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:21 INFO  Fetcher:583 - [Consumer clientId=consumer-201, groupId=81a4a327-7c9a-4529-9540-b85f2e0cf9c4] Resetting offset for partition facedetectiontest101-0 to offset 17688.
2020-01-07 19:13:21 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 65e1bf0b-67ce-49e0-9664-d5632993deea
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:21 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:21 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:21 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:21 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-202, groupId=65e1bf0b-67ce-49e0-9664-d5632993deea] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:21 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-202, groupId=65e1bf0b-67ce-49e0-9664-d5632993deea] Revoking previously assigned partitions []
2020-01-07 19:13:21 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-202, groupId=65e1bf0b-67ce-49e0-9664-d5632993deea] (Re-)joining group
2020-01-07 19:13:21 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-202, groupId=65e1bf0b-67ce-49e0-9664-d5632993deea] Successfully joined group with generation 1
2020-01-07 19:13:21 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-202, groupId=65e1bf0b-67ce-49e0-9664-d5632993deea] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:21 INFO  Fetcher:583 - [Consumer clientId=consumer-202, groupId=65e1bf0b-67ce-49e0-9664-d5632993deea] Resetting offset for partition facedetectiontest101-0 to offset 17689.
2020-01-07 19:13:21 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8366e544-bc70-4d58-9d53-db1fb06a942b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:21 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:21 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:21 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:21 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-203, groupId=8366e544-bc70-4d58-9d53-db1fb06a942b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:21 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-203, groupId=8366e544-bc70-4d58-9d53-db1fb06a942b] Revoking previously assigned partitions []
2020-01-07 19:13:21 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-203, groupId=8366e544-bc70-4d58-9d53-db1fb06a942b] (Re-)joining group
2020-01-07 19:13:21 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-203, groupId=8366e544-bc70-4d58-9d53-db1fb06a942b] Successfully joined group with generation 1
2020-01-07 19:13:21 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-203, groupId=8366e544-bc70-4d58-9d53-db1fb06a942b] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:21 INFO  Fetcher:583 - [Consumer clientId=consumer-203, groupId=8366e544-bc70-4d58-9d53-db1fb06a942b] Resetting offset for partition facedetectiontest101-0 to offset 17690.
2020-01-07 19:13:21 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 940392e0-1aec-4e45-9129-e688d6bd0585
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:21 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:21 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:21 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:21 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-204, groupId=940392e0-1aec-4e45-9129-e688d6bd0585] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:21 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-204, groupId=940392e0-1aec-4e45-9129-e688d6bd0585] Revoking previously assigned partitions []
2020-01-07 19:13:21 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-204, groupId=940392e0-1aec-4e45-9129-e688d6bd0585] (Re-)joining group
2020-01-07 19:13:21 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-204, groupId=940392e0-1aec-4e45-9129-e688d6bd0585] Successfully joined group with generation 1
2020-01-07 19:13:21 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-204, groupId=940392e0-1aec-4e45-9129-e688d6bd0585] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:21 INFO  Fetcher:583 - [Consumer clientId=consumer-204, groupId=940392e0-1aec-4e45-9129-e688d6bd0585] Resetting offset for partition facedetectiontest101-0 to offset 17692.
2020-01-07 19:13:21 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 52bab266-1891-4bd7-a4d2-4947e2538ee9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:21 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:21 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:21 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:21 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-205, groupId=52bab266-1891-4bd7-a4d2-4947e2538ee9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:21 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-205, groupId=52bab266-1891-4bd7-a4d2-4947e2538ee9] Revoking previously assigned partitions []
2020-01-07 19:13:21 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-205, groupId=52bab266-1891-4bd7-a4d2-4947e2538ee9] (Re-)joining group
2020-01-07 19:13:21 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-205, groupId=52bab266-1891-4bd7-a4d2-4947e2538ee9] Successfully joined group with generation 1
2020-01-07 19:13:21 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-205, groupId=52bab266-1891-4bd7-a4d2-4947e2538ee9] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:21 INFO  Fetcher:583 - [Consumer clientId=consumer-205, groupId=52bab266-1891-4bd7-a4d2-4947e2538ee9] Resetting offset for partition facedetectiontest101-0 to offset 17693.
2020-01-07 19:13:22 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 86a4e222-5f05-43f3-bc7c-b83987e59ba2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:22 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:22 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:22 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:22 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-206, groupId=86a4e222-5f05-43f3-bc7c-b83987e59ba2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:22 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-206, groupId=86a4e222-5f05-43f3-bc7c-b83987e59ba2] Revoking previously assigned partitions []
2020-01-07 19:13:22 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-206, groupId=86a4e222-5f05-43f3-bc7c-b83987e59ba2] (Re-)joining group
2020-01-07 19:13:22 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-206, groupId=86a4e222-5f05-43f3-bc7c-b83987e59ba2] Successfully joined group with generation 1
2020-01-07 19:13:22 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-206, groupId=86a4e222-5f05-43f3-bc7c-b83987e59ba2] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:22 INFO  Fetcher:583 - [Consumer clientId=consumer-206, groupId=86a4e222-5f05-43f3-bc7c-b83987e59ba2] Resetting offset for partition facedetectiontest101-0 to offset 17695.
2020-01-07 19:13:22 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = bae665fb-97c9-46d5-9a8e-53c96b986394
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:22 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:22 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:22 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:22 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-207, groupId=bae665fb-97c9-46d5-9a8e-53c96b986394] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:22 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-207, groupId=bae665fb-97c9-46d5-9a8e-53c96b986394] Revoking previously assigned partitions []
2020-01-07 19:13:22 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-207, groupId=bae665fb-97c9-46d5-9a8e-53c96b986394] (Re-)joining group
2020-01-07 19:13:22 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-207, groupId=bae665fb-97c9-46d5-9a8e-53c96b986394] Successfully joined group with generation 1
2020-01-07 19:13:22 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-207, groupId=bae665fb-97c9-46d5-9a8e-53c96b986394] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:22 INFO  Fetcher:583 - [Consumer clientId=consumer-207, groupId=bae665fb-97c9-46d5-9a8e-53c96b986394] Resetting offset for partition facedetectiontest101-0 to offset 17696.
2020-01-07 19:13:22 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d46fb6c0-ffb2-4bee-a9d9-eebcb51ea7a6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:22 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:22 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:22 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:22 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-208, groupId=d46fb6c0-ffb2-4bee-a9d9-eebcb51ea7a6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:22 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-208, groupId=d46fb6c0-ffb2-4bee-a9d9-eebcb51ea7a6] Revoking previously assigned partitions []
2020-01-07 19:13:22 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-208, groupId=d46fb6c0-ffb2-4bee-a9d9-eebcb51ea7a6] (Re-)joining group
2020-01-07 19:13:22 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-208, groupId=d46fb6c0-ffb2-4bee-a9d9-eebcb51ea7a6] Successfully joined group with generation 1
2020-01-07 19:13:22 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-208, groupId=d46fb6c0-ffb2-4bee-a9d9-eebcb51ea7a6] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:22 INFO  Fetcher:583 - [Consumer clientId=consumer-208, groupId=d46fb6c0-ffb2-4bee-a9d9-eebcb51ea7a6] Resetting offset for partition facedetectiontest101-0 to offset 17697.
2020-01-07 19:13:22 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0645a0ba-1732-4484-9373-8049d280d7f8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:22 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:22 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:22 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:22 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-209, groupId=0645a0ba-1732-4484-9373-8049d280d7f8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:22 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-209, groupId=0645a0ba-1732-4484-9373-8049d280d7f8] Revoking previously assigned partitions []
2020-01-07 19:13:22 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-209, groupId=0645a0ba-1732-4484-9373-8049d280d7f8] (Re-)joining group
2020-01-07 19:13:22 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-209, groupId=0645a0ba-1732-4484-9373-8049d280d7f8] Successfully joined group with generation 1
2020-01-07 19:13:22 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-209, groupId=0645a0ba-1732-4484-9373-8049d280d7f8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:22 INFO  Fetcher:583 - [Consumer clientId=consumer-209, groupId=0645a0ba-1732-4484-9373-8049d280d7f8] Resetting offset for partition facedetectiontest101-0 to offset 17698.
2020-01-07 19:13:22 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8a92b853-5827-4a5c-9b64-f0b931a870ae
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:22 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:22 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:22 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:22 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-210, groupId=8a92b853-5827-4a5c-9b64-f0b931a870ae] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:22 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-210, groupId=8a92b853-5827-4a5c-9b64-f0b931a870ae] Revoking previously assigned partitions []
2020-01-07 19:13:22 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-210, groupId=8a92b853-5827-4a5c-9b64-f0b931a870ae] (Re-)joining group
2020-01-07 19:13:22 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-210, groupId=8a92b853-5827-4a5c-9b64-f0b931a870ae] Successfully joined group with generation 1
2020-01-07 19:13:22 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-210, groupId=8a92b853-5827-4a5c-9b64-f0b931a870ae] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:22 INFO  Fetcher:583 - [Consumer clientId=consumer-210, groupId=8a92b853-5827-4a5c-9b64-f0b931a870ae] Resetting offset for partition facedetectiontest101-0 to offset 17700.
2020-01-07 19:13:22 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 547054ed-d1fb-42b1-94e9-5c4fef99c024
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:22 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:22 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:22 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:22 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-211, groupId=547054ed-d1fb-42b1-94e9-5c4fef99c024] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:22 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-211, groupId=547054ed-d1fb-42b1-94e9-5c4fef99c024] Revoking previously assigned partitions []
2020-01-07 19:13:22 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-211, groupId=547054ed-d1fb-42b1-94e9-5c4fef99c024] (Re-)joining group
2020-01-07 19:13:22 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-211, groupId=547054ed-d1fb-42b1-94e9-5c4fef99c024] Successfully joined group with generation 1
2020-01-07 19:13:22 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-211, groupId=547054ed-d1fb-42b1-94e9-5c4fef99c024] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:22 INFO  Fetcher:583 - [Consumer clientId=consumer-211, groupId=547054ed-d1fb-42b1-94e9-5c4fef99c024] Resetting offset for partition facedetectiontest101-0 to offset 17701.
2020-01-07 19:13:22 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6cba3f9a-3066-4541-a323-5c1dbf64b53b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:22 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:22 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:22 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:22 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-212, groupId=6cba3f9a-3066-4541-a323-5c1dbf64b53b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:22 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-212, groupId=6cba3f9a-3066-4541-a323-5c1dbf64b53b] Revoking previously assigned partitions []
2020-01-07 19:13:22 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-212, groupId=6cba3f9a-3066-4541-a323-5c1dbf64b53b] (Re-)joining group
2020-01-07 19:13:22 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-212, groupId=6cba3f9a-3066-4541-a323-5c1dbf64b53b] Successfully joined group with generation 1
2020-01-07 19:13:22 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-212, groupId=6cba3f9a-3066-4541-a323-5c1dbf64b53b] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:22 INFO  Fetcher:583 - [Consumer clientId=consumer-212, groupId=6cba3f9a-3066-4541-a323-5c1dbf64b53b] Resetting offset for partition facedetectiontest101-0 to offset 17703.
2020-01-07 19:13:22 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ec2e406a-a212-47bb-824c-32ce59850d60
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:22 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:22 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:22 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:22 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-213, groupId=ec2e406a-a212-47bb-824c-32ce59850d60] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:22 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-213, groupId=ec2e406a-a212-47bb-824c-32ce59850d60] Revoking previously assigned partitions []
2020-01-07 19:13:22 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-213, groupId=ec2e406a-a212-47bb-824c-32ce59850d60] (Re-)joining group
2020-01-07 19:13:22 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-213, groupId=ec2e406a-a212-47bb-824c-32ce59850d60] Successfully joined group with generation 1
2020-01-07 19:13:22 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-213, groupId=ec2e406a-a212-47bb-824c-32ce59850d60] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:22 INFO  Fetcher:583 - [Consumer clientId=consumer-213, groupId=ec2e406a-a212-47bb-824c-32ce59850d60] Resetting offset for partition facedetectiontest101-0 to offset 17704.
2020-01-07 19:13:22 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a03b09a6-32f4-4110-b7d4-ff808bdfe7c4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:22 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:22 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:22 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:22 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-214, groupId=a03b09a6-32f4-4110-b7d4-ff808bdfe7c4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:22 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-214, groupId=a03b09a6-32f4-4110-b7d4-ff808bdfe7c4] Revoking previously assigned partitions []
2020-01-07 19:13:22 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-214, groupId=a03b09a6-32f4-4110-b7d4-ff808bdfe7c4] (Re-)joining group
2020-01-07 19:13:22 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-214, groupId=a03b09a6-32f4-4110-b7d4-ff808bdfe7c4] Successfully joined group with generation 1
2020-01-07 19:13:22 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-214, groupId=a03b09a6-32f4-4110-b7d4-ff808bdfe7c4] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:22 INFO  Fetcher:583 - [Consumer clientId=consumer-214, groupId=a03b09a6-32f4-4110-b7d4-ff808bdfe7c4] Resetting offset for partition facedetectiontest101-0 to offset 17705.
2020-01-07 19:13:22 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6d85e345-f2df-4b6f-bd89-088efbc8a4fe
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:22 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:22 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:22 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:22 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-215, groupId=6d85e345-f2df-4b6f-bd89-088efbc8a4fe] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:22 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-215, groupId=6d85e345-f2df-4b6f-bd89-088efbc8a4fe] Revoking previously assigned partitions []
2020-01-07 19:13:22 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-215, groupId=6d85e345-f2df-4b6f-bd89-088efbc8a4fe] (Re-)joining group
2020-01-07 19:13:22 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-215, groupId=6d85e345-f2df-4b6f-bd89-088efbc8a4fe] Successfully joined group with generation 1
2020-01-07 19:13:22 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-215, groupId=6d85e345-f2df-4b6f-bd89-088efbc8a4fe] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:22 INFO  Fetcher:583 - [Consumer clientId=consumer-215, groupId=6d85e345-f2df-4b6f-bd89-088efbc8a4fe] Resetting offset for partition facedetectiontest101-0 to offset 17706.
2020-01-07 19:13:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 28f17cba-6d04-46aa-907c-977093404026
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-216, groupId=28f17cba-6d04-46aa-907c-977093404026] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-216, groupId=28f17cba-6d04-46aa-907c-977093404026] Revoking previously assigned partitions []
2020-01-07 19:13:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-216, groupId=28f17cba-6d04-46aa-907c-977093404026] (Re-)joining group
2020-01-07 19:13:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-216, groupId=28f17cba-6d04-46aa-907c-977093404026] Successfully joined group with generation 1
2020-01-07 19:13:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-216, groupId=28f17cba-6d04-46aa-907c-977093404026] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:23 INFO  Fetcher:583 - [Consumer clientId=consumer-216, groupId=28f17cba-6d04-46aa-907c-977093404026] Resetting offset for partition facedetectiontest101-0 to offset 17708.
2020-01-07 19:13:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3fe9a1be-e998-43f0-9fe3-60396ce6da90
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-217, groupId=3fe9a1be-e998-43f0-9fe3-60396ce6da90] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-217, groupId=3fe9a1be-e998-43f0-9fe3-60396ce6da90] Revoking previously assigned partitions []
2020-01-07 19:13:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-217, groupId=3fe9a1be-e998-43f0-9fe3-60396ce6da90] (Re-)joining group
2020-01-07 19:13:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-217, groupId=3fe9a1be-e998-43f0-9fe3-60396ce6da90] Successfully joined group with generation 1
2020-01-07 19:13:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-217, groupId=3fe9a1be-e998-43f0-9fe3-60396ce6da90] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:23 INFO  Fetcher:583 - [Consumer clientId=consumer-217, groupId=3fe9a1be-e998-43f0-9fe3-60396ce6da90] Resetting offset for partition facedetectiontest101-0 to offset 17709.
2020-01-07 19:13:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1ff06445-0e47-478b-84e8-6a63133d1f50
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-218, groupId=1ff06445-0e47-478b-84e8-6a63133d1f50] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-218, groupId=1ff06445-0e47-478b-84e8-6a63133d1f50] Revoking previously assigned partitions []
2020-01-07 19:13:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-218, groupId=1ff06445-0e47-478b-84e8-6a63133d1f50] (Re-)joining group
2020-01-07 19:13:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-218, groupId=1ff06445-0e47-478b-84e8-6a63133d1f50] Successfully joined group with generation 1
2020-01-07 19:13:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-218, groupId=1ff06445-0e47-478b-84e8-6a63133d1f50] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:23 INFO  Fetcher:583 - [Consumer clientId=consumer-218, groupId=1ff06445-0e47-478b-84e8-6a63133d1f50] Resetting offset for partition facedetectiontest101-0 to offset 17710.
2020-01-07 19:13:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5c0fa64d-e7ef-4271-ba52-fb320e4175c8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-219, groupId=5c0fa64d-e7ef-4271-ba52-fb320e4175c8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-219, groupId=5c0fa64d-e7ef-4271-ba52-fb320e4175c8] Revoking previously assigned partitions []
2020-01-07 19:13:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-219, groupId=5c0fa64d-e7ef-4271-ba52-fb320e4175c8] (Re-)joining group
2020-01-07 19:13:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-219, groupId=5c0fa64d-e7ef-4271-ba52-fb320e4175c8] Successfully joined group with generation 1
2020-01-07 19:13:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-219, groupId=5c0fa64d-e7ef-4271-ba52-fb320e4175c8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:23 INFO  Fetcher:583 - [Consumer clientId=consumer-219, groupId=5c0fa64d-e7ef-4271-ba52-fb320e4175c8] Resetting offset for partition facedetectiontest101-0 to offset 17711.
2020-01-07 19:13:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 94121bc9-3f3e-46c3-85c7-52fee4a92423
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-220, groupId=94121bc9-3f3e-46c3-85c7-52fee4a92423] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-220, groupId=94121bc9-3f3e-46c3-85c7-52fee4a92423] Revoking previously assigned partitions []
2020-01-07 19:13:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-220, groupId=94121bc9-3f3e-46c3-85c7-52fee4a92423] (Re-)joining group
2020-01-07 19:13:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-220, groupId=94121bc9-3f3e-46c3-85c7-52fee4a92423] Successfully joined group with generation 1
2020-01-07 19:13:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-220, groupId=94121bc9-3f3e-46c3-85c7-52fee4a92423] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:23 INFO  Fetcher:583 - [Consumer clientId=consumer-220, groupId=94121bc9-3f3e-46c3-85c7-52fee4a92423] Resetting offset for partition facedetectiontest101-0 to offset 17712.
2020-01-07 19:13:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ad918f8e-a993-4001-a836-52170d8617c2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-221, groupId=ad918f8e-a993-4001-a836-52170d8617c2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-221, groupId=ad918f8e-a993-4001-a836-52170d8617c2] Revoking previously assigned partitions []
2020-01-07 19:13:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-221, groupId=ad918f8e-a993-4001-a836-52170d8617c2] (Re-)joining group
2020-01-07 19:13:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-221, groupId=ad918f8e-a993-4001-a836-52170d8617c2] Successfully joined group with generation 1
2020-01-07 19:13:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-221, groupId=ad918f8e-a993-4001-a836-52170d8617c2] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:23 INFO  Fetcher:583 - [Consumer clientId=consumer-221, groupId=ad918f8e-a993-4001-a836-52170d8617c2] Resetting offset for partition facedetectiontest101-0 to offset 17713.
2020-01-07 19:13:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 271d7096-b014-4d50-b36e-ebdfd2a046b7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-222, groupId=271d7096-b014-4d50-b36e-ebdfd2a046b7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-222, groupId=271d7096-b014-4d50-b36e-ebdfd2a046b7] Revoking previously assigned partitions []
2020-01-07 19:13:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-222, groupId=271d7096-b014-4d50-b36e-ebdfd2a046b7] (Re-)joining group
2020-01-07 19:13:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-222, groupId=271d7096-b014-4d50-b36e-ebdfd2a046b7] Successfully joined group with generation 1
2020-01-07 19:13:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-222, groupId=271d7096-b014-4d50-b36e-ebdfd2a046b7] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:23 INFO  Fetcher:583 - [Consumer clientId=consumer-222, groupId=271d7096-b014-4d50-b36e-ebdfd2a046b7] Resetting offset for partition facedetectiontest101-0 to offset 17714.
2020-01-07 19:13:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 87a4b8c7-b3cf-446c-933c-d18a88ecd693
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-223, groupId=87a4b8c7-b3cf-446c-933c-d18a88ecd693] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-223, groupId=87a4b8c7-b3cf-446c-933c-d18a88ecd693] Revoking previously assigned partitions []
2020-01-07 19:13:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-223, groupId=87a4b8c7-b3cf-446c-933c-d18a88ecd693] (Re-)joining group
2020-01-07 19:13:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-223, groupId=87a4b8c7-b3cf-446c-933c-d18a88ecd693] Successfully joined group with generation 1
2020-01-07 19:13:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-223, groupId=87a4b8c7-b3cf-446c-933c-d18a88ecd693] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:23 INFO  Fetcher:583 - [Consumer clientId=consumer-223, groupId=87a4b8c7-b3cf-446c-933c-d18a88ecd693] Resetting offset for partition facedetectiontest101-0 to offset 17715.
2020-01-07 19:13:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5f698d77-eb92-45f1-a0c0-905e9e7d0d60
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-224, groupId=5f698d77-eb92-45f1-a0c0-905e9e7d0d60] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-224, groupId=5f698d77-eb92-45f1-a0c0-905e9e7d0d60] Revoking previously assigned partitions []
2020-01-07 19:13:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-224, groupId=5f698d77-eb92-45f1-a0c0-905e9e7d0d60] (Re-)joining group
2020-01-07 19:13:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-224, groupId=5f698d77-eb92-45f1-a0c0-905e9e7d0d60] Successfully joined group with generation 1
2020-01-07 19:13:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-224, groupId=5f698d77-eb92-45f1-a0c0-905e9e7d0d60] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:23 INFO  Fetcher:583 - [Consumer clientId=consumer-224, groupId=5f698d77-eb92-45f1-a0c0-905e9e7d0d60] Resetting offset for partition facedetectiontest101-0 to offset 17716.
2020-01-07 19:13:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a56b0e90-7407-4b2f-b40f-53a3ebdbc2d0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-225, groupId=a56b0e90-7407-4b2f-b40f-53a3ebdbc2d0] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-225, groupId=a56b0e90-7407-4b2f-b40f-53a3ebdbc2d0] Revoking previously assigned partitions []
2020-01-07 19:13:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-225, groupId=a56b0e90-7407-4b2f-b40f-53a3ebdbc2d0] (Re-)joining group
2020-01-07 19:13:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-225, groupId=a56b0e90-7407-4b2f-b40f-53a3ebdbc2d0] Successfully joined group with generation 1
2020-01-07 19:13:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-225, groupId=a56b0e90-7407-4b2f-b40f-53a3ebdbc2d0] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:23 INFO  Fetcher:583 - [Consumer clientId=consumer-225, groupId=a56b0e90-7407-4b2f-b40f-53a3ebdbc2d0] Resetting offset for partition facedetectiontest101-0 to offset 17717.
2020-01-07 19:13:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ba8960fe-502c-4fe3-94e7-afe32db78f3e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-226, groupId=ba8960fe-502c-4fe3-94e7-afe32db78f3e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-226, groupId=ba8960fe-502c-4fe3-94e7-afe32db78f3e] Revoking previously assigned partitions []
2020-01-07 19:13:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-226, groupId=ba8960fe-502c-4fe3-94e7-afe32db78f3e] (Re-)joining group
2020-01-07 19:13:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-226, groupId=ba8960fe-502c-4fe3-94e7-afe32db78f3e] Successfully joined group with generation 1
2020-01-07 19:13:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-226, groupId=ba8960fe-502c-4fe3-94e7-afe32db78f3e] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:24 INFO  Fetcher:583 - [Consumer clientId=consumer-226, groupId=ba8960fe-502c-4fe3-94e7-afe32db78f3e] Resetting offset for partition facedetectiontest101-0 to offset 17718.
2020-01-07 19:13:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 74524034-1f7e-4b02-bf6e-fde56f38913e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-227, groupId=74524034-1f7e-4b02-bf6e-fde56f38913e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-227, groupId=74524034-1f7e-4b02-bf6e-fde56f38913e] Revoking previously assigned partitions []
2020-01-07 19:13:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-227, groupId=74524034-1f7e-4b02-bf6e-fde56f38913e] (Re-)joining group
2020-01-07 19:13:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-227, groupId=74524034-1f7e-4b02-bf6e-fde56f38913e] Successfully joined group with generation 1
2020-01-07 19:13:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-227, groupId=74524034-1f7e-4b02-bf6e-fde56f38913e] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:24 INFO  Fetcher:583 - [Consumer clientId=consumer-227, groupId=74524034-1f7e-4b02-bf6e-fde56f38913e] Resetting offset for partition facedetectiontest101-0 to offset 17719.
2020-01-07 19:13:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 46a583da-aca0-4b67-9852-01135b9366d6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-228, groupId=46a583da-aca0-4b67-9852-01135b9366d6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-228, groupId=46a583da-aca0-4b67-9852-01135b9366d6] Revoking previously assigned partitions []
2020-01-07 19:13:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-228, groupId=46a583da-aca0-4b67-9852-01135b9366d6] (Re-)joining group
2020-01-07 19:13:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-228, groupId=46a583da-aca0-4b67-9852-01135b9366d6] Successfully joined group with generation 1
2020-01-07 19:13:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-228, groupId=46a583da-aca0-4b67-9852-01135b9366d6] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:24 INFO  Fetcher:583 - [Consumer clientId=consumer-228, groupId=46a583da-aca0-4b67-9852-01135b9366d6] Resetting offset for partition facedetectiontest101-0 to offset 17720.
2020-01-07 19:13:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 537dd30e-cf40-420c-8ba2-4eb0706c46f1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-229, groupId=537dd30e-cf40-420c-8ba2-4eb0706c46f1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-229, groupId=537dd30e-cf40-420c-8ba2-4eb0706c46f1] Revoking previously assigned partitions []
2020-01-07 19:13:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-229, groupId=537dd30e-cf40-420c-8ba2-4eb0706c46f1] (Re-)joining group
2020-01-07 19:13:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-229, groupId=537dd30e-cf40-420c-8ba2-4eb0706c46f1] Successfully joined group with generation 1
2020-01-07 19:13:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-229, groupId=537dd30e-cf40-420c-8ba2-4eb0706c46f1] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:24 INFO  Fetcher:583 - [Consumer clientId=consumer-229, groupId=537dd30e-cf40-420c-8ba2-4eb0706c46f1] Resetting offset for partition facedetectiontest101-0 to offset 17721.
2020-01-07 19:13:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 57d8a13c-c453-4794-b0c3-226c647d88d0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-230, groupId=57d8a13c-c453-4794-b0c3-226c647d88d0] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-230, groupId=57d8a13c-c453-4794-b0c3-226c647d88d0] Revoking previously assigned partitions []
2020-01-07 19:13:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-230, groupId=57d8a13c-c453-4794-b0c3-226c647d88d0] (Re-)joining group
2020-01-07 19:13:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-230, groupId=57d8a13c-c453-4794-b0c3-226c647d88d0] Successfully joined group with generation 1
2020-01-07 19:13:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-230, groupId=57d8a13c-c453-4794-b0c3-226c647d88d0] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:24 INFO  Fetcher:583 - [Consumer clientId=consumer-230, groupId=57d8a13c-c453-4794-b0c3-226c647d88d0] Resetting offset for partition facedetectiontest101-0 to offset 17722.
2020-01-07 19:13:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f15f6685-32a1-43f3-89ec-81f057eef147
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-231, groupId=f15f6685-32a1-43f3-89ec-81f057eef147] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-231, groupId=f15f6685-32a1-43f3-89ec-81f057eef147] Revoking previously assigned partitions []
2020-01-07 19:13:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-231, groupId=f15f6685-32a1-43f3-89ec-81f057eef147] (Re-)joining group
2020-01-07 19:13:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-231, groupId=f15f6685-32a1-43f3-89ec-81f057eef147] Successfully joined group with generation 1
2020-01-07 19:13:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-231, groupId=f15f6685-32a1-43f3-89ec-81f057eef147] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:24 INFO  Fetcher:583 - [Consumer clientId=consumer-231, groupId=f15f6685-32a1-43f3-89ec-81f057eef147] Resetting offset for partition facedetectiontest101-0 to offset 17723.
2020-01-07 19:13:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6a1abab8-aaf3-445d-b940-1b37b77e43c7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-232, groupId=6a1abab8-aaf3-445d-b940-1b37b77e43c7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-232, groupId=6a1abab8-aaf3-445d-b940-1b37b77e43c7] Revoking previously assigned partitions []
2020-01-07 19:13:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-232, groupId=6a1abab8-aaf3-445d-b940-1b37b77e43c7] (Re-)joining group
2020-01-07 19:13:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-232, groupId=6a1abab8-aaf3-445d-b940-1b37b77e43c7] Successfully joined group with generation 1
2020-01-07 19:13:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-232, groupId=6a1abab8-aaf3-445d-b940-1b37b77e43c7] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:24 INFO  Fetcher:583 - [Consumer clientId=consumer-232, groupId=6a1abab8-aaf3-445d-b940-1b37b77e43c7] Resetting offset for partition facedetectiontest101-0 to offset 17724.
2020-01-07 19:13:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 88964afa-7254-4df6-9a71-cfc7fd9da473
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-233, groupId=88964afa-7254-4df6-9a71-cfc7fd9da473] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-233, groupId=88964afa-7254-4df6-9a71-cfc7fd9da473] Revoking previously assigned partitions []
2020-01-07 19:13:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-233, groupId=88964afa-7254-4df6-9a71-cfc7fd9da473] (Re-)joining group
2020-01-07 19:13:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-233, groupId=88964afa-7254-4df6-9a71-cfc7fd9da473] Successfully joined group with generation 1
2020-01-07 19:13:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-233, groupId=88964afa-7254-4df6-9a71-cfc7fd9da473] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:24 INFO  Fetcher:583 - [Consumer clientId=consumer-233, groupId=88964afa-7254-4df6-9a71-cfc7fd9da473] Resetting offset for partition facedetectiontest101-0 to offset 17725.
2020-01-07 19:13:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 777943ac-334d-4482-ace4-6d2347e3e743
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-234, groupId=777943ac-334d-4482-ace4-6d2347e3e743] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-234, groupId=777943ac-334d-4482-ace4-6d2347e3e743] Revoking previously assigned partitions []
2020-01-07 19:13:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-234, groupId=777943ac-334d-4482-ace4-6d2347e3e743] (Re-)joining group
2020-01-07 19:13:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-234, groupId=777943ac-334d-4482-ace4-6d2347e3e743] Successfully joined group with generation 1
2020-01-07 19:13:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-234, groupId=777943ac-334d-4482-ace4-6d2347e3e743] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:24 INFO  Fetcher:583 - [Consumer clientId=consumer-234, groupId=777943ac-334d-4482-ace4-6d2347e3e743] Resetting offset for partition facedetectiontest101-0 to offset 17726.
2020-01-07 19:13:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ace8834e-552b-4e8a-98b9-626ddacc97f9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-235, groupId=ace8834e-552b-4e8a-98b9-626ddacc97f9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-235, groupId=ace8834e-552b-4e8a-98b9-626ddacc97f9] Revoking previously assigned partitions []
2020-01-07 19:13:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-235, groupId=ace8834e-552b-4e8a-98b9-626ddacc97f9] (Re-)joining group
2020-01-07 19:13:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-235, groupId=ace8834e-552b-4e8a-98b9-626ddacc97f9] Successfully joined group with generation 1
2020-01-07 19:13:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-235, groupId=ace8834e-552b-4e8a-98b9-626ddacc97f9] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:24 INFO  Fetcher:583 - [Consumer clientId=consumer-235, groupId=ace8834e-552b-4e8a-98b9-626ddacc97f9] Resetting offset for partition facedetectiontest101-0 to offset 17727.
2020-01-07 19:13:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 40e0fb03-b512-43e5-a838-5ae1df5c7dd8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-236, groupId=40e0fb03-b512-43e5-a838-5ae1df5c7dd8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-236, groupId=40e0fb03-b512-43e5-a838-5ae1df5c7dd8] Revoking previously assigned partitions []
2020-01-07 19:13:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-236, groupId=40e0fb03-b512-43e5-a838-5ae1df5c7dd8] (Re-)joining group
2020-01-07 19:13:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-236, groupId=40e0fb03-b512-43e5-a838-5ae1df5c7dd8] Successfully joined group with generation 1
2020-01-07 19:13:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-236, groupId=40e0fb03-b512-43e5-a838-5ae1df5c7dd8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:24 INFO  Fetcher:583 - [Consumer clientId=consumer-236, groupId=40e0fb03-b512-43e5-a838-5ae1df5c7dd8] Resetting offset for partition facedetectiontest101-0 to offset 17728.
2020-01-07 19:13:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = aed8d9e9-49e0-4f85-ac70-883b6e747ef6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-237, groupId=aed8d9e9-49e0-4f85-ac70-883b6e747ef6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-237, groupId=aed8d9e9-49e0-4f85-ac70-883b6e747ef6] Revoking previously assigned partitions []
2020-01-07 19:13:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-237, groupId=aed8d9e9-49e0-4f85-ac70-883b6e747ef6] (Re-)joining group
2020-01-07 19:13:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-237, groupId=aed8d9e9-49e0-4f85-ac70-883b6e747ef6] Successfully joined group with generation 1
2020-01-07 19:13:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-237, groupId=aed8d9e9-49e0-4f85-ac70-883b6e747ef6] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:24 INFO  Fetcher:583 - [Consumer clientId=consumer-237, groupId=aed8d9e9-49e0-4f85-ac70-883b6e747ef6] Resetting offset for partition facedetectiontest101-0 to offset 17729.
2020-01-07 19:13:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7d4d7847-7b4f-4788-9497-f2d7708a74b4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-238, groupId=7d4d7847-7b4f-4788-9497-f2d7708a74b4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-238, groupId=7d4d7847-7b4f-4788-9497-f2d7708a74b4] Revoking previously assigned partitions []
2020-01-07 19:13:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-238, groupId=7d4d7847-7b4f-4788-9497-f2d7708a74b4] (Re-)joining group
2020-01-07 19:13:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-238, groupId=7d4d7847-7b4f-4788-9497-f2d7708a74b4] Successfully joined group with generation 1
2020-01-07 19:13:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-238, groupId=7d4d7847-7b4f-4788-9497-f2d7708a74b4] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:24 INFO  Fetcher:583 - [Consumer clientId=consumer-238, groupId=7d4d7847-7b4f-4788-9497-f2d7708a74b4] Resetting offset for partition facedetectiontest101-0 to offset 17730.
2020-01-07 19:13:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a8ac1afe-ba15-4d3e-94d9-479df5021c26
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-239, groupId=a8ac1afe-ba15-4d3e-94d9-479df5021c26] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-239, groupId=a8ac1afe-ba15-4d3e-94d9-479df5021c26] Revoking previously assigned partitions []
2020-01-07 19:13:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-239, groupId=a8ac1afe-ba15-4d3e-94d9-479df5021c26] (Re-)joining group
2020-01-07 19:13:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-239, groupId=a8ac1afe-ba15-4d3e-94d9-479df5021c26] Successfully joined group with generation 1
2020-01-07 19:13:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-239, groupId=a8ac1afe-ba15-4d3e-94d9-479df5021c26] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:25 INFO  Fetcher:583 - [Consumer clientId=consumer-239, groupId=a8ac1afe-ba15-4d3e-94d9-479df5021c26] Resetting offset for partition facedetectiontest101-0 to offset 17731.
2020-01-07 19:13:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 18c60e7b-6abc-44db-a731-323ecd6e8c1d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-240, groupId=18c60e7b-6abc-44db-a731-323ecd6e8c1d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-240, groupId=18c60e7b-6abc-44db-a731-323ecd6e8c1d] Revoking previously assigned partitions []
2020-01-07 19:13:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-240, groupId=18c60e7b-6abc-44db-a731-323ecd6e8c1d] (Re-)joining group
2020-01-07 19:13:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-240, groupId=18c60e7b-6abc-44db-a731-323ecd6e8c1d] Successfully joined group with generation 1
2020-01-07 19:13:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-240, groupId=18c60e7b-6abc-44db-a731-323ecd6e8c1d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:25 INFO  Fetcher:583 - [Consumer clientId=consumer-240, groupId=18c60e7b-6abc-44db-a731-323ecd6e8c1d] Resetting offset for partition facedetectiontest101-0 to offset 17732.
2020-01-07 19:13:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0a9f4795-2602-4aa2-8c14-932a62d26635
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-241, groupId=0a9f4795-2602-4aa2-8c14-932a62d26635] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-241, groupId=0a9f4795-2602-4aa2-8c14-932a62d26635] Revoking previously assigned partitions []
2020-01-07 19:13:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-241, groupId=0a9f4795-2602-4aa2-8c14-932a62d26635] (Re-)joining group
2020-01-07 19:13:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-241, groupId=0a9f4795-2602-4aa2-8c14-932a62d26635] Successfully joined group with generation 1
2020-01-07 19:13:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-241, groupId=0a9f4795-2602-4aa2-8c14-932a62d26635] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:25 INFO  Fetcher:583 - [Consumer clientId=consumer-241, groupId=0a9f4795-2602-4aa2-8c14-932a62d26635] Resetting offset for partition facedetectiontest101-0 to offset 17733.
2020-01-07 19:13:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 87aa75ca-52e1-457b-8bcb-7c9ccc1c7f98
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-242, groupId=87aa75ca-52e1-457b-8bcb-7c9ccc1c7f98] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-242, groupId=87aa75ca-52e1-457b-8bcb-7c9ccc1c7f98] Revoking previously assigned partitions []
2020-01-07 19:13:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-242, groupId=87aa75ca-52e1-457b-8bcb-7c9ccc1c7f98] (Re-)joining group
2020-01-07 19:13:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-242, groupId=87aa75ca-52e1-457b-8bcb-7c9ccc1c7f98] Successfully joined group with generation 1
2020-01-07 19:13:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-242, groupId=87aa75ca-52e1-457b-8bcb-7c9ccc1c7f98] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:25 INFO  Fetcher:583 - [Consumer clientId=consumer-242, groupId=87aa75ca-52e1-457b-8bcb-7c9ccc1c7f98] Resetting offset for partition facedetectiontest101-0 to offset 17734.
2020-01-07 19:13:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f7270f23-e43b-42a3-ae7c-b5f4c7f51e7a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-243, groupId=f7270f23-e43b-42a3-ae7c-b5f4c7f51e7a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-243, groupId=f7270f23-e43b-42a3-ae7c-b5f4c7f51e7a] Revoking previously assigned partitions []
2020-01-07 19:13:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-243, groupId=f7270f23-e43b-42a3-ae7c-b5f4c7f51e7a] (Re-)joining group
2020-01-07 19:13:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-243, groupId=f7270f23-e43b-42a3-ae7c-b5f4c7f51e7a] Successfully joined group with generation 1
2020-01-07 19:13:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-243, groupId=f7270f23-e43b-42a3-ae7c-b5f4c7f51e7a] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:25 INFO  Fetcher:583 - [Consumer clientId=consumer-243, groupId=f7270f23-e43b-42a3-ae7c-b5f4c7f51e7a] Resetting offset for partition facedetectiontest101-0 to offset 17735.
2020-01-07 19:13:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1d76e243-0aad-4a5a-a12c-82a08865af70
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-244, groupId=1d76e243-0aad-4a5a-a12c-82a08865af70] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-244, groupId=1d76e243-0aad-4a5a-a12c-82a08865af70] Revoking previously assigned partitions []
2020-01-07 19:13:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-244, groupId=1d76e243-0aad-4a5a-a12c-82a08865af70] (Re-)joining group
2020-01-07 19:13:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-244, groupId=1d76e243-0aad-4a5a-a12c-82a08865af70] Successfully joined group with generation 1
2020-01-07 19:13:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-244, groupId=1d76e243-0aad-4a5a-a12c-82a08865af70] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:25 INFO  Fetcher:583 - [Consumer clientId=consumer-244, groupId=1d76e243-0aad-4a5a-a12c-82a08865af70] Resetting offset for partition facedetectiontest101-0 to offset 17736.
2020-01-07 19:13:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5b26f2cb-656d-4f2a-a655-82ec24a0b2ee
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-245, groupId=5b26f2cb-656d-4f2a-a655-82ec24a0b2ee] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-245, groupId=5b26f2cb-656d-4f2a-a655-82ec24a0b2ee] Revoking previously assigned partitions []
2020-01-07 19:13:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-245, groupId=5b26f2cb-656d-4f2a-a655-82ec24a0b2ee] (Re-)joining group
2020-01-07 19:13:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-245, groupId=5b26f2cb-656d-4f2a-a655-82ec24a0b2ee] Successfully joined group with generation 1
2020-01-07 19:13:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-245, groupId=5b26f2cb-656d-4f2a-a655-82ec24a0b2ee] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:25 INFO  Fetcher:583 - [Consumer clientId=consumer-245, groupId=5b26f2cb-656d-4f2a-a655-82ec24a0b2ee] Resetting offset for partition facedetectiontest101-0 to offset 17737.
2020-01-07 19:13:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c619ea6a-b23f-4698-b0e0-83b60b046c47
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-246, groupId=c619ea6a-b23f-4698-b0e0-83b60b046c47] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-246, groupId=c619ea6a-b23f-4698-b0e0-83b60b046c47] Revoking previously assigned partitions []
2020-01-07 19:13:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-246, groupId=c619ea6a-b23f-4698-b0e0-83b60b046c47] (Re-)joining group
2020-01-07 19:13:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-246, groupId=c619ea6a-b23f-4698-b0e0-83b60b046c47] Successfully joined group with generation 1
2020-01-07 19:13:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-246, groupId=c619ea6a-b23f-4698-b0e0-83b60b046c47] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:25 INFO  Fetcher:583 - [Consumer clientId=consumer-246, groupId=c619ea6a-b23f-4698-b0e0-83b60b046c47] Resetting offset for partition facedetectiontest101-0 to offset 17738.
2020-01-07 19:13:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e01a18f8-0906-4a97-b1d7-fd8acbef6c8f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-247, groupId=e01a18f8-0906-4a97-b1d7-fd8acbef6c8f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-247, groupId=e01a18f8-0906-4a97-b1d7-fd8acbef6c8f] Revoking previously assigned partitions []
2020-01-07 19:13:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-247, groupId=e01a18f8-0906-4a97-b1d7-fd8acbef6c8f] (Re-)joining group
2020-01-07 19:13:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-247, groupId=e01a18f8-0906-4a97-b1d7-fd8acbef6c8f] Successfully joined group with generation 1
2020-01-07 19:13:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-247, groupId=e01a18f8-0906-4a97-b1d7-fd8acbef6c8f] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:25 INFO  Fetcher:583 - [Consumer clientId=consumer-247, groupId=e01a18f8-0906-4a97-b1d7-fd8acbef6c8f] Resetting offset for partition facedetectiontest101-0 to offset 17739.
2020-01-07 19:13:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 83bff2a2-8966-4144-ae4a-1a55acc47d4d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-248, groupId=83bff2a2-8966-4144-ae4a-1a55acc47d4d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-248, groupId=83bff2a2-8966-4144-ae4a-1a55acc47d4d] Revoking previously assigned partitions []
2020-01-07 19:13:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-248, groupId=83bff2a2-8966-4144-ae4a-1a55acc47d4d] (Re-)joining group
2020-01-07 19:13:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-248, groupId=83bff2a2-8966-4144-ae4a-1a55acc47d4d] Successfully joined group with generation 1
2020-01-07 19:13:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-248, groupId=83bff2a2-8966-4144-ae4a-1a55acc47d4d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:25 INFO  Fetcher:583 - [Consumer clientId=consumer-248, groupId=83bff2a2-8966-4144-ae4a-1a55acc47d4d] Resetting offset for partition facedetectiontest101-0 to offset 17740.
2020-01-07 19:13:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c963fe4d-3607-4c66-a392-9ff6c1e9723d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-249, groupId=c963fe4d-3607-4c66-a392-9ff6c1e9723d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-249, groupId=c963fe4d-3607-4c66-a392-9ff6c1e9723d] Revoking previously assigned partitions []
2020-01-07 19:13:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-249, groupId=c963fe4d-3607-4c66-a392-9ff6c1e9723d] (Re-)joining group
2020-01-07 19:13:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-249, groupId=c963fe4d-3607-4c66-a392-9ff6c1e9723d] Successfully joined group with generation 1
2020-01-07 19:13:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-249, groupId=c963fe4d-3607-4c66-a392-9ff6c1e9723d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:25 INFO  Fetcher:583 - [Consumer clientId=consumer-249, groupId=c963fe4d-3607-4c66-a392-9ff6c1e9723d] Resetting offset for partition facedetectiontest101-0 to offset 17741.
2020-01-07 19:13:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7a0f0c5a-b974-499a-822a-bbe9a4f524ec
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-250, groupId=7a0f0c5a-b974-499a-822a-bbe9a4f524ec] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-250, groupId=7a0f0c5a-b974-499a-822a-bbe9a4f524ec] Revoking previously assigned partitions []
2020-01-07 19:13:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-250, groupId=7a0f0c5a-b974-499a-822a-bbe9a4f524ec] (Re-)joining group
2020-01-07 19:13:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-250, groupId=7a0f0c5a-b974-499a-822a-bbe9a4f524ec] Successfully joined group with generation 1
2020-01-07 19:13:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-250, groupId=7a0f0c5a-b974-499a-822a-bbe9a4f524ec] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:25 INFO  Fetcher:583 - [Consumer clientId=consumer-250, groupId=7a0f0c5a-b974-499a-822a-bbe9a4f524ec] Resetting offset for partition facedetectiontest101-0 to offset 17742.
2020-01-07 19:13:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 04868e26-95f4-4c18-bcd6-e95cea94ff19
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-251, groupId=04868e26-95f4-4c18-bcd6-e95cea94ff19] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-251, groupId=04868e26-95f4-4c18-bcd6-e95cea94ff19] Revoking previously assigned partitions []
2020-01-07 19:13:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-251, groupId=04868e26-95f4-4c18-bcd6-e95cea94ff19] (Re-)joining group
2020-01-07 19:13:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-251, groupId=04868e26-95f4-4c18-bcd6-e95cea94ff19] Successfully joined group with generation 1
2020-01-07 19:13:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-251, groupId=04868e26-95f4-4c18-bcd6-e95cea94ff19] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:25 INFO  Fetcher:583 - [Consumer clientId=consumer-251, groupId=04868e26-95f4-4c18-bcd6-e95cea94ff19] Resetting offset for partition facedetectiontest101-0 to offset 17743.
2020-01-07 19:13:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 37567821-d271-492c-94e9-c20b28380d1c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-252, groupId=37567821-d271-492c-94e9-c20b28380d1c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-252, groupId=37567821-d271-492c-94e9-c20b28380d1c] Revoking previously assigned partitions []
2020-01-07 19:13:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-252, groupId=37567821-d271-492c-94e9-c20b28380d1c] (Re-)joining group
2020-01-07 19:13:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-252, groupId=37567821-d271-492c-94e9-c20b28380d1c] Successfully joined group with generation 1
2020-01-07 19:13:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-252, groupId=37567821-d271-492c-94e9-c20b28380d1c] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:25 INFO  Fetcher:583 - [Consumer clientId=consumer-252, groupId=37567821-d271-492c-94e9-c20b28380d1c] Resetting offset for partition facedetectiontest101-0 to offset 17744.
2020-01-07 19:13:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b20e76bf-1925-4f7c-a2c6-ab68b2013747
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-253, groupId=b20e76bf-1925-4f7c-a2c6-ab68b2013747] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-253, groupId=b20e76bf-1925-4f7c-a2c6-ab68b2013747] Revoking previously assigned partitions []
2020-01-07 19:13:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-253, groupId=b20e76bf-1925-4f7c-a2c6-ab68b2013747] (Re-)joining group
2020-01-07 19:13:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-253, groupId=b20e76bf-1925-4f7c-a2c6-ab68b2013747] Successfully joined group with generation 1
2020-01-07 19:13:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-253, groupId=b20e76bf-1925-4f7c-a2c6-ab68b2013747] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:26 INFO  Fetcher:583 - [Consumer clientId=consumer-253, groupId=b20e76bf-1925-4f7c-a2c6-ab68b2013747] Resetting offset for partition facedetectiontest101-0 to offset 17746.
2020-01-07 19:13:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c40360e0-c1be-4afd-a035-263a5f1a4765
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-254, groupId=c40360e0-c1be-4afd-a035-263a5f1a4765] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-254, groupId=c40360e0-c1be-4afd-a035-263a5f1a4765] Revoking previously assigned partitions []
2020-01-07 19:13:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-254, groupId=c40360e0-c1be-4afd-a035-263a5f1a4765] (Re-)joining group
2020-01-07 19:13:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-254, groupId=c40360e0-c1be-4afd-a035-263a5f1a4765] Successfully joined group with generation 1
2020-01-07 19:13:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-254, groupId=c40360e0-c1be-4afd-a035-263a5f1a4765] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:26 INFO  Fetcher:583 - [Consumer clientId=consumer-254, groupId=c40360e0-c1be-4afd-a035-263a5f1a4765] Resetting offset for partition facedetectiontest101-0 to offset 17748.
2020-01-07 19:13:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 54550061-f3a6-4bad-9f8b-94a232af7404
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-255, groupId=54550061-f3a6-4bad-9f8b-94a232af7404] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-255, groupId=54550061-f3a6-4bad-9f8b-94a232af7404] Revoking previously assigned partitions []
2020-01-07 19:13:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-255, groupId=54550061-f3a6-4bad-9f8b-94a232af7404] (Re-)joining group
2020-01-07 19:13:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-255, groupId=54550061-f3a6-4bad-9f8b-94a232af7404] Successfully joined group with generation 1
2020-01-07 19:13:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-255, groupId=54550061-f3a6-4bad-9f8b-94a232af7404] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:26 INFO  Fetcher:583 - [Consumer clientId=consumer-255, groupId=54550061-f3a6-4bad-9f8b-94a232af7404] Resetting offset for partition facedetectiontest101-0 to offset 17749.
2020-01-07 19:13:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 85f4a62f-ee35-4a77-a595-d23c87c3ae82
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-256, groupId=85f4a62f-ee35-4a77-a595-d23c87c3ae82] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-256, groupId=85f4a62f-ee35-4a77-a595-d23c87c3ae82] Revoking previously assigned partitions []
2020-01-07 19:13:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-256, groupId=85f4a62f-ee35-4a77-a595-d23c87c3ae82] (Re-)joining group
2020-01-07 19:13:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-256, groupId=85f4a62f-ee35-4a77-a595-d23c87c3ae82] Successfully joined group with generation 1
2020-01-07 19:13:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-256, groupId=85f4a62f-ee35-4a77-a595-d23c87c3ae82] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:26 INFO  Fetcher:583 - [Consumer clientId=consumer-256, groupId=85f4a62f-ee35-4a77-a595-d23c87c3ae82] Resetting offset for partition facedetectiontest101-0 to offset 17750.
2020-01-07 19:13:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e5deee9f-4ecb-4391-a2ae-b51ffa63ae58
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-257, groupId=e5deee9f-4ecb-4391-a2ae-b51ffa63ae58] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-257, groupId=e5deee9f-4ecb-4391-a2ae-b51ffa63ae58] Revoking previously assigned partitions []
2020-01-07 19:13:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-257, groupId=e5deee9f-4ecb-4391-a2ae-b51ffa63ae58] (Re-)joining group
2020-01-07 19:13:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-257, groupId=e5deee9f-4ecb-4391-a2ae-b51ffa63ae58] Successfully joined group with generation 1
2020-01-07 19:13:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-257, groupId=e5deee9f-4ecb-4391-a2ae-b51ffa63ae58] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:26 INFO  Fetcher:583 - [Consumer clientId=consumer-257, groupId=e5deee9f-4ecb-4391-a2ae-b51ffa63ae58] Resetting offset for partition facedetectiontest101-0 to offset 17751.
2020-01-07 19:13:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2c8638dd-20a6-448a-a191-3dfd322f1411
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-258, groupId=2c8638dd-20a6-448a-a191-3dfd322f1411] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-258, groupId=2c8638dd-20a6-448a-a191-3dfd322f1411] Revoking previously assigned partitions []
2020-01-07 19:13:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-258, groupId=2c8638dd-20a6-448a-a191-3dfd322f1411] (Re-)joining group
2020-01-07 19:13:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-258, groupId=2c8638dd-20a6-448a-a191-3dfd322f1411] Successfully joined group with generation 1
2020-01-07 19:13:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-258, groupId=2c8638dd-20a6-448a-a191-3dfd322f1411] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:26 INFO  Fetcher:583 - [Consumer clientId=consumer-258, groupId=2c8638dd-20a6-448a-a191-3dfd322f1411] Resetting offset for partition facedetectiontest101-0 to offset 17752.
2020-01-07 19:13:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b16354bd-71ea-4422-b9bd-51e9930f0e47
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-259, groupId=b16354bd-71ea-4422-b9bd-51e9930f0e47] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-259, groupId=b16354bd-71ea-4422-b9bd-51e9930f0e47] Revoking previously assigned partitions []
2020-01-07 19:13:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-259, groupId=b16354bd-71ea-4422-b9bd-51e9930f0e47] (Re-)joining group
2020-01-07 19:13:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-259, groupId=b16354bd-71ea-4422-b9bd-51e9930f0e47] Successfully joined group with generation 1
2020-01-07 19:13:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-259, groupId=b16354bd-71ea-4422-b9bd-51e9930f0e47] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:26 INFO  Fetcher:583 - [Consumer clientId=consumer-259, groupId=b16354bd-71ea-4422-b9bd-51e9930f0e47] Resetting offset for partition facedetectiontest101-0 to offset 17753.
2020-01-07 19:13:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2f6d88df-b42d-48f8-a4d3-5032a0553498
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-260, groupId=2f6d88df-b42d-48f8-a4d3-5032a0553498] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-260, groupId=2f6d88df-b42d-48f8-a4d3-5032a0553498] Revoking previously assigned partitions []
2020-01-07 19:13:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-260, groupId=2f6d88df-b42d-48f8-a4d3-5032a0553498] (Re-)joining group
2020-01-07 19:13:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-260, groupId=2f6d88df-b42d-48f8-a4d3-5032a0553498] Successfully joined group with generation 1
2020-01-07 19:13:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-260, groupId=2f6d88df-b42d-48f8-a4d3-5032a0553498] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:26 INFO  Fetcher:583 - [Consumer clientId=consumer-260, groupId=2f6d88df-b42d-48f8-a4d3-5032a0553498] Resetting offset for partition facedetectiontest101-0 to offset 17754.
2020-01-07 19:13:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 69c71db9-761c-42d8-a132-d48a88d0348c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-261, groupId=69c71db9-761c-42d8-a132-d48a88d0348c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-261, groupId=69c71db9-761c-42d8-a132-d48a88d0348c] Revoking previously assigned partitions []
2020-01-07 19:13:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-261, groupId=69c71db9-761c-42d8-a132-d48a88d0348c] (Re-)joining group
2020-01-07 19:13:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-261, groupId=69c71db9-761c-42d8-a132-d48a88d0348c] Successfully joined group with generation 1
2020-01-07 19:13:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-261, groupId=69c71db9-761c-42d8-a132-d48a88d0348c] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:26 INFO  Fetcher:583 - [Consumer clientId=consumer-261, groupId=69c71db9-761c-42d8-a132-d48a88d0348c] Resetting offset for partition facedetectiontest101-0 to offset 17756.
2020-01-07 19:13:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ee173e0a-f260-48d1-99af-1bb48ac2d64a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-262, groupId=ee173e0a-f260-48d1-99af-1bb48ac2d64a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-262, groupId=ee173e0a-f260-48d1-99af-1bb48ac2d64a] Revoking previously assigned partitions []
2020-01-07 19:13:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-262, groupId=ee173e0a-f260-48d1-99af-1bb48ac2d64a] (Re-)joining group
2020-01-07 19:13:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-262, groupId=ee173e0a-f260-48d1-99af-1bb48ac2d64a] Successfully joined group with generation 1
2020-01-07 19:13:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-262, groupId=ee173e0a-f260-48d1-99af-1bb48ac2d64a] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:26 INFO  Fetcher:583 - [Consumer clientId=consumer-262, groupId=ee173e0a-f260-48d1-99af-1bb48ac2d64a] Resetting offset for partition facedetectiontest101-0 to offset 17757.
2020-01-07 19:13:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1bb4e258-ff35-4e34-b39b-7aa47aaf17f2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-263, groupId=1bb4e258-ff35-4e34-b39b-7aa47aaf17f2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-263, groupId=1bb4e258-ff35-4e34-b39b-7aa47aaf17f2] Revoking previously assigned partitions []
2020-01-07 19:13:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-263, groupId=1bb4e258-ff35-4e34-b39b-7aa47aaf17f2] (Re-)joining group
2020-01-07 19:13:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-263, groupId=1bb4e258-ff35-4e34-b39b-7aa47aaf17f2] Successfully joined group with generation 1
2020-01-07 19:13:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-263, groupId=1bb4e258-ff35-4e34-b39b-7aa47aaf17f2] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:26 INFO  Fetcher:583 - [Consumer clientId=consumer-263, groupId=1bb4e258-ff35-4e34-b39b-7aa47aaf17f2] Resetting offset for partition facedetectiontest101-0 to offset 17758.
2020-01-07 19:13:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ffbd0940-304e-4333-99bf-467291efcd0d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-264, groupId=ffbd0940-304e-4333-99bf-467291efcd0d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-264, groupId=ffbd0940-304e-4333-99bf-467291efcd0d] Revoking previously assigned partitions []
2020-01-07 19:13:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-264, groupId=ffbd0940-304e-4333-99bf-467291efcd0d] (Re-)joining group
2020-01-07 19:13:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-264, groupId=ffbd0940-304e-4333-99bf-467291efcd0d] Successfully joined group with generation 1
2020-01-07 19:13:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-264, groupId=ffbd0940-304e-4333-99bf-467291efcd0d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:26 INFO  Fetcher:583 - [Consumer clientId=consumer-264, groupId=ffbd0940-304e-4333-99bf-467291efcd0d] Resetting offset for partition facedetectiontest101-0 to offset 17759.
2020-01-07 19:13:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3661397a-0d31-4c06-907a-e7faefe06c8d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-265, groupId=3661397a-0d31-4c06-907a-e7faefe06c8d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-265, groupId=3661397a-0d31-4c06-907a-e7faefe06c8d] Revoking previously assigned partitions []
2020-01-07 19:13:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-265, groupId=3661397a-0d31-4c06-907a-e7faefe06c8d] (Re-)joining group
2020-01-07 19:13:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-265, groupId=3661397a-0d31-4c06-907a-e7faefe06c8d] Successfully joined group with generation 1
2020-01-07 19:13:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-265, groupId=3661397a-0d31-4c06-907a-e7faefe06c8d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:27 INFO  Fetcher:583 - [Consumer clientId=consumer-265, groupId=3661397a-0d31-4c06-907a-e7faefe06c8d] Resetting offset for partition facedetectiontest101-0 to offset 17760.
2020-01-07 19:13:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a3834012-2eaa-434d-b8de-53b48afdfbb1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-266, groupId=a3834012-2eaa-434d-b8de-53b48afdfbb1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-266, groupId=a3834012-2eaa-434d-b8de-53b48afdfbb1] Revoking previously assigned partitions []
2020-01-07 19:13:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-266, groupId=a3834012-2eaa-434d-b8de-53b48afdfbb1] (Re-)joining group
2020-01-07 19:13:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-266, groupId=a3834012-2eaa-434d-b8de-53b48afdfbb1] Successfully joined group with generation 1
2020-01-07 19:13:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-266, groupId=a3834012-2eaa-434d-b8de-53b48afdfbb1] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:27 INFO  Fetcher:583 - [Consumer clientId=consumer-266, groupId=a3834012-2eaa-434d-b8de-53b48afdfbb1] Resetting offset for partition facedetectiontest101-0 to offset 17761.
2020-01-07 19:13:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3b4b68ef-457d-4c7f-9c20-8fed986c0806
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-267, groupId=3b4b68ef-457d-4c7f-9c20-8fed986c0806] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-267, groupId=3b4b68ef-457d-4c7f-9c20-8fed986c0806] Revoking previously assigned partitions []
2020-01-07 19:13:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-267, groupId=3b4b68ef-457d-4c7f-9c20-8fed986c0806] (Re-)joining group
2020-01-07 19:13:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-267, groupId=3b4b68ef-457d-4c7f-9c20-8fed986c0806] Successfully joined group with generation 1
2020-01-07 19:13:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-267, groupId=3b4b68ef-457d-4c7f-9c20-8fed986c0806] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:27 INFO  Fetcher:583 - [Consumer clientId=consumer-267, groupId=3b4b68ef-457d-4c7f-9c20-8fed986c0806] Resetting offset for partition facedetectiontest101-0 to offset 17762.
2020-01-07 19:13:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b8e0885d-06b6-4332-b264-8f0727039f76
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-268, groupId=b8e0885d-06b6-4332-b264-8f0727039f76] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-268, groupId=b8e0885d-06b6-4332-b264-8f0727039f76] Revoking previously assigned partitions []
2020-01-07 19:13:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-268, groupId=b8e0885d-06b6-4332-b264-8f0727039f76] (Re-)joining group
2020-01-07 19:13:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-268, groupId=b8e0885d-06b6-4332-b264-8f0727039f76] Successfully joined group with generation 1
2020-01-07 19:13:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-268, groupId=b8e0885d-06b6-4332-b264-8f0727039f76] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:27 INFO  Fetcher:583 - [Consumer clientId=consumer-268, groupId=b8e0885d-06b6-4332-b264-8f0727039f76] Resetting offset for partition facedetectiontest101-0 to offset 17763.
2020-01-07 19:13:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 54d0136b-2756-420f-ac3d-f010465dda08
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-269, groupId=54d0136b-2756-420f-ac3d-f010465dda08] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-269, groupId=54d0136b-2756-420f-ac3d-f010465dda08] Revoking previously assigned partitions []
2020-01-07 19:13:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-269, groupId=54d0136b-2756-420f-ac3d-f010465dda08] (Re-)joining group
2020-01-07 19:13:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-269, groupId=54d0136b-2756-420f-ac3d-f010465dda08] Successfully joined group with generation 1
2020-01-07 19:13:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-269, groupId=54d0136b-2756-420f-ac3d-f010465dda08] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:27 INFO  Fetcher:583 - [Consumer clientId=consumer-269, groupId=54d0136b-2756-420f-ac3d-f010465dda08] Resetting offset for partition facedetectiontest101-0 to offset 17764.
2020-01-07 19:13:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c71391ce-192d-4f61-b406-e8b70c0830ee
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-270, groupId=c71391ce-192d-4f61-b406-e8b70c0830ee] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-270, groupId=c71391ce-192d-4f61-b406-e8b70c0830ee] Revoking previously assigned partitions []
2020-01-07 19:13:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-270, groupId=c71391ce-192d-4f61-b406-e8b70c0830ee] (Re-)joining group
2020-01-07 19:13:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-270, groupId=c71391ce-192d-4f61-b406-e8b70c0830ee] Successfully joined group with generation 1
2020-01-07 19:13:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-270, groupId=c71391ce-192d-4f61-b406-e8b70c0830ee] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:27 INFO  Fetcher:583 - [Consumer clientId=consumer-270, groupId=c71391ce-192d-4f61-b406-e8b70c0830ee] Resetting offset for partition facedetectiontest101-0 to offset 17765.
2020-01-07 19:13:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7be4bb4d-f87b-4f23-82b4-891d6feea50f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-271, groupId=7be4bb4d-f87b-4f23-82b4-891d6feea50f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-271, groupId=7be4bb4d-f87b-4f23-82b4-891d6feea50f] Revoking previously assigned partitions []
2020-01-07 19:13:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-271, groupId=7be4bb4d-f87b-4f23-82b4-891d6feea50f] (Re-)joining group
2020-01-07 19:13:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-271, groupId=7be4bb4d-f87b-4f23-82b4-891d6feea50f] Successfully joined group with generation 1
2020-01-07 19:13:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-271, groupId=7be4bb4d-f87b-4f23-82b4-891d6feea50f] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:27 INFO  Fetcher:583 - [Consumer clientId=consumer-271, groupId=7be4bb4d-f87b-4f23-82b4-891d6feea50f] Resetting offset for partition facedetectiontest101-0 to offset 17766.
2020-01-07 19:13:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0f685303-7b93-49bc-921f-9e7eadc8a870
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-272, groupId=0f685303-7b93-49bc-921f-9e7eadc8a870] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-272, groupId=0f685303-7b93-49bc-921f-9e7eadc8a870] Revoking previously assigned partitions []
2020-01-07 19:13:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-272, groupId=0f685303-7b93-49bc-921f-9e7eadc8a870] (Re-)joining group
2020-01-07 19:13:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-272, groupId=0f685303-7b93-49bc-921f-9e7eadc8a870] Successfully joined group with generation 1
2020-01-07 19:13:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-272, groupId=0f685303-7b93-49bc-921f-9e7eadc8a870] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:27 INFO  Fetcher:583 - [Consumer clientId=consumer-272, groupId=0f685303-7b93-49bc-921f-9e7eadc8a870] Resetting offset for partition facedetectiontest101-0 to offset 17767.
2020-01-07 19:13:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a52e6b0c-f7c0-4784-8ed4-0705cc59ace4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-273, groupId=a52e6b0c-f7c0-4784-8ed4-0705cc59ace4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-273, groupId=a52e6b0c-f7c0-4784-8ed4-0705cc59ace4] Revoking previously assigned partitions []
2020-01-07 19:13:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-273, groupId=a52e6b0c-f7c0-4784-8ed4-0705cc59ace4] (Re-)joining group
2020-01-07 19:13:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-273, groupId=a52e6b0c-f7c0-4784-8ed4-0705cc59ace4] Successfully joined group with generation 1
2020-01-07 19:13:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-273, groupId=a52e6b0c-f7c0-4784-8ed4-0705cc59ace4] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:27 INFO  Fetcher:583 - [Consumer clientId=consumer-273, groupId=a52e6b0c-f7c0-4784-8ed4-0705cc59ace4] Resetting offset for partition facedetectiontest101-0 to offset 17768.
2020-01-07 19:13:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2f7a0305-253f-49e5-800c-3a55f942d335
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-274, groupId=2f7a0305-253f-49e5-800c-3a55f942d335] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-274, groupId=2f7a0305-253f-49e5-800c-3a55f942d335] Revoking previously assigned partitions []
2020-01-07 19:13:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-274, groupId=2f7a0305-253f-49e5-800c-3a55f942d335] (Re-)joining group
2020-01-07 19:13:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-274, groupId=2f7a0305-253f-49e5-800c-3a55f942d335] Successfully joined group with generation 1
2020-01-07 19:13:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-274, groupId=2f7a0305-253f-49e5-800c-3a55f942d335] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:27 INFO  Fetcher:583 - [Consumer clientId=consumer-274, groupId=2f7a0305-253f-49e5-800c-3a55f942d335] Resetting offset for partition facedetectiontest101-0 to offset 17769.
2020-01-07 19:13:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e640ab37-733c-4b14-b76e-21586d37430d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-275, groupId=e640ab37-733c-4b14-b76e-21586d37430d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-275, groupId=e640ab37-733c-4b14-b76e-21586d37430d] Revoking previously assigned partitions []
2020-01-07 19:13:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-275, groupId=e640ab37-733c-4b14-b76e-21586d37430d] (Re-)joining group
2020-01-07 19:13:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-275, groupId=e640ab37-733c-4b14-b76e-21586d37430d] Successfully joined group with generation 1
2020-01-07 19:13:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-275, groupId=e640ab37-733c-4b14-b76e-21586d37430d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:27 INFO  Fetcher:583 - [Consumer clientId=consumer-275, groupId=e640ab37-733c-4b14-b76e-21586d37430d] Resetting offset for partition facedetectiontest101-0 to offset 17770.
2020-01-07 19:13:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4e43933b-629f-48e7-b066-fb5fcb651ce1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-276, groupId=4e43933b-629f-48e7-b066-fb5fcb651ce1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-276, groupId=4e43933b-629f-48e7-b066-fb5fcb651ce1] Revoking previously assigned partitions []
2020-01-07 19:13:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-276, groupId=4e43933b-629f-48e7-b066-fb5fcb651ce1] (Re-)joining group
2020-01-07 19:13:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-276, groupId=4e43933b-629f-48e7-b066-fb5fcb651ce1] Successfully joined group with generation 1
2020-01-07 19:13:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-276, groupId=4e43933b-629f-48e7-b066-fb5fcb651ce1] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:27 INFO  Fetcher:583 - [Consumer clientId=consumer-276, groupId=4e43933b-629f-48e7-b066-fb5fcb651ce1] Resetting offset for partition facedetectiontest101-0 to offset 17771.
2020-01-07 19:13:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9d131e1c-a136-4589-b08c-09628ebd0d3a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-277, groupId=9d131e1c-a136-4589-b08c-09628ebd0d3a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-277, groupId=9d131e1c-a136-4589-b08c-09628ebd0d3a] Revoking previously assigned partitions []
2020-01-07 19:13:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-277, groupId=9d131e1c-a136-4589-b08c-09628ebd0d3a] (Re-)joining group
2020-01-07 19:13:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-277, groupId=9d131e1c-a136-4589-b08c-09628ebd0d3a] Successfully joined group with generation 1
2020-01-07 19:13:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-277, groupId=9d131e1c-a136-4589-b08c-09628ebd0d3a] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:27 INFO  Fetcher:583 - [Consumer clientId=consumer-277, groupId=9d131e1c-a136-4589-b08c-09628ebd0d3a] Resetting offset for partition facedetectiontest101-0 to offset 17772.
2020-01-07 19:13:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0e0c7885-7489-4901-833f-2c9554004e2d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-278, groupId=0e0c7885-7489-4901-833f-2c9554004e2d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-278, groupId=0e0c7885-7489-4901-833f-2c9554004e2d] Revoking previously assigned partitions []
2020-01-07 19:13:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-278, groupId=0e0c7885-7489-4901-833f-2c9554004e2d] (Re-)joining group
2020-01-07 19:13:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-278, groupId=0e0c7885-7489-4901-833f-2c9554004e2d] Successfully joined group with generation 1
2020-01-07 19:13:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-278, groupId=0e0c7885-7489-4901-833f-2c9554004e2d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:28 INFO  Fetcher:583 - [Consumer clientId=consumer-278, groupId=0e0c7885-7489-4901-833f-2c9554004e2d] Resetting offset for partition facedetectiontest101-0 to offset 17773.
2020-01-07 19:13:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = bdc526db-4647-4eef-8d9c-5d7544629410
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-279, groupId=bdc526db-4647-4eef-8d9c-5d7544629410] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-279, groupId=bdc526db-4647-4eef-8d9c-5d7544629410] Revoking previously assigned partitions []
2020-01-07 19:13:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-279, groupId=bdc526db-4647-4eef-8d9c-5d7544629410] (Re-)joining group
2020-01-07 19:13:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-279, groupId=bdc526db-4647-4eef-8d9c-5d7544629410] Successfully joined group with generation 1
2020-01-07 19:13:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-279, groupId=bdc526db-4647-4eef-8d9c-5d7544629410] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:28 INFO  Fetcher:583 - [Consumer clientId=consumer-279, groupId=bdc526db-4647-4eef-8d9c-5d7544629410] Resetting offset for partition facedetectiontest101-0 to offset 17774.
2020-01-07 19:13:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f16661fe-3b42-48ae-8324-9e4f6666c733
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-280, groupId=f16661fe-3b42-48ae-8324-9e4f6666c733] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-280, groupId=f16661fe-3b42-48ae-8324-9e4f6666c733] Revoking previously assigned partitions []
2020-01-07 19:13:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-280, groupId=f16661fe-3b42-48ae-8324-9e4f6666c733] (Re-)joining group
2020-01-07 19:13:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-280, groupId=f16661fe-3b42-48ae-8324-9e4f6666c733] Successfully joined group with generation 1
2020-01-07 19:13:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-280, groupId=f16661fe-3b42-48ae-8324-9e4f6666c733] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:28 INFO  Fetcher:583 - [Consumer clientId=consumer-280, groupId=f16661fe-3b42-48ae-8324-9e4f6666c733] Resetting offset for partition facedetectiontest101-0 to offset 17775.
2020-01-07 19:13:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 470779be-969b-4364-bad4-742b35408bef
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-281, groupId=470779be-969b-4364-bad4-742b35408bef] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-281, groupId=470779be-969b-4364-bad4-742b35408bef] Revoking previously assigned partitions []
2020-01-07 19:13:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-281, groupId=470779be-969b-4364-bad4-742b35408bef] (Re-)joining group
2020-01-07 19:13:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-281, groupId=470779be-969b-4364-bad4-742b35408bef] Successfully joined group with generation 1
2020-01-07 19:13:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-281, groupId=470779be-969b-4364-bad4-742b35408bef] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:28 INFO  Fetcher:583 - [Consumer clientId=consumer-281, groupId=470779be-969b-4364-bad4-742b35408bef] Resetting offset for partition facedetectiontest101-0 to offset 17776.
2020-01-07 19:13:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5aaa2d12-a6d0-4969-96d1-e8fa9f4d0ac6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-282, groupId=5aaa2d12-a6d0-4969-96d1-e8fa9f4d0ac6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-282, groupId=5aaa2d12-a6d0-4969-96d1-e8fa9f4d0ac6] Revoking previously assigned partitions []
2020-01-07 19:13:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-282, groupId=5aaa2d12-a6d0-4969-96d1-e8fa9f4d0ac6] (Re-)joining group
2020-01-07 19:13:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-282, groupId=5aaa2d12-a6d0-4969-96d1-e8fa9f4d0ac6] Successfully joined group with generation 1
2020-01-07 19:13:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-282, groupId=5aaa2d12-a6d0-4969-96d1-e8fa9f4d0ac6] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:28 INFO  Fetcher:583 - [Consumer clientId=consumer-282, groupId=5aaa2d12-a6d0-4969-96d1-e8fa9f4d0ac6] Resetting offset for partition facedetectiontest101-0 to offset 17778.
2020-01-07 19:13:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2419af05-9ed5-4e1d-b80a-e1b89f132f3c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-283, groupId=2419af05-9ed5-4e1d-b80a-e1b89f132f3c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-283, groupId=2419af05-9ed5-4e1d-b80a-e1b89f132f3c] Revoking previously assigned partitions []
2020-01-07 19:13:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-283, groupId=2419af05-9ed5-4e1d-b80a-e1b89f132f3c] (Re-)joining group
2020-01-07 19:13:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-283, groupId=2419af05-9ed5-4e1d-b80a-e1b89f132f3c] Successfully joined group with generation 1
2020-01-07 19:13:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-283, groupId=2419af05-9ed5-4e1d-b80a-e1b89f132f3c] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:28 INFO  Fetcher:583 - [Consumer clientId=consumer-283, groupId=2419af05-9ed5-4e1d-b80a-e1b89f132f3c] Resetting offset for partition facedetectiontest101-0 to offset 17779.
2020-01-07 19:13:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 97b2375a-f77e-4a1d-ba1a-a45fc89c6ef4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-284, groupId=97b2375a-f77e-4a1d-ba1a-a45fc89c6ef4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-284, groupId=97b2375a-f77e-4a1d-ba1a-a45fc89c6ef4] Revoking previously assigned partitions []
2020-01-07 19:13:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-284, groupId=97b2375a-f77e-4a1d-ba1a-a45fc89c6ef4] (Re-)joining group
2020-01-07 19:13:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-284, groupId=97b2375a-f77e-4a1d-ba1a-a45fc89c6ef4] Successfully joined group with generation 1
2020-01-07 19:13:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-284, groupId=97b2375a-f77e-4a1d-ba1a-a45fc89c6ef4] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:28 INFO  Fetcher:583 - [Consumer clientId=consumer-284, groupId=97b2375a-f77e-4a1d-ba1a-a45fc89c6ef4] Resetting offset for partition facedetectiontest101-0 to offset 17780.
2020-01-07 19:13:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f64697e9-d59e-49ce-a27b-3d2e5bd8ae71
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-285, groupId=f64697e9-d59e-49ce-a27b-3d2e5bd8ae71] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-285, groupId=f64697e9-d59e-49ce-a27b-3d2e5bd8ae71] Revoking previously assigned partitions []
2020-01-07 19:13:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-285, groupId=f64697e9-d59e-49ce-a27b-3d2e5bd8ae71] (Re-)joining group
2020-01-07 19:13:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-285, groupId=f64697e9-d59e-49ce-a27b-3d2e5bd8ae71] Successfully joined group with generation 1
2020-01-07 19:13:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-285, groupId=f64697e9-d59e-49ce-a27b-3d2e5bd8ae71] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:28 INFO  Fetcher:583 - [Consumer clientId=consumer-285, groupId=f64697e9-d59e-49ce-a27b-3d2e5bd8ae71] Resetting offset for partition facedetectiontest101-0 to offset 17781.
2020-01-07 19:13:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 10785103-a2c2-48aa-8b1b-e9c85ab56b6e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-286, groupId=10785103-a2c2-48aa-8b1b-e9c85ab56b6e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-286, groupId=10785103-a2c2-48aa-8b1b-e9c85ab56b6e] Revoking previously assigned partitions []
2020-01-07 19:13:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-286, groupId=10785103-a2c2-48aa-8b1b-e9c85ab56b6e] (Re-)joining group
2020-01-07 19:13:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-286, groupId=10785103-a2c2-48aa-8b1b-e9c85ab56b6e] Successfully joined group with generation 1
2020-01-07 19:13:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-286, groupId=10785103-a2c2-48aa-8b1b-e9c85ab56b6e] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:28 INFO  Fetcher:583 - [Consumer clientId=consumer-286, groupId=10785103-a2c2-48aa-8b1b-e9c85ab56b6e] Resetting offset for partition facedetectiontest101-0 to offset 17782.
2020-01-07 19:13:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 55797448-c65d-487b-8c75-edd6c7f84325
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-287, groupId=55797448-c65d-487b-8c75-edd6c7f84325] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-287, groupId=55797448-c65d-487b-8c75-edd6c7f84325] Revoking previously assigned partitions []
2020-01-07 19:13:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-287, groupId=55797448-c65d-487b-8c75-edd6c7f84325] (Re-)joining group
2020-01-07 19:13:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-287, groupId=55797448-c65d-487b-8c75-edd6c7f84325] Successfully joined group with generation 1
2020-01-07 19:13:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-287, groupId=55797448-c65d-487b-8c75-edd6c7f84325] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:28 INFO  Fetcher:583 - [Consumer clientId=consumer-287, groupId=55797448-c65d-487b-8c75-edd6c7f84325] Resetting offset for partition facedetectiontest101-0 to offset 17783.
2020-01-07 19:13:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ed962828-2af4-4aa4-9d27-295d6d8efecd
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-288, groupId=ed962828-2af4-4aa4-9d27-295d6d8efecd] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-288, groupId=ed962828-2af4-4aa4-9d27-295d6d8efecd] Revoking previously assigned partitions []
2020-01-07 19:13:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-288, groupId=ed962828-2af4-4aa4-9d27-295d6d8efecd] (Re-)joining group
2020-01-07 19:13:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-288, groupId=ed962828-2af4-4aa4-9d27-295d6d8efecd] Successfully joined group with generation 1
2020-01-07 19:13:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-288, groupId=ed962828-2af4-4aa4-9d27-295d6d8efecd] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:28 INFO  Fetcher:583 - [Consumer clientId=consumer-288, groupId=ed962828-2af4-4aa4-9d27-295d6d8efecd] Resetting offset for partition facedetectiontest101-0 to offset 17784.
2020-01-07 19:13:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9deafc2a-0929-4c72-b2ff-222717a6c18d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-289, groupId=9deafc2a-0929-4c72-b2ff-222717a6c18d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-289, groupId=9deafc2a-0929-4c72-b2ff-222717a6c18d] Revoking previously assigned partitions []
2020-01-07 19:13:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-289, groupId=9deafc2a-0929-4c72-b2ff-222717a6c18d] (Re-)joining group
2020-01-07 19:13:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-289, groupId=9deafc2a-0929-4c72-b2ff-222717a6c18d] Successfully joined group with generation 1
2020-01-07 19:13:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-289, groupId=9deafc2a-0929-4c72-b2ff-222717a6c18d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:29 INFO  Fetcher:583 - [Consumer clientId=consumer-289, groupId=9deafc2a-0929-4c72-b2ff-222717a6c18d] Resetting offset for partition facedetectiontest101-0 to offset 17785.
2020-01-07 19:13:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 42ad1eab-4f6b-48d6-be44-7e86c6a2d7b7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-290, groupId=42ad1eab-4f6b-48d6-be44-7e86c6a2d7b7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-290, groupId=42ad1eab-4f6b-48d6-be44-7e86c6a2d7b7] Revoking previously assigned partitions []
2020-01-07 19:13:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-290, groupId=42ad1eab-4f6b-48d6-be44-7e86c6a2d7b7] (Re-)joining group
2020-01-07 19:13:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-290, groupId=42ad1eab-4f6b-48d6-be44-7e86c6a2d7b7] Successfully joined group with generation 1
2020-01-07 19:13:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-290, groupId=42ad1eab-4f6b-48d6-be44-7e86c6a2d7b7] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:29 INFO  Fetcher:583 - [Consumer clientId=consumer-290, groupId=42ad1eab-4f6b-48d6-be44-7e86c6a2d7b7] Resetting offset for partition facedetectiontest101-0 to offset 17786.
2020-01-07 19:13:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = cdcceac4-bd64-46c5-9e50-10f58d586045
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-291, groupId=cdcceac4-bd64-46c5-9e50-10f58d586045] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-291, groupId=cdcceac4-bd64-46c5-9e50-10f58d586045] Revoking previously assigned partitions []
2020-01-07 19:13:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-291, groupId=cdcceac4-bd64-46c5-9e50-10f58d586045] (Re-)joining group
2020-01-07 19:13:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-291, groupId=cdcceac4-bd64-46c5-9e50-10f58d586045] Successfully joined group with generation 1
2020-01-07 19:13:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-291, groupId=cdcceac4-bd64-46c5-9e50-10f58d586045] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:29 INFO  Fetcher:583 - [Consumer clientId=consumer-291, groupId=cdcceac4-bd64-46c5-9e50-10f58d586045] Resetting offset for partition facedetectiontest101-0 to offset 17787.
2020-01-07 19:13:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8b62a450-cc73-4253-9f40-f7eb233713e7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-292, groupId=8b62a450-cc73-4253-9f40-f7eb233713e7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-292, groupId=8b62a450-cc73-4253-9f40-f7eb233713e7] Revoking previously assigned partitions []
2020-01-07 19:13:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-292, groupId=8b62a450-cc73-4253-9f40-f7eb233713e7] (Re-)joining group
2020-01-07 19:13:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-292, groupId=8b62a450-cc73-4253-9f40-f7eb233713e7] Successfully joined group with generation 1
2020-01-07 19:13:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-292, groupId=8b62a450-cc73-4253-9f40-f7eb233713e7] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:29 INFO  Fetcher:583 - [Consumer clientId=consumer-292, groupId=8b62a450-cc73-4253-9f40-f7eb233713e7] Resetting offset for partition facedetectiontest101-0 to offset 17788.
2020-01-07 19:13:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1f4280de-2d56-4e2d-a801-4a41af0c1a90
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-293, groupId=1f4280de-2d56-4e2d-a801-4a41af0c1a90] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-293, groupId=1f4280de-2d56-4e2d-a801-4a41af0c1a90] Revoking previously assigned partitions []
2020-01-07 19:13:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-293, groupId=1f4280de-2d56-4e2d-a801-4a41af0c1a90] (Re-)joining group
2020-01-07 19:13:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-293, groupId=1f4280de-2d56-4e2d-a801-4a41af0c1a90] Successfully joined group with generation 1
2020-01-07 19:13:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-293, groupId=1f4280de-2d56-4e2d-a801-4a41af0c1a90] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:29 INFO  Fetcher:583 - [Consumer clientId=consumer-293, groupId=1f4280de-2d56-4e2d-a801-4a41af0c1a90] Resetting offset for partition facedetectiontest101-0 to offset 17789.
2020-01-07 19:13:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = bc373325-e5bf-4841-9636-88bfda5bcdf3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-294, groupId=bc373325-e5bf-4841-9636-88bfda5bcdf3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-294, groupId=bc373325-e5bf-4841-9636-88bfda5bcdf3] Revoking previously assigned partitions []
2020-01-07 19:13:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-294, groupId=bc373325-e5bf-4841-9636-88bfda5bcdf3] (Re-)joining group
2020-01-07 19:13:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-294, groupId=bc373325-e5bf-4841-9636-88bfda5bcdf3] Successfully joined group with generation 1
2020-01-07 19:13:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-294, groupId=bc373325-e5bf-4841-9636-88bfda5bcdf3] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:29 INFO  Fetcher:583 - [Consumer clientId=consumer-294, groupId=bc373325-e5bf-4841-9636-88bfda5bcdf3] Resetting offset for partition facedetectiontest101-0 to offset 17790.
2020-01-07 19:13:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 50e97b0a-0bbc-4bb4-84e9-1c9bbe504ec0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-295, groupId=50e97b0a-0bbc-4bb4-84e9-1c9bbe504ec0] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-295, groupId=50e97b0a-0bbc-4bb4-84e9-1c9bbe504ec0] Revoking previously assigned partitions []
2020-01-07 19:13:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-295, groupId=50e97b0a-0bbc-4bb4-84e9-1c9bbe504ec0] (Re-)joining group
2020-01-07 19:13:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-295, groupId=50e97b0a-0bbc-4bb4-84e9-1c9bbe504ec0] Successfully joined group with generation 1
2020-01-07 19:13:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-295, groupId=50e97b0a-0bbc-4bb4-84e9-1c9bbe504ec0] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:29 INFO  Fetcher:583 - [Consumer clientId=consumer-295, groupId=50e97b0a-0bbc-4bb4-84e9-1c9bbe504ec0] Resetting offset for partition facedetectiontest101-0 to offset 17791.
2020-01-07 19:13:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a47f3abf-d327-488e-bdb6-c199f5b7cb9e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-296, groupId=a47f3abf-d327-488e-bdb6-c199f5b7cb9e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-296, groupId=a47f3abf-d327-488e-bdb6-c199f5b7cb9e] Revoking previously assigned partitions []
2020-01-07 19:13:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-296, groupId=a47f3abf-d327-488e-bdb6-c199f5b7cb9e] (Re-)joining group
2020-01-07 19:13:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-296, groupId=a47f3abf-d327-488e-bdb6-c199f5b7cb9e] Successfully joined group with generation 1
2020-01-07 19:13:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-296, groupId=a47f3abf-d327-488e-bdb6-c199f5b7cb9e] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:29 INFO  Fetcher:583 - [Consumer clientId=consumer-296, groupId=a47f3abf-d327-488e-bdb6-c199f5b7cb9e] Resetting offset for partition facedetectiontest101-0 to offset 17792.
2020-01-07 19:13:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = af48fc3d-7b93-4582-88e7-944782b9619e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-297, groupId=af48fc3d-7b93-4582-88e7-944782b9619e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-297, groupId=af48fc3d-7b93-4582-88e7-944782b9619e] Revoking previously assigned partitions []
2020-01-07 19:13:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-297, groupId=af48fc3d-7b93-4582-88e7-944782b9619e] (Re-)joining group
2020-01-07 19:13:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-297, groupId=af48fc3d-7b93-4582-88e7-944782b9619e] Successfully joined group with generation 1
2020-01-07 19:13:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-297, groupId=af48fc3d-7b93-4582-88e7-944782b9619e] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:29 INFO  Fetcher:583 - [Consumer clientId=consumer-297, groupId=af48fc3d-7b93-4582-88e7-944782b9619e] Resetting offset for partition facedetectiontest101-0 to offset 17793.
2020-01-07 19:13:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7a530870-8503-4fe5-bb41-be8a2bc4cb83
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-298, groupId=7a530870-8503-4fe5-bb41-be8a2bc4cb83] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-298, groupId=7a530870-8503-4fe5-bb41-be8a2bc4cb83] Revoking previously assigned partitions []
2020-01-07 19:13:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-298, groupId=7a530870-8503-4fe5-bb41-be8a2bc4cb83] (Re-)joining group
2020-01-07 19:13:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-298, groupId=7a530870-8503-4fe5-bb41-be8a2bc4cb83] Successfully joined group with generation 1
2020-01-07 19:13:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-298, groupId=7a530870-8503-4fe5-bb41-be8a2bc4cb83] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:29 INFO  Fetcher:583 - [Consumer clientId=consumer-298, groupId=7a530870-8503-4fe5-bb41-be8a2bc4cb83] Resetting offset for partition facedetectiontest101-0 to offset 17795.
2020-01-07 19:13:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d22da0af-0c74-4d37-b019-2589c20f3855
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-299, groupId=d22da0af-0c74-4d37-b019-2589c20f3855] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-299, groupId=d22da0af-0c74-4d37-b019-2589c20f3855] Revoking previously assigned partitions []
2020-01-07 19:13:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-299, groupId=d22da0af-0c74-4d37-b019-2589c20f3855] (Re-)joining group
2020-01-07 19:13:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-299, groupId=d22da0af-0c74-4d37-b019-2589c20f3855] Successfully joined group with generation 1
2020-01-07 19:13:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-299, groupId=d22da0af-0c74-4d37-b019-2589c20f3855] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:29 INFO  Fetcher:583 - [Consumer clientId=consumer-299, groupId=d22da0af-0c74-4d37-b019-2589c20f3855] Resetting offset for partition facedetectiontest101-0 to offset 17797.
2020-01-07 19:13:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 86556c59-be47-4f15-a41d-419271fe89e9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-300, groupId=86556c59-be47-4f15-a41d-419271fe89e9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-300, groupId=86556c59-be47-4f15-a41d-419271fe89e9] Revoking previously assigned partitions []
2020-01-07 19:13:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-300, groupId=86556c59-be47-4f15-a41d-419271fe89e9] (Re-)joining group
2020-01-07 19:13:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-300, groupId=86556c59-be47-4f15-a41d-419271fe89e9] Successfully joined group with generation 1
2020-01-07 19:13:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-300, groupId=86556c59-be47-4f15-a41d-419271fe89e9] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:29 INFO  Fetcher:583 - [Consumer clientId=consumer-300, groupId=86556c59-be47-4f15-a41d-419271fe89e9] Resetting offset for partition facedetectiontest101-0 to offset 17798.
2020-01-07 19:13:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c6b18429-78ec-4914-8ab2-2b9a5dcb46f9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-301, groupId=c6b18429-78ec-4914-8ab2-2b9a5dcb46f9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-301, groupId=c6b18429-78ec-4914-8ab2-2b9a5dcb46f9] Revoking previously assigned partitions []
2020-01-07 19:13:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-301, groupId=c6b18429-78ec-4914-8ab2-2b9a5dcb46f9] (Re-)joining group
2020-01-07 19:13:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-301, groupId=c6b18429-78ec-4914-8ab2-2b9a5dcb46f9] Successfully joined group with generation 1
2020-01-07 19:13:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-301, groupId=c6b18429-78ec-4914-8ab2-2b9a5dcb46f9] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:29 INFO  Fetcher:583 - [Consumer clientId=consumer-301, groupId=c6b18429-78ec-4914-8ab2-2b9a5dcb46f9] Resetting offset for partition facedetectiontest101-0 to offset 17800.
2020-01-07 19:13:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 60a1cd8e-b759-4a57-b1ce-2702b0846034
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-302, groupId=60a1cd8e-b759-4a57-b1ce-2702b0846034] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-302, groupId=60a1cd8e-b759-4a57-b1ce-2702b0846034] Revoking previously assigned partitions []
2020-01-07 19:13:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-302, groupId=60a1cd8e-b759-4a57-b1ce-2702b0846034] (Re-)joining group
2020-01-07 19:13:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-302, groupId=60a1cd8e-b759-4a57-b1ce-2702b0846034] Successfully joined group with generation 1
2020-01-07 19:13:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-302, groupId=60a1cd8e-b759-4a57-b1ce-2702b0846034] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:30 INFO  Fetcher:583 - [Consumer clientId=consumer-302, groupId=60a1cd8e-b759-4a57-b1ce-2702b0846034] Resetting offset for partition facedetectiontest101-0 to offset 17801.
2020-01-07 19:13:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d666c432-8c5e-4bcc-81a3-ed8d6b220081
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-303, groupId=d666c432-8c5e-4bcc-81a3-ed8d6b220081] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-303, groupId=d666c432-8c5e-4bcc-81a3-ed8d6b220081] Revoking previously assigned partitions []
2020-01-07 19:13:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-303, groupId=d666c432-8c5e-4bcc-81a3-ed8d6b220081] (Re-)joining group
2020-01-07 19:13:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-303, groupId=d666c432-8c5e-4bcc-81a3-ed8d6b220081] Successfully joined group with generation 1
2020-01-07 19:13:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-303, groupId=d666c432-8c5e-4bcc-81a3-ed8d6b220081] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:30 INFO  Fetcher:583 - [Consumer clientId=consumer-303, groupId=d666c432-8c5e-4bcc-81a3-ed8d6b220081] Resetting offset for partition facedetectiontest101-0 to offset 17802.
2020-01-07 19:13:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 34e1c353-958d-4420-93d9-825e0973f849
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-304, groupId=34e1c353-958d-4420-93d9-825e0973f849] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-304, groupId=34e1c353-958d-4420-93d9-825e0973f849] Revoking previously assigned partitions []
2020-01-07 19:13:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-304, groupId=34e1c353-958d-4420-93d9-825e0973f849] (Re-)joining group
2020-01-07 19:13:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-304, groupId=34e1c353-958d-4420-93d9-825e0973f849] Successfully joined group with generation 1
2020-01-07 19:13:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-304, groupId=34e1c353-958d-4420-93d9-825e0973f849] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:30 INFO  Fetcher:583 - [Consumer clientId=consumer-304, groupId=34e1c353-958d-4420-93d9-825e0973f849] Resetting offset for partition facedetectiontest101-0 to offset 17803.
2020-01-07 19:13:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fa45934f-ea7e-4990-98e9-216a40a08e04
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-305, groupId=fa45934f-ea7e-4990-98e9-216a40a08e04] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-305, groupId=fa45934f-ea7e-4990-98e9-216a40a08e04] Revoking previously assigned partitions []
2020-01-07 19:13:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-305, groupId=fa45934f-ea7e-4990-98e9-216a40a08e04] (Re-)joining group
2020-01-07 19:13:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-305, groupId=fa45934f-ea7e-4990-98e9-216a40a08e04] Successfully joined group with generation 1
2020-01-07 19:13:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-305, groupId=fa45934f-ea7e-4990-98e9-216a40a08e04] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:30 INFO  Fetcher:583 - [Consumer clientId=consumer-305, groupId=fa45934f-ea7e-4990-98e9-216a40a08e04] Resetting offset for partition facedetectiontest101-0 to offset 17804.
2020-01-07 19:13:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8173e312-d7c1-44f8-b56e-4e1956320ab0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-306, groupId=8173e312-d7c1-44f8-b56e-4e1956320ab0] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-306, groupId=8173e312-d7c1-44f8-b56e-4e1956320ab0] Revoking previously assigned partitions []
2020-01-07 19:13:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-306, groupId=8173e312-d7c1-44f8-b56e-4e1956320ab0] (Re-)joining group
2020-01-07 19:13:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-306, groupId=8173e312-d7c1-44f8-b56e-4e1956320ab0] Successfully joined group with generation 1
2020-01-07 19:13:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-306, groupId=8173e312-d7c1-44f8-b56e-4e1956320ab0] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:30 INFO  Fetcher:583 - [Consumer clientId=consumer-306, groupId=8173e312-d7c1-44f8-b56e-4e1956320ab0] Resetting offset for partition facedetectiontest101-0 to offset 17805.
2020-01-07 19:13:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 004e00cf-bef1-4521-b650-bd0c396b24e8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-307, groupId=004e00cf-bef1-4521-b650-bd0c396b24e8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-307, groupId=004e00cf-bef1-4521-b650-bd0c396b24e8] Revoking previously assigned partitions []
2020-01-07 19:13:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-307, groupId=004e00cf-bef1-4521-b650-bd0c396b24e8] (Re-)joining group
2020-01-07 19:13:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-307, groupId=004e00cf-bef1-4521-b650-bd0c396b24e8] Successfully joined group with generation 1
2020-01-07 19:13:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-307, groupId=004e00cf-bef1-4521-b650-bd0c396b24e8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:30 INFO  Fetcher:583 - [Consumer clientId=consumer-307, groupId=004e00cf-bef1-4521-b650-bd0c396b24e8] Resetting offset for partition facedetectiontest101-0 to offset 17806.
2020-01-07 19:13:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b57bed8c-6192-4a31-9194-85d2b77109d5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-308, groupId=b57bed8c-6192-4a31-9194-85d2b77109d5] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-308, groupId=b57bed8c-6192-4a31-9194-85d2b77109d5] Revoking previously assigned partitions []
2020-01-07 19:13:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-308, groupId=b57bed8c-6192-4a31-9194-85d2b77109d5] (Re-)joining group
2020-01-07 19:13:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-308, groupId=b57bed8c-6192-4a31-9194-85d2b77109d5] Successfully joined group with generation 1
2020-01-07 19:13:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-308, groupId=b57bed8c-6192-4a31-9194-85d2b77109d5] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:30 INFO  Fetcher:583 - [Consumer clientId=consumer-308, groupId=b57bed8c-6192-4a31-9194-85d2b77109d5] Resetting offset for partition facedetectiontest101-0 to offset 17807.
2020-01-07 19:13:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = de1385c1-ddfd-4733-854d-3dfb63a7c968
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-309, groupId=de1385c1-ddfd-4733-854d-3dfb63a7c968] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-309, groupId=de1385c1-ddfd-4733-854d-3dfb63a7c968] Revoking previously assigned partitions []
2020-01-07 19:13:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-309, groupId=de1385c1-ddfd-4733-854d-3dfb63a7c968] (Re-)joining group
2020-01-07 19:13:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-309, groupId=de1385c1-ddfd-4733-854d-3dfb63a7c968] Successfully joined group with generation 1
2020-01-07 19:13:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-309, groupId=de1385c1-ddfd-4733-854d-3dfb63a7c968] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:30 INFO  Fetcher:583 - [Consumer clientId=consumer-309, groupId=de1385c1-ddfd-4733-854d-3dfb63a7c968] Resetting offset for partition facedetectiontest101-0 to offset 17809.
2020-01-07 19:13:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5ef68658-6ec3-47b1-b22e-a06d138fa22d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-310, groupId=5ef68658-6ec3-47b1-b22e-a06d138fa22d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-310, groupId=5ef68658-6ec3-47b1-b22e-a06d138fa22d] Revoking previously assigned partitions []
2020-01-07 19:13:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-310, groupId=5ef68658-6ec3-47b1-b22e-a06d138fa22d] (Re-)joining group
2020-01-07 19:13:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-310, groupId=5ef68658-6ec3-47b1-b22e-a06d138fa22d] Successfully joined group with generation 1
2020-01-07 19:13:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-310, groupId=5ef68658-6ec3-47b1-b22e-a06d138fa22d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:30 INFO  Fetcher:583 - [Consumer clientId=consumer-310, groupId=5ef68658-6ec3-47b1-b22e-a06d138fa22d] Resetting offset for partition facedetectiontest101-0 to offset 17810.
2020-01-07 19:13:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 59ddd2fd-e21c-47b9-9936-493bf32904c9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-311, groupId=59ddd2fd-e21c-47b9-9936-493bf32904c9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-311, groupId=59ddd2fd-e21c-47b9-9936-493bf32904c9] Revoking previously assigned partitions []
2020-01-07 19:13:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-311, groupId=59ddd2fd-e21c-47b9-9936-493bf32904c9] (Re-)joining group
2020-01-07 19:13:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-311, groupId=59ddd2fd-e21c-47b9-9936-493bf32904c9] Successfully joined group with generation 1
2020-01-07 19:13:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-311, groupId=59ddd2fd-e21c-47b9-9936-493bf32904c9] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:30 INFO  Fetcher:583 - [Consumer clientId=consumer-311, groupId=59ddd2fd-e21c-47b9-9936-493bf32904c9] Resetting offset for partition facedetectiontest101-0 to offset 17812.
2020-01-07 19:13:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b04208e2-8da6-4546-ba96-0906f0588a2e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-312, groupId=b04208e2-8da6-4546-ba96-0906f0588a2e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-312, groupId=b04208e2-8da6-4546-ba96-0906f0588a2e] Revoking previously assigned partitions []
2020-01-07 19:13:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-312, groupId=b04208e2-8da6-4546-ba96-0906f0588a2e] (Re-)joining group
2020-01-07 19:13:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-312, groupId=b04208e2-8da6-4546-ba96-0906f0588a2e] Successfully joined group with generation 1
2020-01-07 19:13:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-312, groupId=b04208e2-8da6-4546-ba96-0906f0588a2e] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:30 INFO  Fetcher:583 - [Consumer clientId=consumer-312, groupId=b04208e2-8da6-4546-ba96-0906f0588a2e] Resetting offset for partition facedetectiontest101-0 to offset 17813.
2020-01-07 19:13:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8ef762b5-81d1-4cb8-9cd4-f45c689cc196
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-313, groupId=8ef762b5-81d1-4cb8-9cd4-f45c689cc196] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-313, groupId=8ef762b5-81d1-4cb8-9cd4-f45c689cc196] Revoking previously assigned partitions []
2020-01-07 19:13:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-313, groupId=8ef762b5-81d1-4cb8-9cd4-f45c689cc196] (Re-)joining group
2020-01-07 19:13:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-313, groupId=8ef762b5-81d1-4cb8-9cd4-f45c689cc196] Successfully joined group with generation 1
2020-01-07 19:13:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-313, groupId=8ef762b5-81d1-4cb8-9cd4-f45c689cc196] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:30 INFO  Fetcher:583 - [Consumer clientId=consumer-313, groupId=8ef762b5-81d1-4cb8-9cd4-f45c689cc196] Resetting offset for partition facedetectiontest101-0 to offset 17814.
2020-01-07 19:13:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 94a8d937-b1ad-4d28-bc8b-b935a3112309
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-314, groupId=94a8d937-b1ad-4d28-bc8b-b935a3112309] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-314, groupId=94a8d937-b1ad-4d28-bc8b-b935a3112309] Revoking previously assigned partitions []
2020-01-07 19:13:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-314, groupId=94a8d937-b1ad-4d28-bc8b-b935a3112309] (Re-)joining group
2020-01-07 19:13:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-314, groupId=94a8d937-b1ad-4d28-bc8b-b935a3112309] Successfully joined group with generation 1
2020-01-07 19:13:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-314, groupId=94a8d937-b1ad-4d28-bc8b-b935a3112309] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:30 INFO  Fetcher:583 - [Consumer clientId=consumer-314, groupId=94a8d937-b1ad-4d28-bc8b-b935a3112309] Resetting offset for partition facedetectiontest101-0 to offset 17816.
2020-01-07 19:13:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1f2fb694-da6d-4c2d-b614-f9c2befd423a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-315, groupId=1f2fb694-da6d-4c2d-b614-f9c2befd423a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-315, groupId=1f2fb694-da6d-4c2d-b614-f9c2befd423a] Revoking previously assigned partitions []
2020-01-07 19:13:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-315, groupId=1f2fb694-da6d-4c2d-b614-f9c2befd423a] (Re-)joining group
2020-01-07 19:13:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-315, groupId=1f2fb694-da6d-4c2d-b614-f9c2befd423a] Successfully joined group with generation 1
2020-01-07 19:13:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-315, groupId=1f2fb694-da6d-4c2d-b614-f9c2befd423a] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:31 INFO  Fetcher:583 - [Consumer clientId=consumer-315, groupId=1f2fb694-da6d-4c2d-b614-f9c2befd423a] Resetting offset for partition facedetectiontest101-0 to offset 17817.
2020-01-07 19:13:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = bd87583f-f579-4f1d-a5c2-3c5edc51bc6b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-316, groupId=bd87583f-f579-4f1d-a5c2-3c5edc51bc6b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-316, groupId=bd87583f-f579-4f1d-a5c2-3c5edc51bc6b] Revoking previously assigned partitions []
2020-01-07 19:13:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-316, groupId=bd87583f-f579-4f1d-a5c2-3c5edc51bc6b] (Re-)joining group
2020-01-07 19:13:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-316, groupId=bd87583f-f579-4f1d-a5c2-3c5edc51bc6b] Successfully joined group with generation 1
2020-01-07 19:13:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-316, groupId=bd87583f-f579-4f1d-a5c2-3c5edc51bc6b] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:31 INFO  Fetcher:583 - [Consumer clientId=consumer-316, groupId=bd87583f-f579-4f1d-a5c2-3c5edc51bc6b] Resetting offset for partition facedetectiontest101-0 to offset 17818.
2020-01-07 19:13:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ad623fcb-e915-40d3-a50a-c4d3d538f7a4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-317, groupId=ad623fcb-e915-40d3-a50a-c4d3d538f7a4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-317, groupId=ad623fcb-e915-40d3-a50a-c4d3d538f7a4] Revoking previously assigned partitions []
2020-01-07 19:13:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-317, groupId=ad623fcb-e915-40d3-a50a-c4d3d538f7a4] (Re-)joining group
2020-01-07 19:13:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-317, groupId=ad623fcb-e915-40d3-a50a-c4d3d538f7a4] Successfully joined group with generation 1
2020-01-07 19:13:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-317, groupId=ad623fcb-e915-40d3-a50a-c4d3d538f7a4] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:31 INFO  Fetcher:583 - [Consumer clientId=consumer-317, groupId=ad623fcb-e915-40d3-a50a-c4d3d538f7a4] Resetting offset for partition facedetectiontest101-0 to offset 17819.
2020-01-07 19:13:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a0c6172a-624b-4838-8779-ee424636acd4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-318, groupId=a0c6172a-624b-4838-8779-ee424636acd4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-318, groupId=a0c6172a-624b-4838-8779-ee424636acd4] Revoking previously assigned partitions []
2020-01-07 19:13:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-318, groupId=a0c6172a-624b-4838-8779-ee424636acd4] (Re-)joining group
2020-01-07 19:13:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-318, groupId=a0c6172a-624b-4838-8779-ee424636acd4] Successfully joined group with generation 1
2020-01-07 19:13:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-318, groupId=a0c6172a-624b-4838-8779-ee424636acd4] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:31 INFO  Fetcher:583 - [Consumer clientId=consumer-318, groupId=a0c6172a-624b-4838-8779-ee424636acd4] Resetting offset for partition facedetectiontest101-0 to offset 17820.
2020-01-07 19:13:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3739a0ea-9df3-40f7-a8d0-29b17ab4d47f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-319, groupId=3739a0ea-9df3-40f7-a8d0-29b17ab4d47f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-319, groupId=3739a0ea-9df3-40f7-a8d0-29b17ab4d47f] Revoking previously assigned partitions []
2020-01-07 19:13:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-319, groupId=3739a0ea-9df3-40f7-a8d0-29b17ab4d47f] (Re-)joining group
2020-01-07 19:13:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-319, groupId=3739a0ea-9df3-40f7-a8d0-29b17ab4d47f] Successfully joined group with generation 1
2020-01-07 19:13:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-319, groupId=3739a0ea-9df3-40f7-a8d0-29b17ab4d47f] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:31 INFO  Fetcher:583 - [Consumer clientId=consumer-319, groupId=3739a0ea-9df3-40f7-a8d0-29b17ab4d47f] Resetting offset for partition facedetectiontest101-0 to offset 17821.
2020-01-07 19:13:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8f87b924-143b-4d81-9e5c-7a2d1e1bcd77
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-320, groupId=8f87b924-143b-4d81-9e5c-7a2d1e1bcd77] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-320, groupId=8f87b924-143b-4d81-9e5c-7a2d1e1bcd77] Revoking previously assigned partitions []
2020-01-07 19:13:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-320, groupId=8f87b924-143b-4d81-9e5c-7a2d1e1bcd77] (Re-)joining group
2020-01-07 19:13:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-320, groupId=8f87b924-143b-4d81-9e5c-7a2d1e1bcd77] Successfully joined group with generation 1
2020-01-07 19:13:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-320, groupId=8f87b924-143b-4d81-9e5c-7a2d1e1bcd77] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:31 INFO  Fetcher:583 - [Consumer clientId=consumer-320, groupId=8f87b924-143b-4d81-9e5c-7a2d1e1bcd77] Resetting offset for partition facedetectiontest101-0 to offset 17822.
2020-01-07 19:13:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4a6651a0-22ab-47ab-842a-a212a1c5af37
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-321, groupId=4a6651a0-22ab-47ab-842a-a212a1c5af37] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-321, groupId=4a6651a0-22ab-47ab-842a-a212a1c5af37] Revoking previously assigned partitions []
2020-01-07 19:13:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-321, groupId=4a6651a0-22ab-47ab-842a-a212a1c5af37] (Re-)joining group
2020-01-07 19:13:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-321, groupId=4a6651a0-22ab-47ab-842a-a212a1c5af37] Successfully joined group with generation 1
2020-01-07 19:13:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-321, groupId=4a6651a0-22ab-47ab-842a-a212a1c5af37] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:31 INFO  Fetcher:583 - [Consumer clientId=consumer-321, groupId=4a6651a0-22ab-47ab-842a-a212a1c5af37] Resetting offset for partition facedetectiontest101-0 to offset 17823.
2020-01-07 19:13:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a1562aa5-66be-4222-9b27-2e1bedceb845
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-322, groupId=a1562aa5-66be-4222-9b27-2e1bedceb845] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-322, groupId=a1562aa5-66be-4222-9b27-2e1bedceb845] Revoking previously assigned partitions []
2020-01-07 19:13:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-322, groupId=a1562aa5-66be-4222-9b27-2e1bedceb845] (Re-)joining group
2020-01-07 19:13:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-322, groupId=a1562aa5-66be-4222-9b27-2e1bedceb845] Successfully joined group with generation 1
2020-01-07 19:13:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-322, groupId=a1562aa5-66be-4222-9b27-2e1bedceb845] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:31 INFO  Fetcher:583 - [Consumer clientId=consumer-322, groupId=a1562aa5-66be-4222-9b27-2e1bedceb845] Resetting offset for partition facedetectiontest101-0 to offset 17824.
2020-01-07 19:13:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 037a3661-8682-4a08-ba3c-581d89a9cdd7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-323, groupId=037a3661-8682-4a08-ba3c-581d89a9cdd7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-323, groupId=037a3661-8682-4a08-ba3c-581d89a9cdd7] Revoking previously assigned partitions []
2020-01-07 19:13:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-323, groupId=037a3661-8682-4a08-ba3c-581d89a9cdd7] (Re-)joining group
2020-01-07 19:13:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-323, groupId=037a3661-8682-4a08-ba3c-581d89a9cdd7] Successfully joined group with generation 1
2020-01-07 19:13:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-323, groupId=037a3661-8682-4a08-ba3c-581d89a9cdd7] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:31 INFO  Fetcher:583 - [Consumer clientId=consumer-323, groupId=037a3661-8682-4a08-ba3c-581d89a9cdd7] Resetting offset for partition facedetectiontest101-0 to offset 17825.
2020-01-07 19:13:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 69508307-8f2e-49a4-9ab8-ae90534595d4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-324, groupId=69508307-8f2e-49a4-9ab8-ae90534595d4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-324, groupId=69508307-8f2e-49a4-9ab8-ae90534595d4] Revoking previously assigned partitions []
2020-01-07 19:13:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-324, groupId=69508307-8f2e-49a4-9ab8-ae90534595d4] (Re-)joining group
2020-01-07 19:13:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-324, groupId=69508307-8f2e-49a4-9ab8-ae90534595d4] Successfully joined group with generation 1
2020-01-07 19:13:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-324, groupId=69508307-8f2e-49a4-9ab8-ae90534595d4] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:31 INFO  Fetcher:583 - [Consumer clientId=consumer-324, groupId=69508307-8f2e-49a4-9ab8-ae90534595d4] Resetting offset for partition facedetectiontest101-0 to offset 17826.
2020-01-07 19:13:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 659d1e54-9249-408d-a897-7516ce3645d6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-325, groupId=659d1e54-9249-408d-a897-7516ce3645d6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-325, groupId=659d1e54-9249-408d-a897-7516ce3645d6] Revoking previously assigned partitions []
2020-01-07 19:13:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-325, groupId=659d1e54-9249-408d-a897-7516ce3645d6] (Re-)joining group
2020-01-07 19:13:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-325, groupId=659d1e54-9249-408d-a897-7516ce3645d6] Successfully joined group with generation 1
2020-01-07 19:13:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-325, groupId=659d1e54-9249-408d-a897-7516ce3645d6] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:31 INFO  Fetcher:583 - [Consumer clientId=consumer-325, groupId=659d1e54-9249-408d-a897-7516ce3645d6] Resetting offset for partition facedetectiontest101-0 to offset 17827.
2020-01-07 19:13:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1a04524d-1c2c-455e-ad68-0c8f6c9bd71e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-326, groupId=1a04524d-1c2c-455e-ad68-0c8f6c9bd71e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-326, groupId=1a04524d-1c2c-455e-ad68-0c8f6c9bd71e] Revoking previously assigned partitions []
2020-01-07 19:13:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-326, groupId=1a04524d-1c2c-455e-ad68-0c8f6c9bd71e] (Re-)joining group
2020-01-07 19:13:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-326, groupId=1a04524d-1c2c-455e-ad68-0c8f6c9bd71e] Successfully joined group with generation 1
2020-01-07 19:13:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-326, groupId=1a04524d-1c2c-455e-ad68-0c8f6c9bd71e] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:31 INFO  Fetcher:583 - [Consumer clientId=consumer-326, groupId=1a04524d-1c2c-455e-ad68-0c8f6c9bd71e] Resetting offset for partition facedetectiontest101-0 to offset 17828.
2020-01-07 19:13:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 67da7825-26ac-4aea-a273-9113379f8ce1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-327, groupId=67da7825-26ac-4aea-a273-9113379f8ce1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-327, groupId=67da7825-26ac-4aea-a273-9113379f8ce1] Revoking previously assigned partitions []
2020-01-07 19:13:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-327, groupId=67da7825-26ac-4aea-a273-9113379f8ce1] (Re-)joining group
2020-01-07 19:13:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-327, groupId=67da7825-26ac-4aea-a273-9113379f8ce1] Successfully joined group with generation 1
2020-01-07 19:13:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-327, groupId=67da7825-26ac-4aea-a273-9113379f8ce1] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:31 INFO  Fetcher:583 - [Consumer clientId=consumer-327, groupId=67da7825-26ac-4aea-a273-9113379f8ce1] Resetting offset for partition facedetectiontest101-0 to offset 17830.
2020-01-07 19:13:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0a1bef45-4d9c-4b12-a357-c8b0720a6760
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-328, groupId=0a1bef45-4d9c-4b12-a357-c8b0720a6760] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-328, groupId=0a1bef45-4d9c-4b12-a357-c8b0720a6760] Revoking previously assigned partitions []
2020-01-07 19:13:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-328, groupId=0a1bef45-4d9c-4b12-a357-c8b0720a6760] (Re-)joining group
2020-01-07 19:13:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-328, groupId=0a1bef45-4d9c-4b12-a357-c8b0720a6760] Successfully joined group with generation 1
2020-01-07 19:13:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-328, groupId=0a1bef45-4d9c-4b12-a357-c8b0720a6760] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:31 INFO  Fetcher:583 - [Consumer clientId=consumer-328, groupId=0a1bef45-4d9c-4b12-a357-c8b0720a6760] Resetting offset for partition facedetectiontest101-0 to offset 17831.
2020-01-07 19:13:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = bdb171da-2313-4d7f-953f-fabc64cc54d4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-329, groupId=bdb171da-2313-4d7f-953f-fabc64cc54d4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-329, groupId=bdb171da-2313-4d7f-953f-fabc64cc54d4] Revoking previously assigned partitions []
2020-01-07 19:13:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-329, groupId=bdb171da-2313-4d7f-953f-fabc64cc54d4] (Re-)joining group
2020-01-07 19:13:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-329, groupId=bdb171da-2313-4d7f-953f-fabc64cc54d4] Successfully joined group with generation 1
2020-01-07 19:13:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-329, groupId=bdb171da-2313-4d7f-953f-fabc64cc54d4] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:32 INFO  Fetcher:583 - [Consumer clientId=consumer-329, groupId=bdb171da-2313-4d7f-953f-fabc64cc54d4] Resetting offset for partition facedetectiontest101-0 to offset 17833.
2020-01-07 19:13:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c51f1af9-9b7d-4e41-82bc-8f78fae6fb09
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-330, groupId=c51f1af9-9b7d-4e41-82bc-8f78fae6fb09] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-330, groupId=c51f1af9-9b7d-4e41-82bc-8f78fae6fb09] Revoking previously assigned partitions []
2020-01-07 19:13:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-330, groupId=c51f1af9-9b7d-4e41-82bc-8f78fae6fb09] (Re-)joining group
2020-01-07 19:13:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-330, groupId=c51f1af9-9b7d-4e41-82bc-8f78fae6fb09] Successfully joined group with generation 1
2020-01-07 19:13:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-330, groupId=c51f1af9-9b7d-4e41-82bc-8f78fae6fb09] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:32 INFO  Fetcher:583 - [Consumer clientId=consumer-330, groupId=c51f1af9-9b7d-4e41-82bc-8f78fae6fb09] Resetting offset for partition facedetectiontest101-0 to offset 17834.
2020-01-07 19:13:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 683fbe3a-cecc-4418-8d11-0517ad563dfd
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-331, groupId=683fbe3a-cecc-4418-8d11-0517ad563dfd] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-331, groupId=683fbe3a-cecc-4418-8d11-0517ad563dfd] Revoking previously assigned partitions []
2020-01-07 19:13:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-331, groupId=683fbe3a-cecc-4418-8d11-0517ad563dfd] (Re-)joining group
2020-01-07 19:13:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-331, groupId=683fbe3a-cecc-4418-8d11-0517ad563dfd] Successfully joined group with generation 1
2020-01-07 19:13:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-331, groupId=683fbe3a-cecc-4418-8d11-0517ad563dfd] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:32 INFO  Fetcher:583 - [Consumer clientId=consumer-331, groupId=683fbe3a-cecc-4418-8d11-0517ad563dfd] Resetting offset for partition facedetectiontest101-0 to offset 17835.
2020-01-07 19:13:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1ad2e06c-cafb-4bbe-9674-712aa368e55f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-332, groupId=1ad2e06c-cafb-4bbe-9674-712aa368e55f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-332, groupId=1ad2e06c-cafb-4bbe-9674-712aa368e55f] Revoking previously assigned partitions []
2020-01-07 19:13:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-332, groupId=1ad2e06c-cafb-4bbe-9674-712aa368e55f] (Re-)joining group
2020-01-07 19:13:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-332, groupId=1ad2e06c-cafb-4bbe-9674-712aa368e55f] Successfully joined group with generation 1
2020-01-07 19:13:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-332, groupId=1ad2e06c-cafb-4bbe-9674-712aa368e55f] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:32 INFO  Fetcher:583 - [Consumer clientId=consumer-332, groupId=1ad2e06c-cafb-4bbe-9674-712aa368e55f] Resetting offset for partition facedetectiontest101-0 to offset 17836.
2020-01-07 19:13:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5936fa95-2bae-4103-bddc-228bd3f617bf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-333, groupId=5936fa95-2bae-4103-bddc-228bd3f617bf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-333, groupId=5936fa95-2bae-4103-bddc-228bd3f617bf] Revoking previously assigned partitions []
2020-01-07 19:13:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-333, groupId=5936fa95-2bae-4103-bddc-228bd3f617bf] (Re-)joining group
2020-01-07 19:13:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-333, groupId=5936fa95-2bae-4103-bddc-228bd3f617bf] Successfully joined group with generation 1
2020-01-07 19:13:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-333, groupId=5936fa95-2bae-4103-bddc-228bd3f617bf] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:32 INFO  Fetcher:583 - [Consumer clientId=consumer-333, groupId=5936fa95-2bae-4103-bddc-228bd3f617bf] Resetting offset for partition facedetectiontest101-0 to offset 17837.
2020-01-07 19:13:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 81609c6f-d52e-405f-af7c-b2052a95a653
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-334, groupId=81609c6f-d52e-405f-af7c-b2052a95a653] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-334, groupId=81609c6f-d52e-405f-af7c-b2052a95a653] Revoking previously assigned partitions []
2020-01-07 19:13:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-334, groupId=81609c6f-d52e-405f-af7c-b2052a95a653] (Re-)joining group
2020-01-07 19:13:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-334, groupId=81609c6f-d52e-405f-af7c-b2052a95a653] Successfully joined group with generation 1
2020-01-07 19:13:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-334, groupId=81609c6f-d52e-405f-af7c-b2052a95a653] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:32 INFO  Fetcher:583 - [Consumer clientId=consumer-334, groupId=81609c6f-d52e-405f-af7c-b2052a95a653] Resetting offset for partition facedetectiontest101-0 to offset 17839.
2020-01-07 19:13:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a193eaab-24b2-423e-a310-10f029e5c055
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-335, groupId=a193eaab-24b2-423e-a310-10f029e5c055] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-335, groupId=a193eaab-24b2-423e-a310-10f029e5c055] Revoking previously assigned partitions []
2020-01-07 19:13:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-335, groupId=a193eaab-24b2-423e-a310-10f029e5c055] (Re-)joining group
2020-01-07 19:13:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-335, groupId=a193eaab-24b2-423e-a310-10f029e5c055] Successfully joined group with generation 1
2020-01-07 19:13:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-335, groupId=a193eaab-24b2-423e-a310-10f029e5c055] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:32 INFO  Fetcher:583 - [Consumer clientId=consumer-335, groupId=a193eaab-24b2-423e-a310-10f029e5c055] Resetting offset for partition facedetectiontest101-0 to offset 17840.
2020-01-07 19:13:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 61581a49-00e2-4b8d-ae51-17f498928a00
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-336, groupId=61581a49-00e2-4b8d-ae51-17f498928a00] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-336, groupId=61581a49-00e2-4b8d-ae51-17f498928a00] Revoking previously assigned partitions []
2020-01-07 19:13:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-336, groupId=61581a49-00e2-4b8d-ae51-17f498928a00] (Re-)joining group
2020-01-07 19:13:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-336, groupId=61581a49-00e2-4b8d-ae51-17f498928a00] Successfully joined group with generation 1
2020-01-07 19:13:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-336, groupId=61581a49-00e2-4b8d-ae51-17f498928a00] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:32 INFO  Fetcher:583 - [Consumer clientId=consumer-336, groupId=61581a49-00e2-4b8d-ae51-17f498928a00] Resetting offset for partition facedetectiontest101-0 to offset 17842.
2020-01-07 19:13:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1c195272-f3e2-4d93-838c-1c919a86c97b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-337, groupId=1c195272-f3e2-4d93-838c-1c919a86c97b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-337, groupId=1c195272-f3e2-4d93-838c-1c919a86c97b] Revoking previously assigned partitions []
2020-01-07 19:13:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-337, groupId=1c195272-f3e2-4d93-838c-1c919a86c97b] (Re-)joining group
2020-01-07 19:13:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-337, groupId=1c195272-f3e2-4d93-838c-1c919a86c97b] Successfully joined group with generation 1
2020-01-07 19:13:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-337, groupId=1c195272-f3e2-4d93-838c-1c919a86c97b] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:32 INFO  Fetcher:583 - [Consumer clientId=consumer-337, groupId=1c195272-f3e2-4d93-838c-1c919a86c97b] Resetting offset for partition facedetectiontest101-0 to offset 17844.
2020-01-07 19:13:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 91e7dd04-f4a0-41c3-9794-0c82c8d1abcb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-338, groupId=91e7dd04-f4a0-41c3-9794-0c82c8d1abcb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-338, groupId=91e7dd04-f4a0-41c3-9794-0c82c8d1abcb] Revoking previously assigned partitions []
2020-01-07 19:13:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-338, groupId=91e7dd04-f4a0-41c3-9794-0c82c8d1abcb] (Re-)joining group
2020-01-07 19:13:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-338, groupId=91e7dd04-f4a0-41c3-9794-0c82c8d1abcb] Successfully joined group with generation 1
2020-01-07 19:13:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-338, groupId=91e7dd04-f4a0-41c3-9794-0c82c8d1abcb] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:32 INFO  Fetcher:583 - [Consumer clientId=consumer-338, groupId=91e7dd04-f4a0-41c3-9794-0c82c8d1abcb] Resetting offset for partition facedetectiontest101-0 to offset 17845.
2020-01-07 19:13:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d8075643-1543-4ceb-8d7c-085a51347645
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-339, groupId=d8075643-1543-4ceb-8d7c-085a51347645] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-339, groupId=d8075643-1543-4ceb-8d7c-085a51347645] Revoking previously assigned partitions []
2020-01-07 19:13:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-339, groupId=d8075643-1543-4ceb-8d7c-085a51347645] (Re-)joining group
2020-01-07 19:13:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-339, groupId=d8075643-1543-4ceb-8d7c-085a51347645] Successfully joined group with generation 1
2020-01-07 19:13:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-339, groupId=d8075643-1543-4ceb-8d7c-085a51347645] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:32 INFO  Fetcher:583 - [Consumer clientId=consumer-339, groupId=d8075643-1543-4ceb-8d7c-085a51347645] Resetting offset for partition facedetectiontest101-0 to offset 17846.
2020-01-07 19:13:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 90391044-8c2e-44a0-9f0f-f401f49ed091
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-340, groupId=90391044-8c2e-44a0-9f0f-f401f49ed091] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-340, groupId=90391044-8c2e-44a0-9f0f-f401f49ed091] Revoking previously assigned partitions []
2020-01-07 19:13:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-340, groupId=90391044-8c2e-44a0-9f0f-f401f49ed091] (Re-)joining group
2020-01-07 19:13:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-340, groupId=90391044-8c2e-44a0-9f0f-f401f49ed091] Successfully joined group with generation 1
2020-01-07 19:13:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-340, groupId=90391044-8c2e-44a0-9f0f-f401f49ed091] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:33 INFO  Fetcher:583 - [Consumer clientId=consumer-340, groupId=90391044-8c2e-44a0-9f0f-f401f49ed091] Resetting offset for partition facedetectiontest101-0 to offset 17847.
2020-01-07 19:13:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 138b34d2-9517-4a63-a806-68e7e9a13f70
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-341, groupId=138b34d2-9517-4a63-a806-68e7e9a13f70] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-341, groupId=138b34d2-9517-4a63-a806-68e7e9a13f70] Revoking previously assigned partitions []
2020-01-07 19:13:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-341, groupId=138b34d2-9517-4a63-a806-68e7e9a13f70] (Re-)joining group
2020-01-07 19:13:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-341, groupId=138b34d2-9517-4a63-a806-68e7e9a13f70] Successfully joined group with generation 1
2020-01-07 19:13:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-341, groupId=138b34d2-9517-4a63-a806-68e7e9a13f70] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:33 INFO  Fetcher:583 - [Consumer clientId=consumer-341, groupId=138b34d2-9517-4a63-a806-68e7e9a13f70] Resetting offset for partition facedetectiontest101-0 to offset 17848.
2020-01-07 19:13:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a14d8b47-2752-48c2-bd9e-aceb6b0d7220
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-342, groupId=a14d8b47-2752-48c2-bd9e-aceb6b0d7220] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-342, groupId=a14d8b47-2752-48c2-bd9e-aceb6b0d7220] Revoking previously assigned partitions []
2020-01-07 19:13:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-342, groupId=a14d8b47-2752-48c2-bd9e-aceb6b0d7220] (Re-)joining group
2020-01-07 19:13:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-342, groupId=a14d8b47-2752-48c2-bd9e-aceb6b0d7220] Successfully joined group with generation 1
2020-01-07 19:13:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-342, groupId=a14d8b47-2752-48c2-bd9e-aceb6b0d7220] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:33 INFO  Fetcher:583 - [Consumer clientId=consumer-342, groupId=a14d8b47-2752-48c2-bd9e-aceb6b0d7220] Resetting offset for partition facedetectiontest101-0 to offset 17849.
2020-01-07 19:13:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 98cfcd70-8856-4d2f-acab-36dc70de6ce5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-343, groupId=98cfcd70-8856-4d2f-acab-36dc70de6ce5] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-343, groupId=98cfcd70-8856-4d2f-acab-36dc70de6ce5] Revoking previously assigned partitions []
2020-01-07 19:13:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-343, groupId=98cfcd70-8856-4d2f-acab-36dc70de6ce5] (Re-)joining group
2020-01-07 19:13:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-343, groupId=98cfcd70-8856-4d2f-acab-36dc70de6ce5] Successfully joined group with generation 1
2020-01-07 19:13:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-343, groupId=98cfcd70-8856-4d2f-acab-36dc70de6ce5] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:33 INFO  Fetcher:583 - [Consumer clientId=consumer-343, groupId=98cfcd70-8856-4d2f-acab-36dc70de6ce5] Resetting offset for partition facedetectiontest101-0 to offset 17850.
2020-01-07 19:13:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = df9385b2-8be8-4abd-82e4-390b7e557953
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-344, groupId=df9385b2-8be8-4abd-82e4-390b7e557953] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-344, groupId=df9385b2-8be8-4abd-82e4-390b7e557953] Revoking previously assigned partitions []
2020-01-07 19:13:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-344, groupId=df9385b2-8be8-4abd-82e4-390b7e557953] (Re-)joining group
2020-01-07 19:13:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-344, groupId=df9385b2-8be8-4abd-82e4-390b7e557953] Successfully joined group with generation 1
2020-01-07 19:13:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-344, groupId=df9385b2-8be8-4abd-82e4-390b7e557953] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:33 INFO  Fetcher:583 - [Consumer clientId=consumer-344, groupId=df9385b2-8be8-4abd-82e4-390b7e557953] Resetting offset for partition facedetectiontest101-0 to offset 17851.
2020-01-07 19:13:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 03117c1d-7447-4ad8-b723-506125243f9e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-345, groupId=03117c1d-7447-4ad8-b723-506125243f9e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-345, groupId=03117c1d-7447-4ad8-b723-506125243f9e] Revoking previously assigned partitions []
2020-01-07 19:13:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-345, groupId=03117c1d-7447-4ad8-b723-506125243f9e] (Re-)joining group
2020-01-07 19:13:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-345, groupId=03117c1d-7447-4ad8-b723-506125243f9e] Successfully joined group with generation 1
2020-01-07 19:13:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-345, groupId=03117c1d-7447-4ad8-b723-506125243f9e] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:33 INFO  Fetcher:583 - [Consumer clientId=consumer-345, groupId=03117c1d-7447-4ad8-b723-506125243f9e] Resetting offset for partition facedetectiontest101-0 to offset 17852.
2020-01-07 19:13:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4c479495-ba99-4cf9-bba6-7b1f80e654d8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-346, groupId=4c479495-ba99-4cf9-bba6-7b1f80e654d8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-346, groupId=4c479495-ba99-4cf9-bba6-7b1f80e654d8] Revoking previously assigned partitions []
2020-01-07 19:13:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-346, groupId=4c479495-ba99-4cf9-bba6-7b1f80e654d8] (Re-)joining group
2020-01-07 19:13:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-346, groupId=4c479495-ba99-4cf9-bba6-7b1f80e654d8] Successfully joined group with generation 1
2020-01-07 19:13:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-346, groupId=4c479495-ba99-4cf9-bba6-7b1f80e654d8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:33 INFO  Fetcher:583 - [Consumer clientId=consumer-346, groupId=4c479495-ba99-4cf9-bba6-7b1f80e654d8] Resetting offset for partition facedetectiontest101-0 to offset 17854.
2020-01-07 19:13:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f80325a0-4658-496c-ab72-3d1df4f6e612
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-347, groupId=f80325a0-4658-496c-ab72-3d1df4f6e612] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-347, groupId=f80325a0-4658-496c-ab72-3d1df4f6e612] Revoking previously assigned partitions []
2020-01-07 19:13:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-347, groupId=f80325a0-4658-496c-ab72-3d1df4f6e612] (Re-)joining group
2020-01-07 19:13:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-347, groupId=f80325a0-4658-496c-ab72-3d1df4f6e612] Successfully joined group with generation 1
2020-01-07 19:13:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-347, groupId=f80325a0-4658-496c-ab72-3d1df4f6e612] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:33 INFO  Fetcher:583 - [Consumer clientId=consumer-347, groupId=f80325a0-4658-496c-ab72-3d1df4f6e612] Resetting offset for partition facedetectiontest101-0 to offset 17855.
2020-01-07 19:13:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e62b5e4e-42ae-4846-a899-ba9690ef85f8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-348, groupId=e62b5e4e-42ae-4846-a899-ba9690ef85f8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-348, groupId=e62b5e4e-42ae-4846-a899-ba9690ef85f8] Revoking previously assigned partitions []
2020-01-07 19:13:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-348, groupId=e62b5e4e-42ae-4846-a899-ba9690ef85f8] (Re-)joining group
2020-01-07 19:13:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-348, groupId=e62b5e4e-42ae-4846-a899-ba9690ef85f8] Successfully joined group with generation 1
2020-01-07 19:13:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-348, groupId=e62b5e4e-42ae-4846-a899-ba9690ef85f8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:33 INFO  Fetcher:583 - [Consumer clientId=consumer-348, groupId=e62b5e4e-42ae-4846-a899-ba9690ef85f8] Resetting offset for partition facedetectiontest101-0 to offset 17856.
2020-01-07 19:13:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = cab07d38-bfa6-401c-b39f-98cf5888547e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-349, groupId=cab07d38-bfa6-401c-b39f-98cf5888547e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-349, groupId=cab07d38-bfa6-401c-b39f-98cf5888547e] Revoking previously assigned partitions []
2020-01-07 19:13:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-349, groupId=cab07d38-bfa6-401c-b39f-98cf5888547e] (Re-)joining group
2020-01-07 19:13:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-349, groupId=cab07d38-bfa6-401c-b39f-98cf5888547e] Successfully joined group with generation 1
2020-01-07 19:13:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-349, groupId=cab07d38-bfa6-401c-b39f-98cf5888547e] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:33 INFO  Fetcher:583 - [Consumer clientId=consumer-349, groupId=cab07d38-bfa6-401c-b39f-98cf5888547e] Resetting offset for partition facedetectiontest101-0 to offset 17857.
2020-01-07 19:13:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a6280c06-5dc5-4f96-841d-01a6067b471a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-350, groupId=a6280c06-5dc5-4f96-841d-01a6067b471a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-350, groupId=a6280c06-5dc5-4f96-841d-01a6067b471a] Revoking previously assigned partitions []
2020-01-07 19:13:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-350, groupId=a6280c06-5dc5-4f96-841d-01a6067b471a] (Re-)joining group
2020-01-07 19:13:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-350, groupId=a6280c06-5dc5-4f96-841d-01a6067b471a] Successfully joined group with generation 1
2020-01-07 19:13:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-350, groupId=a6280c06-5dc5-4f96-841d-01a6067b471a] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:33 INFO  Fetcher:583 - [Consumer clientId=consumer-350, groupId=a6280c06-5dc5-4f96-841d-01a6067b471a] Resetting offset for partition facedetectiontest101-0 to offset 17858.
2020-01-07 19:13:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 90860dd8-faaf-467e-9c2b-25c4a6ee6472
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-351, groupId=90860dd8-faaf-467e-9c2b-25c4a6ee6472] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-351, groupId=90860dd8-faaf-467e-9c2b-25c4a6ee6472] Revoking previously assigned partitions []
2020-01-07 19:13:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-351, groupId=90860dd8-faaf-467e-9c2b-25c4a6ee6472] (Re-)joining group
2020-01-07 19:13:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-351, groupId=90860dd8-faaf-467e-9c2b-25c4a6ee6472] Successfully joined group with generation 1
2020-01-07 19:13:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-351, groupId=90860dd8-faaf-467e-9c2b-25c4a6ee6472] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:33 INFO  Fetcher:583 - [Consumer clientId=consumer-351, groupId=90860dd8-faaf-467e-9c2b-25c4a6ee6472] Resetting offset for partition facedetectiontest101-0 to offset 17860.
2020-01-07 19:13:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 188ecec8-46a2-4712-ba07-4c0fd9b610fb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-352, groupId=188ecec8-46a2-4712-ba07-4c0fd9b610fb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-352, groupId=188ecec8-46a2-4712-ba07-4c0fd9b610fb] Revoking previously assigned partitions []
2020-01-07 19:13:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-352, groupId=188ecec8-46a2-4712-ba07-4c0fd9b610fb] (Re-)joining group
2020-01-07 19:13:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-352, groupId=188ecec8-46a2-4712-ba07-4c0fd9b610fb] Successfully joined group with generation 1
2020-01-07 19:13:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-352, groupId=188ecec8-46a2-4712-ba07-4c0fd9b610fb] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:33 INFO  Fetcher:583 - [Consumer clientId=consumer-352, groupId=188ecec8-46a2-4712-ba07-4c0fd9b610fb] Resetting offset for partition facedetectiontest101-0 to offset 17861.
2020-01-07 19:13:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6025d898-58aa-4ac9-9353-2bfd02ddfbe7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-353, groupId=6025d898-58aa-4ac9-9353-2bfd02ddfbe7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-353, groupId=6025d898-58aa-4ac9-9353-2bfd02ddfbe7] Revoking previously assigned partitions []
2020-01-07 19:13:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-353, groupId=6025d898-58aa-4ac9-9353-2bfd02ddfbe7] (Re-)joining group
2020-01-07 19:13:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-353, groupId=6025d898-58aa-4ac9-9353-2bfd02ddfbe7] Successfully joined group with generation 1
2020-01-07 19:13:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-353, groupId=6025d898-58aa-4ac9-9353-2bfd02ddfbe7] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:34 INFO  Fetcher:583 - [Consumer clientId=consumer-353, groupId=6025d898-58aa-4ac9-9353-2bfd02ddfbe7] Resetting offset for partition facedetectiontest101-0 to offset 17862.
2020-01-07 19:13:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fabd621e-1992-4d4b-957a-97a347da635e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-354, groupId=fabd621e-1992-4d4b-957a-97a347da635e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-354, groupId=fabd621e-1992-4d4b-957a-97a347da635e] Revoking previously assigned partitions []
2020-01-07 19:13:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-354, groupId=fabd621e-1992-4d4b-957a-97a347da635e] (Re-)joining group
2020-01-07 19:13:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-354, groupId=fabd621e-1992-4d4b-957a-97a347da635e] Successfully joined group with generation 1
2020-01-07 19:13:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-354, groupId=fabd621e-1992-4d4b-957a-97a347da635e] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:34 INFO  Fetcher:583 - [Consumer clientId=consumer-354, groupId=fabd621e-1992-4d4b-957a-97a347da635e] Resetting offset for partition facedetectiontest101-0 to offset 17863.
2020-01-07 19:13:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c84f0126-74a3-44d9-ab46-c54f63f1652d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-355, groupId=c84f0126-74a3-44d9-ab46-c54f63f1652d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-355, groupId=c84f0126-74a3-44d9-ab46-c54f63f1652d] Revoking previously assigned partitions []
2020-01-07 19:13:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-355, groupId=c84f0126-74a3-44d9-ab46-c54f63f1652d] (Re-)joining group
2020-01-07 19:13:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-355, groupId=c84f0126-74a3-44d9-ab46-c54f63f1652d] Successfully joined group with generation 1
2020-01-07 19:13:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-355, groupId=c84f0126-74a3-44d9-ab46-c54f63f1652d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:34 INFO  Fetcher:583 - [Consumer clientId=consumer-355, groupId=c84f0126-74a3-44d9-ab46-c54f63f1652d] Resetting offset for partition facedetectiontest101-0 to offset 17864.
2020-01-07 19:13:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 41163bb3-1461-4d15-b0ad-23f1a7a79aac
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-356, groupId=41163bb3-1461-4d15-b0ad-23f1a7a79aac] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-356, groupId=41163bb3-1461-4d15-b0ad-23f1a7a79aac] Revoking previously assigned partitions []
2020-01-07 19:13:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-356, groupId=41163bb3-1461-4d15-b0ad-23f1a7a79aac] (Re-)joining group
2020-01-07 19:13:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-356, groupId=41163bb3-1461-4d15-b0ad-23f1a7a79aac] Successfully joined group with generation 1
2020-01-07 19:13:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-356, groupId=41163bb3-1461-4d15-b0ad-23f1a7a79aac] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:34 INFO  Fetcher:583 - [Consumer clientId=consumer-356, groupId=41163bb3-1461-4d15-b0ad-23f1a7a79aac] Resetting offset for partition facedetectiontest101-0 to offset 17865.
2020-01-07 19:13:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = cce8bdda-f7c3-499a-9c9a-bc76f53e207d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-357, groupId=cce8bdda-f7c3-499a-9c9a-bc76f53e207d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-357, groupId=cce8bdda-f7c3-499a-9c9a-bc76f53e207d] Revoking previously assigned partitions []
2020-01-07 19:13:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-357, groupId=cce8bdda-f7c3-499a-9c9a-bc76f53e207d] (Re-)joining group
2020-01-07 19:13:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-357, groupId=cce8bdda-f7c3-499a-9c9a-bc76f53e207d] Successfully joined group with generation 1
2020-01-07 19:13:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-357, groupId=cce8bdda-f7c3-499a-9c9a-bc76f53e207d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:34 INFO  Fetcher:583 - [Consumer clientId=consumer-357, groupId=cce8bdda-f7c3-499a-9c9a-bc76f53e207d] Resetting offset for partition facedetectiontest101-0 to offset 17866.
2020-01-07 19:13:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 293f761d-3d5b-4f1a-b7bc-0aeced9e8c6d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-358, groupId=293f761d-3d5b-4f1a-b7bc-0aeced9e8c6d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-358, groupId=293f761d-3d5b-4f1a-b7bc-0aeced9e8c6d] Revoking previously assigned partitions []
2020-01-07 19:13:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-358, groupId=293f761d-3d5b-4f1a-b7bc-0aeced9e8c6d] (Re-)joining group
2020-01-07 19:13:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-358, groupId=293f761d-3d5b-4f1a-b7bc-0aeced9e8c6d] Successfully joined group with generation 1
2020-01-07 19:13:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-358, groupId=293f761d-3d5b-4f1a-b7bc-0aeced9e8c6d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:34 INFO  Fetcher:583 - [Consumer clientId=consumer-358, groupId=293f761d-3d5b-4f1a-b7bc-0aeced9e8c6d] Resetting offset for partition facedetectiontest101-0 to offset 17867.
2020-01-07 19:13:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 309b6131-cfeb-4c66-a8c6-c81029292479
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-359, groupId=309b6131-cfeb-4c66-a8c6-c81029292479] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-359, groupId=309b6131-cfeb-4c66-a8c6-c81029292479] Revoking previously assigned partitions []
2020-01-07 19:13:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-359, groupId=309b6131-cfeb-4c66-a8c6-c81029292479] (Re-)joining group
2020-01-07 19:13:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-359, groupId=309b6131-cfeb-4c66-a8c6-c81029292479] Successfully joined group with generation 1
2020-01-07 19:13:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-359, groupId=309b6131-cfeb-4c66-a8c6-c81029292479] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:34 INFO  Fetcher:583 - [Consumer clientId=consumer-359, groupId=309b6131-cfeb-4c66-a8c6-c81029292479] Resetting offset for partition facedetectiontest101-0 to offset 17868.
2020-01-07 19:13:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5479ac47-87f9-431f-8dfe-b533b9dd699d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-360, groupId=5479ac47-87f9-431f-8dfe-b533b9dd699d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-360, groupId=5479ac47-87f9-431f-8dfe-b533b9dd699d] Revoking previously assigned partitions []
2020-01-07 19:13:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-360, groupId=5479ac47-87f9-431f-8dfe-b533b9dd699d] (Re-)joining group
2020-01-07 19:13:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-360, groupId=5479ac47-87f9-431f-8dfe-b533b9dd699d] Successfully joined group with generation 1
2020-01-07 19:13:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-360, groupId=5479ac47-87f9-431f-8dfe-b533b9dd699d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:34 INFO  Fetcher:583 - [Consumer clientId=consumer-360, groupId=5479ac47-87f9-431f-8dfe-b533b9dd699d] Resetting offset for partition facedetectiontest101-0 to offset 17869.
2020-01-07 19:13:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 305a356b-0d1d-4936-bc3e-23f5b9eb266d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-361, groupId=305a356b-0d1d-4936-bc3e-23f5b9eb266d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-361, groupId=305a356b-0d1d-4936-bc3e-23f5b9eb266d] Revoking previously assigned partitions []
2020-01-07 19:13:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-361, groupId=305a356b-0d1d-4936-bc3e-23f5b9eb266d] (Re-)joining group
2020-01-07 19:13:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-361, groupId=305a356b-0d1d-4936-bc3e-23f5b9eb266d] Successfully joined group with generation 1
2020-01-07 19:13:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-361, groupId=305a356b-0d1d-4936-bc3e-23f5b9eb266d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:34 INFO  Fetcher:583 - [Consumer clientId=consumer-361, groupId=305a356b-0d1d-4936-bc3e-23f5b9eb266d] Resetting offset for partition facedetectiontest101-0 to offset 17870.
2020-01-07 19:13:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6bdd3fae-4745-4a4d-aaac-946b6b874652
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-362, groupId=6bdd3fae-4745-4a4d-aaac-946b6b874652] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-362, groupId=6bdd3fae-4745-4a4d-aaac-946b6b874652] Revoking previously assigned partitions []
2020-01-07 19:13:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-362, groupId=6bdd3fae-4745-4a4d-aaac-946b6b874652] (Re-)joining group
2020-01-07 19:13:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-362, groupId=6bdd3fae-4745-4a4d-aaac-946b6b874652] Successfully joined group with generation 1
2020-01-07 19:13:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-362, groupId=6bdd3fae-4745-4a4d-aaac-946b6b874652] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:34 INFO  Fetcher:583 - [Consumer clientId=consumer-362, groupId=6bdd3fae-4745-4a4d-aaac-946b6b874652] Resetting offset for partition facedetectiontest101-0 to offset 17871.
2020-01-07 19:13:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7a4abb55-d514-4e3e-a64d-e1f370ae43fa
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-363, groupId=7a4abb55-d514-4e3e-a64d-e1f370ae43fa] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-363, groupId=7a4abb55-d514-4e3e-a64d-e1f370ae43fa] Revoking previously assigned partitions []
2020-01-07 19:13:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-363, groupId=7a4abb55-d514-4e3e-a64d-e1f370ae43fa] (Re-)joining group
2020-01-07 19:13:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-363, groupId=7a4abb55-d514-4e3e-a64d-e1f370ae43fa] Successfully joined group with generation 1
2020-01-07 19:13:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-363, groupId=7a4abb55-d514-4e3e-a64d-e1f370ae43fa] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:34 INFO  Fetcher:583 - [Consumer clientId=consumer-363, groupId=7a4abb55-d514-4e3e-a64d-e1f370ae43fa] Resetting offset for partition facedetectiontest101-0 to offset 17872.
2020-01-07 19:13:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 15d00f45-3f34-4d69-96c3-30a866dcd7d7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-364, groupId=15d00f45-3f34-4d69-96c3-30a866dcd7d7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-364, groupId=15d00f45-3f34-4d69-96c3-30a866dcd7d7] Revoking previously assigned partitions []
2020-01-07 19:13:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-364, groupId=15d00f45-3f34-4d69-96c3-30a866dcd7d7] (Re-)joining group
2020-01-07 19:13:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-364, groupId=15d00f45-3f34-4d69-96c3-30a866dcd7d7] Successfully joined group with generation 1
2020-01-07 19:13:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-364, groupId=15d00f45-3f34-4d69-96c3-30a866dcd7d7] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:34 INFO  Fetcher:583 - [Consumer clientId=consumer-364, groupId=15d00f45-3f34-4d69-96c3-30a866dcd7d7] Resetting offset for partition facedetectiontest101-0 to offset 17873.
2020-01-07 19:13:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c388aef4-750a-4915-9bbf-07c808f81331
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-365, groupId=c388aef4-750a-4915-9bbf-07c808f81331] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-365, groupId=c388aef4-750a-4915-9bbf-07c808f81331] Revoking previously assigned partitions []
2020-01-07 19:13:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-365, groupId=c388aef4-750a-4915-9bbf-07c808f81331] (Re-)joining group
2020-01-07 19:13:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-365, groupId=c388aef4-750a-4915-9bbf-07c808f81331] Successfully joined group with generation 1
2020-01-07 19:13:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-365, groupId=c388aef4-750a-4915-9bbf-07c808f81331] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:34 INFO  Fetcher:583 - [Consumer clientId=consumer-365, groupId=c388aef4-750a-4915-9bbf-07c808f81331] Resetting offset for partition facedetectiontest101-0 to offset 17874.
2020-01-07 19:13:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d009e0af-d12c-487d-8bdd-6fcd63c7dd77
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-366, groupId=d009e0af-d12c-487d-8bdd-6fcd63c7dd77] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-366, groupId=d009e0af-d12c-487d-8bdd-6fcd63c7dd77] Revoking previously assigned partitions []
2020-01-07 19:13:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-366, groupId=d009e0af-d12c-487d-8bdd-6fcd63c7dd77] (Re-)joining group
2020-01-07 19:13:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-366, groupId=d009e0af-d12c-487d-8bdd-6fcd63c7dd77] Successfully joined group with generation 1
2020-01-07 19:13:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-366, groupId=d009e0af-d12c-487d-8bdd-6fcd63c7dd77] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:35 INFO  Fetcher:583 - [Consumer clientId=consumer-366, groupId=d009e0af-d12c-487d-8bdd-6fcd63c7dd77] Resetting offset for partition facedetectiontest101-0 to offset 17875.
2020-01-07 19:13:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 825da70c-e536-492a-b5af-d1482f58633c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-367, groupId=825da70c-e536-492a-b5af-d1482f58633c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-367, groupId=825da70c-e536-492a-b5af-d1482f58633c] Revoking previously assigned partitions []
2020-01-07 19:13:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-367, groupId=825da70c-e536-492a-b5af-d1482f58633c] (Re-)joining group
2020-01-07 19:13:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-367, groupId=825da70c-e536-492a-b5af-d1482f58633c] Successfully joined group with generation 1
2020-01-07 19:13:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-367, groupId=825da70c-e536-492a-b5af-d1482f58633c] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:35 INFO  Fetcher:583 - [Consumer clientId=consumer-367, groupId=825da70c-e536-492a-b5af-d1482f58633c] Resetting offset for partition facedetectiontest101-0 to offset 17876.
2020-01-07 19:13:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 82fc5142-83e5-4ec1-bf7b-2a9ba0bbd3b8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-368, groupId=82fc5142-83e5-4ec1-bf7b-2a9ba0bbd3b8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-368, groupId=82fc5142-83e5-4ec1-bf7b-2a9ba0bbd3b8] Revoking previously assigned partitions []
2020-01-07 19:13:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-368, groupId=82fc5142-83e5-4ec1-bf7b-2a9ba0bbd3b8] (Re-)joining group
2020-01-07 19:13:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-368, groupId=82fc5142-83e5-4ec1-bf7b-2a9ba0bbd3b8] Successfully joined group with generation 1
2020-01-07 19:13:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-368, groupId=82fc5142-83e5-4ec1-bf7b-2a9ba0bbd3b8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:35 INFO  Fetcher:583 - [Consumer clientId=consumer-368, groupId=82fc5142-83e5-4ec1-bf7b-2a9ba0bbd3b8] Resetting offset for partition facedetectiontest101-0 to offset 17877.
2020-01-07 19:13:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5b0fd172-21c7-41e4-9ccf-1349edfca1be
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:13:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:13:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:13:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:13:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-369, groupId=5b0fd172-21c7-41e4-9ccf-1349edfca1be] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:13:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-369, groupId=5b0fd172-21c7-41e4-9ccf-1349edfca1be] Revoking previously assigned partitions []
2020-01-07 19:13:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-369, groupId=5b0fd172-21c7-41e4-9ccf-1349edfca1be] (Re-)joining group
2020-01-07 19:13:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-369, groupId=5b0fd172-21c7-41e4-9ccf-1349edfca1be] Successfully joined group with generation 1
2020-01-07 19:13:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-369, groupId=5b0fd172-21c7-41e4-9ccf-1349edfca1be] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:13:35 INFO  Fetcher:583 - [Consumer clientId=consumer-369, groupId=5b0fd172-21c7-41e4-9ccf-1349edfca1be] Resetting offset for partition facedetectiontest101-0 to offset 17878.
2020-01-07 19:15:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b916d115-9929-4ae9-bcad-e5d2918a92d0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=b916d115-9929-4ae9-bcad-e5d2918a92d0] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=b916d115-9929-4ae9-bcad-e5d2918a92d0] Revoking previously assigned partitions []
2020-01-07 19:15:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=b916d115-9929-4ae9-bcad-e5d2918a92d0] (Re-)joining group
2020-01-07 19:15:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=b916d115-9929-4ae9-bcad-e5d2918a92d0] Successfully joined group with generation 1
2020-01-07 19:15:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=b916d115-9929-4ae9-bcad-e5d2918a92d0] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:24 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=b916d115-9929-4ae9-bcad-e5d2918a92d0] Resetting offset for partition facedetectiontest101-0 to offset 18305.
2020-01-07 19:15:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 86ff7295-14ce-4a59-9ba6-a6765beeaf0b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-2, groupId=86ff7295-14ce-4a59-9ba6-a6765beeaf0b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-2, groupId=86ff7295-14ce-4a59-9ba6-a6765beeaf0b] Revoking previously assigned partitions []
2020-01-07 19:15:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-2, groupId=86ff7295-14ce-4a59-9ba6-a6765beeaf0b] (Re-)joining group
2020-01-07 19:15:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-2, groupId=86ff7295-14ce-4a59-9ba6-a6765beeaf0b] Successfully joined group with generation 1
2020-01-07 19:15:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-2, groupId=86ff7295-14ce-4a59-9ba6-a6765beeaf0b] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:24 INFO  Fetcher:583 - [Consumer clientId=consumer-2, groupId=86ff7295-14ce-4a59-9ba6-a6765beeaf0b] Resetting offset for partition facedetectiontest101-0 to offset 18309.
2020-01-07 19:15:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3f257d45-5264-49e7-b74b-f27c4c3b4489
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-3, groupId=3f257d45-5264-49e7-b74b-f27c4c3b4489] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-3, groupId=3f257d45-5264-49e7-b74b-f27c4c3b4489] Revoking previously assigned partitions []
2020-01-07 19:15:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-3, groupId=3f257d45-5264-49e7-b74b-f27c4c3b4489] (Re-)joining group
2020-01-07 19:15:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-3, groupId=3f257d45-5264-49e7-b74b-f27c4c3b4489] Successfully joined group with generation 1
2020-01-07 19:15:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-3, groupId=3f257d45-5264-49e7-b74b-f27c4c3b4489] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:24 INFO  Fetcher:583 - [Consumer clientId=consumer-3, groupId=3f257d45-5264-49e7-b74b-f27c4c3b4489] Resetting offset for partition facedetectiontest101-0 to offset 18310.
2020-01-07 19:15:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7d76890d-b18c-46c6-8359-fe04e7b318e6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-4, groupId=7d76890d-b18c-46c6-8359-fe04e7b318e6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-4, groupId=7d76890d-b18c-46c6-8359-fe04e7b318e6] Revoking previously assigned partitions []
2020-01-07 19:15:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-4, groupId=7d76890d-b18c-46c6-8359-fe04e7b318e6] (Re-)joining group
2020-01-07 19:15:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-4, groupId=7d76890d-b18c-46c6-8359-fe04e7b318e6] Successfully joined group with generation 1
2020-01-07 19:15:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-4, groupId=7d76890d-b18c-46c6-8359-fe04e7b318e6] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:25 INFO  Fetcher:583 - [Consumer clientId=consumer-4, groupId=7d76890d-b18c-46c6-8359-fe04e7b318e6] Resetting offset for partition facedetectiontest101-0 to offset 18311.
2020-01-07 19:15:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 098dc177-4bfe-4012-b592-0047ca12dedf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-5, groupId=098dc177-4bfe-4012-b592-0047ca12dedf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-5, groupId=098dc177-4bfe-4012-b592-0047ca12dedf] Revoking previously assigned partitions []
2020-01-07 19:15:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-5, groupId=098dc177-4bfe-4012-b592-0047ca12dedf] (Re-)joining group
2020-01-07 19:15:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-5, groupId=098dc177-4bfe-4012-b592-0047ca12dedf] Successfully joined group with generation 1
2020-01-07 19:15:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-5, groupId=098dc177-4bfe-4012-b592-0047ca12dedf] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:25 INFO  Fetcher:583 - [Consumer clientId=consumer-5, groupId=098dc177-4bfe-4012-b592-0047ca12dedf] Resetting offset for partition facedetectiontest101-0 to offset 18312.
2020-01-07 19:15:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 76fd07cf-e5ea-451a-bc14-a867a35a56dd
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-6, groupId=76fd07cf-e5ea-451a-bc14-a867a35a56dd] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-6, groupId=76fd07cf-e5ea-451a-bc14-a867a35a56dd] Revoking previously assigned partitions []
2020-01-07 19:15:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-6, groupId=76fd07cf-e5ea-451a-bc14-a867a35a56dd] (Re-)joining group
2020-01-07 19:15:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-6, groupId=76fd07cf-e5ea-451a-bc14-a867a35a56dd] Successfully joined group with generation 1
2020-01-07 19:15:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-6, groupId=76fd07cf-e5ea-451a-bc14-a867a35a56dd] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:25 INFO  Fetcher:583 - [Consumer clientId=consumer-6, groupId=76fd07cf-e5ea-451a-bc14-a867a35a56dd] Resetting offset for partition facedetectiontest101-0 to offset 18313.
2020-01-07 19:15:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 712c1cbb-d324-4b7c-b7e9-774f1d47ccd2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-7, groupId=712c1cbb-d324-4b7c-b7e9-774f1d47ccd2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-7, groupId=712c1cbb-d324-4b7c-b7e9-774f1d47ccd2] Revoking previously assigned partitions []
2020-01-07 19:15:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-7, groupId=712c1cbb-d324-4b7c-b7e9-774f1d47ccd2] (Re-)joining group
2020-01-07 19:15:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-7, groupId=712c1cbb-d324-4b7c-b7e9-774f1d47ccd2] Successfully joined group with generation 1
2020-01-07 19:15:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-7, groupId=712c1cbb-d324-4b7c-b7e9-774f1d47ccd2] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:25 INFO  Fetcher:583 - [Consumer clientId=consumer-7, groupId=712c1cbb-d324-4b7c-b7e9-774f1d47ccd2] Resetting offset for partition facedetectiontest101-0 to offset 18315.
2020-01-07 19:15:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 658aece0-dc41-4ee1-b859-75a33e41059e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-8, groupId=658aece0-dc41-4ee1-b859-75a33e41059e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-8, groupId=658aece0-dc41-4ee1-b859-75a33e41059e] Revoking previously assigned partitions []
2020-01-07 19:15:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-8, groupId=658aece0-dc41-4ee1-b859-75a33e41059e] (Re-)joining group
2020-01-07 19:15:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-8, groupId=658aece0-dc41-4ee1-b859-75a33e41059e] Successfully joined group with generation 1
2020-01-07 19:15:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-8, groupId=658aece0-dc41-4ee1-b859-75a33e41059e] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:25 INFO  Fetcher:583 - [Consumer clientId=consumer-8, groupId=658aece0-dc41-4ee1-b859-75a33e41059e] Resetting offset for partition facedetectiontest101-0 to offset 18316.
2020-01-07 19:15:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 98164f28-20e1-4ae0-8d96-2b51028258fe
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-9, groupId=98164f28-20e1-4ae0-8d96-2b51028258fe] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-9, groupId=98164f28-20e1-4ae0-8d96-2b51028258fe] Revoking previously assigned partitions []
2020-01-07 19:15:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-9, groupId=98164f28-20e1-4ae0-8d96-2b51028258fe] (Re-)joining group
2020-01-07 19:15:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-9, groupId=98164f28-20e1-4ae0-8d96-2b51028258fe] Successfully joined group with generation 1
2020-01-07 19:15:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-9, groupId=98164f28-20e1-4ae0-8d96-2b51028258fe] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:25 INFO  Fetcher:583 - [Consumer clientId=consumer-9, groupId=98164f28-20e1-4ae0-8d96-2b51028258fe] Resetting offset for partition facedetectiontest101-0 to offset 18317.
2020-01-07 19:15:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 31f99b85-ca96-48e4-8a89-8f39d12cc7c8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-10, groupId=31f99b85-ca96-48e4-8a89-8f39d12cc7c8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-10, groupId=31f99b85-ca96-48e4-8a89-8f39d12cc7c8] Revoking previously assigned partitions []
2020-01-07 19:15:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-10, groupId=31f99b85-ca96-48e4-8a89-8f39d12cc7c8] (Re-)joining group
2020-01-07 19:15:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-10, groupId=31f99b85-ca96-48e4-8a89-8f39d12cc7c8] Successfully joined group with generation 1
2020-01-07 19:15:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-10, groupId=31f99b85-ca96-48e4-8a89-8f39d12cc7c8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:25 INFO  Fetcher:583 - [Consumer clientId=consumer-10, groupId=31f99b85-ca96-48e4-8a89-8f39d12cc7c8] Resetting offset for partition facedetectiontest101-0 to offset 18318.
2020-01-07 19:15:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a5e4b750-d1b6-4889-95a9-83a78674433f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-11, groupId=a5e4b750-d1b6-4889-95a9-83a78674433f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-11, groupId=a5e4b750-d1b6-4889-95a9-83a78674433f] Revoking previously assigned partitions []
2020-01-07 19:15:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-11, groupId=a5e4b750-d1b6-4889-95a9-83a78674433f] (Re-)joining group
2020-01-07 19:15:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-11, groupId=a5e4b750-d1b6-4889-95a9-83a78674433f] Successfully joined group with generation 1
2020-01-07 19:15:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-11, groupId=a5e4b750-d1b6-4889-95a9-83a78674433f] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:25 INFO  Fetcher:583 - [Consumer clientId=consumer-11, groupId=a5e4b750-d1b6-4889-95a9-83a78674433f] Resetting offset for partition facedetectiontest101-0 to offset 18319.
2020-01-07 19:15:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 96894923-022c-4238-96d0-8fb8cbacc6cf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-12, groupId=96894923-022c-4238-96d0-8fb8cbacc6cf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-12, groupId=96894923-022c-4238-96d0-8fb8cbacc6cf] Revoking previously assigned partitions []
2020-01-07 19:15:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-12, groupId=96894923-022c-4238-96d0-8fb8cbacc6cf] (Re-)joining group
2020-01-07 19:15:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-12, groupId=96894923-022c-4238-96d0-8fb8cbacc6cf] Successfully joined group with generation 1
2020-01-07 19:15:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-12, groupId=96894923-022c-4238-96d0-8fb8cbacc6cf] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:26 INFO  Fetcher:583 - [Consumer clientId=consumer-12, groupId=96894923-022c-4238-96d0-8fb8cbacc6cf] Resetting offset for partition facedetectiontest101-0 to offset 18320.
2020-01-07 19:15:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b96f0227-67d1-494d-8a04-16cb21662a9f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-13, groupId=b96f0227-67d1-494d-8a04-16cb21662a9f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-13, groupId=b96f0227-67d1-494d-8a04-16cb21662a9f] Revoking previously assigned partitions []
2020-01-07 19:15:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-13, groupId=b96f0227-67d1-494d-8a04-16cb21662a9f] (Re-)joining group
2020-01-07 19:15:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-13, groupId=b96f0227-67d1-494d-8a04-16cb21662a9f] Successfully joined group with generation 1
2020-01-07 19:15:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-13, groupId=b96f0227-67d1-494d-8a04-16cb21662a9f] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:26 INFO  Fetcher:583 - [Consumer clientId=consumer-13, groupId=b96f0227-67d1-494d-8a04-16cb21662a9f] Resetting offset for partition facedetectiontest101-0 to offset 18321.
2020-01-07 19:15:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ed83f231-d380-406c-90c1-802e94c2fe5d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-14, groupId=ed83f231-d380-406c-90c1-802e94c2fe5d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-14, groupId=ed83f231-d380-406c-90c1-802e94c2fe5d] Revoking previously assigned partitions []
2020-01-07 19:15:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-14, groupId=ed83f231-d380-406c-90c1-802e94c2fe5d] (Re-)joining group
2020-01-07 19:15:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-14, groupId=ed83f231-d380-406c-90c1-802e94c2fe5d] Successfully joined group with generation 1
2020-01-07 19:15:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-14, groupId=ed83f231-d380-406c-90c1-802e94c2fe5d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:26 INFO  Fetcher:583 - [Consumer clientId=consumer-14, groupId=ed83f231-d380-406c-90c1-802e94c2fe5d] Resetting offset for partition facedetectiontest101-0 to offset 18322.
2020-01-07 19:15:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f461b39c-d21b-4ecd-a831-b137eaefaf77
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-15, groupId=f461b39c-d21b-4ecd-a831-b137eaefaf77] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-15, groupId=f461b39c-d21b-4ecd-a831-b137eaefaf77] Revoking previously assigned partitions []
2020-01-07 19:15:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-15, groupId=f461b39c-d21b-4ecd-a831-b137eaefaf77] (Re-)joining group
2020-01-07 19:15:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-15, groupId=f461b39c-d21b-4ecd-a831-b137eaefaf77] Successfully joined group with generation 1
2020-01-07 19:15:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-15, groupId=f461b39c-d21b-4ecd-a831-b137eaefaf77] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:26 INFO  Fetcher:583 - [Consumer clientId=consumer-15, groupId=f461b39c-d21b-4ecd-a831-b137eaefaf77] Resetting offset for partition facedetectiontest101-0 to offset 18323.
2020-01-07 19:15:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5838b1d0-d6d8-4263-811f-3c4732fef062
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-16, groupId=5838b1d0-d6d8-4263-811f-3c4732fef062] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-16, groupId=5838b1d0-d6d8-4263-811f-3c4732fef062] Revoking previously assigned partitions []
2020-01-07 19:15:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-16, groupId=5838b1d0-d6d8-4263-811f-3c4732fef062] (Re-)joining group
2020-01-07 19:15:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-16, groupId=5838b1d0-d6d8-4263-811f-3c4732fef062] Successfully joined group with generation 1
2020-01-07 19:15:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-16, groupId=5838b1d0-d6d8-4263-811f-3c4732fef062] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:26 INFO  Fetcher:583 - [Consumer clientId=consumer-16, groupId=5838b1d0-d6d8-4263-811f-3c4732fef062] Resetting offset for partition facedetectiontest101-0 to offset 18324.
2020-01-07 19:15:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 57b18e48-b484-4ba8-9043-da75b39d8bb0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-17, groupId=57b18e48-b484-4ba8-9043-da75b39d8bb0] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-17, groupId=57b18e48-b484-4ba8-9043-da75b39d8bb0] Revoking previously assigned partitions []
2020-01-07 19:15:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-17, groupId=57b18e48-b484-4ba8-9043-da75b39d8bb0] (Re-)joining group
2020-01-07 19:15:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-17, groupId=57b18e48-b484-4ba8-9043-da75b39d8bb0] Successfully joined group with generation 1
2020-01-07 19:15:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-17, groupId=57b18e48-b484-4ba8-9043-da75b39d8bb0] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:26 INFO  Fetcher:583 - [Consumer clientId=consumer-17, groupId=57b18e48-b484-4ba8-9043-da75b39d8bb0] Resetting offset for partition facedetectiontest101-0 to offset 18325.
2020-01-07 19:15:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9d952df8-d2bc-47af-b93d-144f15abd8a8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-18, groupId=9d952df8-d2bc-47af-b93d-144f15abd8a8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-18, groupId=9d952df8-d2bc-47af-b93d-144f15abd8a8] Revoking previously assigned partitions []
2020-01-07 19:15:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-18, groupId=9d952df8-d2bc-47af-b93d-144f15abd8a8] (Re-)joining group
2020-01-07 19:15:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-18, groupId=9d952df8-d2bc-47af-b93d-144f15abd8a8] Successfully joined group with generation 1
2020-01-07 19:15:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-18, groupId=9d952df8-d2bc-47af-b93d-144f15abd8a8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:26 INFO  Fetcher:583 - [Consumer clientId=consumer-18, groupId=9d952df8-d2bc-47af-b93d-144f15abd8a8] Resetting offset for partition facedetectiontest101-0 to offset 18326.
2020-01-07 19:15:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0fe8eaf8-c0a9-49f7-a2be-cfbc30ed713f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-19, groupId=0fe8eaf8-c0a9-49f7-a2be-cfbc30ed713f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-19, groupId=0fe8eaf8-c0a9-49f7-a2be-cfbc30ed713f] Revoking previously assigned partitions []
2020-01-07 19:15:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-19, groupId=0fe8eaf8-c0a9-49f7-a2be-cfbc30ed713f] (Re-)joining group
2020-01-07 19:15:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-19, groupId=0fe8eaf8-c0a9-49f7-a2be-cfbc30ed713f] Successfully joined group with generation 1
2020-01-07 19:15:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-19, groupId=0fe8eaf8-c0a9-49f7-a2be-cfbc30ed713f] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:26 INFO  Fetcher:583 - [Consumer clientId=consumer-19, groupId=0fe8eaf8-c0a9-49f7-a2be-cfbc30ed713f] Resetting offset for partition facedetectiontest101-0 to offset 18327.
2020-01-07 19:15:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 76cdceee-039d-47b0-9179-68e5e10cd59d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-20, groupId=76cdceee-039d-47b0-9179-68e5e10cd59d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-20, groupId=76cdceee-039d-47b0-9179-68e5e10cd59d] Revoking previously assigned partitions []
2020-01-07 19:15:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-20, groupId=76cdceee-039d-47b0-9179-68e5e10cd59d] (Re-)joining group
2020-01-07 19:15:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-20, groupId=76cdceee-039d-47b0-9179-68e5e10cd59d] Successfully joined group with generation 1
2020-01-07 19:15:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-20, groupId=76cdceee-039d-47b0-9179-68e5e10cd59d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:26 INFO  Fetcher:583 - [Consumer clientId=consumer-20, groupId=76cdceee-039d-47b0-9179-68e5e10cd59d] Resetting offset for partition facedetectiontest101-0 to offset 18328.
2020-01-07 19:15:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 06083476-152f-421f-98a7-2807ddd6cdb8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-21, groupId=06083476-152f-421f-98a7-2807ddd6cdb8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-21, groupId=06083476-152f-421f-98a7-2807ddd6cdb8] Revoking previously assigned partitions []
2020-01-07 19:15:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-21, groupId=06083476-152f-421f-98a7-2807ddd6cdb8] (Re-)joining group
2020-01-07 19:15:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-21, groupId=06083476-152f-421f-98a7-2807ddd6cdb8] Successfully joined group with generation 1
2020-01-07 19:15:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-21, groupId=06083476-152f-421f-98a7-2807ddd6cdb8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:27 INFO  Fetcher:583 - [Consumer clientId=consumer-21, groupId=06083476-152f-421f-98a7-2807ddd6cdb8] Resetting offset for partition facedetectiontest101-0 to offset 18329.
2020-01-07 19:15:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 121d122a-9a67-4354-9e24-b3609fe497ee
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-22, groupId=121d122a-9a67-4354-9e24-b3609fe497ee] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-22, groupId=121d122a-9a67-4354-9e24-b3609fe497ee] Revoking previously assigned partitions []
2020-01-07 19:15:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-22, groupId=121d122a-9a67-4354-9e24-b3609fe497ee] (Re-)joining group
2020-01-07 19:15:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-22, groupId=121d122a-9a67-4354-9e24-b3609fe497ee] Successfully joined group with generation 1
2020-01-07 19:15:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-22, groupId=121d122a-9a67-4354-9e24-b3609fe497ee] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:27 INFO  Fetcher:583 - [Consumer clientId=consumer-22, groupId=121d122a-9a67-4354-9e24-b3609fe497ee] Resetting offset for partition facedetectiontest101-0 to offset 18330.
2020-01-07 19:15:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9fdb801b-14bc-4a3d-9cdc-21806e0edd08
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-23, groupId=9fdb801b-14bc-4a3d-9cdc-21806e0edd08] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-23, groupId=9fdb801b-14bc-4a3d-9cdc-21806e0edd08] Revoking previously assigned partitions []
2020-01-07 19:15:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-23, groupId=9fdb801b-14bc-4a3d-9cdc-21806e0edd08] (Re-)joining group
2020-01-07 19:15:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-23, groupId=9fdb801b-14bc-4a3d-9cdc-21806e0edd08] Successfully joined group with generation 1
2020-01-07 19:15:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-23, groupId=9fdb801b-14bc-4a3d-9cdc-21806e0edd08] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:27 INFO  Fetcher:583 - [Consumer clientId=consumer-23, groupId=9fdb801b-14bc-4a3d-9cdc-21806e0edd08] Resetting offset for partition facedetectiontest101-0 to offset 18332.
2020-01-07 19:15:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e98e2446-7d7b-48ca-b7d9-28a0f94680da
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-24, groupId=e98e2446-7d7b-48ca-b7d9-28a0f94680da] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-24, groupId=e98e2446-7d7b-48ca-b7d9-28a0f94680da] Revoking previously assigned partitions []
2020-01-07 19:15:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-24, groupId=e98e2446-7d7b-48ca-b7d9-28a0f94680da] (Re-)joining group
2020-01-07 19:15:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-24, groupId=e98e2446-7d7b-48ca-b7d9-28a0f94680da] Successfully joined group with generation 1
2020-01-07 19:15:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-24, groupId=e98e2446-7d7b-48ca-b7d9-28a0f94680da] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:27 INFO  Fetcher:583 - [Consumer clientId=consumer-24, groupId=e98e2446-7d7b-48ca-b7d9-28a0f94680da] Resetting offset for partition facedetectiontest101-0 to offset 18334.
2020-01-07 19:15:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 047f1ada-8d43-4d7b-a1ce-e3d6e21d5ce8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-25, groupId=047f1ada-8d43-4d7b-a1ce-e3d6e21d5ce8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-25, groupId=047f1ada-8d43-4d7b-a1ce-e3d6e21d5ce8] Revoking previously assigned partitions []
2020-01-07 19:15:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-25, groupId=047f1ada-8d43-4d7b-a1ce-e3d6e21d5ce8] (Re-)joining group
2020-01-07 19:15:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-25, groupId=047f1ada-8d43-4d7b-a1ce-e3d6e21d5ce8] Successfully joined group with generation 1
2020-01-07 19:15:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-25, groupId=047f1ada-8d43-4d7b-a1ce-e3d6e21d5ce8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:27 INFO  Fetcher:583 - [Consumer clientId=consumer-25, groupId=047f1ada-8d43-4d7b-a1ce-e3d6e21d5ce8] Resetting offset for partition facedetectiontest101-0 to offset 18336.
2020-01-07 19:15:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 24d5965b-f0c1-46a9-b12f-ffc7ea0c5bf0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-26, groupId=24d5965b-f0c1-46a9-b12f-ffc7ea0c5bf0] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-26, groupId=24d5965b-f0c1-46a9-b12f-ffc7ea0c5bf0] Revoking previously assigned partitions []
2020-01-07 19:15:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-26, groupId=24d5965b-f0c1-46a9-b12f-ffc7ea0c5bf0] (Re-)joining group
2020-01-07 19:15:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-26, groupId=24d5965b-f0c1-46a9-b12f-ffc7ea0c5bf0] Successfully joined group with generation 1
2020-01-07 19:15:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-26, groupId=24d5965b-f0c1-46a9-b12f-ffc7ea0c5bf0] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:27 INFO  Fetcher:583 - [Consumer clientId=consumer-26, groupId=24d5965b-f0c1-46a9-b12f-ffc7ea0c5bf0] Resetting offset for partition facedetectiontest101-0 to offset 18337.
2020-01-07 19:15:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6c2d3ddb-83a6-457a-97b4-c1f60d75a32f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-27, groupId=6c2d3ddb-83a6-457a-97b4-c1f60d75a32f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-27, groupId=6c2d3ddb-83a6-457a-97b4-c1f60d75a32f] Revoking previously assigned partitions []
2020-01-07 19:15:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-27, groupId=6c2d3ddb-83a6-457a-97b4-c1f60d75a32f] (Re-)joining group
2020-01-07 19:15:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-27, groupId=6c2d3ddb-83a6-457a-97b4-c1f60d75a32f] Successfully joined group with generation 1
2020-01-07 19:15:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-27, groupId=6c2d3ddb-83a6-457a-97b4-c1f60d75a32f] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:27 INFO  Fetcher:583 - [Consumer clientId=consumer-27, groupId=6c2d3ddb-83a6-457a-97b4-c1f60d75a32f] Resetting offset for partition facedetectiontest101-0 to offset 18338.
2020-01-07 19:15:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c23aea5e-be9f-4ff0-a9f8-994dc0a7d914
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-28, groupId=c23aea5e-be9f-4ff0-a9f8-994dc0a7d914] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-28, groupId=c23aea5e-be9f-4ff0-a9f8-994dc0a7d914] Revoking previously assigned partitions []
2020-01-07 19:15:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-28, groupId=c23aea5e-be9f-4ff0-a9f8-994dc0a7d914] (Re-)joining group
2020-01-07 19:15:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-28, groupId=c23aea5e-be9f-4ff0-a9f8-994dc0a7d914] Successfully joined group with generation 1
2020-01-07 19:15:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-28, groupId=c23aea5e-be9f-4ff0-a9f8-994dc0a7d914] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:28 INFO  Fetcher:583 - [Consumer clientId=consumer-28, groupId=c23aea5e-be9f-4ff0-a9f8-994dc0a7d914] Resetting offset for partition facedetectiontest101-0 to offset 18339.
2020-01-07 19:15:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5a2e93f2-d2bb-4677-b861-b4782a247708
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-29, groupId=5a2e93f2-d2bb-4677-b861-b4782a247708] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-29, groupId=5a2e93f2-d2bb-4677-b861-b4782a247708] Revoking previously assigned partitions []
2020-01-07 19:15:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-29, groupId=5a2e93f2-d2bb-4677-b861-b4782a247708] (Re-)joining group
2020-01-07 19:15:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-29, groupId=5a2e93f2-d2bb-4677-b861-b4782a247708] Successfully joined group with generation 1
2020-01-07 19:15:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-29, groupId=5a2e93f2-d2bb-4677-b861-b4782a247708] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:28 INFO  Fetcher:583 - [Consumer clientId=consumer-29, groupId=5a2e93f2-d2bb-4677-b861-b4782a247708] Resetting offset for partition facedetectiontest101-0 to offset 18340.
2020-01-07 19:15:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d90c5f18-366d-48e3-bd62-368b07e1153c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-30, groupId=d90c5f18-366d-48e3-bd62-368b07e1153c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-30, groupId=d90c5f18-366d-48e3-bd62-368b07e1153c] Revoking previously assigned partitions []
2020-01-07 19:15:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-30, groupId=d90c5f18-366d-48e3-bd62-368b07e1153c] (Re-)joining group
2020-01-07 19:15:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-30, groupId=d90c5f18-366d-48e3-bd62-368b07e1153c] Successfully joined group with generation 1
2020-01-07 19:15:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-30, groupId=d90c5f18-366d-48e3-bd62-368b07e1153c] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:28 INFO  Fetcher:583 - [Consumer clientId=consumer-30, groupId=d90c5f18-366d-48e3-bd62-368b07e1153c] Resetting offset for partition facedetectiontest101-0 to offset 18341.
2020-01-07 19:15:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6bfdfcd1-cfd7-4598-8bd4-1d0c135edbc8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-31, groupId=6bfdfcd1-cfd7-4598-8bd4-1d0c135edbc8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-31, groupId=6bfdfcd1-cfd7-4598-8bd4-1d0c135edbc8] Revoking previously assigned partitions []
2020-01-07 19:15:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-31, groupId=6bfdfcd1-cfd7-4598-8bd4-1d0c135edbc8] (Re-)joining group
2020-01-07 19:15:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-31, groupId=6bfdfcd1-cfd7-4598-8bd4-1d0c135edbc8] Successfully joined group with generation 1
2020-01-07 19:15:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-31, groupId=6bfdfcd1-cfd7-4598-8bd4-1d0c135edbc8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:28 INFO  Fetcher:583 - [Consumer clientId=consumer-31, groupId=6bfdfcd1-cfd7-4598-8bd4-1d0c135edbc8] Resetting offset for partition facedetectiontest101-0 to offset 18343.
2020-01-07 19:15:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dfebee3e-2c0f-47cd-b20d-2fce2fc63339
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-32, groupId=dfebee3e-2c0f-47cd-b20d-2fce2fc63339] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-32, groupId=dfebee3e-2c0f-47cd-b20d-2fce2fc63339] Revoking previously assigned partitions []
2020-01-07 19:15:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-32, groupId=dfebee3e-2c0f-47cd-b20d-2fce2fc63339] (Re-)joining group
2020-01-07 19:15:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-32, groupId=dfebee3e-2c0f-47cd-b20d-2fce2fc63339] Successfully joined group with generation 1
2020-01-07 19:15:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-32, groupId=dfebee3e-2c0f-47cd-b20d-2fce2fc63339] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:28 INFO  Fetcher:583 - [Consumer clientId=consumer-32, groupId=dfebee3e-2c0f-47cd-b20d-2fce2fc63339] Resetting offset for partition facedetectiontest101-0 to offset 18344.
2020-01-07 19:15:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ce348852-c93f-4ff5-ad0b-57de5fc5ad9c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-33, groupId=ce348852-c93f-4ff5-ad0b-57de5fc5ad9c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-33, groupId=ce348852-c93f-4ff5-ad0b-57de5fc5ad9c] Revoking previously assigned partitions []
2020-01-07 19:15:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-33, groupId=ce348852-c93f-4ff5-ad0b-57de5fc5ad9c] (Re-)joining group
2020-01-07 19:15:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-33, groupId=ce348852-c93f-4ff5-ad0b-57de5fc5ad9c] Successfully joined group with generation 1
2020-01-07 19:15:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-33, groupId=ce348852-c93f-4ff5-ad0b-57de5fc5ad9c] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:28 INFO  Fetcher:583 - [Consumer clientId=consumer-33, groupId=ce348852-c93f-4ff5-ad0b-57de5fc5ad9c] Resetting offset for partition facedetectiontest101-0 to offset 18345.
2020-01-07 19:15:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 72046359-e820-4313-a66c-1181ce734fc1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-34, groupId=72046359-e820-4313-a66c-1181ce734fc1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-34, groupId=72046359-e820-4313-a66c-1181ce734fc1] Revoking previously assigned partitions []
2020-01-07 19:15:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-34, groupId=72046359-e820-4313-a66c-1181ce734fc1] (Re-)joining group
2020-01-07 19:15:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-34, groupId=72046359-e820-4313-a66c-1181ce734fc1] Successfully joined group with generation 1
2020-01-07 19:15:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-34, groupId=72046359-e820-4313-a66c-1181ce734fc1] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:28 INFO  Fetcher:583 - [Consumer clientId=consumer-34, groupId=72046359-e820-4313-a66c-1181ce734fc1] Resetting offset for partition facedetectiontest101-0 to offset 18346.
2020-01-07 19:15:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 24b4b853-ee4b-46ab-a476-c835b02326da
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-35, groupId=24b4b853-ee4b-46ab-a476-c835b02326da] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-35, groupId=24b4b853-ee4b-46ab-a476-c835b02326da] Revoking previously assigned partitions []
2020-01-07 19:15:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-35, groupId=24b4b853-ee4b-46ab-a476-c835b02326da] (Re-)joining group
2020-01-07 19:15:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-35, groupId=24b4b853-ee4b-46ab-a476-c835b02326da] Successfully joined group with generation 1
2020-01-07 19:15:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-35, groupId=24b4b853-ee4b-46ab-a476-c835b02326da] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:28 INFO  Fetcher:583 - [Consumer clientId=consumer-35, groupId=24b4b853-ee4b-46ab-a476-c835b02326da] Resetting offset for partition facedetectiontest101-0 to offset 18347.
2020-01-07 19:15:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 22c31a2e-9f05-4b3a-a267-207b5f77b48c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-36, groupId=22c31a2e-9f05-4b3a-a267-207b5f77b48c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-36, groupId=22c31a2e-9f05-4b3a-a267-207b5f77b48c] Revoking previously assigned partitions []
2020-01-07 19:15:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-36, groupId=22c31a2e-9f05-4b3a-a267-207b5f77b48c] (Re-)joining group
2020-01-07 19:15:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-36, groupId=22c31a2e-9f05-4b3a-a267-207b5f77b48c] Successfully joined group with generation 1
2020-01-07 19:15:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-36, groupId=22c31a2e-9f05-4b3a-a267-207b5f77b48c] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:28 INFO  Fetcher:583 - [Consumer clientId=consumer-36, groupId=22c31a2e-9f05-4b3a-a267-207b5f77b48c] Resetting offset for partition facedetectiontest101-0 to offset 18348.
2020-01-07 19:15:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f2c66604-dd75-4b77-94c5-5979e22b7681
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-37, groupId=f2c66604-dd75-4b77-94c5-5979e22b7681] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-37, groupId=f2c66604-dd75-4b77-94c5-5979e22b7681] Revoking previously assigned partitions []
2020-01-07 19:15:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-37, groupId=f2c66604-dd75-4b77-94c5-5979e22b7681] (Re-)joining group
2020-01-07 19:15:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-37, groupId=f2c66604-dd75-4b77-94c5-5979e22b7681] Successfully joined group with generation 1
2020-01-07 19:15:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-37, groupId=f2c66604-dd75-4b77-94c5-5979e22b7681] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:29 INFO  Fetcher:583 - [Consumer clientId=consumer-37, groupId=f2c66604-dd75-4b77-94c5-5979e22b7681] Resetting offset for partition facedetectiontest101-0 to offset 18349.
2020-01-07 19:15:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0d35848b-ea03-4d66-be0a-c022a2bcd5c6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-38, groupId=0d35848b-ea03-4d66-be0a-c022a2bcd5c6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-38, groupId=0d35848b-ea03-4d66-be0a-c022a2bcd5c6] Revoking previously assigned partitions []
2020-01-07 19:15:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-38, groupId=0d35848b-ea03-4d66-be0a-c022a2bcd5c6] (Re-)joining group
2020-01-07 19:15:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-38, groupId=0d35848b-ea03-4d66-be0a-c022a2bcd5c6] Successfully joined group with generation 1
2020-01-07 19:15:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-38, groupId=0d35848b-ea03-4d66-be0a-c022a2bcd5c6] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:29 INFO  Fetcher:583 - [Consumer clientId=consumer-38, groupId=0d35848b-ea03-4d66-be0a-c022a2bcd5c6] Resetting offset for partition facedetectiontest101-0 to offset 18350.
2020-01-07 19:15:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0940cf4b-f793-4e92-996d-845d7e5fcc66
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-39, groupId=0940cf4b-f793-4e92-996d-845d7e5fcc66] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-39, groupId=0940cf4b-f793-4e92-996d-845d7e5fcc66] Revoking previously assigned partitions []
2020-01-07 19:15:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-39, groupId=0940cf4b-f793-4e92-996d-845d7e5fcc66] (Re-)joining group
2020-01-07 19:15:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-39, groupId=0940cf4b-f793-4e92-996d-845d7e5fcc66] Successfully joined group with generation 1
2020-01-07 19:15:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-39, groupId=0940cf4b-f793-4e92-996d-845d7e5fcc66] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:29 INFO  Fetcher:583 - [Consumer clientId=consumer-39, groupId=0940cf4b-f793-4e92-996d-845d7e5fcc66] Resetting offset for partition facedetectiontest101-0 to offset 18351.
2020-01-07 19:15:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b1e2a9b9-a7b7-4a87-b38f-67507f3581cb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-40, groupId=b1e2a9b9-a7b7-4a87-b38f-67507f3581cb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-40, groupId=b1e2a9b9-a7b7-4a87-b38f-67507f3581cb] Revoking previously assigned partitions []
2020-01-07 19:15:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-40, groupId=b1e2a9b9-a7b7-4a87-b38f-67507f3581cb] (Re-)joining group
2020-01-07 19:15:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-40, groupId=b1e2a9b9-a7b7-4a87-b38f-67507f3581cb] Successfully joined group with generation 1
2020-01-07 19:15:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-40, groupId=b1e2a9b9-a7b7-4a87-b38f-67507f3581cb] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:29 INFO  Fetcher:583 - [Consumer clientId=consumer-40, groupId=b1e2a9b9-a7b7-4a87-b38f-67507f3581cb] Resetting offset for partition facedetectiontest101-0 to offset 18352.
2020-01-07 19:15:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 73c85eae-5178-470e-a2a8-ebf6aa57018b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-41, groupId=73c85eae-5178-470e-a2a8-ebf6aa57018b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-41, groupId=73c85eae-5178-470e-a2a8-ebf6aa57018b] Revoking previously assigned partitions []
2020-01-07 19:15:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-41, groupId=73c85eae-5178-470e-a2a8-ebf6aa57018b] (Re-)joining group
2020-01-07 19:15:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-41, groupId=73c85eae-5178-470e-a2a8-ebf6aa57018b] Successfully joined group with generation 1
2020-01-07 19:15:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-41, groupId=73c85eae-5178-470e-a2a8-ebf6aa57018b] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:29 INFO  Fetcher:583 - [Consumer clientId=consumer-41, groupId=73c85eae-5178-470e-a2a8-ebf6aa57018b] Resetting offset for partition facedetectiontest101-0 to offset 18353.
2020-01-07 19:15:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c9f275b3-629b-4c46-b93e-2fadeae8464c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-42, groupId=c9f275b3-629b-4c46-b93e-2fadeae8464c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-42, groupId=c9f275b3-629b-4c46-b93e-2fadeae8464c] Revoking previously assigned partitions []
2020-01-07 19:15:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-42, groupId=c9f275b3-629b-4c46-b93e-2fadeae8464c] (Re-)joining group
2020-01-07 19:15:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-42, groupId=c9f275b3-629b-4c46-b93e-2fadeae8464c] Successfully joined group with generation 1
2020-01-07 19:15:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-42, groupId=c9f275b3-629b-4c46-b93e-2fadeae8464c] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:29 INFO  Fetcher:583 - [Consumer clientId=consumer-42, groupId=c9f275b3-629b-4c46-b93e-2fadeae8464c] Resetting offset for partition facedetectiontest101-0 to offset 18355.
2020-01-07 19:15:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 01a55827-52b5-4730-97dc-1f619f2c6913
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-43, groupId=01a55827-52b5-4730-97dc-1f619f2c6913] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-43, groupId=01a55827-52b5-4730-97dc-1f619f2c6913] Revoking previously assigned partitions []
2020-01-07 19:15:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-43, groupId=01a55827-52b5-4730-97dc-1f619f2c6913] (Re-)joining group
2020-01-07 19:15:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-43, groupId=01a55827-52b5-4730-97dc-1f619f2c6913] Successfully joined group with generation 1
2020-01-07 19:15:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-43, groupId=01a55827-52b5-4730-97dc-1f619f2c6913] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:29 INFO  Fetcher:583 - [Consumer clientId=consumer-43, groupId=01a55827-52b5-4730-97dc-1f619f2c6913] Resetting offset for partition facedetectiontest101-0 to offset 18356.
2020-01-07 19:15:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e7d6b527-0ede-41a5-a37b-6cc4f779b6b1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-44, groupId=e7d6b527-0ede-41a5-a37b-6cc4f779b6b1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-44, groupId=e7d6b527-0ede-41a5-a37b-6cc4f779b6b1] Revoking previously assigned partitions []
2020-01-07 19:15:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-44, groupId=e7d6b527-0ede-41a5-a37b-6cc4f779b6b1] (Re-)joining group
2020-01-07 19:15:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-44, groupId=e7d6b527-0ede-41a5-a37b-6cc4f779b6b1] Successfully joined group with generation 1
2020-01-07 19:15:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-44, groupId=e7d6b527-0ede-41a5-a37b-6cc4f779b6b1] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:29 INFO  Fetcher:583 - [Consumer clientId=consumer-44, groupId=e7d6b527-0ede-41a5-a37b-6cc4f779b6b1] Resetting offset for partition facedetectiontest101-0 to offset 18357.
2020-01-07 19:15:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2a26da79-676b-4e0d-bce2-0a7f6588bd80
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-45, groupId=2a26da79-676b-4e0d-bce2-0a7f6588bd80] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-45, groupId=2a26da79-676b-4e0d-bce2-0a7f6588bd80] Revoking previously assigned partitions []
2020-01-07 19:15:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-45, groupId=2a26da79-676b-4e0d-bce2-0a7f6588bd80] (Re-)joining group
2020-01-07 19:15:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-45, groupId=2a26da79-676b-4e0d-bce2-0a7f6588bd80] Successfully joined group with generation 1
2020-01-07 19:15:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-45, groupId=2a26da79-676b-4e0d-bce2-0a7f6588bd80] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:29 INFO  Fetcher:583 - [Consumer clientId=consumer-45, groupId=2a26da79-676b-4e0d-bce2-0a7f6588bd80] Resetting offset for partition facedetectiontest101-0 to offset 18359.
2020-01-07 19:15:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 51e325f3-7d32-4b36-86ac-ea134aa71f31
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-46, groupId=51e325f3-7d32-4b36-86ac-ea134aa71f31] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-46, groupId=51e325f3-7d32-4b36-86ac-ea134aa71f31] Revoking previously assigned partitions []
2020-01-07 19:15:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-46, groupId=51e325f3-7d32-4b36-86ac-ea134aa71f31] (Re-)joining group
2020-01-07 19:15:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-46, groupId=51e325f3-7d32-4b36-86ac-ea134aa71f31] Successfully joined group with generation 1
2020-01-07 19:15:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-46, groupId=51e325f3-7d32-4b36-86ac-ea134aa71f31] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:29 INFO  Fetcher:583 - [Consumer clientId=consumer-46, groupId=51e325f3-7d32-4b36-86ac-ea134aa71f31] Resetting offset for partition facedetectiontest101-0 to offset 18360.
2020-01-07 19:15:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5e42214c-f8a5-4304-83b3-90931cb82f17
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-47, groupId=5e42214c-f8a5-4304-83b3-90931cb82f17] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-47, groupId=5e42214c-f8a5-4304-83b3-90931cb82f17] Revoking previously assigned partitions []
2020-01-07 19:15:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-47, groupId=5e42214c-f8a5-4304-83b3-90931cb82f17] (Re-)joining group
2020-01-07 19:15:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-47, groupId=5e42214c-f8a5-4304-83b3-90931cb82f17] Successfully joined group with generation 1
2020-01-07 19:15:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-47, groupId=5e42214c-f8a5-4304-83b3-90931cb82f17] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:29 INFO  Fetcher:583 - [Consumer clientId=consumer-47, groupId=5e42214c-f8a5-4304-83b3-90931cb82f17] Resetting offset for partition facedetectiontest101-0 to offset 18361.
2020-01-07 19:15:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = abb81b04-8c53-45d9-9db1-2ba2a26185f1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-48, groupId=abb81b04-8c53-45d9-9db1-2ba2a26185f1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-48, groupId=abb81b04-8c53-45d9-9db1-2ba2a26185f1] Revoking previously assigned partitions []
2020-01-07 19:15:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-48, groupId=abb81b04-8c53-45d9-9db1-2ba2a26185f1] (Re-)joining group
2020-01-07 19:15:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-48, groupId=abb81b04-8c53-45d9-9db1-2ba2a26185f1] Successfully joined group with generation 1
2020-01-07 19:15:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-48, groupId=abb81b04-8c53-45d9-9db1-2ba2a26185f1] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:30 INFO  Fetcher:583 - [Consumer clientId=consumer-48, groupId=abb81b04-8c53-45d9-9db1-2ba2a26185f1] Resetting offset for partition facedetectiontest101-0 to offset 18362.
2020-01-07 19:15:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 805fdd38-e5d7-4313-910e-f8ba528ee683
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-49, groupId=805fdd38-e5d7-4313-910e-f8ba528ee683] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-49, groupId=805fdd38-e5d7-4313-910e-f8ba528ee683] Revoking previously assigned partitions []
2020-01-07 19:15:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-49, groupId=805fdd38-e5d7-4313-910e-f8ba528ee683] (Re-)joining group
2020-01-07 19:15:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-49, groupId=805fdd38-e5d7-4313-910e-f8ba528ee683] Successfully joined group with generation 1
2020-01-07 19:15:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-49, groupId=805fdd38-e5d7-4313-910e-f8ba528ee683] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:30 INFO  Fetcher:583 - [Consumer clientId=consumer-49, groupId=805fdd38-e5d7-4313-910e-f8ba528ee683] Resetting offset for partition facedetectiontest101-0 to offset 18363.
2020-01-07 19:15:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 80af868e-5aa5-47b4-93ae-c8746dffc039
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-50, groupId=80af868e-5aa5-47b4-93ae-c8746dffc039] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-50, groupId=80af868e-5aa5-47b4-93ae-c8746dffc039] Revoking previously assigned partitions []
2020-01-07 19:15:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-50, groupId=80af868e-5aa5-47b4-93ae-c8746dffc039] (Re-)joining group
2020-01-07 19:15:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-50, groupId=80af868e-5aa5-47b4-93ae-c8746dffc039] Successfully joined group with generation 1
2020-01-07 19:15:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-50, groupId=80af868e-5aa5-47b4-93ae-c8746dffc039] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:30 INFO  Fetcher:583 - [Consumer clientId=consumer-50, groupId=80af868e-5aa5-47b4-93ae-c8746dffc039] Resetting offset for partition facedetectiontest101-0 to offset 18364.
2020-01-07 19:15:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 78a713a8-fbec-4f49-9b8e-296bdc967ec8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-51, groupId=78a713a8-fbec-4f49-9b8e-296bdc967ec8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-51, groupId=78a713a8-fbec-4f49-9b8e-296bdc967ec8] Revoking previously assigned partitions []
2020-01-07 19:15:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-51, groupId=78a713a8-fbec-4f49-9b8e-296bdc967ec8] (Re-)joining group
2020-01-07 19:15:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-51, groupId=78a713a8-fbec-4f49-9b8e-296bdc967ec8] Successfully joined group with generation 1
2020-01-07 19:15:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-51, groupId=78a713a8-fbec-4f49-9b8e-296bdc967ec8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:30 INFO  Fetcher:583 - [Consumer clientId=consumer-51, groupId=78a713a8-fbec-4f49-9b8e-296bdc967ec8] Resetting offset for partition facedetectiontest101-0 to offset 18365.
2020-01-07 19:15:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ca0ca379-421d-45d2-a36a-1a336aa49d2b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-52, groupId=ca0ca379-421d-45d2-a36a-1a336aa49d2b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-52, groupId=ca0ca379-421d-45d2-a36a-1a336aa49d2b] Revoking previously assigned partitions []
2020-01-07 19:15:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-52, groupId=ca0ca379-421d-45d2-a36a-1a336aa49d2b] (Re-)joining group
2020-01-07 19:15:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-52, groupId=ca0ca379-421d-45d2-a36a-1a336aa49d2b] Successfully joined group with generation 1
2020-01-07 19:15:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-52, groupId=ca0ca379-421d-45d2-a36a-1a336aa49d2b] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:30 INFO  Fetcher:583 - [Consumer clientId=consumer-52, groupId=ca0ca379-421d-45d2-a36a-1a336aa49d2b] Resetting offset for partition facedetectiontest101-0 to offset 18366.
2020-01-07 19:15:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f5d253d5-451e-403f-9f7d-b73639d053e6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-53, groupId=f5d253d5-451e-403f-9f7d-b73639d053e6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-53, groupId=f5d253d5-451e-403f-9f7d-b73639d053e6] Revoking previously assigned partitions []
2020-01-07 19:15:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-53, groupId=f5d253d5-451e-403f-9f7d-b73639d053e6] (Re-)joining group
2020-01-07 19:15:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-53, groupId=f5d253d5-451e-403f-9f7d-b73639d053e6] Successfully joined group with generation 1
2020-01-07 19:15:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-53, groupId=f5d253d5-451e-403f-9f7d-b73639d053e6] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:30 INFO  Fetcher:583 - [Consumer clientId=consumer-53, groupId=f5d253d5-451e-403f-9f7d-b73639d053e6] Resetting offset for partition facedetectiontest101-0 to offset 18367.
2020-01-07 19:15:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 03851fb4-e3d6-474b-8b01-18492874cc01
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-54, groupId=03851fb4-e3d6-474b-8b01-18492874cc01] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-54, groupId=03851fb4-e3d6-474b-8b01-18492874cc01] Revoking previously assigned partitions []
2020-01-07 19:15:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-54, groupId=03851fb4-e3d6-474b-8b01-18492874cc01] (Re-)joining group
2020-01-07 19:15:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-54, groupId=03851fb4-e3d6-474b-8b01-18492874cc01] Successfully joined group with generation 1
2020-01-07 19:15:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-54, groupId=03851fb4-e3d6-474b-8b01-18492874cc01] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:30 INFO  Fetcher:583 - [Consumer clientId=consumer-54, groupId=03851fb4-e3d6-474b-8b01-18492874cc01] Resetting offset for partition facedetectiontest101-0 to offset 18368.
2020-01-07 19:15:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fcee6229-25d1-4292-a17a-c8f585f89db1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-55, groupId=fcee6229-25d1-4292-a17a-c8f585f89db1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-55, groupId=fcee6229-25d1-4292-a17a-c8f585f89db1] Revoking previously assigned partitions []
2020-01-07 19:15:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-55, groupId=fcee6229-25d1-4292-a17a-c8f585f89db1] (Re-)joining group
2020-01-07 19:15:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-55, groupId=fcee6229-25d1-4292-a17a-c8f585f89db1] Successfully joined group with generation 1
2020-01-07 19:15:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-55, groupId=fcee6229-25d1-4292-a17a-c8f585f89db1] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:30 INFO  Fetcher:583 - [Consumer clientId=consumer-55, groupId=fcee6229-25d1-4292-a17a-c8f585f89db1] Resetting offset for partition facedetectiontest101-0 to offset 18369.
2020-01-07 19:15:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0f3b2ee3-3e34-4b25-b72f-9d1addb739c4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-56, groupId=0f3b2ee3-3e34-4b25-b72f-9d1addb739c4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-56, groupId=0f3b2ee3-3e34-4b25-b72f-9d1addb739c4] Revoking previously assigned partitions []
2020-01-07 19:15:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-56, groupId=0f3b2ee3-3e34-4b25-b72f-9d1addb739c4] (Re-)joining group
2020-01-07 19:15:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-56, groupId=0f3b2ee3-3e34-4b25-b72f-9d1addb739c4] Successfully joined group with generation 1
2020-01-07 19:15:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-56, groupId=0f3b2ee3-3e34-4b25-b72f-9d1addb739c4] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:31 INFO  Fetcher:583 - [Consumer clientId=consumer-56, groupId=0f3b2ee3-3e34-4b25-b72f-9d1addb739c4] Resetting offset for partition facedetectiontest101-0 to offset 18370.
2020-01-07 19:15:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1c0b8e86-8684-4119-b56b-2a29f3baecf0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-57, groupId=1c0b8e86-8684-4119-b56b-2a29f3baecf0] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-57, groupId=1c0b8e86-8684-4119-b56b-2a29f3baecf0] Revoking previously assigned partitions []
2020-01-07 19:15:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-57, groupId=1c0b8e86-8684-4119-b56b-2a29f3baecf0] (Re-)joining group
2020-01-07 19:15:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-57, groupId=1c0b8e86-8684-4119-b56b-2a29f3baecf0] Successfully joined group with generation 1
2020-01-07 19:15:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-57, groupId=1c0b8e86-8684-4119-b56b-2a29f3baecf0] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:31 INFO  Fetcher:583 - [Consumer clientId=consumer-57, groupId=1c0b8e86-8684-4119-b56b-2a29f3baecf0] Resetting offset for partition facedetectiontest101-0 to offset 18371.
2020-01-07 19:15:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2905315a-2102-4571-b7cf-d950a4b1b4f8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-58, groupId=2905315a-2102-4571-b7cf-d950a4b1b4f8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-58, groupId=2905315a-2102-4571-b7cf-d950a4b1b4f8] Revoking previously assigned partitions []
2020-01-07 19:15:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-58, groupId=2905315a-2102-4571-b7cf-d950a4b1b4f8] (Re-)joining group
2020-01-07 19:15:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-58, groupId=2905315a-2102-4571-b7cf-d950a4b1b4f8] Successfully joined group with generation 1
2020-01-07 19:15:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-58, groupId=2905315a-2102-4571-b7cf-d950a4b1b4f8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:31 INFO  Fetcher:583 - [Consumer clientId=consumer-58, groupId=2905315a-2102-4571-b7cf-d950a4b1b4f8] Resetting offset for partition facedetectiontest101-0 to offset 18372.
2020-01-07 19:15:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 29710403-4c90-4f0d-a54b-b96b4fab1b2f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-59, groupId=29710403-4c90-4f0d-a54b-b96b4fab1b2f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-59, groupId=29710403-4c90-4f0d-a54b-b96b4fab1b2f] Revoking previously assigned partitions []
2020-01-07 19:15:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-59, groupId=29710403-4c90-4f0d-a54b-b96b4fab1b2f] (Re-)joining group
2020-01-07 19:15:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-59, groupId=29710403-4c90-4f0d-a54b-b96b4fab1b2f] Successfully joined group with generation 1
2020-01-07 19:15:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-59, groupId=29710403-4c90-4f0d-a54b-b96b4fab1b2f] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:31 INFO  Fetcher:583 - [Consumer clientId=consumer-59, groupId=29710403-4c90-4f0d-a54b-b96b4fab1b2f] Resetting offset for partition facedetectiontest101-0 to offset 18373.
2020-01-07 19:15:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6956b34e-a005-445d-9dde-efae129b375a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-60, groupId=6956b34e-a005-445d-9dde-efae129b375a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-60, groupId=6956b34e-a005-445d-9dde-efae129b375a] Revoking previously assigned partitions []
2020-01-07 19:15:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-60, groupId=6956b34e-a005-445d-9dde-efae129b375a] (Re-)joining group
2020-01-07 19:15:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-60, groupId=6956b34e-a005-445d-9dde-efae129b375a] Successfully joined group with generation 1
2020-01-07 19:15:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-60, groupId=6956b34e-a005-445d-9dde-efae129b375a] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:31 INFO  Fetcher:583 - [Consumer clientId=consumer-60, groupId=6956b34e-a005-445d-9dde-efae129b375a] Resetting offset for partition facedetectiontest101-0 to offset 18375.
2020-01-07 19:15:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 02a8a1be-aae5-4d3b-9670-18f9b61f2b51
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-61, groupId=02a8a1be-aae5-4d3b-9670-18f9b61f2b51] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-61, groupId=02a8a1be-aae5-4d3b-9670-18f9b61f2b51] Revoking previously assigned partitions []
2020-01-07 19:15:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-61, groupId=02a8a1be-aae5-4d3b-9670-18f9b61f2b51] (Re-)joining group
2020-01-07 19:15:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-61, groupId=02a8a1be-aae5-4d3b-9670-18f9b61f2b51] Successfully joined group with generation 1
2020-01-07 19:15:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-61, groupId=02a8a1be-aae5-4d3b-9670-18f9b61f2b51] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:31 INFO  Fetcher:583 - [Consumer clientId=consumer-61, groupId=02a8a1be-aae5-4d3b-9670-18f9b61f2b51] Resetting offset for partition facedetectiontest101-0 to offset 18377.
2020-01-07 19:15:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 780b229a-aa28-425f-a771-0dcfe6240ff8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-62, groupId=780b229a-aa28-425f-a771-0dcfe6240ff8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-62, groupId=780b229a-aa28-425f-a771-0dcfe6240ff8] Revoking previously assigned partitions []
2020-01-07 19:15:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-62, groupId=780b229a-aa28-425f-a771-0dcfe6240ff8] (Re-)joining group
2020-01-07 19:15:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-62, groupId=780b229a-aa28-425f-a771-0dcfe6240ff8] Successfully joined group with generation 1
2020-01-07 19:15:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-62, groupId=780b229a-aa28-425f-a771-0dcfe6240ff8] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:31 INFO  Fetcher:583 - [Consumer clientId=consumer-62, groupId=780b229a-aa28-425f-a771-0dcfe6240ff8] Resetting offset for partition facedetectiontest101-0 to offset 18378.
2020-01-07 19:15:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3ca074e8-d4b7-4319-9c38-123108673f58
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-63, groupId=3ca074e8-d4b7-4319-9c38-123108673f58] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-63, groupId=3ca074e8-d4b7-4319-9c38-123108673f58] Revoking previously assigned partitions []
2020-01-07 19:15:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-63, groupId=3ca074e8-d4b7-4319-9c38-123108673f58] (Re-)joining group
2020-01-07 19:15:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-63, groupId=3ca074e8-d4b7-4319-9c38-123108673f58] Successfully joined group with generation 1
2020-01-07 19:15:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-63, groupId=3ca074e8-d4b7-4319-9c38-123108673f58] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:31 INFO  Fetcher:583 - [Consumer clientId=consumer-63, groupId=3ca074e8-d4b7-4319-9c38-123108673f58] Resetting offset for partition facedetectiontest101-0 to offset 18379.
2020-01-07 19:15:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f41d5e0d-78fe-4548-b535-cb7fe0971249
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-64, groupId=f41d5e0d-78fe-4548-b535-cb7fe0971249] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-64, groupId=f41d5e0d-78fe-4548-b535-cb7fe0971249] Revoking previously assigned partitions []
2020-01-07 19:15:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-64, groupId=f41d5e0d-78fe-4548-b535-cb7fe0971249] (Re-)joining group
2020-01-07 19:15:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-64, groupId=f41d5e0d-78fe-4548-b535-cb7fe0971249] Successfully joined group with generation 1
2020-01-07 19:15:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-64, groupId=f41d5e0d-78fe-4548-b535-cb7fe0971249] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:31 INFO  Fetcher:583 - [Consumer clientId=consumer-64, groupId=f41d5e0d-78fe-4548-b535-cb7fe0971249] Resetting offset for partition facedetectiontest101-0 to offset 18380.
2020-01-07 19:15:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a5505dfc-d9ca-4aa6-b5db-ecd0edd16b9e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-65, groupId=a5505dfc-d9ca-4aa6-b5db-ecd0edd16b9e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-65, groupId=a5505dfc-d9ca-4aa6-b5db-ecd0edd16b9e] Revoking previously assigned partitions []
2020-01-07 19:15:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-65, groupId=a5505dfc-d9ca-4aa6-b5db-ecd0edd16b9e] (Re-)joining group
2020-01-07 19:15:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-65, groupId=a5505dfc-d9ca-4aa6-b5db-ecd0edd16b9e] Successfully joined group with generation 1
2020-01-07 19:15:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-65, groupId=a5505dfc-d9ca-4aa6-b5db-ecd0edd16b9e] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:31 INFO  Fetcher:583 - [Consumer clientId=consumer-65, groupId=a5505dfc-d9ca-4aa6-b5db-ecd0edd16b9e] Resetting offset for partition facedetectiontest101-0 to offset 18381.
2020-01-07 19:15:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3a2ad1a7-b35f-4af7-88ad-42a00b06bc30
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-66, groupId=3a2ad1a7-b35f-4af7-88ad-42a00b06bc30] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-66, groupId=3a2ad1a7-b35f-4af7-88ad-42a00b06bc30] Revoking previously assigned partitions []
2020-01-07 19:15:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-66, groupId=3a2ad1a7-b35f-4af7-88ad-42a00b06bc30] (Re-)joining group
2020-01-07 19:15:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-66, groupId=3a2ad1a7-b35f-4af7-88ad-42a00b06bc30] Successfully joined group with generation 1
2020-01-07 19:15:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-66, groupId=3a2ad1a7-b35f-4af7-88ad-42a00b06bc30] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:32 INFO  Fetcher:583 - [Consumer clientId=consumer-66, groupId=3a2ad1a7-b35f-4af7-88ad-42a00b06bc30] Resetting offset for partition facedetectiontest101-0 to offset 18382.
2020-01-07 19:15:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d40f7a85-ec70-46bf-8873-70afeb63f53b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-67, groupId=d40f7a85-ec70-46bf-8873-70afeb63f53b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-67, groupId=d40f7a85-ec70-46bf-8873-70afeb63f53b] Revoking previously assigned partitions []
2020-01-07 19:15:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-67, groupId=d40f7a85-ec70-46bf-8873-70afeb63f53b] (Re-)joining group
2020-01-07 19:15:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-67, groupId=d40f7a85-ec70-46bf-8873-70afeb63f53b] Successfully joined group with generation 1
2020-01-07 19:15:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-67, groupId=d40f7a85-ec70-46bf-8873-70afeb63f53b] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:32 INFO  Fetcher:583 - [Consumer clientId=consumer-67, groupId=d40f7a85-ec70-46bf-8873-70afeb63f53b] Resetting offset for partition facedetectiontest101-0 to offset 18383.
2020-01-07 19:15:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 486126ba-c757-42c9-a7d4-f92ef1bc37d6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-68, groupId=486126ba-c757-42c9-a7d4-f92ef1bc37d6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-68, groupId=486126ba-c757-42c9-a7d4-f92ef1bc37d6] Revoking previously assigned partitions []
2020-01-07 19:15:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-68, groupId=486126ba-c757-42c9-a7d4-f92ef1bc37d6] (Re-)joining group
2020-01-07 19:15:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-68, groupId=486126ba-c757-42c9-a7d4-f92ef1bc37d6] Successfully joined group with generation 1
2020-01-07 19:15:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-68, groupId=486126ba-c757-42c9-a7d4-f92ef1bc37d6] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:32 INFO  Fetcher:583 - [Consumer clientId=consumer-68, groupId=486126ba-c757-42c9-a7d4-f92ef1bc37d6] Resetting offset for partition facedetectiontest101-0 to offset 18384.
2020-01-07 19:15:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1794562b-bfcd-49f7-8549-cdf912d138ee
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-69, groupId=1794562b-bfcd-49f7-8549-cdf912d138ee] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-69, groupId=1794562b-bfcd-49f7-8549-cdf912d138ee] Revoking previously assigned partitions []
2020-01-07 19:15:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-69, groupId=1794562b-bfcd-49f7-8549-cdf912d138ee] (Re-)joining group
2020-01-07 19:15:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-69, groupId=1794562b-bfcd-49f7-8549-cdf912d138ee] Successfully joined group with generation 1
2020-01-07 19:15:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-69, groupId=1794562b-bfcd-49f7-8549-cdf912d138ee] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:32 INFO  Fetcher:583 - [Consumer clientId=consumer-69, groupId=1794562b-bfcd-49f7-8549-cdf912d138ee] Resetting offset for partition facedetectiontest101-0 to offset 18385.
2020-01-07 19:15:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = aed52272-0715-443d-91ea-189615238287
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-70, groupId=aed52272-0715-443d-91ea-189615238287] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-70, groupId=aed52272-0715-443d-91ea-189615238287] Revoking previously assigned partitions []
2020-01-07 19:15:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-70, groupId=aed52272-0715-443d-91ea-189615238287] (Re-)joining group
2020-01-07 19:15:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-70, groupId=aed52272-0715-443d-91ea-189615238287] Successfully joined group with generation 1
2020-01-07 19:15:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-70, groupId=aed52272-0715-443d-91ea-189615238287] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:32 INFO  Fetcher:583 - [Consumer clientId=consumer-70, groupId=aed52272-0715-443d-91ea-189615238287] Resetting offset for partition facedetectiontest101-0 to offset 18386.
2020-01-07 19:15:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 03ea6871-fbe1-434b-b12e-6d888d1e0403
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-71, groupId=03ea6871-fbe1-434b-b12e-6d888d1e0403] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-71, groupId=03ea6871-fbe1-434b-b12e-6d888d1e0403] Revoking previously assigned partitions []
2020-01-07 19:15:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-71, groupId=03ea6871-fbe1-434b-b12e-6d888d1e0403] (Re-)joining group
2020-01-07 19:15:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-71, groupId=03ea6871-fbe1-434b-b12e-6d888d1e0403] Successfully joined group with generation 1
2020-01-07 19:15:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-71, groupId=03ea6871-fbe1-434b-b12e-6d888d1e0403] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:32 INFO  Fetcher:583 - [Consumer clientId=consumer-71, groupId=03ea6871-fbe1-434b-b12e-6d888d1e0403] Resetting offset for partition facedetectiontest101-0 to offset 18387.
2020-01-07 19:15:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2fe0f15f-41b7-49ae-8835-2af0852b9769
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-72, groupId=2fe0f15f-41b7-49ae-8835-2af0852b9769] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-72, groupId=2fe0f15f-41b7-49ae-8835-2af0852b9769] Revoking previously assigned partitions []
2020-01-07 19:15:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-72, groupId=2fe0f15f-41b7-49ae-8835-2af0852b9769] (Re-)joining group
2020-01-07 19:15:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-72, groupId=2fe0f15f-41b7-49ae-8835-2af0852b9769] Successfully joined group with generation 1
2020-01-07 19:15:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-72, groupId=2fe0f15f-41b7-49ae-8835-2af0852b9769] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:32 INFO  Fetcher:583 - [Consumer clientId=consumer-72, groupId=2fe0f15f-41b7-49ae-8835-2af0852b9769] Resetting offset for partition facedetectiontest101-0 to offset 18388.
2020-01-07 19:15:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 898f7af5-bafa-46c9-8045-ad58de435e59
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-73, groupId=898f7af5-bafa-46c9-8045-ad58de435e59] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-73, groupId=898f7af5-bafa-46c9-8045-ad58de435e59] Revoking previously assigned partitions []
2020-01-07 19:15:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-73, groupId=898f7af5-bafa-46c9-8045-ad58de435e59] (Re-)joining group
2020-01-07 19:15:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-73, groupId=898f7af5-bafa-46c9-8045-ad58de435e59] Successfully joined group with generation 1
2020-01-07 19:15:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-73, groupId=898f7af5-bafa-46c9-8045-ad58de435e59] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:32 INFO  Fetcher:583 - [Consumer clientId=consumer-73, groupId=898f7af5-bafa-46c9-8045-ad58de435e59] Resetting offset for partition facedetectiontest101-0 to offset 18389.
2020-01-07 19:15:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8760520b-7c5d-4d74-8cda-8eb500ec2e2f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-74, groupId=8760520b-7c5d-4d74-8cda-8eb500ec2e2f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-74, groupId=8760520b-7c5d-4d74-8cda-8eb500ec2e2f] Revoking previously assigned partitions []
2020-01-07 19:15:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-74, groupId=8760520b-7c5d-4d74-8cda-8eb500ec2e2f] (Re-)joining group
2020-01-07 19:15:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-74, groupId=8760520b-7c5d-4d74-8cda-8eb500ec2e2f] Successfully joined group with generation 1
2020-01-07 19:15:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-74, groupId=8760520b-7c5d-4d74-8cda-8eb500ec2e2f] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:32 INFO  Fetcher:583 - [Consumer clientId=consumer-74, groupId=8760520b-7c5d-4d74-8cda-8eb500ec2e2f] Resetting offset for partition facedetectiontest101-0 to offset 18390.
2020-01-07 19:15:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7ea1dfa6-0979-4017-b987-b8017ab11f91
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-75, groupId=7ea1dfa6-0979-4017-b987-b8017ab11f91] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-75, groupId=7ea1dfa6-0979-4017-b987-b8017ab11f91] Revoking previously assigned partitions []
2020-01-07 19:15:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-75, groupId=7ea1dfa6-0979-4017-b987-b8017ab11f91] (Re-)joining group
2020-01-07 19:15:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-75, groupId=7ea1dfa6-0979-4017-b987-b8017ab11f91] Successfully joined group with generation 1
2020-01-07 19:15:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-75, groupId=7ea1dfa6-0979-4017-b987-b8017ab11f91] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:32 INFO  Fetcher:583 - [Consumer clientId=consumer-75, groupId=7ea1dfa6-0979-4017-b987-b8017ab11f91] Resetting offset for partition facedetectiontest101-0 to offset 18391.
2020-01-07 19:15:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8f1d474e-c4ac-4957-9ea5-abe6b05c13fe
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-76, groupId=8f1d474e-c4ac-4957-9ea5-abe6b05c13fe] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-76, groupId=8f1d474e-c4ac-4957-9ea5-abe6b05c13fe] Revoking previously assigned partitions []
2020-01-07 19:15:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-76, groupId=8f1d474e-c4ac-4957-9ea5-abe6b05c13fe] (Re-)joining group
2020-01-07 19:15:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-76, groupId=8f1d474e-c4ac-4957-9ea5-abe6b05c13fe] Successfully joined group with generation 1
2020-01-07 19:15:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-76, groupId=8f1d474e-c4ac-4957-9ea5-abe6b05c13fe] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:33 INFO  Fetcher:583 - [Consumer clientId=consumer-76, groupId=8f1d474e-c4ac-4957-9ea5-abe6b05c13fe] Resetting offset for partition facedetectiontest101-0 to offset 18392.
2020-01-07 19:15:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8edd876c-ec73-4433-bd83-1dece9208967
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-77, groupId=8edd876c-ec73-4433-bd83-1dece9208967] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-77, groupId=8edd876c-ec73-4433-bd83-1dece9208967] Revoking previously assigned partitions []
2020-01-07 19:15:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-77, groupId=8edd876c-ec73-4433-bd83-1dece9208967] (Re-)joining group
2020-01-07 19:15:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-77, groupId=8edd876c-ec73-4433-bd83-1dece9208967] Successfully joined group with generation 1
2020-01-07 19:15:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-77, groupId=8edd876c-ec73-4433-bd83-1dece9208967] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:33 INFO  Fetcher:583 - [Consumer clientId=consumer-77, groupId=8edd876c-ec73-4433-bd83-1dece9208967] Resetting offset for partition facedetectiontest101-0 to offset 18394.
2020-01-07 19:15:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 02902e49-9975-4733-bdd5-b42d3841d3a7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-78, groupId=02902e49-9975-4733-bdd5-b42d3841d3a7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-78, groupId=02902e49-9975-4733-bdd5-b42d3841d3a7] Revoking previously assigned partitions []
2020-01-07 19:15:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-78, groupId=02902e49-9975-4733-bdd5-b42d3841d3a7] (Re-)joining group
2020-01-07 19:15:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-78, groupId=02902e49-9975-4733-bdd5-b42d3841d3a7] Successfully joined group with generation 1
2020-01-07 19:15:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-78, groupId=02902e49-9975-4733-bdd5-b42d3841d3a7] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:33 INFO  Fetcher:583 - [Consumer clientId=consumer-78, groupId=02902e49-9975-4733-bdd5-b42d3841d3a7] Resetting offset for partition facedetectiontest101-0 to offset 18395.
2020-01-07 19:15:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ebf06b76-78e5-4415-9c8a-10162d0c1e53
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-79, groupId=ebf06b76-78e5-4415-9c8a-10162d0c1e53] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-79, groupId=ebf06b76-78e5-4415-9c8a-10162d0c1e53] Revoking previously assigned partitions []
2020-01-07 19:15:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-79, groupId=ebf06b76-78e5-4415-9c8a-10162d0c1e53] (Re-)joining group
2020-01-07 19:15:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-79, groupId=ebf06b76-78e5-4415-9c8a-10162d0c1e53] Successfully joined group with generation 1
2020-01-07 19:15:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-79, groupId=ebf06b76-78e5-4415-9c8a-10162d0c1e53] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:33 INFO  Fetcher:583 - [Consumer clientId=consumer-79, groupId=ebf06b76-78e5-4415-9c8a-10162d0c1e53] Resetting offset for partition facedetectiontest101-0 to offset 18396.
2020-01-07 19:15:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5ce36cc6-eca3-429f-8b7b-71a84180a936
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-80, groupId=5ce36cc6-eca3-429f-8b7b-71a84180a936] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-80, groupId=5ce36cc6-eca3-429f-8b7b-71a84180a936] Revoking previously assigned partitions []
2020-01-07 19:15:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-80, groupId=5ce36cc6-eca3-429f-8b7b-71a84180a936] (Re-)joining group
2020-01-07 19:15:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-80, groupId=5ce36cc6-eca3-429f-8b7b-71a84180a936] Successfully joined group with generation 1
2020-01-07 19:15:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-80, groupId=5ce36cc6-eca3-429f-8b7b-71a84180a936] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:33 INFO  Fetcher:583 - [Consumer clientId=consumer-80, groupId=5ce36cc6-eca3-429f-8b7b-71a84180a936] Resetting offset for partition facedetectiontest101-0 to offset 18397.
2020-01-07 19:15:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 44a48b9c-371e-48c8-be5c-ea2a91cbcc2b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-81, groupId=44a48b9c-371e-48c8-be5c-ea2a91cbcc2b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-81, groupId=44a48b9c-371e-48c8-be5c-ea2a91cbcc2b] Revoking previously assigned partitions []
2020-01-07 19:15:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-81, groupId=44a48b9c-371e-48c8-be5c-ea2a91cbcc2b] (Re-)joining group
2020-01-07 19:15:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-81, groupId=44a48b9c-371e-48c8-be5c-ea2a91cbcc2b] Successfully joined group with generation 1
2020-01-07 19:15:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-81, groupId=44a48b9c-371e-48c8-be5c-ea2a91cbcc2b] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:33 INFO  Fetcher:583 - [Consumer clientId=consumer-81, groupId=44a48b9c-371e-48c8-be5c-ea2a91cbcc2b] Resetting offset for partition facedetectiontest101-0 to offset 18398.
2020-01-07 19:15:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ad7d4385-4381-4229-8f44-a8f5684e88b6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-82, groupId=ad7d4385-4381-4229-8f44-a8f5684e88b6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-82, groupId=ad7d4385-4381-4229-8f44-a8f5684e88b6] Revoking previously assigned partitions []
2020-01-07 19:15:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-82, groupId=ad7d4385-4381-4229-8f44-a8f5684e88b6] (Re-)joining group
2020-01-07 19:15:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-82, groupId=ad7d4385-4381-4229-8f44-a8f5684e88b6] Successfully joined group with generation 1
2020-01-07 19:15:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-82, groupId=ad7d4385-4381-4229-8f44-a8f5684e88b6] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:33 INFO  Fetcher:583 - [Consumer clientId=consumer-82, groupId=ad7d4385-4381-4229-8f44-a8f5684e88b6] Resetting offset for partition facedetectiontest101-0 to offset 18399.
2020-01-07 19:15:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = bb5cb2c5-b139-4c45-b2f2-3719d3c7005c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-83, groupId=bb5cb2c5-b139-4c45-b2f2-3719d3c7005c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-83, groupId=bb5cb2c5-b139-4c45-b2f2-3719d3c7005c] Revoking previously assigned partitions []
2020-01-07 19:15:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-83, groupId=bb5cb2c5-b139-4c45-b2f2-3719d3c7005c] (Re-)joining group
2020-01-07 19:15:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-83, groupId=bb5cb2c5-b139-4c45-b2f2-3719d3c7005c] Successfully joined group with generation 1
2020-01-07 19:15:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-83, groupId=bb5cb2c5-b139-4c45-b2f2-3719d3c7005c] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:33 INFO  Fetcher:583 - [Consumer clientId=consumer-83, groupId=bb5cb2c5-b139-4c45-b2f2-3719d3c7005c] Resetting offset for partition facedetectiontest101-0 to offset 18400.
2020-01-07 19:15:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 308fc7dc-6d59-41de-9f90-62d00b1e867c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-84, groupId=308fc7dc-6d59-41de-9f90-62d00b1e867c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-84, groupId=308fc7dc-6d59-41de-9f90-62d00b1e867c] Revoking previously assigned partitions []
2020-01-07 19:15:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-84, groupId=308fc7dc-6d59-41de-9f90-62d00b1e867c] (Re-)joining group
2020-01-07 19:15:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-84, groupId=308fc7dc-6d59-41de-9f90-62d00b1e867c] Successfully joined group with generation 1
2020-01-07 19:15:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-84, groupId=308fc7dc-6d59-41de-9f90-62d00b1e867c] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:33 INFO  Fetcher:583 - [Consumer clientId=consumer-84, groupId=308fc7dc-6d59-41de-9f90-62d00b1e867c] Resetting offset for partition facedetectiontest101-0 to offset 18401.
2020-01-07 19:15:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7126b925-f33b-4d44-a4e6-82bf82a2034b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-85, groupId=7126b925-f33b-4d44-a4e6-82bf82a2034b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-85, groupId=7126b925-f33b-4d44-a4e6-82bf82a2034b] Revoking previously assigned partitions []
2020-01-07 19:15:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-85, groupId=7126b925-f33b-4d44-a4e6-82bf82a2034b] (Re-)joining group
2020-01-07 19:15:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-85, groupId=7126b925-f33b-4d44-a4e6-82bf82a2034b] Successfully joined group with generation 1
2020-01-07 19:15:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-85, groupId=7126b925-f33b-4d44-a4e6-82bf82a2034b] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:34 INFO  Fetcher:583 - [Consumer clientId=consumer-85, groupId=7126b925-f33b-4d44-a4e6-82bf82a2034b] Resetting offset for partition facedetectiontest101-0 to offset 18402.
2020-01-07 19:15:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 050f536c-3134-4f41-b051-c6389967dcb6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-86, groupId=050f536c-3134-4f41-b051-c6389967dcb6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-86, groupId=050f536c-3134-4f41-b051-c6389967dcb6] Revoking previously assigned partitions []
2020-01-07 19:15:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-86, groupId=050f536c-3134-4f41-b051-c6389967dcb6] (Re-)joining group
2020-01-07 19:15:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-86, groupId=050f536c-3134-4f41-b051-c6389967dcb6] Successfully joined group with generation 1
2020-01-07 19:15:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-86, groupId=050f536c-3134-4f41-b051-c6389967dcb6] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:34 INFO  Fetcher:583 - [Consumer clientId=consumer-86, groupId=050f536c-3134-4f41-b051-c6389967dcb6] Resetting offset for partition facedetectiontest101-0 to offset 18403.
2020-01-07 19:15:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4f190113-f091-4ea6-9626-9ed14b99f8df
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-87, groupId=4f190113-f091-4ea6-9626-9ed14b99f8df] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-87, groupId=4f190113-f091-4ea6-9626-9ed14b99f8df] Revoking previously assigned partitions []
2020-01-07 19:15:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-87, groupId=4f190113-f091-4ea6-9626-9ed14b99f8df] (Re-)joining group
2020-01-07 19:15:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-87, groupId=4f190113-f091-4ea6-9626-9ed14b99f8df] Successfully joined group with generation 1
2020-01-07 19:15:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-87, groupId=4f190113-f091-4ea6-9626-9ed14b99f8df] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:34 INFO  Fetcher:583 - [Consumer clientId=consumer-87, groupId=4f190113-f091-4ea6-9626-9ed14b99f8df] Resetting offset for partition facedetectiontest101-0 to offset 18404.
2020-01-07 19:15:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 79d9a122-8501-4e1b-b297-34996520d2fb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-88, groupId=79d9a122-8501-4e1b-b297-34996520d2fb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-88, groupId=79d9a122-8501-4e1b-b297-34996520d2fb] Revoking previously assigned partitions []
2020-01-07 19:15:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-88, groupId=79d9a122-8501-4e1b-b297-34996520d2fb] (Re-)joining group
2020-01-07 19:15:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-88, groupId=79d9a122-8501-4e1b-b297-34996520d2fb] Successfully joined group with generation 1
2020-01-07 19:15:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-88, groupId=79d9a122-8501-4e1b-b297-34996520d2fb] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:34 INFO  Fetcher:583 - [Consumer clientId=consumer-88, groupId=79d9a122-8501-4e1b-b297-34996520d2fb] Resetting offset for partition facedetectiontest101-0 to offset 18406.
2020-01-07 19:15:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 140a64b9-d25e-4b9b-8a47-a1228f5c8833
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-89, groupId=140a64b9-d25e-4b9b-8a47-a1228f5c8833] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-89, groupId=140a64b9-d25e-4b9b-8a47-a1228f5c8833] Revoking previously assigned partitions []
2020-01-07 19:15:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-89, groupId=140a64b9-d25e-4b9b-8a47-a1228f5c8833] (Re-)joining group
2020-01-07 19:15:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-89, groupId=140a64b9-d25e-4b9b-8a47-a1228f5c8833] Successfully joined group with generation 1
2020-01-07 19:15:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-89, groupId=140a64b9-d25e-4b9b-8a47-a1228f5c8833] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:34 INFO  Fetcher:583 - [Consumer clientId=consumer-89, groupId=140a64b9-d25e-4b9b-8a47-a1228f5c8833] Resetting offset for partition facedetectiontest101-0 to offset 18408.
2020-01-07 19:15:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a34901a9-dbd0-4798-a37e-3a4ef8bed808
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-90, groupId=a34901a9-dbd0-4798-a37e-3a4ef8bed808] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-90, groupId=a34901a9-dbd0-4798-a37e-3a4ef8bed808] Revoking previously assigned partitions []
2020-01-07 19:15:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-90, groupId=a34901a9-dbd0-4798-a37e-3a4ef8bed808] (Re-)joining group
2020-01-07 19:15:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-90, groupId=a34901a9-dbd0-4798-a37e-3a4ef8bed808] Successfully joined group with generation 1
2020-01-07 19:15:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-90, groupId=a34901a9-dbd0-4798-a37e-3a4ef8bed808] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:34 INFO  Fetcher:583 - [Consumer clientId=consumer-90, groupId=a34901a9-dbd0-4798-a37e-3a4ef8bed808] Resetting offset for partition facedetectiontest101-0 to offset 18411.
2020-01-07 19:15:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5d5cfbd9-abf3-4f67-8ea7-b40067d6a4bf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-91, groupId=5d5cfbd9-abf3-4f67-8ea7-b40067d6a4bf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-91, groupId=5d5cfbd9-abf3-4f67-8ea7-b40067d6a4bf] Revoking previously assigned partitions []
2020-01-07 19:15:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-91, groupId=5d5cfbd9-abf3-4f67-8ea7-b40067d6a4bf] (Re-)joining group
2020-01-07 19:15:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-91, groupId=5d5cfbd9-abf3-4f67-8ea7-b40067d6a4bf] Successfully joined group with generation 1
2020-01-07 19:15:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-91, groupId=5d5cfbd9-abf3-4f67-8ea7-b40067d6a4bf] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:35 INFO  Fetcher:583 - [Consumer clientId=consumer-91, groupId=5d5cfbd9-abf3-4f67-8ea7-b40067d6a4bf] Resetting offset for partition facedetectiontest101-0 to offset 18413.
2020-01-07 19:15:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a4a2c998-3426-462c-8fa1-9bd79baf9c9d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-92, groupId=a4a2c998-3426-462c-8fa1-9bd79baf9c9d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-92, groupId=a4a2c998-3426-462c-8fa1-9bd79baf9c9d] Revoking previously assigned partitions []
2020-01-07 19:15:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-92, groupId=a4a2c998-3426-462c-8fa1-9bd79baf9c9d] (Re-)joining group
2020-01-07 19:15:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-92, groupId=a4a2c998-3426-462c-8fa1-9bd79baf9c9d] Successfully joined group with generation 1
2020-01-07 19:15:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-92, groupId=a4a2c998-3426-462c-8fa1-9bd79baf9c9d] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:35 INFO  Fetcher:583 - [Consumer clientId=consumer-92, groupId=a4a2c998-3426-462c-8fa1-9bd79baf9c9d] Resetting offset for partition facedetectiontest101-0 to offset 18415.
2020-01-07 19:15:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 79309425-1610-4133-87fd-7dc9d001a3a3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-93, groupId=79309425-1610-4133-87fd-7dc9d001a3a3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-93, groupId=79309425-1610-4133-87fd-7dc9d001a3a3] Revoking previously assigned partitions []
2020-01-07 19:15:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-93, groupId=79309425-1610-4133-87fd-7dc9d001a3a3] (Re-)joining group
2020-01-07 19:15:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-93, groupId=79309425-1610-4133-87fd-7dc9d001a3a3] Successfully joined group with generation 1
2020-01-07 19:15:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-93, groupId=79309425-1610-4133-87fd-7dc9d001a3a3] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:35 INFO  Fetcher:583 - [Consumer clientId=consumer-93, groupId=79309425-1610-4133-87fd-7dc9d001a3a3] Resetting offset for partition facedetectiontest101-0 to offset 18417.
2020-01-07 19:15:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a85df70d-d55c-46ad-8aa2-25dd4dca05b7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-94, groupId=a85df70d-d55c-46ad-8aa2-25dd4dca05b7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-94, groupId=a85df70d-d55c-46ad-8aa2-25dd4dca05b7] Revoking previously assigned partitions []
2020-01-07 19:15:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-94, groupId=a85df70d-d55c-46ad-8aa2-25dd4dca05b7] (Re-)joining group
2020-01-07 19:15:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-94, groupId=a85df70d-d55c-46ad-8aa2-25dd4dca05b7] Successfully joined group with generation 1
2020-01-07 19:15:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-94, groupId=a85df70d-d55c-46ad-8aa2-25dd4dca05b7] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:35 INFO  Fetcher:583 - [Consumer clientId=consumer-94, groupId=a85df70d-d55c-46ad-8aa2-25dd4dca05b7] Resetting offset for partition facedetectiontest101-0 to offset 18419.
2020-01-07 19:15:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 19d8d176-f457-464f-8dfc-5390325f47c3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:15:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:15:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:15:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:15:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-95, groupId=19d8d176-f457-464f-8dfc-5390325f47c3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:15:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-95, groupId=19d8d176-f457-464f-8dfc-5390325f47c3] Revoking previously assigned partitions []
2020-01-07 19:15:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-95, groupId=19d8d176-f457-464f-8dfc-5390325f47c3] (Re-)joining group
2020-01-07 19:15:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-95, groupId=19d8d176-f457-464f-8dfc-5390325f47c3] Successfully joined group with generation 1
2020-01-07 19:15:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-95, groupId=19d8d176-f457-464f-8dfc-5390325f47c3] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:15:35 INFO  Fetcher:583 - [Consumer clientId=consumer-95, groupId=19d8d176-f457-464f-8dfc-5390325f47c3] Resetting offset for partition facedetectiontest101-0 to offset 18421.
2020-01-07 19:19:41 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a6a47c78-3870-4fe2-bbde-e8e4304053a4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:41 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:41 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:41 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:41 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=a6a47c78-3870-4fe2-bbde-e8e4304053a4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:42 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=a6a47c78-3870-4fe2-bbde-e8e4304053a4] Revoking previously assigned partitions []
2020-01-07 19:19:42 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=a6a47c78-3870-4fe2-bbde-e8e4304053a4] (Re-)joining group
2020-01-07 19:19:42 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=a6a47c78-3870-4fe2-bbde-e8e4304053a4] Successfully joined group with generation 1
2020-01-07 19:19:42 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=a6a47c78-3870-4fe2-bbde-e8e4304053a4] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:42 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=a6a47c78-3870-4fe2-bbde-e8e4304053a4] Resetting offset for partition stream9-0 to offset 63137.
2020-01-07 19:19:42 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e5ba69cc-543e-4281-ba6a-397f7e118171
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:42 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:42 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:42 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:42 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-2, groupId=e5ba69cc-543e-4281-ba6a-397f7e118171] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:42 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-2, groupId=e5ba69cc-543e-4281-ba6a-397f7e118171] Revoking previously assigned partitions []
2020-01-07 19:19:42 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-2, groupId=e5ba69cc-543e-4281-ba6a-397f7e118171] (Re-)joining group
2020-01-07 19:19:42 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-2, groupId=e5ba69cc-543e-4281-ba6a-397f7e118171] Successfully joined group with generation 1
2020-01-07 19:19:42 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-2, groupId=e5ba69cc-543e-4281-ba6a-397f7e118171] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:42 INFO  Fetcher:583 - [Consumer clientId=consumer-2, groupId=e5ba69cc-543e-4281-ba6a-397f7e118171] Resetting offset for partition stream9-0 to offset 63141.
2020-01-07 19:19:42 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ab734cd2-1554-4206-8fb7-6209a90258df
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:42 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:42 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:42 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:42 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-3, groupId=ab734cd2-1554-4206-8fb7-6209a90258df] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:42 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-3, groupId=ab734cd2-1554-4206-8fb7-6209a90258df] Revoking previously assigned partitions []
2020-01-07 19:19:42 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-3, groupId=ab734cd2-1554-4206-8fb7-6209a90258df] (Re-)joining group
2020-01-07 19:19:42 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-3, groupId=ab734cd2-1554-4206-8fb7-6209a90258df] Successfully joined group with generation 1
2020-01-07 19:19:42 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-3, groupId=ab734cd2-1554-4206-8fb7-6209a90258df] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:42 INFO  Fetcher:583 - [Consumer clientId=consumer-3, groupId=ab734cd2-1554-4206-8fb7-6209a90258df] Resetting offset for partition stream9-0 to offset 63142.
2020-01-07 19:19:42 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4a3e8a59-a2f1-40dc-8107-8505d155afaf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:42 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:42 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:42 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:42 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-4, groupId=4a3e8a59-a2f1-40dc-8107-8505d155afaf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:42 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-4, groupId=4a3e8a59-a2f1-40dc-8107-8505d155afaf] Revoking previously assigned partitions []
2020-01-07 19:19:42 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-4, groupId=4a3e8a59-a2f1-40dc-8107-8505d155afaf] (Re-)joining group
2020-01-07 19:19:42 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-4, groupId=4a3e8a59-a2f1-40dc-8107-8505d155afaf] Successfully joined group with generation 1
2020-01-07 19:19:42 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-4, groupId=4a3e8a59-a2f1-40dc-8107-8505d155afaf] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:42 INFO  Fetcher:583 - [Consumer clientId=consumer-4, groupId=4a3e8a59-a2f1-40dc-8107-8505d155afaf] Resetting offset for partition stream9-0 to offset 63143.
2020-01-07 19:19:42 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 78353142-1b65-4263-b4af-bd255637e5b2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:42 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:42 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:42 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:42 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-5, groupId=78353142-1b65-4263-b4af-bd255637e5b2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:42 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-5, groupId=78353142-1b65-4263-b4af-bd255637e5b2] Revoking previously assigned partitions []
2020-01-07 19:19:42 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-5, groupId=78353142-1b65-4263-b4af-bd255637e5b2] (Re-)joining group
2020-01-07 19:19:42 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-5, groupId=78353142-1b65-4263-b4af-bd255637e5b2] Successfully joined group with generation 1
2020-01-07 19:19:42 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-5, groupId=78353142-1b65-4263-b4af-bd255637e5b2] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:42 INFO  Fetcher:583 - [Consumer clientId=consumer-5, groupId=78353142-1b65-4263-b4af-bd255637e5b2] Resetting offset for partition stream9-0 to offset 63144.
2020-01-07 19:19:42 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c6acdf91-becb-4cfd-b422-d04111f5e2f6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:42 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:42 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:42 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:42 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-6, groupId=c6acdf91-becb-4cfd-b422-d04111f5e2f6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:42 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-6, groupId=c6acdf91-becb-4cfd-b422-d04111f5e2f6] Revoking previously assigned partitions []
2020-01-07 19:19:42 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-6, groupId=c6acdf91-becb-4cfd-b422-d04111f5e2f6] (Re-)joining group
2020-01-07 19:19:42 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-6, groupId=c6acdf91-becb-4cfd-b422-d04111f5e2f6] Successfully joined group with generation 1
2020-01-07 19:19:42 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-6, groupId=c6acdf91-becb-4cfd-b422-d04111f5e2f6] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:42 INFO  Fetcher:583 - [Consumer clientId=consumer-6, groupId=c6acdf91-becb-4cfd-b422-d04111f5e2f6] Resetting offset for partition stream9-0 to offset 63145.
2020-01-07 19:19:43 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d4fee254-3a31-4f0c-b42d-000fb19b1d0b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:43 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:43 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:43 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:43 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-7, groupId=d4fee254-3a31-4f0c-b42d-000fb19b1d0b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:43 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-7, groupId=d4fee254-3a31-4f0c-b42d-000fb19b1d0b] Revoking previously assigned partitions []
2020-01-07 19:19:43 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-7, groupId=d4fee254-3a31-4f0c-b42d-000fb19b1d0b] (Re-)joining group
2020-01-07 19:19:43 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-7, groupId=d4fee254-3a31-4f0c-b42d-000fb19b1d0b] Successfully joined group with generation 1
2020-01-07 19:19:43 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-7, groupId=d4fee254-3a31-4f0c-b42d-000fb19b1d0b] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:43 INFO  Fetcher:583 - [Consumer clientId=consumer-7, groupId=d4fee254-3a31-4f0c-b42d-000fb19b1d0b] Resetting offset for partition stream9-0 to offset 63146.
2020-01-07 19:19:43 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b1aa1d51-45d9-465d-8d29-446536b21a11
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:43 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:43 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:43 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:43 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-8, groupId=b1aa1d51-45d9-465d-8d29-446536b21a11] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:43 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-8, groupId=b1aa1d51-45d9-465d-8d29-446536b21a11] Revoking previously assigned partitions []
2020-01-07 19:19:43 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-8, groupId=b1aa1d51-45d9-465d-8d29-446536b21a11] (Re-)joining group
2020-01-07 19:19:43 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-8, groupId=b1aa1d51-45d9-465d-8d29-446536b21a11] Successfully joined group with generation 1
2020-01-07 19:19:43 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-8, groupId=b1aa1d51-45d9-465d-8d29-446536b21a11] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:43 INFO  Fetcher:583 - [Consumer clientId=consumer-8, groupId=b1aa1d51-45d9-465d-8d29-446536b21a11] Resetting offset for partition stream9-0 to offset 63147.
2020-01-07 19:19:43 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ec98d93a-0690-4773-b977-d3985dec41d7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:43 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:43 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:43 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:43 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-9, groupId=ec98d93a-0690-4773-b977-d3985dec41d7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:43 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-9, groupId=ec98d93a-0690-4773-b977-d3985dec41d7] Revoking previously assigned partitions []
2020-01-07 19:19:43 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-9, groupId=ec98d93a-0690-4773-b977-d3985dec41d7] (Re-)joining group
2020-01-07 19:19:43 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-9, groupId=ec98d93a-0690-4773-b977-d3985dec41d7] Successfully joined group with generation 1
2020-01-07 19:19:43 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-9, groupId=ec98d93a-0690-4773-b977-d3985dec41d7] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:43 INFO  Fetcher:583 - [Consumer clientId=consumer-9, groupId=ec98d93a-0690-4773-b977-d3985dec41d7] Resetting offset for partition stream9-0 to offset 63148.
2020-01-07 19:19:43 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 41759637-8ba0-419f-aaa4-f379e9f87cd7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:43 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:43 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:43 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:43 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-10, groupId=41759637-8ba0-419f-aaa4-f379e9f87cd7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:43 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-10, groupId=41759637-8ba0-419f-aaa4-f379e9f87cd7] Revoking previously assigned partitions []
2020-01-07 19:19:43 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-10, groupId=41759637-8ba0-419f-aaa4-f379e9f87cd7] (Re-)joining group
2020-01-07 19:19:43 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-10, groupId=41759637-8ba0-419f-aaa4-f379e9f87cd7] Successfully joined group with generation 1
2020-01-07 19:19:43 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-10, groupId=41759637-8ba0-419f-aaa4-f379e9f87cd7] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:43 INFO  Fetcher:583 - [Consumer clientId=consumer-10, groupId=41759637-8ba0-419f-aaa4-f379e9f87cd7] Resetting offset for partition stream9-0 to offset 63149.
2020-01-07 19:19:43 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 10d6dadb-9764-4b66-9f07-02760f9b45de
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:43 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:43 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:43 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:43 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-11, groupId=10d6dadb-9764-4b66-9f07-02760f9b45de] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:43 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-11, groupId=10d6dadb-9764-4b66-9f07-02760f9b45de] Revoking previously assigned partitions []
2020-01-07 19:19:43 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-11, groupId=10d6dadb-9764-4b66-9f07-02760f9b45de] (Re-)joining group
2020-01-07 19:19:43 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-11, groupId=10d6dadb-9764-4b66-9f07-02760f9b45de] Successfully joined group with generation 1
2020-01-07 19:19:43 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-11, groupId=10d6dadb-9764-4b66-9f07-02760f9b45de] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:43 INFO  Fetcher:583 - [Consumer clientId=consumer-11, groupId=10d6dadb-9764-4b66-9f07-02760f9b45de] Resetting offset for partition stream9-0 to offset 63150.
2020-01-07 19:19:43 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3a1b15b6-86e2-462c-b2af-02eb69add783
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:43 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:43 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:43 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:43 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-12, groupId=3a1b15b6-86e2-462c-b2af-02eb69add783] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:43 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-12, groupId=3a1b15b6-86e2-462c-b2af-02eb69add783] Revoking previously assigned partitions []
2020-01-07 19:19:43 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-12, groupId=3a1b15b6-86e2-462c-b2af-02eb69add783] (Re-)joining group
2020-01-07 19:19:43 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-12, groupId=3a1b15b6-86e2-462c-b2af-02eb69add783] Successfully joined group with generation 1
2020-01-07 19:19:43 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-12, groupId=3a1b15b6-86e2-462c-b2af-02eb69add783] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:43 INFO  Fetcher:583 - [Consumer clientId=consumer-12, groupId=3a1b15b6-86e2-462c-b2af-02eb69add783] Resetting offset for partition stream9-0 to offset 63151.
2020-01-07 19:19:44 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fb851888-8d14-4282-8eb7-469d73c15a3c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:44 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:44 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:44 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:44 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-13, groupId=fb851888-8d14-4282-8eb7-469d73c15a3c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:44 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-13, groupId=fb851888-8d14-4282-8eb7-469d73c15a3c] Revoking previously assigned partitions []
2020-01-07 19:19:44 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-13, groupId=fb851888-8d14-4282-8eb7-469d73c15a3c] (Re-)joining group
2020-01-07 19:19:44 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-13, groupId=fb851888-8d14-4282-8eb7-469d73c15a3c] Successfully joined group with generation 1
2020-01-07 19:19:44 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-13, groupId=fb851888-8d14-4282-8eb7-469d73c15a3c] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:44 INFO  Fetcher:583 - [Consumer clientId=consumer-13, groupId=fb851888-8d14-4282-8eb7-469d73c15a3c] Resetting offset for partition stream9-0 to offset 63152.
2020-01-07 19:19:44 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e896d676-bfe2-4e43-b2b4-fa7902144c71
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:44 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:44 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:44 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:44 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-14, groupId=e896d676-bfe2-4e43-b2b4-fa7902144c71] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:44 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-14, groupId=e896d676-bfe2-4e43-b2b4-fa7902144c71] Revoking previously assigned partitions []
2020-01-07 19:19:44 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-14, groupId=e896d676-bfe2-4e43-b2b4-fa7902144c71] (Re-)joining group
2020-01-07 19:19:44 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-14, groupId=e896d676-bfe2-4e43-b2b4-fa7902144c71] Successfully joined group with generation 1
2020-01-07 19:19:44 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-14, groupId=e896d676-bfe2-4e43-b2b4-fa7902144c71] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:44 INFO  Fetcher:583 - [Consumer clientId=consumer-14, groupId=e896d676-bfe2-4e43-b2b4-fa7902144c71] Resetting offset for partition stream9-0 to offset 63154.
2020-01-07 19:19:44 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9dce693c-e32c-460b-9f36-b39450b4ae1e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:44 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:44 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:44 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:44 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-15, groupId=9dce693c-e32c-460b-9f36-b39450b4ae1e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:44 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-15, groupId=9dce693c-e32c-460b-9f36-b39450b4ae1e] Revoking previously assigned partitions []
2020-01-07 19:19:44 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-15, groupId=9dce693c-e32c-460b-9f36-b39450b4ae1e] (Re-)joining group
2020-01-07 19:19:44 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-15, groupId=9dce693c-e32c-460b-9f36-b39450b4ae1e] Successfully joined group with generation 1
2020-01-07 19:19:44 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-15, groupId=9dce693c-e32c-460b-9f36-b39450b4ae1e] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:44 INFO  Fetcher:583 - [Consumer clientId=consumer-15, groupId=9dce693c-e32c-460b-9f36-b39450b4ae1e] Resetting offset for partition stream9-0 to offset 63155.
2020-01-07 19:19:44 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3c29bef2-6d37-4731-b17c-f17c7d711578
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:44 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:44 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:44 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:44 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-16, groupId=3c29bef2-6d37-4731-b17c-f17c7d711578] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:44 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-16, groupId=3c29bef2-6d37-4731-b17c-f17c7d711578] Revoking previously assigned partitions []
2020-01-07 19:19:44 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-16, groupId=3c29bef2-6d37-4731-b17c-f17c7d711578] (Re-)joining group
2020-01-07 19:19:44 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-16, groupId=3c29bef2-6d37-4731-b17c-f17c7d711578] Successfully joined group with generation 1
2020-01-07 19:19:44 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-16, groupId=3c29bef2-6d37-4731-b17c-f17c7d711578] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:44 INFO  Fetcher:583 - [Consumer clientId=consumer-16, groupId=3c29bef2-6d37-4731-b17c-f17c7d711578] Resetting offset for partition stream9-0 to offset 63156.
2020-01-07 19:19:44 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7e13fe10-eccc-4f78-aed2-87fd6b4873ca
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:44 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:44 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:44 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:44 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-17, groupId=7e13fe10-eccc-4f78-aed2-87fd6b4873ca] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:44 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-17, groupId=7e13fe10-eccc-4f78-aed2-87fd6b4873ca] Revoking previously assigned partitions []
2020-01-07 19:19:44 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-17, groupId=7e13fe10-eccc-4f78-aed2-87fd6b4873ca] (Re-)joining group
2020-01-07 19:19:44 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-17, groupId=7e13fe10-eccc-4f78-aed2-87fd6b4873ca] Successfully joined group with generation 1
2020-01-07 19:19:44 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-17, groupId=7e13fe10-eccc-4f78-aed2-87fd6b4873ca] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:44 INFO  Fetcher:583 - [Consumer clientId=consumer-17, groupId=7e13fe10-eccc-4f78-aed2-87fd6b4873ca] Resetting offset for partition stream9-0 to offset 63157.
2020-01-07 19:19:44 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8396cf5c-b312-4665-a605-78f7665c24e5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:44 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:44 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:44 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:44 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-18, groupId=8396cf5c-b312-4665-a605-78f7665c24e5] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:44 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-18, groupId=8396cf5c-b312-4665-a605-78f7665c24e5] Revoking previously assigned partitions []
2020-01-07 19:19:44 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-18, groupId=8396cf5c-b312-4665-a605-78f7665c24e5] (Re-)joining group
2020-01-07 19:19:44 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-18, groupId=8396cf5c-b312-4665-a605-78f7665c24e5] Successfully joined group with generation 1
2020-01-07 19:19:44 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-18, groupId=8396cf5c-b312-4665-a605-78f7665c24e5] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:44 INFO  Fetcher:583 - [Consumer clientId=consumer-18, groupId=8396cf5c-b312-4665-a605-78f7665c24e5] Resetting offset for partition stream9-0 to offset 63158.
2020-01-07 19:19:45 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6eb5440a-968e-4790-8963-3776cff72c80
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:45 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:45 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:45 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:45 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-19, groupId=6eb5440a-968e-4790-8963-3776cff72c80] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:45 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-19, groupId=6eb5440a-968e-4790-8963-3776cff72c80] Revoking previously assigned partitions []
2020-01-07 19:19:45 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-19, groupId=6eb5440a-968e-4790-8963-3776cff72c80] (Re-)joining group
2020-01-07 19:19:45 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-19, groupId=6eb5440a-968e-4790-8963-3776cff72c80] Successfully joined group with generation 1
2020-01-07 19:19:45 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-19, groupId=6eb5440a-968e-4790-8963-3776cff72c80] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:45 INFO  Fetcher:583 - [Consumer clientId=consumer-19, groupId=6eb5440a-968e-4790-8963-3776cff72c80] Resetting offset for partition stream9-0 to offset 63160.
2020-01-07 19:19:45 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c1e3a1a7-f9f6-4edf-8844-f8c2ebaeaf87
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:45 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:45 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:45 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:45 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-20, groupId=c1e3a1a7-f9f6-4edf-8844-f8c2ebaeaf87] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:45 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-20, groupId=c1e3a1a7-f9f6-4edf-8844-f8c2ebaeaf87] Revoking previously assigned partitions []
2020-01-07 19:19:45 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-20, groupId=c1e3a1a7-f9f6-4edf-8844-f8c2ebaeaf87] (Re-)joining group
2020-01-07 19:19:45 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-20, groupId=c1e3a1a7-f9f6-4edf-8844-f8c2ebaeaf87] Successfully joined group with generation 1
2020-01-07 19:19:45 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-20, groupId=c1e3a1a7-f9f6-4edf-8844-f8c2ebaeaf87] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:45 INFO  Fetcher:583 - [Consumer clientId=consumer-20, groupId=c1e3a1a7-f9f6-4edf-8844-f8c2ebaeaf87] Resetting offset for partition stream9-0 to offset 63161.
2020-01-07 19:19:45 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e455e53e-7deb-46a7-b628-8356a4e0df5d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:45 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:45 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:45 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:45 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-21, groupId=e455e53e-7deb-46a7-b628-8356a4e0df5d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:45 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-21, groupId=e455e53e-7deb-46a7-b628-8356a4e0df5d] Revoking previously assigned partitions []
2020-01-07 19:19:45 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-21, groupId=e455e53e-7deb-46a7-b628-8356a4e0df5d] (Re-)joining group
2020-01-07 19:19:45 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-21, groupId=e455e53e-7deb-46a7-b628-8356a4e0df5d] Successfully joined group with generation 1
2020-01-07 19:19:45 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-21, groupId=e455e53e-7deb-46a7-b628-8356a4e0df5d] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:45 INFO  Fetcher:583 - [Consumer clientId=consumer-21, groupId=e455e53e-7deb-46a7-b628-8356a4e0df5d] Resetting offset for partition stream9-0 to offset 63162.
2020-01-07 19:19:45 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 748f7fba-f485-46cf-8a4c-b2dab29f8ebe
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:45 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:45 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:45 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:45 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-22, groupId=748f7fba-f485-46cf-8a4c-b2dab29f8ebe] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:45 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-22, groupId=748f7fba-f485-46cf-8a4c-b2dab29f8ebe] Revoking previously assigned partitions []
2020-01-07 19:19:45 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-22, groupId=748f7fba-f485-46cf-8a4c-b2dab29f8ebe] (Re-)joining group
2020-01-07 19:19:45 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-22, groupId=748f7fba-f485-46cf-8a4c-b2dab29f8ebe] Successfully joined group with generation 1
2020-01-07 19:19:45 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-22, groupId=748f7fba-f485-46cf-8a4c-b2dab29f8ebe] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:45 INFO  Fetcher:583 - [Consumer clientId=consumer-22, groupId=748f7fba-f485-46cf-8a4c-b2dab29f8ebe] Resetting offset for partition stream9-0 to offset 63163.
2020-01-07 19:19:45 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 612e080f-10ef-47c4-bdc7-f4cacae1d793
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:45 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:45 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:45 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:45 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-23, groupId=612e080f-10ef-47c4-bdc7-f4cacae1d793] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:45 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-23, groupId=612e080f-10ef-47c4-bdc7-f4cacae1d793] Revoking previously assigned partitions []
2020-01-07 19:19:45 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-23, groupId=612e080f-10ef-47c4-bdc7-f4cacae1d793] (Re-)joining group
2020-01-07 19:19:45 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-23, groupId=612e080f-10ef-47c4-bdc7-f4cacae1d793] Successfully joined group with generation 1
2020-01-07 19:19:45 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-23, groupId=612e080f-10ef-47c4-bdc7-f4cacae1d793] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:45 INFO  Fetcher:583 - [Consumer clientId=consumer-23, groupId=612e080f-10ef-47c4-bdc7-f4cacae1d793] Resetting offset for partition stream9-0 to offset 63164.
2020-01-07 19:19:45 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5136e92a-db5c-4e3c-87d6-ec527a9fe878
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:45 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:45 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:45 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:45 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-24, groupId=5136e92a-db5c-4e3c-87d6-ec527a9fe878] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:45 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-24, groupId=5136e92a-db5c-4e3c-87d6-ec527a9fe878] Revoking previously assigned partitions []
2020-01-07 19:19:45 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-24, groupId=5136e92a-db5c-4e3c-87d6-ec527a9fe878] (Re-)joining group
2020-01-07 19:19:45 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-24, groupId=5136e92a-db5c-4e3c-87d6-ec527a9fe878] Successfully joined group with generation 1
2020-01-07 19:19:45 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-24, groupId=5136e92a-db5c-4e3c-87d6-ec527a9fe878] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:45 INFO  Fetcher:583 - [Consumer clientId=consumer-24, groupId=5136e92a-db5c-4e3c-87d6-ec527a9fe878] Resetting offset for partition stream9-0 to offset 63165.
2020-01-07 19:19:45 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3c1303b2-a431-4c0d-8fd5-c759de616ebb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:45 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:45 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:45 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:45 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-25, groupId=3c1303b2-a431-4c0d-8fd5-c759de616ebb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:45 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-25, groupId=3c1303b2-a431-4c0d-8fd5-c759de616ebb] Revoking previously assigned partitions []
2020-01-07 19:19:45 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-25, groupId=3c1303b2-a431-4c0d-8fd5-c759de616ebb] (Re-)joining group
2020-01-07 19:19:45 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-25, groupId=3c1303b2-a431-4c0d-8fd5-c759de616ebb] Successfully joined group with generation 1
2020-01-07 19:19:45 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-25, groupId=3c1303b2-a431-4c0d-8fd5-c759de616ebb] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:45 INFO  Fetcher:583 - [Consumer clientId=consumer-25, groupId=3c1303b2-a431-4c0d-8fd5-c759de616ebb] Resetting offset for partition stream9-0 to offset 63166.
2020-01-07 19:19:45 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ad1695c8-6241-43c2-bec0-2ddc5677d439
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:45 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:45 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:45 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:45 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-26, groupId=ad1695c8-6241-43c2-bec0-2ddc5677d439] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:45 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-26, groupId=ad1695c8-6241-43c2-bec0-2ddc5677d439] Revoking previously assigned partitions []
2020-01-07 19:19:45 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-26, groupId=ad1695c8-6241-43c2-bec0-2ddc5677d439] (Re-)joining group
2020-01-07 19:19:46 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-26, groupId=ad1695c8-6241-43c2-bec0-2ddc5677d439] Successfully joined group with generation 1
2020-01-07 19:19:46 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-26, groupId=ad1695c8-6241-43c2-bec0-2ddc5677d439] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:46 INFO  Fetcher:583 - [Consumer clientId=consumer-26, groupId=ad1695c8-6241-43c2-bec0-2ddc5677d439] Resetting offset for partition stream9-0 to offset 63167.
2020-01-07 19:19:46 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 21867c5c-c178-44ea-b71b-327c195c07ab
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:46 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:46 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:46 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:46 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-27, groupId=21867c5c-c178-44ea-b71b-327c195c07ab] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:46 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-27, groupId=21867c5c-c178-44ea-b71b-327c195c07ab] Revoking previously assigned partitions []
2020-01-07 19:19:46 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-27, groupId=21867c5c-c178-44ea-b71b-327c195c07ab] (Re-)joining group
2020-01-07 19:19:46 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-27, groupId=21867c5c-c178-44ea-b71b-327c195c07ab] Successfully joined group with generation 1
2020-01-07 19:19:46 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-27, groupId=21867c5c-c178-44ea-b71b-327c195c07ab] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:46 INFO  Fetcher:583 - [Consumer clientId=consumer-27, groupId=21867c5c-c178-44ea-b71b-327c195c07ab] Resetting offset for partition stream9-0 to offset 63168.
2020-01-07 19:19:46 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 354e7bc9-0786-4177-9fb8-228eef753a2c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:46 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:46 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:46 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:46 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-28, groupId=354e7bc9-0786-4177-9fb8-228eef753a2c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:46 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-28, groupId=354e7bc9-0786-4177-9fb8-228eef753a2c] Revoking previously assigned partitions []
2020-01-07 19:19:46 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-28, groupId=354e7bc9-0786-4177-9fb8-228eef753a2c] (Re-)joining group
2020-01-07 19:19:46 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-28, groupId=354e7bc9-0786-4177-9fb8-228eef753a2c] Successfully joined group with generation 1
2020-01-07 19:19:46 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-28, groupId=354e7bc9-0786-4177-9fb8-228eef753a2c] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:46 INFO  Fetcher:583 - [Consumer clientId=consumer-28, groupId=354e7bc9-0786-4177-9fb8-228eef753a2c] Resetting offset for partition stream9-0 to offset 63169.
2020-01-07 19:19:46 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5eb1c6d5-6bbf-42f9-96af-4b47392d1546
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:46 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:46 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:46 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:46 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-29, groupId=5eb1c6d5-6bbf-42f9-96af-4b47392d1546] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:46 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-29, groupId=5eb1c6d5-6bbf-42f9-96af-4b47392d1546] Revoking previously assigned partitions []
2020-01-07 19:19:46 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-29, groupId=5eb1c6d5-6bbf-42f9-96af-4b47392d1546] (Re-)joining group
2020-01-07 19:19:46 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-29, groupId=5eb1c6d5-6bbf-42f9-96af-4b47392d1546] Successfully joined group with generation 1
2020-01-07 19:19:46 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-29, groupId=5eb1c6d5-6bbf-42f9-96af-4b47392d1546] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:46 INFO  Fetcher:583 - [Consumer clientId=consumer-29, groupId=5eb1c6d5-6bbf-42f9-96af-4b47392d1546] Resetting offset for partition stream9-0 to offset 63170.
2020-01-07 19:19:46 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 87413af0-16f9-49de-8658-fa05888e04db
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:46 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:46 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:46 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:46 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-30, groupId=87413af0-16f9-49de-8658-fa05888e04db] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:46 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-30, groupId=87413af0-16f9-49de-8658-fa05888e04db] Revoking previously assigned partitions []
2020-01-07 19:19:46 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-30, groupId=87413af0-16f9-49de-8658-fa05888e04db] (Re-)joining group
2020-01-07 19:19:46 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-30, groupId=87413af0-16f9-49de-8658-fa05888e04db] Successfully joined group with generation 1
2020-01-07 19:19:46 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-30, groupId=87413af0-16f9-49de-8658-fa05888e04db] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:46 INFO  Fetcher:583 - [Consumer clientId=consumer-30, groupId=87413af0-16f9-49de-8658-fa05888e04db] Resetting offset for partition stream9-0 to offset 63171.
2020-01-07 19:19:46 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1e06942e-93a4-4862-984c-52b539731d18
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:46 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:46 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:46 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:46 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-31, groupId=1e06942e-93a4-4862-984c-52b539731d18] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:46 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-31, groupId=1e06942e-93a4-4862-984c-52b539731d18] Revoking previously assigned partitions []
2020-01-07 19:19:46 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-31, groupId=1e06942e-93a4-4862-984c-52b539731d18] (Re-)joining group
2020-01-07 19:19:46 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-31, groupId=1e06942e-93a4-4862-984c-52b539731d18] Successfully joined group with generation 1
2020-01-07 19:19:46 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-31, groupId=1e06942e-93a4-4862-984c-52b539731d18] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:46 INFO  Fetcher:583 - [Consumer clientId=consumer-31, groupId=1e06942e-93a4-4862-984c-52b539731d18] Resetting offset for partition stream9-0 to offset 63173.
2020-01-07 19:19:46 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7ace99a1-9a16-4f82-9423-e4899be00951
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:46 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:46 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:46 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:46 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-32, groupId=7ace99a1-9a16-4f82-9423-e4899be00951] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:46 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-32, groupId=7ace99a1-9a16-4f82-9423-e4899be00951] Revoking previously assigned partitions []
2020-01-07 19:19:46 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-32, groupId=7ace99a1-9a16-4f82-9423-e4899be00951] (Re-)joining group
2020-01-07 19:19:46 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-32, groupId=7ace99a1-9a16-4f82-9423-e4899be00951] Successfully joined group with generation 1
2020-01-07 19:19:46 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-32, groupId=7ace99a1-9a16-4f82-9423-e4899be00951] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:46 INFO  Fetcher:583 - [Consumer clientId=consumer-32, groupId=7ace99a1-9a16-4f82-9423-e4899be00951] Resetting offset for partition stream9-0 to offset 63174.
2020-01-07 19:19:47 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 71b2c0e0-3424-4bfb-9042-7ae0f16ad6c8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:47 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:47 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:47 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:47 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-33, groupId=71b2c0e0-3424-4bfb-9042-7ae0f16ad6c8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:47 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-33, groupId=71b2c0e0-3424-4bfb-9042-7ae0f16ad6c8] Revoking previously assigned partitions []
2020-01-07 19:19:47 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-33, groupId=71b2c0e0-3424-4bfb-9042-7ae0f16ad6c8] (Re-)joining group
2020-01-07 19:19:47 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-33, groupId=71b2c0e0-3424-4bfb-9042-7ae0f16ad6c8] Successfully joined group with generation 1
2020-01-07 19:19:47 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-33, groupId=71b2c0e0-3424-4bfb-9042-7ae0f16ad6c8] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:47 INFO  Fetcher:583 - [Consumer clientId=consumer-33, groupId=71b2c0e0-3424-4bfb-9042-7ae0f16ad6c8] Resetting offset for partition stream9-0 to offset 63175.
2020-01-07 19:19:47 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 564c1e75-109c-4c02-b815-d50f2122524c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:47 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:47 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:47 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:47 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-34, groupId=564c1e75-109c-4c02-b815-d50f2122524c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:47 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-34, groupId=564c1e75-109c-4c02-b815-d50f2122524c] Revoking previously assigned partitions []
2020-01-07 19:19:47 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-34, groupId=564c1e75-109c-4c02-b815-d50f2122524c] (Re-)joining group
2020-01-07 19:19:47 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-34, groupId=564c1e75-109c-4c02-b815-d50f2122524c] Successfully joined group with generation 1
2020-01-07 19:19:47 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-34, groupId=564c1e75-109c-4c02-b815-d50f2122524c] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:47 INFO  Fetcher:583 - [Consumer clientId=consumer-34, groupId=564c1e75-109c-4c02-b815-d50f2122524c] Resetting offset for partition stream9-0 to offset 63176.
2020-01-07 19:19:47 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 40badb43-17b6-4e0d-ba0a-e5cbfb137f8c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:47 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:47 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:47 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:47 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-35, groupId=40badb43-17b6-4e0d-ba0a-e5cbfb137f8c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:47 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-35, groupId=40badb43-17b6-4e0d-ba0a-e5cbfb137f8c] Revoking previously assigned partitions []
2020-01-07 19:19:47 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-35, groupId=40badb43-17b6-4e0d-ba0a-e5cbfb137f8c] (Re-)joining group
2020-01-07 19:19:47 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-35, groupId=40badb43-17b6-4e0d-ba0a-e5cbfb137f8c] Successfully joined group with generation 1
2020-01-07 19:19:47 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-35, groupId=40badb43-17b6-4e0d-ba0a-e5cbfb137f8c] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:47 INFO  Fetcher:583 - [Consumer clientId=consumer-35, groupId=40badb43-17b6-4e0d-ba0a-e5cbfb137f8c] Resetting offset for partition stream9-0 to offset 63177.
2020-01-07 19:19:47 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2e49c53f-bdf4-4cbb-b78c-f8edc78a97df
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:47 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:47 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:47 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:47 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-36, groupId=2e49c53f-bdf4-4cbb-b78c-f8edc78a97df] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:47 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-36, groupId=2e49c53f-bdf4-4cbb-b78c-f8edc78a97df] Revoking previously assigned partitions []
2020-01-07 19:19:47 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-36, groupId=2e49c53f-bdf4-4cbb-b78c-f8edc78a97df] (Re-)joining group
2020-01-07 19:19:47 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-36, groupId=2e49c53f-bdf4-4cbb-b78c-f8edc78a97df] Successfully joined group with generation 1
2020-01-07 19:19:47 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-36, groupId=2e49c53f-bdf4-4cbb-b78c-f8edc78a97df] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:47 INFO  Fetcher:583 - [Consumer clientId=consumer-36, groupId=2e49c53f-bdf4-4cbb-b78c-f8edc78a97df] Resetting offset for partition stream9-0 to offset 63178.
2020-01-07 19:19:47 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dd6e454e-187e-42a9-b878-f4a3ae08cfd1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:47 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:47 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:47 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:47 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-37, groupId=dd6e454e-187e-42a9-b878-f4a3ae08cfd1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:47 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-37, groupId=dd6e454e-187e-42a9-b878-f4a3ae08cfd1] Revoking previously assigned partitions []
2020-01-07 19:19:47 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-37, groupId=dd6e454e-187e-42a9-b878-f4a3ae08cfd1] (Re-)joining group
2020-01-07 19:19:48 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-37, groupId=dd6e454e-187e-42a9-b878-f4a3ae08cfd1] Successfully joined group with generation 1
2020-01-07 19:19:48 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-37, groupId=dd6e454e-187e-42a9-b878-f4a3ae08cfd1] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:48 INFO  Fetcher:583 - [Consumer clientId=consumer-37, groupId=dd6e454e-187e-42a9-b878-f4a3ae08cfd1] Resetting offset for partition stream9-0 to offset 63179.
2020-01-07 19:19:48 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b3a54eb0-0f48-47c7-9ad8-47cc2d53f10a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:48 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:48 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:48 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:48 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-38, groupId=b3a54eb0-0f48-47c7-9ad8-47cc2d53f10a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:48 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-38, groupId=b3a54eb0-0f48-47c7-9ad8-47cc2d53f10a] Revoking previously assigned partitions []
2020-01-07 19:19:48 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-38, groupId=b3a54eb0-0f48-47c7-9ad8-47cc2d53f10a] (Re-)joining group
2020-01-07 19:19:48 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-38, groupId=b3a54eb0-0f48-47c7-9ad8-47cc2d53f10a] Successfully joined group with generation 1
2020-01-07 19:19:48 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-38, groupId=b3a54eb0-0f48-47c7-9ad8-47cc2d53f10a] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:48 INFO  Fetcher:583 - [Consumer clientId=consumer-38, groupId=b3a54eb0-0f48-47c7-9ad8-47cc2d53f10a] Resetting offset for partition stream9-0 to offset 63180.
2020-01-07 19:19:48 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = af5954f8-e79b-4d67-bb56-9cd1ce93ccc8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:48 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:48 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:48 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:48 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-39, groupId=af5954f8-e79b-4d67-bb56-9cd1ce93ccc8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:48 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-39, groupId=af5954f8-e79b-4d67-bb56-9cd1ce93ccc8] Revoking previously assigned partitions []
2020-01-07 19:19:48 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-39, groupId=af5954f8-e79b-4d67-bb56-9cd1ce93ccc8] (Re-)joining group
2020-01-07 19:19:48 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-39, groupId=af5954f8-e79b-4d67-bb56-9cd1ce93ccc8] Successfully joined group with generation 1
2020-01-07 19:19:48 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-39, groupId=af5954f8-e79b-4d67-bb56-9cd1ce93ccc8] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:48 INFO  Fetcher:583 - [Consumer clientId=consumer-39, groupId=af5954f8-e79b-4d67-bb56-9cd1ce93ccc8] Resetting offset for partition stream9-0 to offset 63181.
2020-01-07 19:19:48 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6f67eaac-00b8-49c9-aa66-5b970a2328b1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:48 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:48 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:48 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:48 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-40, groupId=6f67eaac-00b8-49c9-aa66-5b970a2328b1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:48 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-40, groupId=6f67eaac-00b8-49c9-aa66-5b970a2328b1] Revoking previously assigned partitions []
2020-01-07 19:19:48 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-40, groupId=6f67eaac-00b8-49c9-aa66-5b970a2328b1] (Re-)joining group
2020-01-07 19:19:48 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-40, groupId=6f67eaac-00b8-49c9-aa66-5b970a2328b1] Successfully joined group with generation 1
2020-01-07 19:19:48 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-40, groupId=6f67eaac-00b8-49c9-aa66-5b970a2328b1] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:48 INFO  Fetcher:583 - [Consumer clientId=consumer-40, groupId=6f67eaac-00b8-49c9-aa66-5b970a2328b1] Resetting offset for partition stream9-0 to offset 63182.
2020-01-07 19:19:48 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5d2b0e70-9779-4891-b685-7a51a42790e5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:48 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:48 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:48 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:48 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-41, groupId=5d2b0e70-9779-4891-b685-7a51a42790e5] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:48 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-41, groupId=5d2b0e70-9779-4891-b685-7a51a42790e5] Revoking previously assigned partitions []
2020-01-07 19:19:48 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-41, groupId=5d2b0e70-9779-4891-b685-7a51a42790e5] (Re-)joining group
2020-01-07 19:19:48 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-41, groupId=5d2b0e70-9779-4891-b685-7a51a42790e5] Successfully joined group with generation 1
2020-01-07 19:19:48 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-41, groupId=5d2b0e70-9779-4891-b685-7a51a42790e5] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:48 INFO  Fetcher:583 - [Consumer clientId=consumer-41, groupId=5d2b0e70-9779-4891-b685-7a51a42790e5] Resetting offset for partition stream9-0 to offset 63183.
2020-01-07 19:19:48 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = af75223b-adab-439e-b7a0-22d86f256299
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:48 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:48 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:48 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:48 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-42, groupId=af75223b-adab-439e-b7a0-22d86f256299] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:48 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-42, groupId=af75223b-adab-439e-b7a0-22d86f256299] Revoking previously assigned partitions []
2020-01-07 19:19:48 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-42, groupId=af75223b-adab-439e-b7a0-22d86f256299] (Re-)joining group
2020-01-07 19:19:48 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-42, groupId=af75223b-adab-439e-b7a0-22d86f256299] Successfully joined group with generation 1
2020-01-07 19:19:48 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-42, groupId=af75223b-adab-439e-b7a0-22d86f256299] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:48 INFO  Fetcher:583 - [Consumer clientId=consumer-42, groupId=af75223b-adab-439e-b7a0-22d86f256299] Resetting offset for partition stream9-0 to offset 63184.
2020-01-07 19:19:48 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 72a3bd59-7b0c-4180-bb34-4a1eb803f34f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:48 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:48 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:48 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:48 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-43, groupId=72a3bd59-7b0c-4180-bb34-4a1eb803f34f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:48 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-43, groupId=72a3bd59-7b0c-4180-bb34-4a1eb803f34f] Revoking previously assigned partitions []
2020-01-07 19:19:48 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-43, groupId=72a3bd59-7b0c-4180-bb34-4a1eb803f34f] (Re-)joining group
2020-01-07 19:19:48 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-43, groupId=72a3bd59-7b0c-4180-bb34-4a1eb803f34f] Successfully joined group with generation 1
2020-01-07 19:19:48 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-43, groupId=72a3bd59-7b0c-4180-bb34-4a1eb803f34f] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:48 INFO  Fetcher:583 - [Consumer clientId=consumer-43, groupId=72a3bd59-7b0c-4180-bb34-4a1eb803f34f] Resetting offset for partition stream9-0 to offset 63185.
2020-01-07 19:19:48 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d52b74d8-8e92-42aa-80a5-f15cc21eb7cb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:48 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:48 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:48 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:48 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-44, groupId=d52b74d8-8e92-42aa-80a5-f15cc21eb7cb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:48 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-44, groupId=d52b74d8-8e92-42aa-80a5-f15cc21eb7cb] Revoking previously assigned partitions []
2020-01-07 19:19:48 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-44, groupId=d52b74d8-8e92-42aa-80a5-f15cc21eb7cb] (Re-)joining group
2020-01-07 19:19:48 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-44, groupId=d52b74d8-8e92-42aa-80a5-f15cc21eb7cb] Successfully joined group with generation 1
2020-01-07 19:19:48 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-44, groupId=d52b74d8-8e92-42aa-80a5-f15cc21eb7cb] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:48 INFO  Fetcher:583 - [Consumer clientId=consumer-44, groupId=d52b74d8-8e92-42aa-80a5-f15cc21eb7cb] Resetting offset for partition stream9-0 to offset 63186.
2020-01-07 19:19:48 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e69342d9-c1d1-4b45-8477-1f798fa781c7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:48 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:48 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:48 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:48 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-45, groupId=e69342d9-c1d1-4b45-8477-1f798fa781c7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:48 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-45, groupId=e69342d9-c1d1-4b45-8477-1f798fa781c7] Revoking previously assigned partitions []
2020-01-07 19:19:48 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-45, groupId=e69342d9-c1d1-4b45-8477-1f798fa781c7] (Re-)joining group
2020-01-07 19:19:48 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-45, groupId=e69342d9-c1d1-4b45-8477-1f798fa781c7] Successfully joined group with generation 1
2020-01-07 19:19:48 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-45, groupId=e69342d9-c1d1-4b45-8477-1f798fa781c7] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:48 INFO  Fetcher:583 - [Consumer clientId=consumer-45, groupId=e69342d9-c1d1-4b45-8477-1f798fa781c7] Resetting offset for partition stream9-0 to offset 63187.
2020-01-07 19:19:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8beffb1d-aa56-4d03-8fe5-498d5c30f45c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:49 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-46, groupId=8beffb1d-aa56-4d03-8fe5-498d5c30f45c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-46, groupId=8beffb1d-aa56-4d03-8fe5-498d5c30f45c] Revoking previously assigned partitions []
2020-01-07 19:19:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-46, groupId=8beffb1d-aa56-4d03-8fe5-498d5c30f45c] (Re-)joining group
2020-01-07 19:19:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-46, groupId=8beffb1d-aa56-4d03-8fe5-498d5c30f45c] Successfully joined group with generation 1
2020-01-07 19:19:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-46, groupId=8beffb1d-aa56-4d03-8fe5-498d5c30f45c] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:49 INFO  Fetcher:583 - [Consumer clientId=consumer-46, groupId=8beffb1d-aa56-4d03-8fe5-498d5c30f45c] Resetting offset for partition stream9-0 to offset 63188.
2020-01-07 19:19:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c3d57777-8b5a-42a8-b577-856ec69a3bf0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:49 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-47, groupId=c3d57777-8b5a-42a8-b577-856ec69a3bf0] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-47, groupId=c3d57777-8b5a-42a8-b577-856ec69a3bf0] Revoking previously assigned partitions []
2020-01-07 19:19:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-47, groupId=c3d57777-8b5a-42a8-b577-856ec69a3bf0] (Re-)joining group
2020-01-07 19:19:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-47, groupId=c3d57777-8b5a-42a8-b577-856ec69a3bf0] Successfully joined group with generation 1
2020-01-07 19:19:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-47, groupId=c3d57777-8b5a-42a8-b577-856ec69a3bf0] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:49 INFO  Fetcher:583 - [Consumer clientId=consumer-47, groupId=c3d57777-8b5a-42a8-b577-856ec69a3bf0] Resetting offset for partition stream9-0 to offset 63189.
2020-01-07 19:19:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 552b4031-b43f-4764-99c8-9154c0cc81c2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:49 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-48, groupId=552b4031-b43f-4764-99c8-9154c0cc81c2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-48, groupId=552b4031-b43f-4764-99c8-9154c0cc81c2] Revoking previously assigned partitions []
2020-01-07 19:19:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-48, groupId=552b4031-b43f-4764-99c8-9154c0cc81c2] (Re-)joining group
2020-01-07 19:19:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-48, groupId=552b4031-b43f-4764-99c8-9154c0cc81c2] Successfully joined group with generation 1
2020-01-07 19:19:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-48, groupId=552b4031-b43f-4764-99c8-9154c0cc81c2] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:49 INFO  Fetcher:583 - [Consumer clientId=consumer-48, groupId=552b4031-b43f-4764-99c8-9154c0cc81c2] Resetting offset for partition stream9-0 to offset 63190.
2020-01-07 19:19:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ad90e14e-a8bb-46f5-8a47-8614cbf09edb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:49 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-49, groupId=ad90e14e-a8bb-46f5-8a47-8614cbf09edb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-49, groupId=ad90e14e-a8bb-46f5-8a47-8614cbf09edb] Revoking previously assigned partitions []
2020-01-07 19:19:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-49, groupId=ad90e14e-a8bb-46f5-8a47-8614cbf09edb] (Re-)joining group
2020-01-07 19:19:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-49, groupId=ad90e14e-a8bb-46f5-8a47-8614cbf09edb] Successfully joined group with generation 1
2020-01-07 19:19:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-49, groupId=ad90e14e-a8bb-46f5-8a47-8614cbf09edb] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:49 INFO  Fetcher:583 - [Consumer clientId=consumer-49, groupId=ad90e14e-a8bb-46f5-8a47-8614cbf09edb] Resetting offset for partition stream9-0 to offset 63191.
2020-01-07 19:19:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 58ab25ac-5c90-4743-ac69-113f65d9cf4c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:49 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-50, groupId=58ab25ac-5c90-4743-ac69-113f65d9cf4c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-50, groupId=58ab25ac-5c90-4743-ac69-113f65d9cf4c] Revoking previously assigned partitions []
2020-01-07 19:19:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-50, groupId=58ab25ac-5c90-4743-ac69-113f65d9cf4c] (Re-)joining group
2020-01-07 19:19:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-50, groupId=58ab25ac-5c90-4743-ac69-113f65d9cf4c] Successfully joined group with generation 1
2020-01-07 19:19:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-50, groupId=58ab25ac-5c90-4743-ac69-113f65d9cf4c] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:49 INFO  Fetcher:583 - [Consumer clientId=consumer-50, groupId=58ab25ac-5c90-4743-ac69-113f65d9cf4c] Resetting offset for partition stream9-0 to offset 63192.
2020-01-07 19:19:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3df7df3d-30cb-4632-8511-17de3a6ac0d9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:49 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-51, groupId=3df7df3d-30cb-4632-8511-17de3a6ac0d9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-51, groupId=3df7df3d-30cb-4632-8511-17de3a6ac0d9] Revoking previously assigned partitions []
2020-01-07 19:19:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-51, groupId=3df7df3d-30cb-4632-8511-17de3a6ac0d9] (Re-)joining group
2020-01-07 19:19:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-51, groupId=3df7df3d-30cb-4632-8511-17de3a6ac0d9] Successfully joined group with generation 1
2020-01-07 19:19:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-51, groupId=3df7df3d-30cb-4632-8511-17de3a6ac0d9] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:49 INFO  Fetcher:583 - [Consumer clientId=consumer-51, groupId=3df7df3d-30cb-4632-8511-17de3a6ac0d9] Resetting offset for partition stream9-0 to offset 63193.
2020-01-07 19:19:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f9c29c3c-ef76-41ca-a2dc-0699d9729e01
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:49 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-52, groupId=f9c29c3c-ef76-41ca-a2dc-0699d9729e01] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-52, groupId=f9c29c3c-ef76-41ca-a2dc-0699d9729e01] Revoking previously assigned partitions []
2020-01-07 19:19:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-52, groupId=f9c29c3c-ef76-41ca-a2dc-0699d9729e01] (Re-)joining group
2020-01-07 19:19:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-52, groupId=f9c29c3c-ef76-41ca-a2dc-0699d9729e01] Successfully joined group with generation 1
2020-01-07 19:19:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-52, groupId=f9c29c3c-ef76-41ca-a2dc-0699d9729e01] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:49 INFO  Fetcher:583 - [Consumer clientId=consumer-52, groupId=f9c29c3c-ef76-41ca-a2dc-0699d9729e01] Resetting offset for partition stream9-0 to offset 63194.
2020-01-07 19:19:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f7703585-8cac-40a0-9333-a6c5b9e3abc3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-53, groupId=f7703585-8cac-40a0-9333-a6c5b9e3abc3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-53, groupId=f7703585-8cac-40a0-9333-a6c5b9e3abc3] Revoking previously assigned partitions []
2020-01-07 19:19:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-53, groupId=f7703585-8cac-40a0-9333-a6c5b9e3abc3] (Re-)joining group
2020-01-07 19:19:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-53, groupId=f7703585-8cac-40a0-9333-a6c5b9e3abc3] Successfully joined group with generation 1
2020-01-07 19:19:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-53, groupId=f7703585-8cac-40a0-9333-a6c5b9e3abc3] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:50 INFO  Fetcher:583 - [Consumer clientId=consumer-53, groupId=f7703585-8cac-40a0-9333-a6c5b9e3abc3] Resetting offset for partition stream9-0 to offset 63195.
2020-01-07 19:19:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = baec04fc-179f-4a3c-8379-d512a8c3dea5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-54, groupId=baec04fc-179f-4a3c-8379-d512a8c3dea5] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-54, groupId=baec04fc-179f-4a3c-8379-d512a8c3dea5] Revoking previously assigned partitions []
2020-01-07 19:19:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-54, groupId=baec04fc-179f-4a3c-8379-d512a8c3dea5] (Re-)joining group
2020-01-07 19:19:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-54, groupId=baec04fc-179f-4a3c-8379-d512a8c3dea5] Successfully joined group with generation 1
2020-01-07 19:19:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-54, groupId=baec04fc-179f-4a3c-8379-d512a8c3dea5] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:50 INFO  Fetcher:583 - [Consumer clientId=consumer-54, groupId=baec04fc-179f-4a3c-8379-d512a8c3dea5] Resetting offset for partition stream9-0 to offset 63196.
2020-01-07 19:19:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a0a6119b-0bdb-48c2-ac23-d903b7448301
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-55, groupId=a0a6119b-0bdb-48c2-ac23-d903b7448301] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-55, groupId=a0a6119b-0bdb-48c2-ac23-d903b7448301] Revoking previously assigned partitions []
2020-01-07 19:19:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-55, groupId=a0a6119b-0bdb-48c2-ac23-d903b7448301] (Re-)joining group
2020-01-07 19:19:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-55, groupId=a0a6119b-0bdb-48c2-ac23-d903b7448301] Successfully joined group with generation 1
2020-01-07 19:19:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-55, groupId=a0a6119b-0bdb-48c2-ac23-d903b7448301] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:50 INFO  Fetcher:583 - [Consumer clientId=consumer-55, groupId=a0a6119b-0bdb-48c2-ac23-d903b7448301] Resetting offset for partition stream9-0 to offset 63197.
2020-01-07 19:19:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c625cf20-c84d-47d3-bfca-7ad7537ea289
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-56, groupId=c625cf20-c84d-47d3-bfca-7ad7537ea289] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-56, groupId=c625cf20-c84d-47d3-bfca-7ad7537ea289] Revoking previously assigned partitions []
2020-01-07 19:19:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-56, groupId=c625cf20-c84d-47d3-bfca-7ad7537ea289] (Re-)joining group
2020-01-07 19:19:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-56, groupId=c625cf20-c84d-47d3-bfca-7ad7537ea289] Successfully joined group with generation 1
2020-01-07 19:19:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-56, groupId=c625cf20-c84d-47d3-bfca-7ad7537ea289] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:50 INFO  Fetcher:583 - [Consumer clientId=consumer-56, groupId=c625cf20-c84d-47d3-bfca-7ad7537ea289] Resetting offset for partition stream9-0 to offset 63198.
2020-01-07 19:19:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e943e726-65cb-4e57-b1ac-98c198d846c9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-57, groupId=e943e726-65cb-4e57-b1ac-98c198d846c9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-57, groupId=e943e726-65cb-4e57-b1ac-98c198d846c9] Revoking previously assigned partitions []
2020-01-07 19:19:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-57, groupId=e943e726-65cb-4e57-b1ac-98c198d846c9] (Re-)joining group
2020-01-07 19:19:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-57, groupId=e943e726-65cb-4e57-b1ac-98c198d846c9] Successfully joined group with generation 1
2020-01-07 19:19:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-57, groupId=e943e726-65cb-4e57-b1ac-98c198d846c9] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:50 INFO  Fetcher:583 - [Consumer clientId=consumer-57, groupId=e943e726-65cb-4e57-b1ac-98c198d846c9] Resetting offset for partition stream9-0 to offset 63199.
2020-01-07 19:19:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = df26816a-1b50-4909-934d-fd3d62e659b9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-58, groupId=df26816a-1b50-4909-934d-fd3d62e659b9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-58, groupId=df26816a-1b50-4909-934d-fd3d62e659b9] Revoking previously assigned partitions []
2020-01-07 19:19:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-58, groupId=df26816a-1b50-4909-934d-fd3d62e659b9] (Re-)joining group
2020-01-07 19:19:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-58, groupId=df26816a-1b50-4909-934d-fd3d62e659b9] Successfully joined group with generation 1
2020-01-07 19:19:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-58, groupId=df26816a-1b50-4909-934d-fd3d62e659b9] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:50 INFO  Fetcher:583 - [Consumer clientId=consumer-58, groupId=df26816a-1b50-4909-934d-fd3d62e659b9] Resetting offset for partition stream9-0 to offset 63200.
2020-01-07 19:19:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1832b1ca-0024-4a73-8a40-f03a53ec5dc8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-59, groupId=1832b1ca-0024-4a73-8a40-f03a53ec5dc8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-59, groupId=1832b1ca-0024-4a73-8a40-f03a53ec5dc8] Revoking previously assigned partitions []
2020-01-07 19:19:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-59, groupId=1832b1ca-0024-4a73-8a40-f03a53ec5dc8] (Re-)joining group
2020-01-07 19:19:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-59, groupId=1832b1ca-0024-4a73-8a40-f03a53ec5dc8] Successfully joined group with generation 1
2020-01-07 19:19:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-59, groupId=1832b1ca-0024-4a73-8a40-f03a53ec5dc8] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:50 INFO  Fetcher:583 - [Consumer clientId=consumer-59, groupId=1832b1ca-0024-4a73-8a40-f03a53ec5dc8] Resetting offset for partition stream9-0 to offset 63201.
2020-01-07 19:19:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 92dd86c2-53f4-4a14-8b84-dee81d3f5ab3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-60, groupId=92dd86c2-53f4-4a14-8b84-dee81d3f5ab3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-60, groupId=92dd86c2-53f4-4a14-8b84-dee81d3f5ab3] Revoking previously assigned partitions []
2020-01-07 19:19:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-60, groupId=92dd86c2-53f4-4a14-8b84-dee81d3f5ab3] (Re-)joining group
2020-01-07 19:19:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-60, groupId=92dd86c2-53f4-4a14-8b84-dee81d3f5ab3] Successfully joined group with generation 1
2020-01-07 19:19:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-60, groupId=92dd86c2-53f4-4a14-8b84-dee81d3f5ab3] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:50 INFO  Fetcher:583 - [Consumer clientId=consumer-60, groupId=92dd86c2-53f4-4a14-8b84-dee81d3f5ab3] Resetting offset for partition stream9-0 to offset 63202.
2020-01-07 19:19:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 88c4593f-cec8-4481-8f00-fe6ac18e910b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-61, groupId=88c4593f-cec8-4481-8f00-fe6ac18e910b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-61, groupId=88c4593f-cec8-4481-8f00-fe6ac18e910b] Revoking previously assigned partitions []
2020-01-07 19:19:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-61, groupId=88c4593f-cec8-4481-8f00-fe6ac18e910b] (Re-)joining group
2020-01-07 19:19:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-61, groupId=88c4593f-cec8-4481-8f00-fe6ac18e910b] Successfully joined group with generation 1
2020-01-07 19:19:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-61, groupId=88c4593f-cec8-4481-8f00-fe6ac18e910b] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:50 INFO  Fetcher:583 - [Consumer clientId=consumer-61, groupId=88c4593f-cec8-4481-8f00-fe6ac18e910b] Resetting offset for partition stream9-0 to offset 63203.
2020-01-07 19:19:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 84834b40-b79d-4f19-bd4c-c539e7d0b823
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-62, groupId=84834b40-b79d-4f19-bd4c-c539e7d0b823] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-62, groupId=84834b40-b79d-4f19-bd4c-c539e7d0b823] Revoking previously assigned partitions []
2020-01-07 19:19:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-62, groupId=84834b40-b79d-4f19-bd4c-c539e7d0b823] (Re-)joining group
2020-01-07 19:19:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-62, groupId=84834b40-b79d-4f19-bd4c-c539e7d0b823] Successfully joined group with generation 1
2020-01-07 19:19:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-62, groupId=84834b40-b79d-4f19-bd4c-c539e7d0b823] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:50 INFO  Fetcher:583 - [Consumer clientId=consumer-62, groupId=84834b40-b79d-4f19-bd4c-c539e7d0b823] Resetting offset for partition stream9-0 to offset 63204.
2020-01-07 19:19:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d38c7b18-c98b-46cc-9234-f76a2bd4cabd
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-63, groupId=d38c7b18-c98b-46cc-9234-f76a2bd4cabd] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-63, groupId=d38c7b18-c98b-46cc-9234-f76a2bd4cabd] Revoking previously assigned partitions []
2020-01-07 19:19:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-63, groupId=d38c7b18-c98b-46cc-9234-f76a2bd4cabd] (Re-)joining group
2020-01-07 19:19:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-63, groupId=d38c7b18-c98b-46cc-9234-f76a2bd4cabd] Successfully joined group with generation 1
2020-01-07 19:19:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-63, groupId=d38c7b18-c98b-46cc-9234-f76a2bd4cabd] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:50 INFO  Fetcher:583 - [Consumer clientId=consumer-63, groupId=d38c7b18-c98b-46cc-9234-f76a2bd4cabd] Resetting offset for partition stream9-0 to offset 63205.
2020-01-07 19:19:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dab04dd6-4444-4409-afd8-336a223bede7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-64, groupId=dab04dd6-4444-4409-afd8-336a223bede7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-64, groupId=dab04dd6-4444-4409-afd8-336a223bede7] Revoking previously assigned partitions []
2020-01-07 19:19:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-64, groupId=dab04dd6-4444-4409-afd8-336a223bede7] (Re-)joining group
2020-01-07 19:19:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-64, groupId=dab04dd6-4444-4409-afd8-336a223bede7] Successfully joined group with generation 1
2020-01-07 19:19:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-64, groupId=dab04dd6-4444-4409-afd8-336a223bede7] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:50 INFO  Fetcher:583 - [Consumer clientId=consumer-64, groupId=dab04dd6-4444-4409-afd8-336a223bede7] Resetting offset for partition stream9-0 to offset 63206.
2020-01-07 19:19:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 24600a73-4edd-4fd2-9f0e-6c27b8aa0cf9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-65, groupId=24600a73-4edd-4fd2-9f0e-6c27b8aa0cf9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-65, groupId=24600a73-4edd-4fd2-9f0e-6c27b8aa0cf9] Revoking previously assigned partitions []
2020-01-07 19:19:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-65, groupId=24600a73-4edd-4fd2-9f0e-6c27b8aa0cf9] (Re-)joining group
2020-01-07 19:19:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-65, groupId=24600a73-4edd-4fd2-9f0e-6c27b8aa0cf9] Successfully joined group with generation 1
2020-01-07 19:19:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-65, groupId=24600a73-4edd-4fd2-9f0e-6c27b8aa0cf9] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:51 INFO  Fetcher:583 - [Consumer clientId=consumer-65, groupId=24600a73-4edd-4fd2-9f0e-6c27b8aa0cf9] Resetting offset for partition stream9-0 to offset 63207.
2020-01-07 19:19:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 906988a2-e015-4cc2-9c8d-78d40699e6a6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-66, groupId=906988a2-e015-4cc2-9c8d-78d40699e6a6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-66, groupId=906988a2-e015-4cc2-9c8d-78d40699e6a6] Revoking previously assigned partitions []
2020-01-07 19:19:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-66, groupId=906988a2-e015-4cc2-9c8d-78d40699e6a6] (Re-)joining group
2020-01-07 19:19:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-66, groupId=906988a2-e015-4cc2-9c8d-78d40699e6a6] Successfully joined group with generation 1
2020-01-07 19:19:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-66, groupId=906988a2-e015-4cc2-9c8d-78d40699e6a6] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:51 INFO  Fetcher:583 - [Consumer clientId=consumer-66, groupId=906988a2-e015-4cc2-9c8d-78d40699e6a6] Resetting offset for partition stream9-0 to offset 63208.
2020-01-07 19:19:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56bb9455-92eb-44f3-888a-40d58b298581
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-67, groupId=56bb9455-92eb-44f3-888a-40d58b298581] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-67, groupId=56bb9455-92eb-44f3-888a-40d58b298581] Revoking previously assigned partitions []
2020-01-07 19:19:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-67, groupId=56bb9455-92eb-44f3-888a-40d58b298581] (Re-)joining group
2020-01-07 19:19:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-67, groupId=56bb9455-92eb-44f3-888a-40d58b298581] Successfully joined group with generation 1
2020-01-07 19:19:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-67, groupId=56bb9455-92eb-44f3-888a-40d58b298581] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:51 INFO  Fetcher:583 - [Consumer clientId=consumer-67, groupId=56bb9455-92eb-44f3-888a-40d58b298581] Resetting offset for partition stream9-0 to offset 63209.
2020-01-07 19:19:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = eb2b1b55-93df-47bd-86cd-54073f9b91d7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-68, groupId=eb2b1b55-93df-47bd-86cd-54073f9b91d7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-68, groupId=eb2b1b55-93df-47bd-86cd-54073f9b91d7] Revoking previously assigned partitions []
2020-01-07 19:19:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-68, groupId=eb2b1b55-93df-47bd-86cd-54073f9b91d7] (Re-)joining group
2020-01-07 19:19:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-68, groupId=eb2b1b55-93df-47bd-86cd-54073f9b91d7] Successfully joined group with generation 1
2020-01-07 19:19:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-68, groupId=eb2b1b55-93df-47bd-86cd-54073f9b91d7] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:51 INFO  Fetcher:583 - [Consumer clientId=consumer-68, groupId=eb2b1b55-93df-47bd-86cd-54073f9b91d7] Resetting offset for partition stream9-0 to offset 63210.
2020-01-07 19:19:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b0958465-eef7-45e2-8730-2390e1abea78
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-69, groupId=b0958465-eef7-45e2-8730-2390e1abea78] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-69, groupId=b0958465-eef7-45e2-8730-2390e1abea78] Revoking previously assigned partitions []
2020-01-07 19:19:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-69, groupId=b0958465-eef7-45e2-8730-2390e1abea78] (Re-)joining group
2020-01-07 19:19:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-69, groupId=b0958465-eef7-45e2-8730-2390e1abea78] Successfully joined group with generation 1
2020-01-07 19:19:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-69, groupId=b0958465-eef7-45e2-8730-2390e1abea78] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:51 INFO  Fetcher:583 - [Consumer clientId=consumer-69, groupId=b0958465-eef7-45e2-8730-2390e1abea78] Resetting offset for partition stream9-0 to offset 63211.
2020-01-07 19:19:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7dc125f9-ee95-48ae-8f6f-77615e5fed98
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-70, groupId=7dc125f9-ee95-48ae-8f6f-77615e5fed98] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-70, groupId=7dc125f9-ee95-48ae-8f6f-77615e5fed98] Revoking previously assigned partitions []
2020-01-07 19:19:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-70, groupId=7dc125f9-ee95-48ae-8f6f-77615e5fed98] (Re-)joining group
2020-01-07 19:19:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-70, groupId=7dc125f9-ee95-48ae-8f6f-77615e5fed98] Successfully joined group with generation 1
2020-01-07 19:19:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-70, groupId=7dc125f9-ee95-48ae-8f6f-77615e5fed98] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:51 INFO  Fetcher:583 - [Consumer clientId=consumer-70, groupId=7dc125f9-ee95-48ae-8f6f-77615e5fed98] Resetting offset for partition stream9-0 to offset 63212.
2020-01-07 19:19:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 37c0b579-956b-4358-9fbe-fbd08da0c1b5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-71, groupId=37c0b579-956b-4358-9fbe-fbd08da0c1b5] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-71, groupId=37c0b579-956b-4358-9fbe-fbd08da0c1b5] Revoking previously assigned partitions []
2020-01-07 19:19:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-71, groupId=37c0b579-956b-4358-9fbe-fbd08da0c1b5] (Re-)joining group
2020-01-07 19:19:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-71, groupId=37c0b579-956b-4358-9fbe-fbd08da0c1b5] Successfully joined group with generation 1
2020-01-07 19:19:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-71, groupId=37c0b579-956b-4358-9fbe-fbd08da0c1b5] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:51 INFO  Fetcher:583 - [Consumer clientId=consumer-71, groupId=37c0b579-956b-4358-9fbe-fbd08da0c1b5] Resetting offset for partition stream9-0 to offset 63213.
2020-01-07 19:19:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9023e090-ece7-4fa9-b4e6-c7566e1810f5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-72, groupId=9023e090-ece7-4fa9-b4e6-c7566e1810f5] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-72, groupId=9023e090-ece7-4fa9-b4e6-c7566e1810f5] Revoking previously assigned partitions []
2020-01-07 19:19:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-72, groupId=9023e090-ece7-4fa9-b4e6-c7566e1810f5] (Re-)joining group
2020-01-07 19:19:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-72, groupId=9023e090-ece7-4fa9-b4e6-c7566e1810f5] Successfully joined group with generation 1
2020-01-07 19:19:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-72, groupId=9023e090-ece7-4fa9-b4e6-c7566e1810f5] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:51 INFO  Fetcher:583 - [Consumer clientId=consumer-72, groupId=9023e090-ece7-4fa9-b4e6-c7566e1810f5] Resetting offset for partition stream9-0 to offset 63214.
2020-01-07 19:19:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 68622ced-a671-4199-921a-d43a63885ab3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-73, groupId=68622ced-a671-4199-921a-d43a63885ab3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-73, groupId=68622ced-a671-4199-921a-d43a63885ab3] Revoking previously assigned partitions []
2020-01-07 19:19:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-73, groupId=68622ced-a671-4199-921a-d43a63885ab3] (Re-)joining group
2020-01-07 19:19:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-73, groupId=68622ced-a671-4199-921a-d43a63885ab3] Successfully joined group with generation 1
2020-01-07 19:19:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-73, groupId=68622ced-a671-4199-921a-d43a63885ab3] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:51 INFO  Fetcher:583 - [Consumer clientId=consumer-73, groupId=68622ced-a671-4199-921a-d43a63885ab3] Resetting offset for partition stream9-0 to offset 63215.
2020-01-07 19:19:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9335c865-f99d-4d52-a70b-b33043027281
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-74, groupId=9335c865-f99d-4d52-a70b-b33043027281] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-74, groupId=9335c865-f99d-4d52-a70b-b33043027281] Revoking previously assigned partitions []
2020-01-07 19:19:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-74, groupId=9335c865-f99d-4d52-a70b-b33043027281] (Re-)joining group
2020-01-07 19:19:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-74, groupId=9335c865-f99d-4d52-a70b-b33043027281] Successfully joined group with generation 1
2020-01-07 19:19:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-74, groupId=9335c865-f99d-4d52-a70b-b33043027281] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:51 INFO  Fetcher:583 - [Consumer clientId=consumer-74, groupId=9335c865-f99d-4d52-a70b-b33043027281] Resetting offset for partition stream9-0 to offset 63216.
2020-01-07 19:19:52 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 353d1cda-bc4d-4e53-bb96-855f4dbe17b9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:52 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:52 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:52 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:52 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-75, groupId=353d1cda-bc4d-4e53-bb96-855f4dbe17b9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:52 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-75, groupId=353d1cda-bc4d-4e53-bb96-855f4dbe17b9] Revoking previously assigned partitions []
2020-01-07 19:19:52 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-75, groupId=353d1cda-bc4d-4e53-bb96-855f4dbe17b9] (Re-)joining group
2020-01-07 19:19:52 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-75, groupId=353d1cda-bc4d-4e53-bb96-855f4dbe17b9] Successfully joined group with generation 1
2020-01-07 19:19:52 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-75, groupId=353d1cda-bc4d-4e53-bb96-855f4dbe17b9] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:52 INFO  Fetcher:583 - [Consumer clientId=consumer-75, groupId=353d1cda-bc4d-4e53-bb96-855f4dbe17b9] Resetting offset for partition stream9-0 to offset 63217.
2020-01-07 19:19:52 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9d4ad07d-a7f2-423f-b7f1-3ece96da4339
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:52 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:52 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:52 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:52 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-76, groupId=9d4ad07d-a7f2-423f-b7f1-3ece96da4339] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:52 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-76, groupId=9d4ad07d-a7f2-423f-b7f1-3ece96da4339] Revoking previously assigned partitions []
2020-01-07 19:19:52 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-76, groupId=9d4ad07d-a7f2-423f-b7f1-3ece96da4339] (Re-)joining group
2020-01-07 19:19:52 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-76, groupId=9d4ad07d-a7f2-423f-b7f1-3ece96da4339] Successfully joined group with generation 1
2020-01-07 19:19:52 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-76, groupId=9d4ad07d-a7f2-423f-b7f1-3ece96da4339] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:52 INFO  Fetcher:583 - [Consumer clientId=consumer-76, groupId=9d4ad07d-a7f2-423f-b7f1-3ece96da4339] Resetting offset for partition stream9-0 to offset 63218.
2020-01-07 19:19:52 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3d209089-0d06-4967-bd17-ab59555180bb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:52 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:52 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:52 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:52 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-77, groupId=3d209089-0d06-4967-bd17-ab59555180bb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:52 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-77, groupId=3d209089-0d06-4967-bd17-ab59555180bb] Revoking previously assigned partitions []
2020-01-07 19:19:52 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-77, groupId=3d209089-0d06-4967-bd17-ab59555180bb] (Re-)joining group
2020-01-07 19:19:52 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-77, groupId=3d209089-0d06-4967-bd17-ab59555180bb] Successfully joined group with generation 1
2020-01-07 19:19:52 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-77, groupId=3d209089-0d06-4967-bd17-ab59555180bb] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:52 INFO  Fetcher:583 - [Consumer clientId=consumer-77, groupId=3d209089-0d06-4967-bd17-ab59555180bb] Resetting offset for partition stream9-0 to offset 63219.
2020-01-07 19:19:52 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8026dc72-b3d5-4a38-8fd2-46176e102365
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:52 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:52 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:52 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:52 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-78, groupId=8026dc72-b3d5-4a38-8fd2-46176e102365] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:52 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-78, groupId=8026dc72-b3d5-4a38-8fd2-46176e102365] Revoking previously assigned partitions []
2020-01-07 19:19:52 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-78, groupId=8026dc72-b3d5-4a38-8fd2-46176e102365] (Re-)joining group
2020-01-07 19:19:52 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-78, groupId=8026dc72-b3d5-4a38-8fd2-46176e102365] Successfully joined group with generation 1
2020-01-07 19:19:52 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-78, groupId=8026dc72-b3d5-4a38-8fd2-46176e102365] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:52 INFO  Fetcher:583 - [Consumer clientId=consumer-78, groupId=8026dc72-b3d5-4a38-8fd2-46176e102365] Resetting offset for partition stream9-0 to offset 63220.
2020-01-07 19:19:52 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f742f493-f715-4989-9de3-fafb5473c50f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:52 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:52 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:52 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:52 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-79, groupId=f742f493-f715-4989-9de3-fafb5473c50f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:52 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-79, groupId=f742f493-f715-4989-9de3-fafb5473c50f] Revoking previously assigned partitions []
2020-01-07 19:19:52 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-79, groupId=f742f493-f715-4989-9de3-fafb5473c50f] (Re-)joining group
2020-01-07 19:19:52 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-79, groupId=f742f493-f715-4989-9de3-fafb5473c50f] Successfully joined group with generation 1
2020-01-07 19:19:52 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-79, groupId=f742f493-f715-4989-9de3-fafb5473c50f] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:52 INFO  Fetcher:583 - [Consumer clientId=consumer-79, groupId=f742f493-f715-4989-9de3-fafb5473c50f] Resetting offset for partition stream9-0 to offset 63221.
2020-01-07 19:19:52 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a430ce2f-4dc7-4f11-8094-c9fc12d58fab
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:52 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:52 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:52 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:52 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-80, groupId=a430ce2f-4dc7-4f11-8094-c9fc12d58fab] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:52 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-80, groupId=a430ce2f-4dc7-4f11-8094-c9fc12d58fab] Revoking previously assigned partitions []
2020-01-07 19:19:52 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-80, groupId=a430ce2f-4dc7-4f11-8094-c9fc12d58fab] (Re-)joining group
2020-01-07 19:19:52 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-80, groupId=a430ce2f-4dc7-4f11-8094-c9fc12d58fab] Successfully joined group with generation 1
2020-01-07 19:19:52 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-80, groupId=a430ce2f-4dc7-4f11-8094-c9fc12d58fab] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:52 INFO  Fetcher:583 - [Consumer clientId=consumer-80, groupId=a430ce2f-4dc7-4f11-8094-c9fc12d58fab] Resetting offset for partition stream9-0 to offset 63222.
2020-01-07 19:19:52 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a7fe9b4f-2c1b-4924-972d-c425b71971c4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:52 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:52 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:52 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:52 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-81, groupId=a7fe9b4f-2c1b-4924-972d-c425b71971c4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:52 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-81, groupId=a7fe9b4f-2c1b-4924-972d-c425b71971c4] Revoking previously assigned partitions []
2020-01-07 19:19:52 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-81, groupId=a7fe9b4f-2c1b-4924-972d-c425b71971c4] (Re-)joining group
2020-01-07 19:19:52 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-81, groupId=a7fe9b4f-2c1b-4924-972d-c425b71971c4] Successfully joined group with generation 1
2020-01-07 19:19:52 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-81, groupId=a7fe9b4f-2c1b-4924-972d-c425b71971c4] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:52 INFO  Fetcher:583 - [Consumer clientId=consumer-81, groupId=a7fe9b4f-2c1b-4924-972d-c425b71971c4] Resetting offset for partition stream9-0 to offset 63223.
2020-01-07 19:19:52 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 912046e7-0ec5-4c9b-9c12-d981d7b0f322
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:52 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:52 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:52 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:52 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-82, groupId=912046e7-0ec5-4c9b-9c12-d981d7b0f322] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:52 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-82, groupId=912046e7-0ec5-4c9b-9c12-d981d7b0f322] Revoking previously assigned partitions []
2020-01-07 19:19:52 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-82, groupId=912046e7-0ec5-4c9b-9c12-d981d7b0f322] (Re-)joining group
2020-01-07 19:19:52 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-82, groupId=912046e7-0ec5-4c9b-9c12-d981d7b0f322] Successfully joined group with generation 1
2020-01-07 19:19:52 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-82, groupId=912046e7-0ec5-4c9b-9c12-d981d7b0f322] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:52 INFO  Fetcher:583 - [Consumer clientId=consumer-82, groupId=912046e7-0ec5-4c9b-9c12-d981d7b0f322] Resetting offset for partition stream9-0 to offset 63224.
2020-01-07 19:19:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = bcd19625-53c4-45bc-8bbd-2451650b4f27
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-83, groupId=bcd19625-53c4-45bc-8bbd-2451650b4f27] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-83, groupId=bcd19625-53c4-45bc-8bbd-2451650b4f27] Revoking previously assigned partitions []
2020-01-07 19:19:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-83, groupId=bcd19625-53c4-45bc-8bbd-2451650b4f27] (Re-)joining group
2020-01-07 19:19:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-83, groupId=bcd19625-53c4-45bc-8bbd-2451650b4f27] Successfully joined group with generation 1
2020-01-07 19:19:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-83, groupId=bcd19625-53c4-45bc-8bbd-2451650b4f27] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:53 INFO  Fetcher:583 - [Consumer clientId=consumer-83, groupId=bcd19625-53c4-45bc-8bbd-2451650b4f27] Resetting offset for partition stream9-0 to offset 63225.
2020-01-07 19:19:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 750206fe-8079-443b-8c17-a828fef681ee
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-84, groupId=750206fe-8079-443b-8c17-a828fef681ee] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-84, groupId=750206fe-8079-443b-8c17-a828fef681ee] Revoking previously assigned partitions []
2020-01-07 19:19:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-84, groupId=750206fe-8079-443b-8c17-a828fef681ee] (Re-)joining group
2020-01-07 19:19:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-84, groupId=750206fe-8079-443b-8c17-a828fef681ee] Successfully joined group with generation 1
2020-01-07 19:19:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-84, groupId=750206fe-8079-443b-8c17-a828fef681ee] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:53 INFO  Fetcher:583 - [Consumer clientId=consumer-84, groupId=750206fe-8079-443b-8c17-a828fef681ee] Resetting offset for partition stream9-0 to offset 63226.
2020-01-07 19:19:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2f01bb7d-7ae9-4e73-873c-ca791ee4db81
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-85, groupId=2f01bb7d-7ae9-4e73-873c-ca791ee4db81] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-85, groupId=2f01bb7d-7ae9-4e73-873c-ca791ee4db81] Revoking previously assigned partitions []
2020-01-07 19:19:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-85, groupId=2f01bb7d-7ae9-4e73-873c-ca791ee4db81] (Re-)joining group
2020-01-07 19:19:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-85, groupId=2f01bb7d-7ae9-4e73-873c-ca791ee4db81] Successfully joined group with generation 1
2020-01-07 19:19:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-85, groupId=2f01bb7d-7ae9-4e73-873c-ca791ee4db81] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:53 INFO  Fetcher:583 - [Consumer clientId=consumer-85, groupId=2f01bb7d-7ae9-4e73-873c-ca791ee4db81] Resetting offset for partition stream9-0 to offset 63227.
2020-01-07 19:19:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8db10c04-d100-4d70-a696-26251ee019c4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-86, groupId=8db10c04-d100-4d70-a696-26251ee019c4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-86, groupId=8db10c04-d100-4d70-a696-26251ee019c4] Revoking previously assigned partitions []
2020-01-07 19:19:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-86, groupId=8db10c04-d100-4d70-a696-26251ee019c4] (Re-)joining group
2020-01-07 19:19:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-86, groupId=8db10c04-d100-4d70-a696-26251ee019c4] Successfully joined group with generation 1
2020-01-07 19:19:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-86, groupId=8db10c04-d100-4d70-a696-26251ee019c4] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:53 INFO  Fetcher:583 - [Consumer clientId=consumer-86, groupId=8db10c04-d100-4d70-a696-26251ee019c4] Resetting offset for partition stream9-0 to offset 63228.
2020-01-07 19:19:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f34e7279-c345-4dbe-be92-c33e0b44bfaf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-87, groupId=f34e7279-c345-4dbe-be92-c33e0b44bfaf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-87, groupId=f34e7279-c345-4dbe-be92-c33e0b44bfaf] Revoking previously assigned partitions []
2020-01-07 19:19:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-87, groupId=f34e7279-c345-4dbe-be92-c33e0b44bfaf] (Re-)joining group
2020-01-07 19:19:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-87, groupId=f34e7279-c345-4dbe-be92-c33e0b44bfaf] Successfully joined group with generation 1
2020-01-07 19:19:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-87, groupId=f34e7279-c345-4dbe-be92-c33e0b44bfaf] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:53 INFO  Fetcher:583 - [Consumer clientId=consumer-87, groupId=f34e7279-c345-4dbe-be92-c33e0b44bfaf] Resetting offset for partition stream9-0 to offset 63229.
2020-01-07 19:19:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 02fd669a-74e7-48ef-824c-8cde0fc3452a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-88, groupId=02fd669a-74e7-48ef-824c-8cde0fc3452a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-88, groupId=02fd669a-74e7-48ef-824c-8cde0fc3452a] Revoking previously assigned partitions []
2020-01-07 19:19:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-88, groupId=02fd669a-74e7-48ef-824c-8cde0fc3452a] (Re-)joining group
2020-01-07 19:19:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-88, groupId=02fd669a-74e7-48ef-824c-8cde0fc3452a] Successfully joined group with generation 1
2020-01-07 19:19:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-88, groupId=02fd669a-74e7-48ef-824c-8cde0fc3452a] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:53 INFO  Fetcher:583 - [Consumer clientId=consumer-88, groupId=02fd669a-74e7-48ef-824c-8cde0fc3452a] Resetting offset for partition stream9-0 to offset 63230.
2020-01-07 19:19:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5847b646-d385-45ad-8142-01c98c229973
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-89, groupId=5847b646-d385-45ad-8142-01c98c229973] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-89, groupId=5847b646-d385-45ad-8142-01c98c229973] Revoking previously assigned partitions []
2020-01-07 19:19:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-89, groupId=5847b646-d385-45ad-8142-01c98c229973] (Re-)joining group
2020-01-07 19:19:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-89, groupId=5847b646-d385-45ad-8142-01c98c229973] Successfully joined group with generation 1
2020-01-07 19:19:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-89, groupId=5847b646-d385-45ad-8142-01c98c229973] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:53 INFO  Fetcher:583 - [Consumer clientId=consumer-89, groupId=5847b646-d385-45ad-8142-01c98c229973] Resetting offset for partition stream9-0 to offset 63231.
2020-01-07 19:19:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 876f1a98-45bd-4984-8cab-4dd45bb9def3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-90, groupId=876f1a98-45bd-4984-8cab-4dd45bb9def3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-90, groupId=876f1a98-45bd-4984-8cab-4dd45bb9def3] Revoking previously assigned partitions []
2020-01-07 19:19:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-90, groupId=876f1a98-45bd-4984-8cab-4dd45bb9def3] (Re-)joining group
2020-01-07 19:19:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-90, groupId=876f1a98-45bd-4984-8cab-4dd45bb9def3] Successfully joined group with generation 1
2020-01-07 19:19:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-90, groupId=876f1a98-45bd-4984-8cab-4dd45bb9def3] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:53 INFO  Fetcher:583 - [Consumer clientId=consumer-90, groupId=876f1a98-45bd-4984-8cab-4dd45bb9def3] Resetting offset for partition stream9-0 to offset 63232.
2020-01-07 19:19:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8fe89cc0-2a08-4f9e-9ae7-9f11f939e928
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-91, groupId=8fe89cc0-2a08-4f9e-9ae7-9f11f939e928] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-91, groupId=8fe89cc0-2a08-4f9e-9ae7-9f11f939e928] Revoking previously assigned partitions []
2020-01-07 19:19:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-91, groupId=8fe89cc0-2a08-4f9e-9ae7-9f11f939e928] (Re-)joining group
2020-01-07 19:19:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-91, groupId=8fe89cc0-2a08-4f9e-9ae7-9f11f939e928] Successfully joined group with generation 1
2020-01-07 19:19:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-91, groupId=8fe89cc0-2a08-4f9e-9ae7-9f11f939e928] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:53 INFO  Fetcher:583 - [Consumer clientId=consumer-91, groupId=8fe89cc0-2a08-4f9e-9ae7-9f11f939e928] Resetting offset for partition stream9-0 to offset 63233.
2020-01-07 19:19:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 99786847-2a67-4a31-8574-a1a512c4e1f3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-92, groupId=99786847-2a67-4a31-8574-a1a512c4e1f3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-92, groupId=99786847-2a67-4a31-8574-a1a512c4e1f3] Revoking previously assigned partitions []
2020-01-07 19:19:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-92, groupId=99786847-2a67-4a31-8574-a1a512c4e1f3] (Re-)joining group
2020-01-07 19:19:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-92, groupId=99786847-2a67-4a31-8574-a1a512c4e1f3] Successfully joined group with generation 1
2020-01-07 19:19:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-92, groupId=99786847-2a67-4a31-8574-a1a512c4e1f3] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:53 INFO  Fetcher:583 - [Consumer clientId=consumer-92, groupId=99786847-2a67-4a31-8574-a1a512c4e1f3] Resetting offset for partition stream9-0 to offset 63234.
2020-01-07 19:19:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 607ccf6f-df12-4e1e-b5e9-c71268965fa7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-93, groupId=607ccf6f-df12-4e1e-b5e9-c71268965fa7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-93, groupId=607ccf6f-df12-4e1e-b5e9-c71268965fa7] Revoking previously assigned partitions []
2020-01-07 19:19:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-93, groupId=607ccf6f-df12-4e1e-b5e9-c71268965fa7] (Re-)joining group
2020-01-07 19:19:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-93, groupId=607ccf6f-df12-4e1e-b5e9-c71268965fa7] Successfully joined group with generation 1
2020-01-07 19:19:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-93, groupId=607ccf6f-df12-4e1e-b5e9-c71268965fa7] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:54 INFO  Fetcher:583 - [Consumer clientId=consumer-93, groupId=607ccf6f-df12-4e1e-b5e9-c71268965fa7] Resetting offset for partition stream9-0 to offset 63235.
2020-01-07 19:19:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b8acb479-215c-4dd6-92ec-1cc3871a8379
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-94, groupId=b8acb479-215c-4dd6-92ec-1cc3871a8379] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-94, groupId=b8acb479-215c-4dd6-92ec-1cc3871a8379] Revoking previously assigned partitions []
2020-01-07 19:19:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-94, groupId=b8acb479-215c-4dd6-92ec-1cc3871a8379] (Re-)joining group
2020-01-07 19:19:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-94, groupId=b8acb479-215c-4dd6-92ec-1cc3871a8379] Successfully joined group with generation 1
2020-01-07 19:19:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-94, groupId=b8acb479-215c-4dd6-92ec-1cc3871a8379] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:54 INFO  Fetcher:583 - [Consumer clientId=consumer-94, groupId=b8acb479-215c-4dd6-92ec-1cc3871a8379] Resetting offset for partition stream9-0 to offset 63236.
2020-01-07 19:19:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = adcd8180-1dd8-49f0-af24-aba89b338553
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-95, groupId=adcd8180-1dd8-49f0-af24-aba89b338553] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-95, groupId=adcd8180-1dd8-49f0-af24-aba89b338553] Revoking previously assigned partitions []
2020-01-07 19:19:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-95, groupId=adcd8180-1dd8-49f0-af24-aba89b338553] (Re-)joining group
2020-01-07 19:19:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-95, groupId=adcd8180-1dd8-49f0-af24-aba89b338553] Successfully joined group with generation 1
2020-01-07 19:19:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-95, groupId=adcd8180-1dd8-49f0-af24-aba89b338553] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:54 INFO  Fetcher:583 - [Consumer clientId=consumer-95, groupId=adcd8180-1dd8-49f0-af24-aba89b338553] Resetting offset for partition stream9-0 to offset 63237.
2020-01-07 19:19:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 21875e23-d172-402b-b233-2ee24797d49c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-96, groupId=21875e23-d172-402b-b233-2ee24797d49c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-96, groupId=21875e23-d172-402b-b233-2ee24797d49c] Revoking previously assigned partitions []
2020-01-07 19:19:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-96, groupId=21875e23-d172-402b-b233-2ee24797d49c] (Re-)joining group
2020-01-07 19:19:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-96, groupId=21875e23-d172-402b-b233-2ee24797d49c] Successfully joined group with generation 1
2020-01-07 19:19:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-96, groupId=21875e23-d172-402b-b233-2ee24797d49c] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:54 INFO  Fetcher:583 - [Consumer clientId=consumer-96, groupId=21875e23-d172-402b-b233-2ee24797d49c] Resetting offset for partition stream9-0 to offset 63238.
2020-01-07 19:19:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 91c4f5b6-c7d3-4179-89bb-c7edf2d0b81d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-97, groupId=91c4f5b6-c7d3-4179-89bb-c7edf2d0b81d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-97, groupId=91c4f5b6-c7d3-4179-89bb-c7edf2d0b81d] Revoking previously assigned partitions []
2020-01-07 19:19:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-97, groupId=91c4f5b6-c7d3-4179-89bb-c7edf2d0b81d] (Re-)joining group
2020-01-07 19:19:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-97, groupId=91c4f5b6-c7d3-4179-89bb-c7edf2d0b81d] Successfully joined group with generation 1
2020-01-07 19:19:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-97, groupId=91c4f5b6-c7d3-4179-89bb-c7edf2d0b81d] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:54 INFO  Fetcher:583 - [Consumer clientId=consumer-97, groupId=91c4f5b6-c7d3-4179-89bb-c7edf2d0b81d] Resetting offset for partition stream9-0 to offset 63239.
2020-01-07 19:19:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ae373b31-601f-41d6-b81b-7baf018d50c4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-98, groupId=ae373b31-601f-41d6-b81b-7baf018d50c4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-98, groupId=ae373b31-601f-41d6-b81b-7baf018d50c4] Revoking previously assigned partitions []
2020-01-07 19:19:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-98, groupId=ae373b31-601f-41d6-b81b-7baf018d50c4] (Re-)joining group
2020-01-07 19:19:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-98, groupId=ae373b31-601f-41d6-b81b-7baf018d50c4] Successfully joined group with generation 1
2020-01-07 19:19:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-98, groupId=ae373b31-601f-41d6-b81b-7baf018d50c4] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:54 INFO  Fetcher:583 - [Consumer clientId=consumer-98, groupId=ae373b31-601f-41d6-b81b-7baf018d50c4] Resetting offset for partition stream9-0 to offset 63240.
2020-01-07 19:19:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0d763f2f-e4b8-4f56-9409-aea86b70e92e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-99, groupId=0d763f2f-e4b8-4f56-9409-aea86b70e92e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-99, groupId=0d763f2f-e4b8-4f56-9409-aea86b70e92e] Revoking previously assigned partitions []
2020-01-07 19:19:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-99, groupId=0d763f2f-e4b8-4f56-9409-aea86b70e92e] (Re-)joining group
2020-01-07 19:19:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-99, groupId=0d763f2f-e4b8-4f56-9409-aea86b70e92e] Successfully joined group with generation 1
2020-01-07 19:19:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-99, groupId=0d763f2f-e4b8-4f56-9409-aea86b70e92e] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:54 INFO  Fetcher:583 - [Consumer clientId=consumer-99, groupId=0d763f2f-e4b8-4f56-9409-aea86b70e92e] Resetting offset for partition stream9-0 to offset 63241.
2020-01-07 19:19:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5ea0705b-ab73-4c56-a95f-9cb20107338f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-100, groupId=5ea0705b-ab73-4c56-a95f-9cb20107338f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-100, groupId=5ea0705b-ab73-4c56-a95f-9cb20107338f] Revoking previously assigned partitions []
2020-01-07 19:19:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-100, groupId=5ea0705b-ab73-4c56-a95f-9cb20107338f] (Re-)joining group
2020-01-07 19:19:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-100, groupId=5ea0705b-ab73-4c56-a95f-9cb20107338f] Successfully joined group with generation 1
2020-01-07 19:19:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-100, groupId=5ea0705b-ab73-4c56-a95f-9cb20107338f] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:54 INFO  Fetcher:583 - [Consumer clientId=consumer-100, groupId=5ea0705b-ab73-4c56-a95f-9cb20107338f] Resetting offset for partition stream9-0 to offset 63242.
2020-01-07 19:19:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7515097b-38ee-4a31-8d13-e27ad46922e4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-101, groupId=7515097b-38ee-4a31-8d13-e27ad46922e4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-101, groupId=7515097b-38ee-4a31-8d13-e27ad46922e4] Revoking previously assigned partitions []
2020-01-07 19:19:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-101, groupId=7515097b-38ee-4a31-8d13-e27ad46922e4] (Re-)joining group
2020-01-07 19:19:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-101, groupId=7515097b-38ee-4a31-8d13-e27ad46922e4] Successfully joined group with generation 1
2020-01-07 19:19:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-101, groupId=7515097b-38ee-4a31-8d13-e27ad46922e4] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:54 INFO  Fetcher:583 - [Consumer clientId=consumer-101, groupId=7515097b-38ee-4a31-8d13-e27ad46922e4] Resetting offset for partition stream9-0 to offset 63243.
2020-01-07 19:19:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5ce1e649-8a3a-44f6-89b7-ac7a80b09a83
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-102, groupId=5ce1e649-8a3a-44f6-89b7-ac7a80b09a83] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-102, groupId=5ce1e649-8a3a-44f6-89b7-ac7a80b09a83] Revoking previously assigned partitions []
2020-01-07 19:19:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-102, groupId=5ce1e649-8a3a-44f6-89b7-ac7a80b09a83] (Re-)joining group
2020-01-07 19:19:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-102, groupId=5ce1e649-8a3a-44f6-89b7-ac7a80b09a83] Successfully joined group with generation 1
2020-01-07 19:19:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-102, groupId=5ce1e649-8a3a-44f6-89b7-ac7a80b09a83] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:54 INFO  Fetcher:583 - [Consumer clientId=consumer-102, groupId=5ce1e649-8a3a-44f6-89b7-ac7a80b09a83] Resetting offset for partition stream9-0 to offset 63244.
2020-01-07 19:19:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 711d92e8-e459-4337-8d12-5e87b52b3d8d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-103, groupId=711d92e8-e459-4337-8d12-5e87b52b3d8d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-103, groupId=711d92e8-e459-4337-8d12-5e87b52b3d8d] Revoking previously assigned partitions []
2020-01-07 19:19:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-103, groupId=711d92e8-e459-4337-8d12-5e87b52b3d8d] (Re-)joining group
2020-01-07 19:19:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-103, groupId=711d92e8-e459-4337-8d12-5e87b52b3d8d] Successfully joined group with generation 1
2020-01-07 19:19:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-103, groupId=711d92e8-e459-4337-8d12-5e87b52b3d8d] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:54 INFO  Fetcher:583 - [Consumer clientId=consumer-103, groupId=711d92e8-e459-4337-8d12-5e87b52b3d8d] Resetting offset for partition stream9-0 to offset 63245.
2020-01-07 19:19:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 51a55597-d83e-4728-a2b3-ac5111e7b1e8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-104, groupId=51a55597-d83e-4728-a2b3-ac5111e7b1e8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-104, groupId=51a55597-d83e-4728-a2b3-ac5111e7b1e8] Revoking previously assigned partitions []
2020-01-07 19:19:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-104, groupId=51a55597-d83e-4728-a2b3-ac5111e7b1e8] (Re-)joining group
2020-01-07 19:19:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-104, groupId=51a55597-d83e-4728-a2b3-ac5111e7b1e8] Successfully joined group with generation 1
2020-01-07 19:19:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-104, groupId=51a55597-d83e-4728-a2b3-ac5111e7b1e8] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:55 INFO  Fetcher:583 - [Consumer clientId=consumer-104, groupId=51a55597-d83e-4728-a2b3-ac5111e7b1e8] Resetting offset for partition stream9-0 to offset 63246.
2020-01-07 19:19:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e73a5ed1-2fd0-4d63-b37c-313b4fc8724e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-105, groupId=e73a5ed1-2fd0-4d63-b37c-313b4fc8724e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-105, groupId=e73a5ed1-2fd0-4d63-b37c-313b4fc8724e] Revoking previously assigned partitions []
2020-01-07 19:19:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-105, groupId=e73a5ed1-2fd0-4d63-b37c-313b4fc8724e] (Re-)joining group
2020-01-07 19:19:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-105, groupId=e73a5ed1-2fd0-4d63-b37c-313b4fc8724e] Successfully joined group with generation 1
2020-01-07 19:19:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-105, groupId=e73a5ed1-2fd0-4d63-b37c-313b4fc8724e] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:55 INFO  Fetcher:583 - [Consumer clientId=consumer-105, groupId=e73a5ed1-2fd0-4d63-b37c-313b4fc8724e] Resetting offset for partition stream9-0 to offset 63247.
2020-01-07 19:19:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 68603438-4b09-4c2e-846f-cc5b92e118fb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-106, groupId=68603438-4b09-4c2e-846f-cc5b92e118fb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-106, groupId=68603438-4b09-4c2e-846f-cc5b92e118fb] Revoking previously assigned partitions []
2020-01-07 19:19:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-106, groupId=68603438-4b09-4c2e-846f-cc5b92e118fb] (Re-)joining group
2020-01-07 19:19:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-106, groupId=68603438-4b09-4c2e-846f-cc5b92e118fb] Successfully joined group with generation 1
2020-01-07 19:19:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-106, groupId=68603438-4b09-4c2e-846f-cc5b92e118fb] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:55 INFO  Fetcher:583 - [Consumer clientId=consumer-106, groupId=68603438-4b09-4c2e-846f-cc5b92e118fb] Resetting offset for partition stream9-0 to offset 63248.
2020-01-07 19:19:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a914968a-abae-432b-9588-9595c2382a50
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-107, groupId=a914968a-abae-432b-9588-9595c2382a50] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-107, groupId=a914968a-abae-432b-9588-9595c2382a50] Revoking previously assigned partitions []
2020-01-07 19:19:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-107, groupId=a914968a-abae-432b-9588-9595c2382a50] (Re-)joining group
2020-01-07 19:19:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-107, groupId=a914968a-abae-432b-9588-9595c2382a50] Successfully joined group with generation 1
2020-01-07 19:19:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-107, groupId=a914968a-abae-432b-9588-9595c2382a50] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:55 INFO  Fetcher:583 - [Consumer clientId=consumer-107, groupId=a914968a-abae-432b-9588-9595c2382a50] Resetting offset for partition stream9-0 to offset 63249.
2020-01-07 19:19:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7c1caea1-9571-492d-b928-401c1fd05ab6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-108, groupId=7c1caea1-9571-492d-b928-401c1fd05ab6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-108, groupId=7c1caea1-9571-492d-b928-401c1fd05ab6] Revoking previously assigned partitions []
2020-01-07 19:19:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-108, groupId=7c1caea1-9571-492d-b928-401c1fd05ab6] (Re-)joining group
2020-01-07 19:19:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-108, groupId=7c1caea1-9571-492d-b928-401c1fd05ab6] Successfully joined group with generation 1
2020-01-07 19:19:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-108, groupId=7c1caea1-9571-492d-b928-401c1fd05ab6] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:55 INFO  Fetcher:583 - [Consumer clientId=consumer-108, groupId=7c1caea1-9571-492d-b928-401c1fd05ab6] Resetting offset for partition stream9-0 to offset 63250.
2020-01-07 19:19:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 89e079f6-279d-4720-babd-d57a9666b6d6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-109, groupId=89e079f6-279d-4720-babd-d57a9666b6d6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-109, groupId=89e079f6-279d-4720-babd-d57a9666b6d6] Revoking previously assigned partitions []
2020-01-07 19:19:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-109, groupId=89e079f6-279d-4720-babd-d57a9666b6d6] (Re-)joining group
2020-01-07 19:19:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-109, groupId=89e079f6-279d-4720-babd-d57a9666b6d6] Successfully joined group with generation 1
2020-01-07 19:19:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-109, groupId=89e079f6-279d-4720-babd-d57a9666b6d6] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:55 INFO  Fetcher:583 - [Consumer clientId=consumer-109, groupId=89e079f6-279d-4720-babd-d57a9666b6d6] Resetting offset for partition stream9-0 to offset 63251.
2020-01-07 19:19:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4b9fff18-f02a-4255-9798-d6d37d49e2a3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-110, groupId=4b9fff18-f02a-4255-9798-d6d37d49e2a3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-110, groupId=4b9fff18-f02a-4255-9798-d6d37d49e2a3] Revoking previously assigned partitions []
2020-01-07 19:19:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-110, groupId=4b9fff18-f02a-4255-9798-d6d37d49e2a3] (Re-)joining group
2020-01-07 19:19:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-110, groupId=4b9fff18-f02a-4255-9798-d6d37d49e2a3] Successfully joined group with generation 1
2020-01-07 19:19:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-110, groupId=4b9fff18-f02a-4255-9798-d6d37d49e2a3] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:55 INFO  Fetcher:583 - [Consumer clientId=consumer-110, groupId=4b9fff18-f02a-4255-9798-d6d37d49e2a3] Resetting offset for partition stream9-0 to offset 63252.
2020-01-07 19:19:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ec94da77-0a43-475b-9266-483d9a0d6acf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-111, groupId=ec94da77-0a43-475b-9266-483d9a0d6acf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-111, groupId=ec94da77-0a43-475b-9266-483d9a0d6acf] Revoking previously assigned partitions []
2020-01-07 19:19:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-111, groupId=ec94da77-0a43-475b-9266-483d9a0d6acf] (Re-)joining group
2020-01-07 19:19:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-111, groupId=ec94da77-0a43-475b-9266-483d9a0d6acf] Successfully joined group with generation 1
2020-01-07 19:19:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-111, groupId=ec94da77-0a43-475b-9266-483d9a0d6acf] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:55 INFO  Fetcher:583 - [Consumer clientId=consumer-111, groupId=ec94da77-0a43-475b-9266-483d9a0d6acf] Resetting offset for partition stream9-0 to offset 63254.
2020-01-07 19:19:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b1df2569-73eb-49a7-9779-6e3d7c10c72a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-112, groupId=b1df2569-73eb-49a7-9779-6e3d7c10c72a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-112, groupId=b1df2569-73eb-49a7-9779-6e3d7c10c72a] Revoking previously assigned partitions []
2020-01-07 19:19:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-112, groupId=b1df2569-73eb-49a7-9779-6e3d7c10c72a] (Re-)joining group
2020-01-07 19:19:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-112, groupId=b1df2569-73eb-49a7-9779-6e3d7c10c72a] Successfully joined group with generation 1
2020-01-07 19:19:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-112, groupId=b1df2569-73eb-49a7-9779-6e3d7c10c72a] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:55 INFO  Fetcher:583 - [Consumer clientId=consumer-112, groupId=b1df2569-73eb-49a7-9779-6e3d7c10c72a] Resetting offset for partition stream9-0 to offset 63255.
2020-01-07 19:19:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 18cec7a1-362d-4e48-98ef-520e3d18a9e1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-113, groupId=18cec7a1-362d-4e48-98ef-520e3d18a9e1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-113, groupId=18cec7a1-362d-4e48-98ef-520e3d18a9e1] Revoking previously assigned partitions []
2020-01-07 19:19:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-113, groupId=18cec7a1-362d-4e48-98ef-520e3d18a9e1] (Re-)joining group
2020-01-07 19:19:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-113, groupId=18cec7a1-362d-4e48-98ef-520e3d18a9e1] Successfully joined group with generation 1
2020-01-07 19:19:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-113, groupId=18cec7a1-362d-4e48-98ef-520e3d18a9e1] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:55 INFO  Fetcher:583 - [Consumer clientId=consumer-113, groupId=18cec7a1-362d-4e48-98ef-520e3d18a9e1] Resetting offset for partition stream9-0 to offset 63256.
2020-01-07 19:19:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d3cf3604-3560-4e83-81a2-960c834cae8f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-114, groupId=d3cf3604-3560-4e83-81a2-960c834cae8f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-114, groupId=d3cf3604-3560-4e83-81a2-960c834cae8f] Revoking previously assigned partitions []
2020-01-07 19:19:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-114, groupId=d3cf3604-3560-4e83-81a2-960c834cae8f] (Re-)joining group
2020-01-07 19:19:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-114, groupId=d3cf3604-3560-4e83-81a2-960c834cae8f] Successfully joined group with generation 1
2020-01-07 19:19:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-114, groupId=d3cf3604-3560-4e83-81a2-960c834cae8f] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:56 INFO  Fetcher:583 - [Consumer clientId=consumer-114, groupId=d3cf3604-3560-4e83-81a2-960c834cae8f] Resetting offset for partition stream9-0 to offset 63257.
2020-01-07 19:19:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 533840c1-92c7-4089-8b52-9aadb3175a57
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-115, groupId=533840c1-92c7-4089-8b52-9aadb3175a57] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-115, groupId=533840c1-92c7-4089-8b52-9aadb3175a57] Revoking previously assigned partitions []
2020-01-07 19:19:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-115, groupId=533840c1-92c7-4089-8b52-9aadb3175a57] (Re-)joining group
2020-01-07 19:19:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-115, groupId=533840c1-92c7-4089-8b52-9aadb3175a57] Successfully joined group with generation 1
2020-01-07 19:19:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-115, groupId=533840c1-92c7-4089-8b52-9aadb3175a57] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:56 INFO  Fetcher:583 - [Consumer clientId=consumer-115, groupId=533840c1-92c7-4089-8b52-9aadb3175a57] Resetting offset for partition stream9-0 to offset 63258.
2020-01-07 19:19:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 37bfa2df-95f4-4b18-8b48-e6e385127f57
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-116, groupId=37bfa2df-95f4-4b18-8b48-e6e385127f57] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-116, groupId=37bfa2df-95f4-4b18-8b48-e6e385127f57] Revoking previously assigned partitions []
2020-01-07 19:19:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-116, groupId=37bfa2df-95f4-4b18-8b48-e6e385127f57] (Re-)joining group
2020-01-07 19:19:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-116, groupId=37bfa2df-95f4-4b18-8b48-e6e385127f57] Successfully joined group with generation 1
2020-01-07 19:19:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-116, groupId=37bfa2df-95f4-4b18-8b48-e6e385127f57] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:56 INFO  Fetcher:583 - [Consumer clientId=consumer-116, groupId=37bfa2df-95f4-4b18-8b48-e6e385127f57] Resetting offset for partition stream9-0 to offset 63259.
2020-01-07 19:19:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 87d72e52-52f9-4930-9779-7c44743744b6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-117, groupId=87d72e52-52f9-4930-9779-7c44743744b6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-117, groupId=87d72e52-52f9-4930-9779-7c44743744b6] Revoking previously assigned partitions []
2020-01-07 19:19:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-117, groupId=87d72e52-52f9-4930-9779-7c44743744b6] (Re-)joining group
2020-01-07 19:19:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-117, groupId=87d72e52-52f9-4930-9779-7c44743744b6] Successfully joined group with generation 1
2020-01-07 19:19:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-117, groupId=87d72e52-52f9-4930-9779-7c44743744b6] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:56 INFO  Fetcher:583 - [Consumer clientId=consumer-117, groupId=87d72e52-52f9-4930-9779-7c44743744b6] Resetting offset for partition stream9-0 to offset 63260.
2020-01-07 19:19:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 375065e1-569f-41f3-a0e0-f8f9c469e044
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-118, groupId=375065e1-569f-41f3-a0e0-f8f9c469e044] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-118, groupId=375065e1-569f-41f3-a0e0-f8f9c469e044] Revoking previously assigned partitions []
2020-01-07 19:19:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-118, groupId=375065e1-569f-41f3-a0e0-f8f9c469e044] (Re-)joining group
2020-01-07 19:19:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-118, groupId=375065e1-569f-41f3-a0e0-f8f9c469e044] Successfully joined group with generation 1
2020-01-07 19:19:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-118, groupId=375065e1-569f-41f3-a0e0-f8f9c469e044] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:56 INFO  Fetcher:583 - [Consumer clientId=consumer-118, groupId=375065e1-569f-41f3-a0e0-f8f9c469e044] Resetting offset for partition stream9-0 to offset 63261.
2020-01-07 19:19:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2e89403a-513f-4933-afa4-51afac38d8ef
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-119, groupId=2e89403a-513f-4933-afa4-51afac38d8ef] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-119, groupId=2e89403a-513f-4933-afa4-51afac38d8ef] Revoking previously assigned partitions []
2020-01-07 19:19:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-119, groupId=2e89403a-513f-4933-afa4-51afac38d8ef] (Re-)joining group
2020-01-07 19:19:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-119, groupId=2e89403a-513f-4933-afa4-51afac38d8ef] Successfully joined group with generation 1
2020-01-07 19:19:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-119, groupId=2e89403a-513f-4933-afa4-51afac38d8ef] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:56 INFO  Fetcher:583 - [Consumer clientId=consumer-119, groupId=2e89403a-513f-4933-afa4-51afac38d8ef] Resetting offset for partition stream9-0 to offset 63262.
2020-01-07 19:19:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 12614896-4e90-4aa5-ae18-ce4e1ce734c7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-120, groupId=12614896-4e90-4aa5-ae18-ce4e1ce734c7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-120, groupId=12614896-4e90-4aa5-ae18-ce4e1ce734c7] Revoking previously assigned partitions []
2020-01-07 19:19:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-120, groupId=12614896-4e90-4aa5-ae18-ce4e1ce734c7] (Re-)joining group
2020-01-07 19:19:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-120, groupId=12614896-4e90-4aa5-ae18-ce4e1ce734c7] Successfully joined group with generation 1
2020-01-07 19:19:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-120, groupId=12614896-4e90-4aa5-ae18-ce4e1ce734c7] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:56 INFO  Fetcher:583 - [Consumer clientId=consumer-120, groupId=12614896-4e90-4aa5-ae18-ce4e1ce734c7] Resetting offset for partition stream9-0 to offset 63263.
2020-01-07 19:19:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4e48b1d5-8181-4147-8a5e-f43ea9ca7250
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-121, groupId=4e48b1d5-8181-4147-8a5e-f43ea9ca7250] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-121, groupId=4e48b1d5-8181-4147-8a5e-f43ea9ca7250] Revoking previously assigned partitions []
2020-01-07 19:19:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-121, groupId=4e48b1d5-8181-4147-8a5e-f43ea9ca7250] (Re-)joining group
2020-01-07 19:19:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-121, groupId=4e48b1d5-8181-4147-8a5e-f43ea9ca7250] Successfully joined group with generation 1
2020-01-07 19:19:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-121, groupId=4e48b1d5-8181-4147-8a5e-f43ea9ca7250] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:56 INFO  Fetcher:583 - [Consumer clientId=consumer-121, groupId=4e48b1d5-8181-4147-8a5e-f43ea9ca7250] Resetting offset for partition stream9-0 to offset 63264.
2020-01-07 19:19:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7d053916-b30d-44dd-84a1-a24d844d6fb7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-122, groupId=7d053916-b30d-44dd-84a1-a24d844d6fb7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-122, groupId=7d053916-b30d-44dd-84a1-a24d844d6fb7] Revoking previously assigned partitions []
2020-01-07 19:19:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-122, groupId=7d053916-b30d-44dd-84a1-a24d844d6fb7] (Re-)joining group
2020-01-07 19:19:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-122, groupId=7d053916-b30d-44dd-84a1-a24d844d6fb7] Successfully joined group with generation 1
2020-01-07 19:19:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-122, groupId=7d053916-b30d-44dd-84a1-a24d844d6fb7] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:56 INFO  Fetcher:583 - [Consumer clientId=consumer-122, groupId=7d053916-b30d-44dd-84a1-a24d844d6fb7] Resetting offset for partition stream9-0 to offset 63265.
2020-01-07 19:19:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = bd365200-e0b0-4e5d-a6b9-7f7e12a89a21
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-123, groupId=bd365200-e0b0-4e5d-a6b9-7f7e12a89a21] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-123, groupId=bd365200-e0b0-4e5d-a6b9-7f7e12a89a21] Revoking previously assigned partitions []
2020-01-07 19:19:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-123, groupId=bd365200-e0b0-4e5d-a6b9-7f7e12a89a21] (Re-)joining group
2020-01-07 19:19:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-123, groupId=bd365200-e0b0-4e5d-a6b9-7f7e12a89a21] Successfully joined group with generation 1
2020-01-07 19:19:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-123, groupId=bd365200-e0b0-4e5d-a6b9-7f7e12a89a21] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:56 INFO  Fetcher:583 - [Consumer clientId=consumer-123, groupId=bd365200-e0b0-4e5d-a6b9-7f7e12a89a21] Resetting offset for partition stream9-0 to offset 63266.
2020-01-07 19:19:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 567b6d23-581c-4d67-afb1-001fd9fd63e9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-124, groupId=567b6d23-581c-4d67-afb1-001fd9fd63e9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-124, groupId=567b6d23-581c-4d67-afb1-001fd9fd63e9] Revoking previously assigned partitions []
2020-01-07 19:19:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-124, groupId=567b6d23-581c-4d67-afb1-001fd9fd63e9] (Re-)joining group
2020-01-07 19:19:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-124, groupId=567b6d23-581c-4d67-afb1-001fd9fd63e9] Successfully joined group with generation 1
2020-01-07 19:19:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-124, groupId=567b6d23-581c-4d67-afb1-001fd9fd63e9] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:56 INFO  Fetcher:583 - [Consumer clientId=consumer-124, groupId=567b6d23-581c-4d67-afb1-001fd9fd63e9] Resetting offset for partition stream9-0 to offset 63267.
2020-01-07 19:19:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5495b129-3cfa-49a6-88e8-6cd62c3837b7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-125, groupId=5495b129-3cfa-49a6-88e8-6cd62c3837b7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-125, groupId=5495b129-3cfa-49a6-88e8-6cd62c3837b7] Revoking previously assigned partitions []
2020-01-07 19:19:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-125, groupId=5495b129-3cfa-49a6-88e8-6cd62c3837b7] (Re-)joining group
2020-01-07 19:19:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-125, groupId=5495b129-3cfa-49a6-88e8-6cd62c3837b7] Successfully joined group with generation 1
2020-01-07 19:19:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-125, groupId=5495b129-3cfa-49a6-88e8-6cd62c3837b7] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:56 INFO  Fetcher:583 - [Consumer clientId=consumer-125, groupId=5495b129-3cfa-49a6-88e8-6cd62c3837b7] Resetting offset for partition stream9-0 to offset 63268.
2020-01-07 19:19:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c33a24bb-c217-4190-92e7-ecc56d52242a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-126, groupId=c33a24bb-c217-4190-92e7-ecc56d52242a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-126, groupId=c33a24bb-c217-4190-92e7-ecc56d52242a] Revoking previously assigned partitions []
2020-01-07 19:19:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-126, groupId=c33a24bb-c217-4190-92e7-ecc56d52242a] (Re-)joining group
2020-01-07 19:19:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-126, groupId=c33a24bb-c217-4190-92e7-ecc56d52242a] Successfully joined group with generation 1
2020-01-07 19:19:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-126, groupId=c33a24bb-c217-4190-92e7-ecc56d52242a] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:56 INFO  Fetcher:583 - [Consumer clientId=consumer-126, groupId=c33a24bb-c217-4190-92e7-ecc56d52242a] Resetting offset for partition stream9-0 to offset 63270.
2020-01-07 19:19:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6042ca8f-018a-422c-b53a-fa7168b0554e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-127, groupId=6042ca8f-018a-422c-b53a-fa7168b0554e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-127, groupId=6042ca8f-018a-422c-b53a-fa7168b0554e] Revoking previously assigned partitions []
2020-01-07 19:19:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-127, groupId=6042ca8f-018a-422c-b53a-fa7168b0554e] (Re-)joining group
2020-01-07 19:19:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-127, groupId=6042ca8f-018a-422c-b53a-fa7168b0554e] Successfully joined group with generation 1
2020-01-07 19:19:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-127, groupId=6042ca8f-018a-422c-b53a-fa7168b0554e] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:56 INFO  Fetcher:583 - [Consumer clientId=consumer-127, groupId=6042ca8f-018a-422c-b53a-fa7168b0554e] Resetting offset for partition stream9-0 to offset 63271.
2020-01-07 19:19:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 648cd957-2efc-4443-adb0-b42434287626
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-128, groupId=648cd957-2efc-4443-adb0-b42434287626] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-128, groupId=648cd957-2efc-4443-adb0-b42434287626] Revoking previously assigned partitions []
2020-01-07 19:19:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-128, groupId=648cd957-2efc-4443-adb0-b42434287626] (Re-)joining group
2020-01-07 19:19:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-128, groupId=648cd957-2efc-4443-adb0-b42434287626] Successfully joined group with generation 1
2020-01-07 19:19:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-128, groupId=648cd957-2efc-4443-adb0-b42434287626] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:57 INFO  Fetcher:583 - [Consumer clientId=consumer-128, groupId=648cd957-2efc-4443-adb0-b42434287626] Resetting offset for partition stream9-0 to offset 63272.
2020-01-07 19:19:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3252ff0e-d860-48a6-b5a3-c45ff0fa24af
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-129, groupId=3252ff0e-d860-48a6-b5a3-c45ff0fa24af] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-129, groupId=3252ff0e-d860-48a6-b5a3-c45ff0fa24af] Revoking previously assigned partitions []
2020-01-07 19:19:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-129, groupId=3252ff0e-d860-48a6-b5a3-c45ff0fa24af] (Re-)joining group
2020-01-07 19:19:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-129, groupId=3252ff0e-d860-48a6-b5a3-c45ff0fa24af] Successfully joined group with generation 1
2020-01-07 19:19:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-129, groupId=3252ff0e-d860-48a6-b5a3-c45ff0fa24af] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:57 INFO  Fetcher:583 - [Consumer clientId=consumer-129, groupId=3252ff0e-d860-48a6-b5a3-c45ff0fa24af] Resetting offset for partition stream9-0 to offset 63273.
2020-01-07 19:19:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7f9a9ad1-ff18-4d80-8cea-20fae0b1346b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-130, groupId=7f9a9ad1-ff18-4d80-8cea-20fae0b1346b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-130, groupId=7f9a9ad1-ff18-4d80-8cea-20fae0b1346b] Revoking previously assigned partitions []
2020-01-07 19:19:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-130, groupId=7f9a9ad1-ff18-4d80-8cea-20fae0b1346b] (Re-)joining group
2020-01-07 19:19:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-130, groupId=7f9a9ad1-ff18-4d80-8cea-20fae0b1346b] Successfully joined group with generation 1
2020-01-07 19:19:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-130, groupId=7f9a9ad1-ff18-4d80-8cea-20fae0b1346b] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:57 INFO  Fetcher:583 - [Consumer clientId=consumer-130, groupId=7f9a9ad1-ff18-4d80-8cea-20fae0b1346b] Resetting offset for partition stream9-0 to offset 63274.
2020-01-07 19:19:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a147546a-ac1c-45a1-9915-23db32e13abd
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-131, groupId=a147546a-ac1c-45a1-9915-23db32e13abd] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-131, groupId=a147546a-ac1c-45a1-9915-23db32e13abd] Revoking previously assigned partitions []
2020-01-07 19:19:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-131, groupId=a147546a-ac1c-45a1-9915-23db32e13abd] (Re-)joining group
2020-01-07 19:19:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-131, groupId=a147546a-ac1c-45a1-9915-23db32e13abd] Successfully joined group with generation 1
2020-01-07 19:19:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-131, groupId=a147546a-ac1c-45a1-9915-23db32e13abd] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:57 INFO  Fetcher:583 - [Consumer clientId=consumer-131, groupId=a147546a-ac1c-45a1-9915-23db32e13abd] Resetting offset for partition stream9-0 to offset 63275.
2020-01-07 19:19:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d4c329f3-facb-4323-b894-311bd8c68ab9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-132, groupId=d4c329f3-facb-4323-b894-311bd8c68ab9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-132, groupId=d4c329f3-facb-4323-b894-311bd8c68ab9] Revoking previously assigned partitions []
2020-01-07 19:19:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-132, groupId=d4c329f3-facb-4323-b894-311bd8c68ab9] (Re-)joining group
2020-01-07 19:19:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-132, groupId=d4c329f3-facb-4323-b894-311bd8c68ab9] Successfully joined group with generation 1
2020-01-07 19:19:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-132, groupId=d4c329f3-facb-4323-b894-311bd8c68ab9] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:57 INFO  Fetcher:583 - [Consumer clientId=consumer-132, groupId=d4c329f3-facb-4323-b894-311bd8c68ab9] Resetting offset for partition stream9-0 to offset 63276.
2020-01-07 19:19:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e65a725d-805f-4b4b-a6d1-5152a0a98564
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-133, groupId=e65a725d-805f-4b4b-a6d1-5152a0a98564] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-133, groupId=e65a725d-805f-4b4b-a6d1-5152a0a98564] Revoking previously assigned partitions []
2020-01-07 19:19:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-133, groupId=e65a725d-805f-4b4b-a6d1-5152a0a98564] (Re-)joining group
2020-01-07 19:19:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-133, groupId=e65a725d-805f-4b4b-a6d1-5152a0a98564] Successfully joined group with generation 1
2020-01-07 19:19:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-133, groupId=e65a725d-805f-4b4b-a6d1-5152a0a98564] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:57 INFO  Fetcher:583 - [Consumer clientId=consumer-133, groupId=e65a725d-805f-4b4b-a6d1-5152a0a98564] Resetting offset for partition stream9-0 to offset 63277.
2020-01-07 19:19:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6e0a9d57-4dae-485a-bafb-e3395720827d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-134, groupId=6e0a9d57-4dae-485a-bafb-e3395720827d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-134, groupId=6e0a9d57-4dae-485a-bafb-e3395720827d] Revoking previously assigned partitions []
2020-01-07 19:19:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-134, groupId=6e0a9d57-4dae-485a-bafb-e3395720827d] (Re-)joining group
2020-01-07 19:19:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-134, groupId=6e0a9d57-4dae-485a-bafb-e3395720827d] Successfully joined group with generation 1
2020-01-07 19:19:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-134, groupId=6e0a9d57-4dae-485a-bafb-e3395720827d] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:57 INFO  Fetcher:583 - [Consumer clientId=consumer-134, groupId=6e0a9d57-4dae-485a-bafb-e3395720827d] Resetting offset for partition stream9-0 to offset 63278.
2020-01-07 19:19:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f78d8c11-7ad0-4d75-9a53-d5dddbfce143
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-135, groupId=f78d8c11-7ad0-4d75-9a53-d5dddbfce143] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-135, groupId=f78d8c11-7ad0-4d75-9a53-d5dddbfce143] Revoking previously assigned partitions []
2020-01-07 19:19:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-135, groupId=f78d8c11-7ad0-4d75-9a53-d5dddbfce143] (Re-)joining group
2020-01-07 19:19:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-135, groupId=f78d8c11-7ad0-4d75-9a53-d5dddbfce143] Successfully joined group with generation 1
2020-01-07 19:19:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-135, groupId=f78d8c11-7ad0-4d75-9a53-d5dddbfce143] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:57 INFO  Fetcher:583 - [Consumer clientId=consumer-135, groupId=f78d8c11-7ad0-4d75-9a53-d5dddbfce143] Resetting offset for partition stream9-0 to offset 63279.
2020-01-07 19:19:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 54f22661-c951-4fa7-a1ae-c41ba17d0f40
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-136, groupId=54f22661-c951-4fa7-a1ae-c41ba17d0f40] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-136, groupId=54f22661-c951-4fa7-a1ae-c41ba17d0f40] Revoking previously assigned partitions []
2020-01-07 19:19:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-136, groupId=54f22661-c951-4fa7-a1ae-c41ba17d0f40] (Re-)joining group
2020-01-07 19:19:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-136, groupId=54f22661-c951-4fa7-a1ae-c41ba17d0f40] Successfully joined group with generation 1
2020-01-07 19:19:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-136, groupId=54f22661-c951-4fa7-a1ae-c41ba17d0f40] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:57 INFO  Fetcher:583 - [Consumer clientId=consumer-136, groupId=54f22661-c951-4fa7-a1ae-c41ba17d0f40] Resetting offset for partition stream9-0 to offset 63280.
2020-01-07 19:19:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8aa026b5-459c-4a43-a88c-8d0dc3a8e986
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-137, groupId=8aa026b5-459c-4a43-a88c-8d0dc3a8e986] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-137, groupId=8aa026b5-459c-4a43-a88c-8d0dc3a8e986] Revoking previously assigned partitions []
2020-01-07 19:19:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-137, groupId=8aa026b5-459c-4a43-a88c-8d0dc3a8e986] (Re-)joining group
2020-01-07 19:19:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-137, groupId=8aa026b5-459c-4a43-a88c-8d0dc3a8e986] Successfully joined group with generation 1
2020-01-07 19:19:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-137, groupId=8aa026b5-459c-4a43-a88c-8d0dc3a8e986] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:57 INFO  Fetcher:583 - [Consumer clientId=consumer-137, groupId=8aa026b5-459c-4a43-a88c-8d0dc3a8e986] Resetting offset for partition stream9-0 to offset 63281.
2020-01-07 19:19:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 10e0611f-55f2-44e3-86bb-fa0ba0ff3cf8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-138, groupId=10e0611f-55f2-44e3-86bb-fa0ba0ff3cf8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-138, groupId=10e0611f-55f2-44e3-86bb-fa0ba0ff3cf8] Revoking previously assigned partitions []
2020-01-07 19:19:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-138, groupId=10e0611f-55f2-44e3-86bb-fa0ba0ff3cf8] (Re-)joining group
2020-01-07 19:19:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-138, groupId=10e0611f-55f2-44e3-86bb-fa0ba0ff3cf8] Successfully joined group with generation 1
2020-01-07 19:19:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-138, groupId=10e0611f-55f2-44e3-86bb-fa0ba0ff3cf8] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:57 INFO  Fetcher:583 - [Consumer clientId=consumer-138, groupId=10e0611f-55f2-44e3-86bb-fa0ba0ff3cf8] Resetting offset for partition stream9-0 to offset 63282.
2020-01-07 19:19:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f5cf640f-2cd9-46ce-bcea-025505a969c1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-139, groupId=f5cf640f-2cd9-46ce-bcea-025505a969c1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-139, groupId=f5cf640f-2cd9-46ce-bcea-025505a969c1] Revoking previously assigned partitions []
2020-01-07 19:19:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-139, groupId=f5cf640f-2cd9-46ce-bcea-025505a969c1] (Re-)joining group
2020-01-07 19:19:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-139, groupId=f5cf640f-2cd9-46ce-bcea-025505a969c1] Successfully joined group with generation 1
2020-01-07 19:19:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-139, groupId=f5cf640f-2cd9-46ce-bcea-025505a969c1] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:57 INFO  Fetcher:583 - [Consumer clientId=consumer-139, groupId=f5cf640f-2cd9-46ce-bcea-025505a969c1] Resetting offset for partition stream9-0 to offset 63283.
2020-01-07 19:19:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6e9e6311-f78b-4e20-b9a6-72e6774eb5b4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-140, groupId=6e9e6311-f78b-4e20-b9a6-72e6774eb5b4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-140, groupId=6e9e6311-f78b-4e20-b9a6-72e6774eb5b4] Revoking previously assigned partitions []
2020-01-07 19:19:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-140, groupId=6e9e6311-f78b-4e20-b9a6-72e6774eb5b4] (Re-)joining group
2020-01-07 19:19:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-140, groupId=6e9e6311-f78b-4e20-b9a6-72e6774eb5b4] Successfully joined group with generation 1
2020-01-07 19:19:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-140, groupId=6e9e6311-f78b-4e20-b9a6-72e6774eb5b4] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:57 INFO  Fetcher:583 - [Consumer clientId=consumer-140, groupId=6e9e6311-f78b-4e20-b9a6-72e6774eb5b4] Resetting offset for partition stream9-0 to offset 63284.
2020-01-07 19:19:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7add4eed-650f-43a7-8813-4d3f2fb41b20
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-141, groupId=7add4eed-650f-43a7-8813-4d3f2fb41b20] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-141, groupId=7add4eed-650f-43a7-8813-4d3f2fb41b20] Revoking previously assigned partitions []
2020-01-07 19:19:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-141, groupId=7add4eed-650f-43a7-8813-4d3f2fb41b20] (Re-)joining group
2020-01-07 19:19:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-141, groupId=7add4eed-650f-43a7-8813-4d3f2fb41b20] Successfully joined group with generation 1
2020-01-07 19:19:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-141, groupId=7add4eed-650f-43a7-8813-4d3f2fb41b20] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:58 INFO  Fetcher:583 - [Consumer clientId=consumer-141, groupId=7add4eed-650f-43a7-8813-4d3f2fb41b20] Resetting offset for partition stream9-0 to offset 63285.
2020-01-07 19:19:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2421e305-f56b-4a2a-ae3a-8c9548470232
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-142, groupId=2421e305-f56b-4a2a-ae3a-8c9548470232] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-142, groupId=2421e305-f56b-4a2a-ae3a-8c9548470232] Revoking previously assigned partitions []
2020-01-07 19:19:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-142, groupId=2421e305-f56b-4a2a-ae3a-8c9548470232] (Re-)joining group
2020-01-07 19:19:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-142, groupId=2421e305-f56b-4a2a-ae3a-8c9548470232] Successfully joined group with generation 1
2020-01-07 19:19:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-142, groupId=2421e305-f56b-4a2a-ae3a-8c9548470232] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:58 INFO  Fetcher:583 - [Consumer clientId=consumer-142, groupId=2421e305-f56b-4a2a-ae3a-8c9548470232] Resetting offset for partition stream9-0 to offset 63286.
2020-01-07 19:19:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 34fe3e77-be9a-4069-a804-7002f36fe9c6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-143, groupId=34fe3e77-be9a-4069-a804-7002f36fe9c6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-143, groupId=34fe3e77-be9a-4069-a804-7002f36fe9c6] Revoking previously assigned partitions []
2020-01-07 19:19:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-143, groupId=34fe3e77-be9a-4069-a804-7002f36fe9c6] (Re-)joining group
2020-01-07 19:19:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-143, groupId=34fe3e77-be9a-4069-a804-7002f36fe9c6] Successfully joined group with generation 1
2020-01-07 19:19:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-143, groupId=34fe3e77-be9a-4069-a804-7002f36fe9c6] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:58 INFO  Fetcher:583 - [Consumer clientId=consumer-143, groupId=34fe3e77-be9a-4069-a804-7002f36fe9c6] Resetting offset for partition stream9-0 to offset 63287.
2020-01-07 19:19:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 52644b8d-df38-45e0-a618-8a7df913e7b4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-144, groupId=52644b8d-df38-45e0-a618-8a7df913e7b4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-144, groupId=52644b8d-df38-45e0-a618-8a7df913e7b4] Revoking previously assigned partitions []
2020-01-07 19:19:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-144, groupId=52644b8d-df38-45e0-a618-8a7df913e7b4] (Re-)joining group
2020-01-07 19:19:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-144, groupId=52644b8d-df38-45e0-a618-8a7df913e7b4] Successfully joined group with generation 1
2020-01-07 19:19:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-144, groupId=52644b8d-df38-45e0-a618-8a7df913e7b4] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:58 INFO  Fetcher:583 - [Consumer clientId=consumer-144, groupId=52644b8d-df38-45e0-a618-8a7df913e7b4] Resetting offset for partition stream9-0 to offset 63288.
2020-01-07 19:19:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b2491723-4687-450a-854f-7e3c2dfc271b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-145, groupId=b2491723-4687-450a-854f-7e3c2dfc271b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-145, groupId=b2491723-4687-450a-854f-7e3c2dfc271b] Revoking previously assigned partitions []
2020-01-07 19:19:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-145, groupId=b2491723-4687-450a-854f-7e3c2dfc271b] (Re-)joining group
2020-01-07 19:19:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-145, groupId=b2491723-4687-450a-854f-7e3c2dfc271b] Successfully joined group with generation 1
2020-01-07 19:19:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-145, groupId=b2491723-4687-450a-854f-7e3c2dfc271b] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:58 INFO  Fetcher:583 - [Consumer clientId=consumer-145, groupId=b2491723-4687-450a-854f-7e3c2dfc271b] Resetting offset for partition stream9-0 to offset 63289.
2020-01-07 19:19:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c4d20237-dd75-4501-8107-6536de9b147a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-146, groupId=c4d20237-dd75-4501-8107-6536de9b147a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-146, groupId=c4d20237-dd75-4501-8107-6536de9b147a] Revoking previously assigned partitions []
2020-01-07 19:19:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-146, groupId=c4d20237-dd75-4501-8107-6536de9b147a] (Re-)joining group
2020-01-07 19:19:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-146, groupId=c4d20237-dd75-4501-8107-6536de9b147a] Successfully joined group with generation 1
2020-01-07 19:19:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-146, groupId=c4d20237-dd75-4501-8107-6536de9b147a] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:58 INFO  Fetcher:583 - [Consumer clientId=consumer-146, groupId=c4d20237-dd75-4501-8107-6536de9b147a] Resetting offset for partition stream9-0 to offset 63290.
2020-01-07 19:19:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 490ccb1e-e267-43e4-a26d-e0f06df8d951
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-147, groupId=490ccb1e-e267-43e4-a26d-e0f06df8d951] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-147, groupId=490ccb1e-e267-43e4-a26d-e0f06df8d951] Revoking previously assigned partitions []
2020-01-07 19:19:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-147, groupId=490ccb1e-e267-43e4-a26d-e0f06df8d951] (Re-)joining group
2020-01-07 19:19:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-147, groupId=490ccb1e-e267-43e4-a26d-e0f06df8d951] Successfully joined group with generation 1
2020-01-07 19:19:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-147, groupId=490ccb1e-e267-43e4-a26d-e0f06df8d951] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:58 INFO  Fetcher:583 - [Consumer clientId=consumer-147, groupId=490ccb1e-e267-43e4-a26d-e0f06df8d951] Resetting offset for partition stream9-0 to offset 63291.
2020-01-07 19:19:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d03f99e0-ec34-4130-ad8a-5482ba257d02
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-148, groupId=d03f99e0-ec34-4130-ad8a-5482ba257d02] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-148, groupId=d03f99e0-ec34-4130-ad8a-5482ba257d02] Revoking previously assigned partitions []
2020-01-07 19:19:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-148, groupId=d03f99e0-ec34-4130-ad8a-5482ba257d02] (Re-)joining group
2020-01-07 19:19:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-148, groupId=d03f99e0-ec34-4130-ad8a-5482ba257d02] Successfully joined group with generation 1
2020-01-07 19:19:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-148, groupId=d03f99e0-ec34-4130-ad8a-5482ba257d02] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:58 INFO  Fetcher:583 - [Consumer clientId=consumer-148, groupId=d03f99e0-ec34-4130-ad8a-5482ba257d02] Resetting offset for partition stream9-0 to offset 63292.
2020-01-07 19:19:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4b3734ec-1418-4fb8-b039-65226116c6bb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-149, groupId=4b3734ec-1418-4fb8-b039-65226116c6bb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-149, groupId=4b3734ec-1418-4fb8-b039-65226116c6bb] Revoking previously assigned partitions []
2020-01-07 19:19:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-149, groupId=4b3734ec-1418-4fb8-b039-65226116c6bb] (Re-)joining group
2020-01-07 19:19:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-149, groupId=4b3734ec-1418-4fb8-b039-65226116c6bb] Successfully joined group with generation 1
2020-01-07 19:19:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-149, groupId=4b3734ec-1418-4fb8-b039-65226116c6bb] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:58 INFO  Fetcher:583 - [Consumer clientId=consumer-149, groupId=4b3734ec-1418-4fb8-b039-65226116c6bb] Resetting offset for partition stream9-0 to offset 63293.
2020-01-07 19:19:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1efed800-e1dd-43a6-97bc-07548294ac2b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-150, groupId=1efed800-e1dd-43a6-97bc-07548294ac2b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-150, groupId=1efed800-e1dd-43a6-97bc-07548294ac2b] Revoking previously assigned partitions []
2020-01-07 19:19:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-150, groupId=1efed800-e1dd-43a6-97bc-07548294ac2b] (Re-)joining group
2020-01-07 19:19:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-150, groupId=1efed800-e1dd-43a6-97bc-07548294ac2b] Successfully joined group with generation 1
2020-01-07 19:19:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-150, groupId=1efed800-e1dd-43a6-97bc-07548294ac2b] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:58 INFO  Fetcher:583 - [Consumer clientId=consumer-150, groupId=1efed800-e1dd-43a6-97bc-07548294ac2b] Resetting offset for partition stream9-0 to offset 63294.
2020-01-07 19:19:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6824fcd9-fb23-4c66-9270-91cc854f1bfa
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-151, groupId=6824fcd9-fb23-4c66-9270-91cc854f1bfa] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-151, groupId=6824fcd9-fb23-4c66-9270-91cc854f1bfa] Revoking previously assigned partitions []
2020-01-07 19:19:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-151, groupId=6824fcd9-fb23-4c66-9270-91cc854f1bfa] (Re-)joining group
2020-01-07 19:19:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-151, groupId=6824fcd9-fb23-4c66-9270-91cc854f1bfa] Successfully joined group with generation 1
2020-01-07 19:19:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-151, groupId=6824fcd9-fb23-4c66-9270-91cc854f1bfa] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:58 INFO  Fetcher:583 - [Consumer clientId=consumer-151, groupId=6824fcd9-fb23-4c66-9270-91cc854f1bfa] Resetting offset for partition stream9-0 to offset 63295.
2020-01-07 19:19:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4bf989c4-7195-4940-aa86-ad2cd81a49dd
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-152, groupId=4bf989c4-7195-4940-aa86-ad2cd81a49dd] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-152, groupId=4bf989c4-7195-4940-aa86-ad2cd81a49dd] Revoking previously assigned partitions []
2020-01-07 19:19:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-152, groupId=4bf989c4-7195-4940-aa86-ad2cd81a49dd] (Re-)joining group
2020-01-07 19:19:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-152, groupId=4bf989c4-7195-4940-aa86-ad2cd81a49dd] Successfully joined group with generation 1
2020-01-07 19:19:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-152, groupId=4bf989c4-7195-4940-aa86-ad2cd81a49dd] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:58 INFO  Fetcher:583 - [Consumer clientId=consumer-152, groupId=4bf989c4-7195-4940-aa86-ad2cd81a49dd] Resetting offset for partition stream9-0 to offset 63296.
2020-01-07 19:19:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 22ad37bf-518d-4b94-8585-2496487a9311
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-153, groupId=22ad37bf-518d-4b94-8585-2496487a9311] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-153, groupId=22ad37bf-518d-4b94-8585-2496487a9311] Revoking previously assigned partitions []
2020-01-07 19:19:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-153, groupId=22ad37bf-518d-4b94-8585-2496487a9311] (Re-)joining group
2020-01-07 19:19:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-153, groupId=22ad37bf-518d-4b94-8585-2496487a9311] Successfully joined group with generation 1
2020-01-07 19:19:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-153, groupId=22ad37bf-518d-4b94-8585-2496487a9311] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:58 INFO  Fetcher:583 - [Consumer clientId=consumer-153, groupId=22ad37bf-518d-4b94-8585-2496487a9311] Resetting offset for partition stream9-0 to offset 63297.
2020-01-07 19:19:59 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f92c93a2-ac4c-4201-9959-1a4dd4e54f5b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:59 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:59 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:59 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:59 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-154, groupId=f92c93a2-ac4c-4201-9959-1a4dd4e54f5b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:59 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-154, groupId=f92c93a2-ac4c-4201-9959-1a4dd4e54f5b] Revoking previously assigned partitions []
2020-01-07 19:19:59 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-154, groupId=f92c93a2-ac4c-4201-9959-1a4dd4e54f5b] (Re-)joining group
2020-01-07 19:19:59 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-154, groupId=f92c93a2-ac4c-4201-9959-1a4dd4e54f5b] Successfully joined group with generation 1
2020-01-07 19:19:59 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-154, groupId=f92c93a2-ac4c-4201-9959-1a4dd4e54f5b] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:59 INFO  Fetcher:583 - [Consumer clientId=consumer-154, groupId=f92c93a2-ac4c-4201-9959-1a4dd4e54f5b] Resetting offset for partition stream9-0 to offset 63298.
2020-01-07 19:19:59 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c8ebafd5-7fdb-4683-9e96-31652cc6d639
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:59 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:59 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:59 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:59 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-155, groupId=c8ebafd5-7fdb-4683-9e96-31652cc6d639] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:59 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-155, groupId=c8ebafd5-7fdb-4683-9e96-31652cc6d639] Revoking previously assigned partitions []
2020-01-07 19:19:59 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-155, groupId=c8ebafd5-7fdb-4683-9e96-31652cc6d639] (Re-)joining group
2020-01-07 19:19:59 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-155, groupId=c8ebafd5-7fdb-4683-9e96-31652cc6d639] Successfully joined group with generation 1
2020-01-07 19:19:59 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-155, groupId=c8ebafd5-7fdb-4683-9e96-31652cc6d639] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:59 INFO  Fetcher:583 - [Consumer clientId=consumer-155, groupId=c8ebafd5-7fdb-4683-9e96-31652cc6d639] Resetting offset for partition stream9-0 to offset 63299.
2020-01-07 19:19:59 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fb41f6f2-b52c-4563-952f-19dac761a03e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:59 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:59 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:59 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:59 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-156, groupId=fb41f6f2-b52c-4563-952f-19dac761a03e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:59 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-156, groupId=fb41f6f2-b52c-4563-952f-19dac761a03e] Revoking previously assigned partitions []
2020-01-07 19:19:59 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-156, groupId=fb41f6f2-b52c-4563-952f-19dac761a03e] (Re-)joining group
2020-01-07 19:19:59 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-156, groupId=fb41f6f2-b52c-4563-952f-19dac761a03e] Successfully joined group with generation 1
2020-01-07 19:19:59 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-156, groupId=fb41f6f2-b52c-4563-952f-19dac761a03e] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:59 INFO  Fetcher:583 - [Consumer clientId=consumer-156, groupId=fb41f6f2-b52c-4563-952f-19dac761a03e] Resetting offset for partition stream9-0 to offset 63300.
2020-01-07 19:19:59 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = da3a0689-e14c-4738-af38-5b20eecee382
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:59 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:59 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:59 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:59 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-157, groupId=da3a0689-e14c-4738-af38-5b20eecee382] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:59 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-157, groupId=da3a0689-e14c-4738-af38-5b20eecee382] Revoking previously assigned partitions []
2020-01-07 19:19:59 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-157, groupId=da3a0689-e14c-4738-af38-5b20eecee382] (Re-)joining group
2020-01-07 19:19:59 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-157, groupId=da3a0689-e14c-4738-af38-5b20eecee382] Successfully joined group with generation 1
2020-01-07 19:19:59 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-157, groupId=da3a0689-e14c-4738-af38-5b20eecee382] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:59 INFO  Fetcher:583 - [Consumer clientId=consumer-157, groupId=da3a0689-e14c-4738-af38-5b20eecee382] Resetting offset for partition stream9-0 to offset 63301.
2020-01-07 19:19:59 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0557ef1e-829d-4bc1-af36-4d502f64a898
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:59 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:59 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:59 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:59 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-158, groupId=0557ef1e-829d-4bc1-af36-4d502f64a898] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:59 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-158, groupId=0557ef1e-829d-4bc1-af36-4d502f64a898] Revoking previously assigned partitions []
2020-01-07 19:19:59 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-158, groupId=0557ef1e-829d-4bc1-af36-4d502f64a898] (Re-)joining group
2020-01-07 19:19:59 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-158, groupId=0557ef1e-829d-4bc1-af36-4d502f64a898] Successfully joined group with generation 1
2020-01-07 19:19:59 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-158, groupId=0557ef1e-829d-4bc1-af36-4d502f64a898] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:59 INFO  Fetcher:583 - [Consumer clientId=consumer-158, groupId=0557ef1e-829d-4bc1-af36-4d502f64a898] Resetting offset for partition stream9-0 to offset 63302.
2020-01-07 19:19:59 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6f2480db-8b86-4ae5-a5a6-92e652cbff66
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:59 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:59 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:59 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:59 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-159, groupId=6f2480db-8b86-4ae5-a5a6-92e652cbff66] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:59 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-159, groupId=6f2480db-8b86-4ae5-a5a6-92e652cbff66] Revoking previously assigned partitions []
2020-01-07 19:19:59 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-159, groupId=6f2480db-8b86-4ae5-a5a6-92e652cbff66] (Re-)joining group
2020-01-07 19:19:59 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-159, groupId=6f2480db-8b86-4ae5-a5a6-92e652cbff66] Successfully joined group with generation 1
2020-01-07 19:19:59 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-159, groupId=6f2480db-8b86-4ae5-a5a6-92e652cbff66] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:59 INFO  Fetcher:583 - [Consumer clientId=consumer-159, groupId=6f2480db-8b86-4ae5-a5a6-92e652cbff66] Resetting offset for partition stream9-0 to offset 63303.
2020-01-07 19:19:59 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6bdf61c1-53f7-40c9-b723-355634116f61
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:19:59 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:19:59 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:19:59 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:19:59 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-160, groupId=6bdf61c1-53f7-40c9-b723-355634116f61] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:19:59 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-160, groupId=6bdf61c1-53f7-40c9-b723-355634116f61] Revoking previously assigned partitions []
2020-01-07 19:19:59 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-160, groupId=6bdf61c1-53f7-40c9-b723-355634116f61] (Re-)joining group
2020-01-07 19:19:59 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-160, groupId=6bdf61c1-53f7-40c9-b723-355634116f61] Successfully joined group with generation 1
2020-01-07 19:19:59 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-160, groupId=6bdf61c1-53f7-40c9-b723-355634116f61] Setting newly assigned partitions [stream9-0]
2020-01-07 19:19:59 INFO  Fetcher:583 - [Consumer clientId=consumer-160, groupId=6bdf61c1-53f7-40c9-b723-355634116f61] Resetting offset for partition stream9-0 to offset 63304.
2020-01-07 19:20:00 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = bbdfab0b-c31f-44db-95f6-f847f923222f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:20:00 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:20:00 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:20:00 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:20:00 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-161, groupId=bbdfab0b-c31f-44db-95f6-f847f923222f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:20:00 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-161, groupId=bbdfab0b-c31f-44db-95f6-f847f923222f] Revoking previously assigned partitions []
2020-01-07 19:20:00 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-161, groupId=bbdfab0b-c31f-44db-95f6-f847f923222f] (Re-)joining group
2020-01-07 19:20:00 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-161, groupId=bbdfab0b-c31f-44db-95f6-f847f923222f] Successfully joined group with generation 1
2020-01-07 19:20:00 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-161, groupId=bbdfab0b-c31f-44db-95f6-f847f923222f] Setting newly assigned partitions [stream9-0]
2020-01-07 19:20:00 INFO  Fetcher:583 - [Consumer clientId=consumer-161, groupId=bbdfab0b-c31f-44db-95f6-f847f923222f] Resetting offset for partition stream9-0 to offset 63306.
2020-01-07 19:20:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 282ba632-9158-4fbb-80bd-6d9c2e14e3c9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:20:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:20:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:20:01 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:20:01 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-162, groupId=282ba632-9158-4fbb-80bd-6d9c2e14e3c9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:20:01 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-162, groupId=282ba632-9158-4fbb-80bd-6d9c2e14e3c9] Revoking previously assigned partitions []
2020-01-07 19:20:01 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-162, groupId=282ba632-9158-4fbb-80bd-6d9c2e14e3c9] (Re-)joining group
2020-01-07 19:20:01 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-162, groupId=282ba632-9158-4fbb-80bd-6d9c2e14e3c9] Successfully joined group with generation 1
2020-01-07 19:20:01 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-162, groupId=282ba632-9158-4fbb-80bd-6d9c2e14e3c9] Setting newly assigned partitions [stream9-0]
2020-01-07 19:20:01 INFO  Fetcher:583 - [Consumer clientId=consumer-162, groupId=282ba632-9158-4fbb-80bd-6d9c2e14e3c9] Resetting offset for partition stream9-0 to offset 63310.
2020-01-07 19:20:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e82a8bb7-3bb8-410c-bc3c-f2e82c9da218
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:20:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:20:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:20:01 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:20:01 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-163, groupId=e82a8bb7-3bb8-410c-bc3c-f2e82c9da218] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:20:01 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-163, groupId=e82a8bb7-3bb8-410c-bc3c-f2e82c9da218] Revoking previously assigned partitions []
2020-01-07 19:20:01 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-163, groupId=e82a8bb7-3bb8-410c-bc3c-f2e82c9da218] (Re-)joining group
2020-01-07 19:20:01 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-163, groupId=e82a8bb7-3bb8-410c-bc3c-f2e82c9da218] Successfully joined group with generation 1
2020-01-07 19:20:01 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-163, groupId=e82a8bb7-3bb8-410c-bc3c-f2e82c9da218] Setting newly assigned partitions [stream9-0]
2020-01-07 19:20:01 INFO  Fetcher:583 - [Consumer clientId=consumer-163, groupId=e82a8bb7-3bb8-410c-bc3c-f2e82c9da218] Resetting offset for partition stream9-0 to offset 63311.
2020-01-07 19:20:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1a7abb63-76d5-4af0-b731-4ff407085509
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:20:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:20:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:20:01 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:20:01 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-164, groupId=1a7abb63-76d5-4af0-b731-4ff407085509] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:20:01 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-164, groupId=1a7abb63-76d5-4af0-b731-4ff407085509] Revoking previously assigned partitions []
2020-01-07 19:20:01 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-164, groupId=1a7abb63-76d5-4af0-b731-4ff407085509] (Re-)joining group
2020-01-07 19:20:01 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-164, groupId=1a7abb63-76d5-4af0-b731-4ff407085509] Successfully joined group with generation 1
2020-01-07 19:20:01 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-164, groupId=1a7abb63-76d5-4af0-b731-4ff407085509] Setting newly assigned partitions [stream9-0]
2020-01-07 19:20:01 INFO  Fetcher:583 - [Consumer clientId=consumer-164, groupId=1a7abb63-76d5-4af0-b731-4ff407085509] Resetting offset for partition stream9-0 to offset 63313.
2020-01-07 19:20:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e01a6cc5-4cc3-4ac5-8f9f-ef229ca49e7e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:20:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:20:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:20:01 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:20:01 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-165, groupId=e01a6cc5-4cc3-4ac5-8f9f-ef229ca49e7e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:20:01 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-165, groupId=e01a6cc5-4cc3-4ac5-8f9f-ef229ca49e7e] Revoking previously assigned partitions []
2020-01-07 19:20:01 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-165, groupId=e01a6cc5-4cc3-4ac5-8f9f-ef229ca49e7e] (Re-)joining group
2020-01-07 19:20:01 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-165, groupId=e01a6cc5-4cc3-4ac5-8f9f-ef229ca49e7e] Successfully joined group with generation 1
2020-01-07 19:20:01 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-165, groupId=e01a6cc5-4cc3-4ac5-8f9f-ef229ca49e7e] Setting newly assigned partitions [stream9-0]
2020-01-07 19:20:01 INFO  Fetcher:583 - [Consumer clientId=consumer-165, groupId=e01a6cc5-4cc3-4ac5-8f9f-ef229ca49e7e] Resetting offset for partition stream9-0 to offset 63315.
2020-01-07 19:20:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4c38631e-d1c5-45e7-9e5f-9b8745bfd920
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:20:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:20:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:20:01 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:20:01 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-166, groupId=4c38631e-d1c5-45e7-9e5f-9b8745bfd920] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:20:01 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-166, groupId=4c38631e-d1c5-45e7-9e5f-9b8745bfd920] Revoking previously assigned partitions []
2020-01-07 19:20:01 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-166, groupId=4c38631e-d1c5-45e7-9e5f-9b8745bfd920] (Re-)joining group
2020-01-07 19:20:01 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-166, groupId=4c38631e-d1c5-45e7-9e5f-9b8745bfd920] Successfully joined group with generation 1
2020-01-07 19:20:01 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-166, groupId=4c38631e-d1c5-45e7-9e5f-9b8745bfd920] Setting newly assigned partitions [stream9-0]
2020-01-07 19:20:01 INFO  Fetcher:583 - [Consumer clientId=consumer-166, groupId=4c38631e-d1c5-45e7-9e5f-9b8745bfd920] Resetting offset for partition stream9-0 to offset 63317.
2020-01-07 19:20:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3b5a0a62-44e5-4ee1-b1b1-c129f4fb6016
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:20:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:20:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:20:01 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:20:01 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-167, groupId=3b5a0a62-44e5-4ee1-b1b1-c129f4fb6016] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:20:01 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-167, groupId=3b5a0a62-44e5-4ee1-b1b1-c129f4fb6016] Revoking previously assigned partitions []
2020-01-07 19:20:01 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-167, groupId=3b5a0a62-44e5-4ee1-b1b1-c129f4fb6016] (Re-)joining group
2020-01-07 19:20:01 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-167, groupId=3b5a0a62-44e5-4ee1-b1b1-c129f4fb6016] Successfully joined group with generation 1
2020-01-07 19:20:01 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-167, groupId=3b5a0a62-44e5-4ee1-b1b1-c129f4fb6016] Setting newly assigned partitions [stream9-0]
2020-01-07 19:20:01 INFO  Fetcher:583 - [Consumer clientId=consumer-167, groupId=3b5a0a62-44e5-4ee1-b1b1-c129f4fb6016] Resetting offset for partition stream9-0 to offset 63319.
2020-01-07 19:20:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c63b016f-49c4-49e6-8737-7c24b7fd2dc7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:20:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:20:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:20:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:20:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-168, groupId=c63b016f-49c4-49e6-8737-7c24b7fd2dc7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:20:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-168, groupId=c63b016f-49c4-49e6-8737-7c24b7fd2dc7] Revoking previously assigned partitions []
2020-01-07 19:20:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-168, groupId=c63b016f-49c4-49e6-8737-7c24b7fd2dc7] (Re-)joining group
2020-01-07 19:20:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-168, groupId=c63b016f-49c4-49e6-8737-7c24b7fd2dc7] Successfully joined group with generation 1
2020-01-07 19:20:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-168, groupId=c63b016f-49c4-49e6-8737-7c24b7fd2dc7] Setting newly assigned partitions [stream9-0]
2020-01-07 19:20:02 INFO  Fetcher:583 - [Consumer clientId=consumer-168, groupId=c63b016f-49c4-49e6-8737-7c24b7fd2dc7] Resetting offset for partition stream9-0 to offset 63320.
2020-01-07 19:20:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3f6eb412-505a-417d-8ef4-b1bbc7ef4e8b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:20:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:20:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:20:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:20:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-169, groupId=3f6eb412-505a-417d-8ef4-b1bbc7ef4e8b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:20:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-169, groupId=3f6eb412-505a-417d-8ef4-b1bbc7ef4e8b] Revoking previously assigned partitions []
2020-01-07 19:20:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-169, groupId=3f6eb412-505a-417d-8ef4-b1bbc7ef4e8b] (Re-)joining group
2020-01-07 19:20:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-169, groupId=3f6eb412-505a-417d-8ef4-b1bbc7ef4e8b] Successfully joined group with generation 1
2020-01-07 19:20:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-169, groupId=3f6eb412-505a-417d-8ef4-b1bbc7ef4e8b] Setting newly assigned partitions [stream9-0]
2020-01-07 19:20:02 INFO  Fetcher:583 - [Consumer clientId=consumer-169, groupId=3f6eb412-505a-417d-8ef4-b1bbc7ef4e8b] Resetting offset for partition stream9-0 to offset 63322.
2020-01-07 19:20:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 73580fbb-7203-4f74-a75e-69a6d0e36be9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:20:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:20:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:20:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:20:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-170, groupId=73580fbb-7203-4f74-a75e-69a6d0e36be9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:20:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-170, groupId=73580fbb-7203-4f74-a75e-69a6d0e36be9] Revoking previously assigned partitions []
2020-01-07 19:20:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-170, groupId=73580fbb-7203-4f74-a75e-69a6d0e36be9] (Re-)joining group
2020-01-07 19:20:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-170, groupId=73580fbb-7203-4f74-a75e-69a6d0e36be9] Successfully joined group with generation 1
2020-01-07 19:20:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-170, groupId=73580fbb-7203-4f74-a75e-69a6d0e36be9] Setting newly assigned partitions [stream9-0]
2020-01-07 19:20:02 INFO  Fetcher:583 - [Consumer clientId=consumer-170, groupId=73580fbb-7203-4f74-a75e-69a6d0e36be9] Resetting offset for partition stream9-0 to offset 63324.
2020-01-07 19:20:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 660d6fcb-2a24-4634-a771-abc8f608aea9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:20:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:20:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:20:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:20:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-171, groupId=660d6fcb-2a24-4634-a771-abc8f608aea9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:20:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-171, groupId=660d6fcb-2a24-4634-a771-abc8f608aea9] Revoking previously assigned partitions []
2020-01-07 19:20:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-171, groupId=660d6fcb-2a24-4634-a771-abc8f608aea9] (Re-)joining group
2020-01-07 19:20:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-171, groupId=660d6fcb-2a24-4634-a771-abc8f608aea9] Successfully joined group with generation 1
2020-01-07 19:20:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-171, groupId=660d6fcb-2a24-4634-a771-abc8f608aea9] Setting newly assigned partitions [stream9-0]
2020-01-07 19:20:02 INFO  Fetcher:583 - [Consumer clientId=consumer-171, groupId=660d6fcb-2a24-4634-a771-abc8f608aea9] Resetting offset for partition stream9-0 to offset 63326.
2020-01-07 19:20:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3cca0488-f122-4553-a2f8-bdfe34026769
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:20:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:20:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:20:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:20:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-172, groupId=3cca0488-f122-4553-a2f8-bdfe34026769] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:20:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-172, groupId=3cca0488-f122-4553-a2f8-bdfe34026769] Revoking previously assigned partitions []
2020-01-07 19:20:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-172, groupId=3cca0488-f122-4553-a2f8-bdfe34026769] (Re-)joining group
2020-01-07 19:20:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-172, groupId=3cca0488-f122-4553-a2f8-bdfe34026769] Successfully joined group with generation 1
2020-01-07 19:20:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-172, groupId=3cca0488-f122-4553-a2f8-bdfe34026769] Setting newly assigned partitions [stream9-0]
2020-01-07 19:20:02 INFO  Fetcher:583 - [Consumer clientId=consumer-172, groupId=3cca0488-f122-4553-a2f8-bdfe34026769] Resetting offset for partition stream9-0 to offset 63327.
2020-01-07 19:20:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 699fa430-1cf2-44c1-ae88-99cf8d202a5b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:20:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:20:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:20:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:20:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-173, groupId=699fa430-1cf2-44c1-ae88-99cf8d202a5b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:20:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-173, groupId=699fa430-1cf2-44c1-ae88-99cf8d202a5b] Revoking previously assigned partitions []
2020-01-07 19:20:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-173, groupId=699fa430-1cf2-44c1-ae88-99cf8d202a5b] (Re-)joining group
2020-01-07 19:20:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-173, groupId=699fa430-1cf2-44c1-ae88-99cf8d202a5b] Successfully joined group with generation 1
2020-01-07 19:20:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-173, groupId=699fa430-1cf2-44c1-ae88-99cf8d202a5b] Setting newly assigned partitions [stream9-0]
2020-01-07 19:20:02 INFO  Fetcher:583 - [Consumer clientId=consumer-173, groupId=699fa430-1cf2-44c1-ae88-99cf8d202a5b] Resetting offset for partition stream9-0 to offset 63328.
2020-01-07 19:20:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3527ec52-85b3-40f7-8309-908a301d0b04
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:20:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:20:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:20:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:20:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-174, groupId=3527ec52-85b3-40f7-8309-908a301d0b04] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:20:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-174, groupId=3527ec52-85b3-40f7-8309-908a301d0b04] Revoking previously assigned partitions []
2020-01-07 19:20:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-174, groupId=3527ec52-85b3-40f7-8309-908a301d0b04] (Re-)joining group
2020-01-07 19:20:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-174, groupId=3527ec52-85b3-40f7-8309-908a301d0b04] Successfully joined group with generation 1
2020-01-07 19:20:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-174, groupId=3527ec52-85b3-40f7-8309-908a301d0b04] Setting newly assigned partitions [stream9-0]
2020-01-07 19:20:02 INFO  Fetcher:583 - [Consumer clientId=consumer-174, groupId=3527ec52-85b3-40f7-8309-908a301d0b04] Resetting offset for partition stream9-0 to offset 63329.
2020-01-07 19:20:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b29b4d57-1aea-457e-ae83-2afc9d791648
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:20:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:20:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:20:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:20:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-175, groupId=b29b4d57-1aea-457e-ae83-2afc9d791648] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:20:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-175, groupId=b29b4d57-1aea-457e-ae83-2afc9d791648] Revoking previously assigned partitions []
2020-01-07 19:20:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-175, groupId=b29b4d57-1aea-457e-ae83-2afc9d791648] (Re-)joining group
2020-01-07 19:20:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-175, groupId=b29b4d57-1aea-457e-ae83-2afc9d791648] Successfully joined group with generation 1
2020-01-07 19:20:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-175, groupId=b29b4d57-1aea-457e-ae83-2afc9d791648] Setting newly assigned partitions [stream9-0]
2020-01-07 19:20:02 INFO  Fetcher:583 - [Consumer clientId=consumer-175, groupId=b29b4d57-1aea-457e-ae83-2afc9d791648] Resetting offset for partition stream9-0 to offset 63330.
2020-01-07 19:20:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 41c679d0-cfd2-4e67-aba1-e1c943c2a7da
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:20:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:20:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:20:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:20:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-176, groupId=41c679d0-cfd2-4e67-aba1-e1c943c2a7da] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:20:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-176, groupId=41c679d0-cfd2-4e67-aba1-e1c943c2a7da] Revoking previously assigned partitions []
2020-01-07 19:20:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-176, groupId=41c679d0-cfd2-4e67-aba1-e1c943c2a7da] (Re-)joining group
2020-01-07 19:20:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-176, groupId=41c679d0-cfd2-4e67-aba1-e1c943c2a7da] Successfully joined group with generation 1
2020-01-07 19:20:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-176, groupId=41c679d0-cfd2-4e67-aba1-e1c943c2a7da] Setting newly assigned partitions [stream9-0]
2020-01-07 19:20:02 INFO  Fetcher:583 - [Consumer clientId=consumer-176, groupId=41c679d0-cfd2-4e67-aba1-e1c943c2a7da] Resetting offset for partition stream9-0 to offset 63331.
2020-01-07 19:20:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 86943f9f-e3c0-497d-a7df-d3278bc1bf73
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:20:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:20:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:20:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:20:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-177, groupId=86943f9f-e3c0-497d-a7df-d3278bc1bf73] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:20:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-177, groupId=86943f9f-e3c0-497d-a7df-d3278bc1bf73] Revoking previously assigned partitions []
2020-01-07 19:20:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-177, groupId=86943f9f-e3c0-497d-a7df-d3278bc1bf73] (Re-)joining group
2020-01-07 19:20:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-177, groupId=86943f9f-e3c0-497d-a7df-d3278bc1bf73] Successfully joined group with generation 1
2020-01-07 19:20:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-177, groupId=86943f9f-e3c0-497d-a7df-d3278bc1bf73] Setting newly assigned partitions [stream9-0]
2020-01-07 19:20:02 INFO  Fetcher:583 - [Consumer clientId=consumer-177, groupId=86943f9f-e3c0-497d-a7df-d3278bc1bf73] Resetting offset for partition stream9-0 to offset 63332.
2020-01-07 19:20:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 34f3f774-69b7-4dc0-8b61-0932d64e03e0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:20:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:20:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:20:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:20:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-178, groupId=34f3f774-69b7-4dc0-8b61-0932d64e03e0] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:20:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-178, groupId=34f3f774-69b7-4dc0-8b61-0932d64e03e0] Revoking previously assigned partitions []
2020-01-07 19:20:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-178, groupId=34f3f774-69b7-4dc0-8b61-0932d64e03e0] (Re-)joining group
2020-01-07 19:20:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-178, groupId=34f3f774-69b7-4dc0-8b61-0932d64e03e0] Successfully joined group with generation 1
2020-01-07 19:20:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-178, groupId=34f3f774-69b7-4dc0-8b61-0932d64e03e0] Setting newly assigned partitions [stream9-0]
2020-01-07 19:20:02 INFO  Fetcher:583 - [Consumer clientId=consumer-178, groupId=34f3f774-69b7-4dc0-8b61-0932d64e03e0] Resetting offset for partition stream9-0 to offset 63333.
2020-01-07 19:20:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8d71c374-f8d4-4c8d-aabb-5168b845c5d7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:20:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:20:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:20:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:20:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-179, groupId=8d71c374-f8d4-4c8d-aabb-5168b845c5d7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:20:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-179, groupId=8d71c374-f8d4-4c8d-aabb-5168b845c5d7] Revoking previously assigned partitions []
2020-01-07 19:20:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-179, groupId=8d71c374-f8d4-4c8d-aabb-5168b845c5d7] (Re-)joining group
2020-01-07 19:20:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-179, groupId=8d71c374-f8d4-4c8d-aabb-5168b845c5d7] Successfully joined group with generation 1
2020-01-07 19:20:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-179, groupId=8d71c374-f8d4-4c8d-aabb-5168b845c5d7] Setting newly assigned partitions [stream9-0]
2020-01-07 19:20:02 INFO  Fetcher:583 - [Consumer clientId=consumer-179, groupId=8d71c374-f8d4-4c8d-aabb-5168b845c5d7] Resetting offset for partition stream9-0 to offset 63334.
2020-01-07 19:27:17 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6ceea862-772f-412e-bb58-af9da6c55181
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:27:17 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:27:17 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:27:18 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:27:18 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=6ceea862-772f-412e-bb58-af9da6c55181] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:27:18 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=6ceea862-772f-412e-bb58-af9da6c55181] Revoking previously assigned partitions []
2020-01-07 19:27:18 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=6ceea862-772f-412e-bb58-af9da6c55181] (Re-)joining group
2020-01-07 19:27:18 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=6ceea862-772f-412e-bb58-af9da6c55181] Successfully joined group with generation 1
2020-01-07 19:27:18 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=6ceea862-772f-412e-bb58-af9da6c55181] Setting newly assigned partitions [stream9-0]
2020-01-07 19:27:18 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=6ceea862-772f-412e-bb58-af9da6c55181] Resetting offset for partition stream9-0 to offset 63471.
2020-01-07 19:28:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = aa8eea36-ba37-4b90-8be6-0b8990d8be30
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 19:28:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 19:28:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 19:28:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 19:28:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=aa8eea36-ba37-4b90-8be6-0b8990d8be30] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 19:28:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=aa8eea36-ba37-4b90-8be6-0b8990d8be30] Revoking previously assigned partitions []
2020-01-07 19:28:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=aa8eea36-ba37-4b90-8be6-0b8990d8be30] (Re-)joining group
2020-01-07 19:28:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=aa8eea36-ba37-4b90-8be6-0b8990d8be30] Successfully joined group with generation 1
2020-01-07 19:28:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=aa8eea36-ba37-4b90-8be6-0b8990d8be30] Setting newly assigned partitions [facedetectiontest101-0]
2020-01-07 19:28:23 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=aa8eea36-ba37-4b90-8be6-0b8990d8be30] Resetting offset for partition facedetectiontest101-0 to offset 18453.
2020-01-07 20:00:05 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 382e56c1-3e52-4342-8880-573757cf5471
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:00:05 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:00:05 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:00:06 WARN  NetworkClient:968 - [Consumer clientId=consumer-1, groupId=382e56c1-3e52-4342-8880-573757cf5471] Error while fetching metadata with correlation id 2 : {facedetectiontest101 =INVALID_TOPIC_EXCEPTION}
2020-01-07 20:00:06 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:00:06 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=382e56c1-3e52-4342-8880-573757cf5471] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:00:06 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=382e56c1-3e52-4342-8880-573757cf5471] Revoking previously assigned partitions []
2020-01-07 20:00:06 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=382e56c1-3e52-4342-8880-573757cf5471] (Re-)joining group
2020-01-07 20:00:06 WARN  ConsumerCoordinator:427 - [Consumer clientId=consumer-1, groupId=382e56c1-3e52-4342-8880-573757cf5471] The following subscribed topics are not assigned to any members: [facedetectiontest101 ] 
2020-01-07 20:00:06 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=382e56c1-3e52-4342-8880-573757cf5471] Successfully joined group with generation 1
2020-01-07 20:00:06 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=382e56c1-3e52-4342-8880-573757cf5471] Setting newly assigned partitions []
2020-01-07 20:01:47 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 93e439aa-448a-4f78-be6f-c5347ab7d4ad
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:48 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:48 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:48 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:48 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=93e439aa-448a-4f78-be6f-c5347ab7d4ad] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:48 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=93e439aa-448a-4f78-be6f-c5347ab7d4ad] Revoking previously assigned partitions []
2020-01-07 20:01:48 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=93e439aa-448a-4f78-be6f-c5347ab7d4ad] (Re-)joining group
2020-01-07 20:01:48 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=93e439aa-448a-4f78-be6f-c5347ab7d4ad] Successfully joined group with generation 1
2020-01-07 20:01:48 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=93e439aa-448a-4f78-be6f-c5347ab7d4ad] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:48 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=93e439aa-448a-4f78-be6f-c5347ab7d4ad] Resetting offset for partition test101-0 to offset 310.
2020-01-07 20:01:48 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 05e9e3ed-1856-4d76-97b7-c297b62d8fed
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:48 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:48 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:48 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:48 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-2, groupId=05e9e3ed-1856-4d76-97b7-c297b62d8fed] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:48 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-2, groupId=05e9e3ed-1856-4d76-97b7-c297b62d8fed] Revoking previously assigned partitions []
2020-01-07 20:01:48 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-2, groupId=05e9e3ed-1856-4d76-97b7-c297b62d8fed] (Re-)joining group
2020-01-07 20:01:48 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-2, groupId=05e9e3ed-1856-4d76-97b7-c297b62d8fed] Successfully joined group with generation 1
2020-01-07 20:01:48 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-2, groupId=05e9e3ed-1856-4d76-97b7-c297b62d8fed] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:48 INFO  Fetcher:583 - [Consumer clientId=consumer-2, groupId=05e9e3ed-1856-4d76-97b7-c297b62d8fed] Resetting offset for partition test101-0 to offset 314.
2020-01-07 20:01:48 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fbb7fc1b-8ff2-4ebb-a6be-c7202b20073c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:48 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:48 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:48 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:48 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-3, groupId=fbb7fc1b-8ff2-4ebb-a6be-c7202b20073c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:48 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-3, groupId=fbb7fc1b-8ff2-4ebb-a6be-c7202b20073c] Revoking previously assigned partitions []
2020-01-07 20:01:48 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-3, groupId=fbb7fc1b-8ff2-4ebb-a6be-c7202b20073c] (Re-)joining group
2020-01-07 20:01:48 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-3, groupId=fbb7fc1b-8ff2-4ebb-a6be-c7202b20073c] Successfully joined group with generation 1
2020-01-07 20:01:48 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-3, groupId=fbb7fc1b-8ff2-4ebb-a6be-c7202b20073c] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:48 INFO  Fetcher:583 - [Consumer clientId=consumer-3, groupId=fbb7fc1b-8ff2-4ebb-a6be-c7202b20073c] Resetting offset for partition test101-0 to offset 315.
2020-01-07 20:01:48 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fbd9ba96-fb7f-486e-97b2-dd2620427d4c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:48 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:48 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:48 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:48 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-4, groupId=fbd9ba96-fb7f-486e-97b2-dd2620427d4c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:48 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-4, groupId=fbd9ba96-fb7f-486e-97b2-dd2620427d4c] Revoking previously assigned partitions []
2020-01-07 20:01:48 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-4, groupId=fbd9ba96-fb7f-486e-97b2-dd2620427d4c] (Re-)joining group
2020-01-07 20:01:48 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-4, groupId=fbd9ba96-fb7f-486e-97b2-dd2620427d4c] Successfully joined group with generation 1
2020-01-07 20:01:48 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-4, groupId=fbd9ba96-fb7f-486e-97b2-dd2620427d4c] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:48 INFO  Fetcher:583 - [Consumer clientId=consumer-4, groupId=fbd9ba96-fb7f-486e-97b2-dd2620427d4c] Resetting offset for partition test101-0 to offset 316.
2020-01-07 20:01:48 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = cabe0fff-51b1-4c4d-a77f-1fc5b1c0896c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:48 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:48 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:48 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:48 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-5, groupId=cabe0fff-51b1-4c4d-a77f-1fc5b1c0896c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:48 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-5, groupId=cabe0fff-51b1-4c4d-a77f-1fc5b1c0896c] Revoking previously assigned partitions []
2020-01-07 20:01:48 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-5, groupId=cabe0fff-51b1-4c4d-a77f-1fc5b1c0896c] (Re-)joining group
2020-01-07 20:01:48 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-5, groupId=cabe0fff-51b1-4c4d-a77f-1fc5b1c0896c] Successfully joined group with generation 1
2020-01-07 20:01:48 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-5, groupId=cabe0fff-51b1-4c4d-a77f-1fc5b1c0896c] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:49 INFO  Fetcher:583 - [Consumer clientId=consumer-5, groupId=cabe0fff-51b1-4c4d-a77f-1fc5b1c0896c] Resetting offset for partition test101-0 to offset 318.
2020-01-07 20:01:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6d889e13-e0eb-4b6b-88ef-3ee2a2932d2c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:49 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-6, groupId=6d889e13-e0eb-4b6b-88ef-3ee2a2932d2c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-6, groupId=6d889e13-e0eb-4b6b-88ef-3ee2a2932d2c] Revoking previously assigned partitions []
2020-01-07 20:01:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-6, groupId=6d889e13-e0eb-4b6b-88ef-3ee2a2932d2c] (Re-)joining group
2020-01-07 20:01:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-6, groupId=6d889e13-e0eb-4b6b-88ef-3ee2a2932d2c] Successfully joined group with generation 1
2020-01-07 20:01:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-6, groupId=6d889e13-e0eb-4b6b-88ef-3ee2a2932d2c] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:49 INFO  Fetcher:583 - [Consumer clientId=consumer-6, groupId=6d889e13-e0eb-4b6b-88ef-3ee2a2932d2c] Resetting offset for partition test101-0 to offset 320.
2020-01-07 20:01:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e997fa89-76ba-491a-b071-5ccc944d64a0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:49 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-7, groupId=e997fa89-76ba-491a-b071-5ccc944d64a0] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-7, groupId=e997fa89-76ba-491a-b071-5ccc944d64a0] Revoking previously assigned partitions []
2020-01-07 20:01:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-7, groupId=e997fa89-76ba-491a-b071-5ccc944d64a0] (Re-)joining group
2020-01-07 20:01:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-7, groupId=e997fa89-76ba-491a-b071-5ccc944d64a0] Successfully joined group with generation 1
2020-01-07 20:01:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-7, groupId=e997fa89-76ba-491a-b071-5ccc944d64a0] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:49 INFO  Fetcher:583 - [Consumer clientId=consumer-7, groupId=e997fa89-76ba-491a-b071-5ccc944d64a0] Resetting offset for partition test101-0 to offset 321.
2020-01-07 20:01:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 608f3656-bebb-4b06-a08a-308fc175d107
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:49 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-8, groupId=608f3656-bebb-4b06-a08a-308fc175d107] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-8, groupId=608f3656-bebb-4b06-a08a-308fc175d107] Revoking previously assigned partitions []
2020-01-07 20:01:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-8, groupId=608f3656-bebb-4b06-a08a-308fc175d107] (Re-)joining group
2020-01-07 20:01:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-8, groupId=608f3656-bebb-4b06-a08a-308fc175d107] Successfully joined group with generation 1
2020-01-07 20:01:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-8, groupId=608f3656-bebb-4b06-a08a-308fc175d107] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:49 INFO  Fetcher:583 - [Consumer clientId=consumer-8, groupId=608f3656-bebb-4b06-a08a-308fc175d107] Resetting offset for partition test101-0 to offset 323.
2020-01-07 20:01:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ef707799-5944-49f4-b235-5540a46f3b7a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:49 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-9, groupId=ef707799-5944-49f4-b235-5540a46f3b7a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-9, groupId=ef707799-5944-49f4-b235-5540a46f3b7a] Revoking previously assigned partitions []
2020-01-07 20:01:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-9, groupId=ef707799-5944-49f4-b235-5540a46f3b7a] (Re-)joining group
2020-01-07 20:01:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-9, groupId=ef707799-5944-49f4-b235-5540a46f3b7a] Successfully joined group with generation 1
2020-01-07 20:01:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-9, groupId=ef707799-5944-49f4-b235-5540a46f3b7a] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:49 INFO  Fetcher:583 - [Consumer clientId=consumer-9, groupId=ef707799-5944-49f4-b235-5540a46f3b7a] Resetting offset for partition test101-0 to offset 324.
2020-01-07 20:01:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d6a29137-2dd3-4d21-81f7-1fe41f59220f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:49 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-10, groupId=d6a29137-2dd3-4d21-81f7-1fe41f59220f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-10, groupId=d6a29137-2dd3-4d21-81f7-1fe41f59220f] Revoking previously assigned partitions []
2020-01-07 20:01:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-10, groupId=d6a29137-2dd3-4d21-81f7-1fe41f59220f] (Re-)joining group
2020-01-07 20:01:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-10, groupId=d6a29137-2dd3-4d21-81f7-1fe41f59220f] Successfully joined group with generation 1
2020-01-07 20:01:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-10, groupId=d6a29137-2dd3-4d21-81f7-1fe41f59220f] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:49 INFO  Fetcher:583 - [Consumer clientId=consumer-10, groupId=d6a29137-2dd3-4d21-81f7-1fe41f59220f] Resetting offset for partition test101-0 to offset 327.
2020-01-07 20:01:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = db2de753-3653-48f4-9597-b5e06f52b201
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:49 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-11, groupId=db2de753-3653-48f4-9597-b5e06f52b201] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-11, groupId=db2de753-3653-48f4-9597-b5e06f52b201] Revoking previously assigned partitions []
2020-01-07 20:01:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-11, groupId=db2de753-3653-48f4-9597-b5e06f52b201] (Re-)joining group
2020-01-07 20:01:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-11, groupId=db2de753-3653-48f4-9597-b5e06f52b201] Successfully joined group with generation 1
2020-01-07 20:01:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-11, groupId=db2de753-3653-48f4-9597-b5e06f52b201] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:49 INFO  Fetcher:583 - [Consumer clientId=consumer-11, groupId=db2de753-3653-48f4-9597-b5e06f52b201] Resetting offset for partition test101-0 to offset 330.
2020-01-07 20:01:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4fc5d99d-9ae9-4f77-81a2-1d3b65219fca
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:49 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-12, groupId=4fc5d99d-9ae9-4f77-81a2-1d3b65219fca] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-12, groupId=4fc5d99d-9ae9-4f77-81a2-1d3b65219fca] Revoking previously assigned partitions []
2020-01-07 20:01:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-12, groupId=4fc5d99d-9ae9-4f77-81a2-1d3b65219fca] (Re-)joining group
2020-01-07 20:01:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-12, groupId=4fc5d99d-9ae9-4f77-81a2-1d3b65219fca] Successfully joined group with generation 1
2020-01-07 20:01:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-12, groupId=4fc5d99d-9ae9-4f77-81a2-1d3b65219fca] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:49 INFO  Fetcher:583 - [Consumer clientId=consumer-12, groupId=4fc5d99d-9ae9-4f77-81a2-1d3b65219fca] Resetting offset for partition test101-0 to offset 331.
2020-01-07 20:01:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56b7e54d-3c49-4f3b-ac02-5c9ba95e55e6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:49 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-13, groupId=56b7e54d-3c49-4f3b-ac02-5c9ba95e55e6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-13, groupId=56b7e54d-3c49-4f3b-ac02-5c9ba95e55e6] Revoking previously assigned partitions []
2020-01-07 20:01:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-13, groupId=56b7e54d-3c49-4f3b-ac02-5c9ba95e55e6] (Re-)joining group
2020-01-07 20:01:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-13, groupId=56b7e54d-3c49-4f3b-ac02-5c9ba95e55e6] Successfully joined group with generation 1
2020-01-07 20:01:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-13, groupId=56b7e54d-3c49-4f3b-ac02-5c9ba95e55e6] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:49 INFO  Fetcher:583 - [Consumer clientId=consumer-13, groupId=56b7e54d-3c49-4f3b-ac02-5c9ba95e55e6] Resetting offset for partition test101-0 to offset 332.
2020-01-07 20:01:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 851aab84-cf55-455a-b7f9-ee27c7ac904b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:49 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-14, groupId=851aab84-cf55-455a-b7f9-ee27c7ac904b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-14, groupId=851aab84-cf55-455a-b7f9-ee27c7ac904b] Revoking previously assigned partitions []
2020-01-07 20:01:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-14, groupId=851aab84-cf55-455a-b7f9-ee27c7ac904b] (Re-)joining group
2020-01-07 20:01:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-14, groupId=851aab84-cf55-455a-b7f9-ee27c7ac904b] Successfully joined group with generation 1
2020-01-07 20:01:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-14, groupId=851aab84-cf55-455a-b7f9-ee27c7ac904b] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:49 INFO  Fetcher:583 - [Consumer clientId=consumer-14, groupId=851aab84-cf55-455a-b7f9-ee27c7ac904b] Resetting offset for partition test101-0 to offset 333.
2020-01-07 20:01:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f6e30b28-2319-4f0a-9c95-d482768e9a74
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:49 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-15, groupId=f6e30b28-2319-4f0a-9c95-d482768e9a74] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-15, groupId=f6e30b28-2319-4f0a-9c95-d482768e9a74] Revoking previously assigned partitions []
2020-01-07 20:01:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-15, groupId=f6e30b28-2319-4f0a-9c95-d482768e9a74] (Re-)joining group
2020-01-07 20:01:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-15, groupId=f6e30b28-2319-4f0a-9c95-d482768e9a74] Successfully joined group with generation 1
2020-01-07 20:01:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-15, groupId=f6e30b28-2319-4f0a-9c95-d482768e9a74] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:49 INFO  Fetcher:583 - [Consumer clientId=consumer-15, groupId=f6e30b28-2319-4f0a-9c95-d482768e9a74] Resetting offset for partition test101-0 to offset 335.
2020-01-07 20:01:49 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b4e6db89-1fa7-45d0-8776-b4a56aecaab4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:49 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:49 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-16, groupId=b4e6db89-1fa7-45d0-8776-b4a56aecaab4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-16, groupId=b4e6db89-1fa7-45d0-8776-b4a56aecaab4] Revoking previously assigned partitions []
2020-01-07 20:01:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-16, groupId=b4e6db89-1fa7-45d0-8776-b4a56aecaab4] (Re-)joining group
2020-01-07 20:01:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-16, groupId=b4e6db89-1fa7-45d0-8776-b4a56aecaab4] Successfully joined group with generation 1
2020-01-07 20:01:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-16, groupId=b4e6db89-1fa7-45d0-8776-b4a56aecaab4] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:50 INFO  Fetcher:583 - [Consumer clientId=consumer-16, groupId=b4e6db89-1fa7-45d0-8776-b4a56aecaab4] Resetting offset for partition test101-0 to offset 336.
2020-01-07 20:01:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3646d138-b8be-4772-8fe5-0b55e2922e73
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-17, groupId=3646d138-b8be-4772-8fe5-0b55e2922e73] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-17, groupId=3646d138-b8be-4772-8fe5-0b55e2922e73] Revoking previously assigned partitions []
2020-01-07 20:01:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-17, groupId=3646d138-b8be-4772-8fe5-0b55e2922e73] (Re-)joining group
2020-01-07 20:01:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-17, groupId=3646d138-b8be-4772-8fe5-0b55e2922e73] Successfully joined group with generation 1
2020-01-07 20:01:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-17, groupId=3646d138-b8be-4772-8fe5-0b55e2922e73] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:50 INFO  Fetcher:583 - [Consumer clientId=consumer-17, groupId=3646d138-b8be-4772-8fe5-0b55e2922e73] Resetting offset for partition test101-0 to offset 338.
2020-01-07 20:01:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2beeed59-c8cd-40b1-b467-e0faadab140c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-18, groupId=2beeed59-c8cd-40b1-b467-e0faadab140c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-18, groupId=2beeed59-c8cd-40b1-b467-e0faadab140c] Revoking previously assigned partitions []
2020-01-07 20:01:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-18, groupId=2beeed59-c8cd-40b1-b467-e0faadab140c] (Re-)joining group
2020-01-07 20:01:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-18, groupId=2beeed59-c8cd-40b1-b467-e0faadab140c] Successfully joined group with generation 1
2020-01-07 20:01:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-18, groupId=2beeed59-c8cd-40b1-b467-e0faadab140c] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:50 INFO  Fetcher:583 - [Consumer clientId=consumer-18, groupId=2beeed59-c8cd-40b1-b467-e0faadab140c] Resetting offset for partition test101-0 to offset 340.
2020-01-07 20:01:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 12c934e8-cc1a-48f3-bcbc-679a90cdca38
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-19, groupId=12c934e8-cc1a-48f3-bcbc-679a90cdca38] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-19, groupId=12c934e8-cc1a-48f3-bcbc-679a90cdca38] Revoking previously assigned partitions []
2020-01-07 20:01:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-19, groupId=12c934e8-cc1a-48f3-bcbc-679a90cdca38] (Re-)joining group
2020-01-07 20:01:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-19, groupId=12c934e8-cc1a-48f3-bcbc-679a90cdca38] Successfully joined group with generation 1
2020-01-07 20:01:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-19, groupId=12c934e8-cc1a-48f3-bcbc-679a90cdca38] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:50 INFO  Fetcher:583 - [Consumer clientId=consumer-19, groupId=12c934e8-cc1a-48f3-bcbc-679a90cdca38] Resetting offset for partition test101-0 to offset 341.
2020-01-07 20:01:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8dcfa875-3017-4f05-9a6e-2d48a0271780
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-20, groupId=8dcfa875-3017-4f05-9a6e-2d48a0271780] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-20, groupId=8dcfa875-3017-4f05-9a6e-2d48a0271780] Revoking previously assigned partitions []
2020-01-07 20:01:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-20, groupId=8dcfa875-3017-4f05-9a6e-2d48a0271780] (Re-)joining group
2020-01-07 20:01:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-20, groupId=8dcfa875-3017-4f05-9a6e-2d48a0271780] Successfully joined group with generation 1
2020-01-07 20:01:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-20, groupId=8dcfa875-3017-4f05-9a6e-2d48a0271780] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:50 INFO  Fetcher:583 - [Consumer clientId=consumer-20, groupId=8dcfa875-3017-4f05-9a6e-2d48a0271780] Resetting offset for partition test101-0 to offset 342.
2020-01-07 20:01:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 103d313c-d406-40ff-b069-14e461f61940
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-21, groupId=103d313c-d406-40ff-b069-14e461f61940] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-21, groupId=103d313c-d406-40ff-b069-14e461f61940] Revoking previously assigned partitions []
2020-01-07 20:01:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-21, groupId=103d313c-d406-40ff-b069-14e461f61940] (Re-)joining group
2020-01-07 20:01:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-21, groupId=103d313c-d406-40ff-b069-14e461f61940] Successfully joined group with generation 1
2020-01-07 20:01:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-21, groupId=103d313c-d406-40ff-b069-14e461f61940] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:50 INFO  Fetcher:583 - [Consumer clientId=consumer-21, groupId=103d313c-d406-40ff-b069-14e461f61940] Resetting offset for partition test101-0 to offset 343.
2020-01-07 20:01:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7da63229-fe2e-42d2-91fa-132f8aa8fca7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-22, groupId=7da63229-fe2e-42d2-91fa-132f8aa8fca7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-22, groupId=7da63229-fe2e-42d2-91fa-132f8aa8fca7] Revoking previously assigned partitions []
2020-01-07 20:01:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-22, groupId=7da63229-fe2e-42d2-91fa-132f8aa8fca7] (Re-)joining group
2020-01-07 20:01:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-22, groupId=7da63229-fe2e-42d2-91fa-132f8aa8fca7] Successfully joined group with generation 1
2020-01-07 20:01:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-22, groupId=7da63229-fe2e-42d2-91fa-132f8aa8fca7] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:50 INFO  Fetcher:583 - [Consumer clientId=consumer-22, groupId=7da63229-fe2e-42d2-91fa-132f8aa8fca7] Resetting offset for partition test101-0 to offset 345.
2020-01-07 20:01:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ec478c4f-affb-49db-a9d4-09990de90406
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-23, groupId=ec478c4f-affb-49db-a9d4-09990de90406] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-23, groupId=ec478c4f-affb-49db-a9d4-09990de90406] Revoking previously assigned partitions []
2020-01-07 20:01:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-23, groupId=ec478c4f-affb-49db-a9d4-09990de90406] (Re-)joining group
2020-01-07 20:01:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-23, groupId=ec478c4f-affb-49db-a9d4-09990de90406] Successfully joined group with generation 1
2020-01-07 20:01:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-23, groupId=ec478c4f-affb-49db-a9d4-09990de90406] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:50 INFO  Fetcher:583 - [Consumer clientId=consumer-23, groupId=ec478c4f-affb-49db-a9d4-09990de90406] Resetting offset for partition test101-0 to offset 346.
2020-01-07 20:01:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 81cf2d47-4152-454f-8517-eacc7dc80294
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-24, groupId=81cf2d47-4152-454f-8517-eacc7dc80294] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-24, groupId=81cf2d47-4152-454f-8517-eacc7dc80294] Revoking previously assigned partitions []
2020-01-07 20:01:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-24, groupId=81cf2d47-4152-454f-8517-eacc7dc80294] (Re-)joining group
2020-01-07 20:01:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-24, groupId=81cf2d47-4152-454f-8517-eacc7dc80294] Successfully joined group with generation 1
2020-01-07 20:01:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-24, groupId=81cf2d47-4152-454f-8517-eacc7dc80294] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:50 INFO  Fetcher:583 - [Consumer clientId=consumer-24, groupId=81cf2d47-4152-454f-8517-eacc7dc80294] Resetting offset for partition test101-0 to offset 347.
2020-01-07 20:01:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 77ca3443-1049-436e-b3c4-8d3e5a661247
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-25, groupId=77ca3443-1049-436e-b3c4-8d3e5a661247] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-25, groupId=77ca3443-1049-436e-b3c4-8d3e5a661247] Revoking previously assigned partitions []
2020-01-07 20:01:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-25, groupId=77ca3443-1049-436e-b3c4-8d3e5a661247] (Re-)joining group
2020-01-07 20:01:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-25, groupId=77ca3443-1049-436e-b3c4-8d3e5a661247] Successfully joined group with generation 1
2020-01-07 20:01:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-25, groupId=77ca3443-1049-436e-b3c4-8d3e5a661247] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:50 INFO  Fetcher:583 - [Consumer clientId=consumer-25, groupId=77ca3443-1049-436e-b3c4-8d3e5a661247] Resetting offset for partition test101-0 to offset 349.
2020-01-07 20:01:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8043dd20-250a-4ae7-89f7-3e0fcc4015f8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-26, groupId=8043dd20-250a-4ae7-89f7-3e0fcc4015f8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-26, groupId=8043dd20-250a-4ae7-89f7-3e0fcc4015f8] Revoking previously assigned partitions []
2020-01-07 20:01:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-26, groupId=8043dd20-250a-4ae7-89f7-3e0fcc4015f8] (Re-)joining group
2020-01-07 20:01:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-26, groupId=8043dd20-250a-4ae7-89f7-3e0fcc4015f8] Successfully joined group with generation 1
2020-01-07 20:01:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-26, groupId=8043dd20-250a-4ae7-89f7-3e0fcc4015f8] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:50 INFO  Fetcher:583 - [Consumer clientId=consumer-26, groupId=8043dd20-250a-4ae7-89f7-3e0fcc4015f8] Resetting offset for partition test101-0 to offset 350.
2020-01-07 20:01:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6b282b38-188a-424b-924b-13cf21e2401a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-27, groupId=6b282b38-188a-424b-924b-13cf21e2401a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-27, groupId=6b282b38-188a-424b-924b-13cf21e2401a] Revoking previously assigned partitions []
2020-01-07 20:01:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-27, groupId=6b282b38-188a-424b-924b-13cf21e2401a] (Re-)joining group
2020-01-07 20:01:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-27, groupId=6b282b38-188a-424b-924b-13cf21e2401a] Successfully joined group with generation 1
2020-01-07 20:01:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-27, groupId=6b282b38-188a-424b-924b-13cf21e2401a] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:50 INFO  Fetcher:583 - [Consumer clientId=consumer-27, groupId=6b282b38-188a-424b-924b-13cf21e2401a] Resetting offset for partition test101-0 to offset 351.
2020-01-07 20:01:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 401d0073-5c64-45a9-971d-107a98f98fcf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-28, groupId=401d0073-5c64-45a9-971d-107a98f98fcf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-28, groupId=401d0073-5c64-45a9-971d-107a98f98fcf] Revoking previously assigned partitions []
2020-01-07 20:01:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-28, groupId=401d0073-5c64-45a9-971d-107a98f98fcf] (Re-)joining group
2020-01-07 20:01:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-28, groupId=401d0073-5c64-45a9-971d-107a98f98fcf] Successfully joined group with generation 1
2020-01-07 20:01:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-28, groupId=401d0073-5c64-45a9-971d-107a98f98fcf] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:50 INFO  Fetcher:583 - [Consumer clientId=consumer-28, groupId=401d0073-5c64-45a9-971d-107a98f98fcf] Resetting offset for partition test101-0 to offset 352.
2020-01-07 20:01:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0d34dec5-5457-4154-9529-b740bc6f9ce1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-29, groupId=0d34dec5-5457-4154-9529-b740bc6f9ce1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-29, groupId=0d34dec5-5457-4154-9529-b740bc6f9ce1] Revoking previously assigned partitions []
2020-01-07 20:01:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-29, groupId=0d34dec5-5457-4154-9529-b740bc6f9ce1] (Re-)joining group
2020-01-07 20:01:50 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-29, groupId=0d34dec5-5457-4154-9529-b740bc6f9ce1] Successfully joined group with generation 1
2020-01-07 20:01:50 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-29, groupId=0d34dec5-5457-4154-9529-b740bc6f9ce1] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:50 INFO  Fetcher:583 - [Consumer clientId=consumer-29, groupId=0d34dec5-5457-4154-9529-b740bc6f9ce1] Resetting offset for partition test101-0 to offset 354.
2020-01-07 20:01:50 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7fba2a49-282d-43dd-bced-a7d2067a0c04
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:50 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:50 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:50 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:50 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-30, groupId=7fba2a49-282d-43dd-bced-a7d2067a0c04] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:50 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-30, groupId=7fba2a49-282d-43dd-bced-a7d2067a0c04] Revoking previously assigned partitions []
2020-01-07 20:01:50 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-30, groupId=7fba2a49-282d-43dd-bced-a7d2067a0c04] (Re-)joining group
2020-01-07 20:01:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-30, groupId=7fba2a49-282d-43dd-bced-a7d2067a0c04] Successfully joined group with generation 1
2020-01-07 20:01:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-30, groupId=7fba2a49-282d-43dd-bced-a7d2067a0c04] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:51 INFO  Fetcher:583 - [Consumer clientId=consumer-30, groupId=7fba2a49-282d-43dd-bced-a7d2067a0c04] Resetting offset for partition test101-0 to offset 355.
2020-01-07 20:01:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 73c06a4f-3260-4e11-a434-b7dcec603197
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-31, groupId=73c06a4f-3260-4e11-a434-b7dcec603197] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-31, groupId=73c06a4f-3260-4e11-a434-b7dcec603197] Revoking previously assigned partitions []
2020-01-07 20:01:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-31, groupId=73c06a4f-3260-4e11-a434-b7dcec603197] (Re-)joining group
2020-01-07 20:01:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-31, groupId=73c06a4f-3260-4e11-a434-b7dcec603197] Successfully joined group with generation 1
2020-01-07 20:01:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-31, groupId=73c06a4f-3260-4e11-a434-b7dcec603197] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:51 INFO  Fetcher:583 - [Consumer clientId=consumer-31, groupId=73c06a4f-3260-4e11-a434-b7dcec603197] Resetting offset for partition test101-0 to offset 357.
2020-01-07 20:01:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4e8ba6d9-476d-4e0c-9da2-5ff537485706
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-32, groupId=4e8ba6d9-476d-4e0c-9da2-5ff537485706] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-32, groupId=4e8ba6d9-476d-4e0c-9da2-5ff537485706] Revoking previously assigned partitions []
2020-01-07 20:01:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-32, groupId=4e8ba6d9-476d-4e0c-9da2-5ff537485706] (Re-)joining group
2020-01-07 20:01:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-32, groupId=4e8ba6d9-476d-4e0c-9da2-5ff537485706] Successfully joined group with generation 1
2020-01-07 20:01:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-32, groupId=4e8ba6d9-476d-4e0c-9da2-5ff537485706] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:51 INFO  Fetcher:583 - [Consumer clientId=consumer-32, groupId=4e8ba6d9-476d-4e0c-9da2-5ff537485706] Resetting offset for partition test101-0 to offset 358.
2020-01-07 20:01:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4432c6d7-64bb-4ae4-bd38-d4081336009a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-33, groupId=4432c6d7-64bb-4ae4-bd38-d4081336009a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-33, groupId=4432c6d7-64bb-4ae4-bd38-d4081336009a] Revoking previously assigned partitions []
2020-01-07 20:01:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-33, groupId=4432c6d7-64bb-4ae4-bd38-d4081336009a] (Re-)joining group
2020-01-07 20:01:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-33, groupId=4432c6d7-64bb-4ae4-bd38-d4081336009a] Successfully joined group with generation 1
2020-01-07 20:01:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-33, groupId=4432c6d7-64bb-4ae4-bd38-d4081336009a] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:51 INFO  Fetcher:583 - [Consumer clientId=consumer-33, groupId=4432c6d7-64bb-4ae4-bd38-d4081336009a] Resetting offset for partition test101-0 to offset 360.
2020-01-07 20:01:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a664b92e-1120-49d5-b29c-37d878f76ba6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-34, groupId=a664b92e-1120-49d5-b29c-37d878f76ba6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-34, groupId=a664b92e-1120-49d5-b29c-37d878f76ba6] Revoking previously assigned partitions []
2020-01-07 20:01:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-34, groupId=a664b92e-1120-49d5-b29c-37d878f76ba6] (Re-)joining group
2020-01-07 20:01:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-34, groupId=a664b92e-1120-49d5-b29c-37d878f76ba6] Successfully joined group with generation 1
2020-01-07 20:01:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-34, groupId=a664b92e-1120-49d5-b29c-37d878f76ba6] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:51 INFO  Fetcher:583 - [Consumer clientId=consumer-34, groupId=a664b92e-1120-49d5-b29c-37d878f76ba6] Resetting offset for partition test101-0 to offset 362.
2020-01-07 20:01:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 580955d0-3ef9-432a-9dbc-4e58eaf3de7e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-35, groupId=580955d0-3ef9-432a-9dbc-4e58eaf3de7e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-35, groupId=580955d0-3ef9-432a-9dbc-4e58eaf3de7e] Revoking previously assigned partitions []
2020-01-07 20:01:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-35, groupId=580955d0-3ef9-432a-9dbc-4e58eaf3de7e] (Re-)joining group
2020-01-07 20:01:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-35, groupId=580955d0-3ef9-432a-9dbc-4e58eaf3de7e] Successfully joined group with generation 1
2020-01-07 20:01:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-35, groupId=580955d0-3ef9-432a-9dbc-4e58eaf3de7e] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:51 INFO  Fetcher:583 - [Consumer clientId=consumer-35, groupId=580955d0-3ef9-432a-9dbc-4e58eaf3de7e] Resetting offset for partition test101-0 to offset 364.
2020-01-07 20:01:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 43b5756d-db2c-48dc-aad8-39db27c68836
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-36, groupId=43b5756d-db2c-48dc-aad8-39db27c68836] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-36, groupId=43b5756d-db2c-48dc-aad8-39db27c68836] Revoking previously assigned partitions []
2020-01-07 20:01:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-36, groupId=43b5756d-db2c-48dc-aad8-39db27c68836] (Re-)joining group
2020-01-07 20:01:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-36, groupId=43b5756d-db2c-48dc-aad8-39db27c68836] Successfully joined group with generation 1
2020-01-07 20:01:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-36, groupId=43b5756d-db2c-48dc-aad8-39db27c68836] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:51 INFO  Fetcher:583 - [Consumer clientId=consumer-36, groupId=43b5756d-db2c-48dc-aad8-39db27c68836] Resetting offset for partition test101-0 to offset 366.
2020-01-07 20:01:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ac33464a-7568-415a-9a58-473f6fbc56d3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-37, groupId=ac33464a-7568-415a-9a58-473f6fbc56d3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-37, groupId=ac33464a-7568-415a-9a58-473f6fbc56d3] Revoking previously assigned partitions []
2020-01-07 20:01:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-37, groupId=ac33464a-7568-415a-9a58-473f6fbc56d3] (Re-)joining group
2020-01-07 20:01:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-37, groupId=ac33464a-7568-415a-9a58-473f6fbc56d3] Successfully joined group with generation 1
2020-01-07 20:01:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-37, groupId=ac33464a-7568-415a-9a58-473f6fbc56d3] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:51 INFO  Fetcher:583 - [Consumer clientId=consumer-37, groupId=ac33464a-7568-415a-9a58-473f6fbc56d3] Resetting offset for partition test101-0 to offset 367.
2020-01-07 20:01:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 51e57b6f-abcd-416e-ba3d-9f23ea6a0c20
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-38, groupId=51e57b6f-abcd-416e-ba3d-9f23ea6a0c20] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-38, groupId=51e57b6f-abcd-416e-ba3d-9f23ea6a0c20] Revoking previously assigned partitions []
2020-01-07 20:01:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-38, groupId=51e57b6f-abcd-416e-ba3d-9f23ea6a0c20] (Re-)joining group
2020-01-07 20:01:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-38, groupId=51e57b6f-abcd-416e-ba3d-9f23ea6a0c20] Successfully joined group with generation 1
2020-01-07 20:01:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-38, groupId=51e57b6f-abcd-416e-ba3d-9f23ea6a0c20] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:51 INFO  Fetcher:583 - [Consumer clientId=consumer-38, groupId=51e57b6f-abcd-416e-ba3d-9f23ea6a0c20] Resetting offset for partition test101-0 to offset 368.
2020-01-07 20:01:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 112837c6-9524-4186-8f7b-8d5f0e95ff72
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-39, groupId=112837c6-9524-4186-8f7b-8d5f0e95ff72] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-39, groupId=112837c6-9524-4186-8f7b-8d5f0e95ff72] Revoking previously assigned partitions []
2020-01-07 20:01:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-39, groupId=112837c6-9524-4186-8f7b-8d5f0e95ff72] (Re-)joining group
2020-01-07 20:01:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-39, groupId=112837c6-9524-4186-8f7b-8d5f0e95ff72] Successfully joined group with generation 1
2020-01-07 20:01:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-39, groupId=112837c6-9524-4186-8f7b-8d5f0e95ff72] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:51 INFO  Fetcher:583 - [Consumer clientId=consumer-39, groupId=112837c6-9524-4186-8f7b-8d5f0e95ff72] Resetting offset for partition test101-0 to offset 369.
2020-01-07 20:01:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 78e7bb25-5c51-4ce6-9819-982794562370
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-40, groupId=78e7bb25-5c51-4ce6-9819-982794562370] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-40, groupId=78e7bb25-5c51-4ce6-9819-982794562370] Revoking previously assigned partitions []
2020-01-07 20:01:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-40, groupId=78e7bb25-5c51-4ce6-9819-982794562370] (Re-)joining group
2020-01-07 20:01:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-40, groupId=78e7bb25-5c51-4ce6-9819-982794562370] Successfully joined group with generation 1
2020-01-07 20:01:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-40, groupId=78e7bb25-5c51-4ce6-9819-982794562370] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:51 INFO  Fetcher:583 - [Consumer clientId=consumer-40, groupId=78e7bb25-5c51-4ce6-9819-982794562370] Resetting offset for partition test101-0 to offset 370.
2020-01-07 20:01:51 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 304fa0f5-1521-4a37-935d-dab7a802a1cb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:51 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:51 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:51 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:51 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-41, groupId=304fa0f5-1521-4a37-935d-dab7a802a1cb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:51 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-41, groupId=304fa0f5-1521-4a37-935d-dab7a802a1cb] Revoking previously assigned partitions []
2020-01-07 20:01:51 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-41, groupId=304fa0f5-1521-4a37-935d-dab7a802a1cb] (Re-)joining group
2020-01-07 20:01:51 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-41, groupId=304fa0f5-1521-4a37-935d-dab7a802a1cb] Successfully joined group with generation 1
2020-01-07 20:01:51 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-41, groupId=304fa0f5-1521-4a37-935d-dab7a802a1cb] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:51 INFO  Fetcher:583 - [Consumer clientId=consumer-41, groupId=304fa0f5-1521-4a37-935d-dab7a802a1cb] Resetting offset for partition test101-0 to offset 371.
2020-01-07 20:01:52 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f81975a5-d4e0-4004-8dff-3d14e322671a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:52 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:52 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:52 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:52 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-42, groupId=f81975a5-d4e0-4004-8dff-3d14e322671a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:52 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-42, groupId=f81975a5-d4e0-4004-8dff-3d14e322671a] Revoking previously assigned partitions []
2020-01-07 20:01:52 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-42, groupId=f81975a5-d4e0-4004-8dff-3d14e322671a] (Re-)joining group
2020-01-07 20:01:52 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-42, groupId=f81975a5-d4e0-4004-8dff-3d14e322671a] Successfully joined group with generation 1
2020-01-07 20:01:52 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-42, groupId=f81975a5-d4e0-4004-8dff-3d14e322671a] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:52 INFO  Fetcher:583 - [Consumer clientId=consumer-42, groupId=f81975a5-d4e0-4004-8dff-3d14e322671a] Resetting offset for partition test101-0 to offset 373.
2020-01-07 20:01:52 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2be6ac48-e4e2-4ee8-9c5f-fc86d880cf89
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:52 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:52 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:52 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:52 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-43, groupId=2be6ac48-e4e2-4ee8-9c5f-fc86d880cf89] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:52 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-43, groupId=2be6ac48-e4e2-4ee8-9c5f-fc86d880cf89] Revoking previously assigned partitions []
2020-01-07 20:01:52 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-43, groupId=2be6ac48-e4e2-4ee8-9c5f-fc86d880cf89] (Re-)joining group
2020-01-07 20:01:52 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-43, groupId=2be6ac48-e4e2-4ee8-9c5f-fc86d880cf89] Successfully joined group with generation 1
2020-01-07 20:01:52 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-43, groupId=2be6ac48-e4e2-4ee8-9c5f-fc86d880cf89] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:52 INFO  Fetcher:583 - [Consumer clientId=consumer-43, groupId=2be6ac48-e4e2-4ee8-9c5f-fc86d880cf89] Resetting offset for partition test101-0 to offset 374.
2020-01-07 20:01:52 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6a25bea7-4c56-40e4-b1e9-de011381af15
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:52 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:52 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:52 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:52 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-44, groupId=6a25bea7-4c56-40e4-b1e9-de011381af15] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:52 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-44, groupId=6a25bea7-4c56-40e4-b1e9-de011381af15] Revoking previously assigned partitions []
2020-01-07 20:01:52 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-44, groupId=6a25bea7-4c56-40e4-b1e9-de011381af15] (Re-)joining group
2020-01-07 20:01:52 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-44, groupId=6a25bea7-4c56-40e4-b1e9-de011381af15] Successfully joined group with generation 1
2020-01-07 20:01:52 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-44, groupId=6a25bea7-4c56-40e4-b1e9-de011381af15] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:52 INFO  Fetcher:583 - [Consumer clientId=consumer-44, groupId=6a25bea7-4c56-40e4-b1e9-de011381af15] Resetting offset for partition test101-0 to offset 375.
2020-01-07 20:01:52 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = eb0c281d-2c5e-43a0-9874-5f1ed768c26f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:52 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:52 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:52 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:52 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-45, groupId=eb0c281d-2c5e-43a0-9874-5f1ed768c26f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:52 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-45, groupId=eb0c281d-2c5e-43a0-9874-5f1ed768c26f] Revoking previously assigned partitions []
2020-01-07 20:01:52 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-45, groupId=eb0c281d-2c5e-43a0-9874-5f1ed768c26f] (Re-)joining group
2020-01-07 20:01:52 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-45, groupId=eb0c281d-2c5e-43a0-9874-5f1ed768c26f] Successfully joined group with generation 1
2020-01-07 20:01:52 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-45, groupId=eb0c281d-2c5e-43a0-9874-5f1ed768c26f] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:52 INFO  Fetcher:583 - [Consumer clientId=consumer-45, groupId=eb0c281d-2c5e-43a0-9874-5f1ed768c26f] Resetting offset for partition test101-0 to offset 376.
2020-01-07 20:01:52 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b2d42062-1b54-4aca-b296-b6e0bcdee78c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:52 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:52 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:52 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:52 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-46, groupId=b2d42062-1b54-4aca-b296-b6e0bcdee78c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:52 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-46, groupId=b2d42062-1b54-4aca-b296-b6e0bcdee78c] Revoking previously assigned partitions []
2020-01-07 20:01:52 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-46, groupId=b2d42062-1b54-4aca-b296-b6e0bcdee78c] (Re-)joining group
2020-01-07 20:01:52 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-46, groupId=b2d42062-1b54-4aca-b296-b6e0bcdee78c] Successfully joined group with generation 1
2020-01-07 20:01:52 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-46, groupId=b2d42062-1b54-4aca-b296-b6e0bcdee78c] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:52 INFO  Fetcher:583 - [Consumer clientId=consumer-46, groupId=b2d42062-1b54-4aca-b296-b6e0bcdee78c] Resetting offset for partition test101-0 to offset 378.
2020-01-07 20:01:52 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 20b4fc32-a86d-4549-bcf0-db0d4367405e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:52 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:52 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:52 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:52 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-47, groupId=20b4fc32-a86d-4549-bcf0-db0d4367405e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:52 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-47, groupId=20b4fc32-a86d-4549-bcf0-db0d4367405e] Revoking previously assigned partitions []
2020-01-07 20:01:52 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-47, groupId=20b4fc32-a86d-4549-bcf0-db0d4367405e] (Re-)joining group
2020-01-07 20:01:52 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-47, groupId=20b4fc32-a86d-4549-bcf0-db0d4367405e] Successfully joined group with generation 1
2020-01-07 20:01:52 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-47, groupId=20b4fc32-a86d-4549-bcf0-db0d4367405e] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:52 INFO  Fetcher:583 - [Consumer clientId=consumer-47, groupId=20b4fc32-a86d-4549-bcf0-db0d4367405e] Resetting offset for partition test101-0 to offset 379.
2020-01-07 20:01:52 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 18e659cc-483a-4379-b212-26ed7ae8a241
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:52 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:52 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:52 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:52 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-48, groupId=18e659cc-483a-4379-b212-26ed7ae8a241] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:52 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-48, groupId=18e659cc-483a-4379-b212-26ed7ae8a241] Revoking previously assigned partitions []
2020-01-07 20:01:52 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-48, groupId=18e659cc-483a-4379-b212-26ed7ae8a241] (Re-)joining group
2020-01-07 20:01:52 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-48, groupId=18e659cc-483a-4379-b212-26ed7ae8a241] Successfully joined group with generation 1
2020-01-07 20:01:52 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-48, groupId=18e659cc-483a-4379-b212-26ed7ae8a241] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:52 INFO  Fetcher:583 - [Consumer clientId=consumer-48, groupId=18e659cc-483a-4379-b212-26ed7ae8a241] Resetting offset for partition test101-0 to offset 380.
2020-01-07 20:01:52 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6362c535-c664-42df-91b6-6699322b847b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:52 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:52 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:52 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:52 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-49, groupId=6362c535-c664-42df-91b6-6699322b847b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:52 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-49, groupId=6362c535-c664-42df-91b6-6699322b847b] Revoking previously assigned partitions []
2020-01-07 20:01:52 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-49, groupId=6362c535-c664-42df-91b6-6699322b847b] (Re-)joining group
2020-01-07 20:01:52 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-49, groupId=6362c535-c664-42df-91b6-6699322b847b] Successfully joined group with generation 1
2020-01-07 20:01:52 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-49, groupId=6362c535-c664-42df-91b6-6699322b847b] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:52 INFO  Fetcher:583 - [Consumer clientId=consumer-49, groupId=6362c535-c664-42df-91b6-6699322b847b] Resetting offset for partition test101-0 to offset 381.
2020-01-07 20:01:52 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 50ee2a33-fa09-4d9c-8810-66e2a30c6839
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:52 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:52 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:52 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:52 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-50, groupId=50ee2a33-fa09-4d9c-8810-66e2a30c6839] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:52 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-50, groupId=50ee2a33-fa09-4d9c-8810-66e2a30c6839] Revoking previously assigned partitions []
2020-01-07 20:01:52 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-50, groupId=50ee2a33-fa09-4d9c-8810-66e2a30c6839] (Re-)joining group
2020-01-07 20:01:52 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-50, groupId=50ee2a33-fa09-4d9c-8810-66e2a30c6839] Successfully joined group with generation 1
2020-01-07 20:01:52 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-50, groupId=50ee2a33-fa09-4d9c-8810-66e2a30c6839] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:53 INFO  Fetcher:583 - [Consumer clientId=consumer-50, groupId=50ee2a33-fa09-4d9c-8810-66e2a30c6839] Resetting offset for partition test101-0 to offset 383.
2020-01-07 20:01:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ad036575-e650-4ced-adbb-5a0353c6172d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-51, groupId=ad036575-e650-4ced-adbb-5a0353c6172d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-51, groupId=ad036575-e650-4ced-adbb-5a0353c6172d] Revoking previously assigned partitions []
2020-01-07 20:01:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-51, groupId=ad036575-e650-4ced-adbb-5a0353c6172d] (Re-)joining group
2020-01-07 20:01:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-51, groupId=ad036575-e650-4ced-adbb-5a0353c6172d] Successfully joined group with generation 1
2020-01-07 20:01:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-51, groupId=ad036575-e650-4ced-adbb-5a0353c6172d] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:53 INFO  Fetcher:583 - [Consumer clientId=consumer-51, groupId=ad036575-e650-4ced-adbb-5a0353c6172d] Resetting offset for partition test101-0 to offset 384.
2020-01-07 20:01:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f98da05c-bfd7-4856-b69b-ae217e3e4d61
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-52, groupId=f98da05c-bfd7-4856-b69b-ae217e3e4d61] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-52, groupId=f98da05c-bfd7-4856-b69b-ae217e3e4d61] Revoking previously assigned partitions []
2020-01-07 20:01:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-52, groupId=f98da05c-bfd7-4856-b69b-ae217e3e4d61] (Re-)joining group
2020-01-07 20:01:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-52, groupId=f98da05c-bfd7-4856-b69b-ae217e3e4d61] Successfully joined group with generation 1
2020-01-07 20:01:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-52, groupId=f98da05c-bfd7-4856-b69b-ae217e3e4d61] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:53 INFO  Fetcher:583 - [Consumer clientId=consumer-52, groupId=f98da05c-bfd7-4856-b69b-ae217e3e4d61] Resetting offset for partition test101-0 to offset 387.
2020-01-07 20:01:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3a011ac2-0300-4b0c-8312-96445278d693
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-53, groupId=3a011ac2-0300-4b0c-8312-96445278d693] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-53, groupId=3a011ac2-0300-4b0c-8312-96445278d693] Revoking previously assigned partitions []
2020-01-07 20:01:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-53, groupId=3a011ac2-0300-4b0c-8312-96445278d693] (Re-)joining group
2020-01-07 20:01:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-53, groupId=3a011ac2-0300-4b0c-8312-96445278d693] Successfully joined group with generation 1
2020-01-07 20:01:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-53, groupId=3a011ac2-0300-4b0c-8312-96445278d693] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:53 INFO  Fetcher:583 - [Consumer clientId=consumer-53, groupId=3a011ac2-0300-4b0c-8312-96445278d693] Resetting offset for partition test101-0 to offset 388.
2020-01-07 20:01:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8e5bb649-6ed3-484d-ab4c-1c72ee66fb21
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-54, groupId=8e5bb649-6ed3-484d-ab4c-1c72ee66fb21] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-54, groupId=8e5bb649-6ed3-484d-ab4c-1c72ee66fb21] Revoking previously assigned partitions []
2020-01-07 20:01:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-54, groupId=8e5bb649-6ed3-484d-ab4c-1c72ee66fb21] (Re-)joining group
2020-01-07 20:01:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-54, groupId=8e5bb649-6ed3-484d-ab4c-1c72ee66fb21] Successfully joined group with generation 1
2020-01-07 20:01:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-54, groupId=8e5bb649-6ed3-484d-ab4c-1c72ee66fb21] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:53 INFO  Fetcher:583 - [Consumer clientId=consumer-54, groupId=8e5bb649-6ed3-484d-ab4c-1c72ee66fb21] Resetting offset for partition test101-0 to offset 390.
2020-01-07 20:01:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1dda7336-0dab-4bbb-8565-e5dfa721e757
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-55, groupId=1dda7336-0dab-4bbb-8565-e5dfa721e757] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-55, groupId=1dda7336-0dab-4bbb-8565-e5dfa721e757] Revoking previously assigned partitions []
2020-01-07 20:01:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-55, groupId=1dda7336-0dab-4bbb-8565-e5dfa721e757] (Re-)joining group
2020-01-07 20:01:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-55, groupId=1dda7336-0dab-4bbb-8565-e5dfa721e757] Successfully joined group with generation 1
2020-01-07 20:01:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-55, groupId=1dda7336-0dab-4bbb-8565-e5dfa721e757] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:53 INFO  Fetcher:583 - [Consumer clientId=consumer-55, groupId=1dda7336-0dab-4bbb-8565-e5dfa721e757] Resetting offset for partition test101-0 to offset 393.
2020-01-07 20:01:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1fdeb069-95a8-4de8-a4b6-97472d956599
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-56, groupId=1fdeb069-95a8-4de8-a4b6-97472d956599] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-56, groupId=1fdeb069-95a8-4de8-a4b6-97472d956599] Revoking previously assigned partitions []
2020-01-07 20:01:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-56, groupId=1fdeb069-95a8-4de8-a4b6-97472d956599] (Re-)joining group
2020-01-07 20:01:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-56, groupId=1fdeb069-95a8-4de8-a4b6-97472d956599] Successfully joined group with generation 1
2020-01-07 20:01:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-56, groupId=1fdeb069-95a8-4de8-a4b6-97472d956599] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:53 INFO  Fetcher:583 - [Consumer clientId=consumer-56, groupId=1fdeb069-95a8-4de8-a4b6-97472d956599] Resetting offset for partition test101-0 to offset 394.
2020-01-07 20:01:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 99eac369-6017-46c5-80ab-a482329b4cc9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-57, groupId=99eac369-6017-46c5-80ab-a482329b4cc9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-57, groupId=99eac369-6017-46c5-80ab-a482329b4cc9] Revoking previously assigned partitions []
2020-01-07 20:01:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-57, groupId=99eac369-6017-46c5-80ab-a482329b4cc9] (Re-)joining group
2020-01-07 20:01:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-57, groupId=99eac369-6017-46c5-80ab-a482329b4cc9] Successfully joined group with generation 1
2020-01-07 20:01:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-57, groupId=99eac369-6017-46c5-80ab-a482329b4cc9] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:54 INFO  Fetcher:583 - [Consumer clientId=consumer-57, groupId=99eac369-6017-46c5-80ab-a482329b4cc9] Resetting offset for partition test101-0 to offset 397.
2020-01-07 20:01:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 02e9cca6-b384-440f-b3d6-1f0e02d66b2e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-58, groupId=02e9cca6-b384-440f-b3d6-1f0e02d66b2e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-58, groupId=02e9cca6-b384-440f-b3d6-1f0e02d66b2e] Revoking previously assigned partitions []
2020-01-07 20:01:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-58, groupId=02e9cca6-b384-440f-b3d6-1f0e02d66b2e] (Re-)joining group
2020-01-07 20:01:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-58, groupId=02e9cca6-b384-440f-b3d6-1f0e02d66b2e] Successfully joined group with generation 1
2020-01-07 20:01:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-58, groupId=02e9cca6-b384-440f-b3d6-1f0e02d66b2e] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:54 INFO  Fetcher:583 - [Consumer clientId=consumer-58, groupId=02e9cca6-b384-440f-b3d6-1f0e02d66b2e] Resetting offset for partition test101-0 to offset 398.
2020-01-07 20:01:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d0f64528-d0f1-4fe7-b571-fa8099d0c608
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-59, groupId=d0f64528-d0f1-4fe7-b571-fa8099d0c608] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-59, groupId=d0f64528-d0f1-4fe7-b571-fa8099d0c608] Revoking previously assigned partitions []
2020-01-07 20:01:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-59, groupId=d0f64528-d0f1-4fe7-b571-fa8099d0c608] (Re-)joining group
2020-01-07 20:01:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-59, groupId=d0f64528-d0f1-4fe7-b571-fa8099d0c608] Successfully joined group with generation 1
2020-01-07 20:01:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-59, groupId=d0f64528-d0f1-4fe7-b571-fa8099d0c608] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:54 INFO  Fetcher:583 - [Consumer clientId=consumer-59, groupId=d0f64528-d0f1-4fe7-b571-fa8099d0c608] Resetting offset for partition test101-0 to offset 401.
2020-01-07 20:01:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7b3301a7-35d9-424e-b0b6-145ce11d0bba
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-60, groupId=7b3301a7-35d9-424e-b0b6-145ce11d0bba] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-60, groupId=7b3301a7-35d9-424e-b0b6-145ce11d0bba] Revoking previously assigned partitions []
2020-01-07 20:01:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-60, groupId=7b3301a7-35d9-424e-b0b6-145ce11d0bba] (Re-)joining group
2020-01-07 20:01:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-60, groupId=7b3301a7-35d9-424e-b0b6-145ce11d0bba] Successfully joined group with generation 1
2020-01-07 20:01:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-60, groupId=7b3301a7-35d9-424e-b0b6-145ce11d0bba] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:54 INFO  Fetcher:583 - [Consumer clientId=consumer-60, groupId=7b3301a7-35d9-424e-b0b6-145ce11d0bba] Resetting offset for partition test101-0 to offset 403.
2020-01-07 20:01:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 09039654-4ff6-463d-aa5c-6f6c2eabb5c5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-61, groupId=09039654-4ff6-463d-aa5c-6f6c2eabb5c5] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-61, groupId=09039654-4ff6-463d-aa5c-6f6c2eabb5c5] Revoking previously assigned partitions []
2020-01-07 20:01:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-61, groupId=09039654-4ff6-463d-aa5c-6f6c2eabb5c5] (Re-)joining group
2020-01-07 20:01:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-61, groupId=09039654-4ff6-463d-aa5c-6f6c2eabb5c5] Successfully joined group with generation 1
2020-01-07 20:01:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-61, groupId=09039654-4ff6-463d-aa5c-6f6c2eabb5c5] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:54 INFO  Fetcher:583 - [Consumer clientId=consumer-61, groupId=09039654-4ff6-463d-aa5c-6f6c2eabb5c5] Resetting offset for partition test101-0 to offset 404.
2020-01-07 20:01:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3c8f5972-fbb9-47d0-936b-9b9a85cded16
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-62, groupId=3c8f5972-fbb9-47d0-936b-9b9a85cded16] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-62, groupId=3c8f5972-fbb9-47d0-936b-9b9a85cded16] Revoking previously assigned partitions []
2020-01-07 20:01:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-62, groupId=3c8f5972-fbb9-47d0-936b-9b9a85cded16] (Re-)joining group
2020-01-07 20:01:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-62, groupId=3c8f5972-fbb9-47d0-936b-9b9a85cded16] Successfully joined group with generation 1
2020-01-07 20:01:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-62, groupId=3c8f5972-fbb9-47d0-936b-9b9a85cded16] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:54 INFO  Fetcher:583 - [Consumer clientId=consumer-62, groupId=3c8f5972-fbb9-47d0-936b-9b9a85cded16] Resetting offset for partition test101-0 to offset 406.
2020-01-07 20:01:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3df1d322-ee5a-4a2c-a9b1-6e310a20d2b7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-63, groupId=3df1d322-ee5a-4a2c-a9b1-6e310a20d2b7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-63, groupId=3df1d322-ee5a-4a2c-a9b1-6e310a20d2b7] Revoking previously assigned partitions []
2020-01-07 20:01:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-63, groupId=3df1d322-ee5a-4a2c-a9b1-6e310a20d2b7] (Re-)joining group
2020-01-07 20:01:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-63, groupId=3df1d322-ee5a-4a2c-a9b1-6e310a20d2b7] Successfully joined group with generation 1
2020-01-07 20:01:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-63, groupId=3df1d322-ee5a-4a2c-a9b1-6e310a20d2b7] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:54 INFO  Fetcher:583 - [Consumer clientId=consumer-63, groupId=3df1d322-ee5a-4a2c-a9b1-6e310a20d2b7] Resetting offset for partition test101-0 to offset 408.
2020-01-07 20:01:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0da38049-1162-4383-8e59-b85be66e45c2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-64, groupId=0da38049-1162-4383-8e59-b85be66e45c2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-64, groupId=0da38049-1162-4383-8e59-b85be66e45c2] Revoking previously assigned partitions []
2020-01-07 20:01:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-64, groupId=0da38049-1162-4383-8e59-b85be66e45c2] (Re-)joining group
2020-01-07 20:01:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-64, groupId=0da38049-1162-4383-8e59-b85be66e45c2] Successfully joined group with generation 1
2020-01-07 20:01:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-64, groupId=0da38049-1162-4383-8e59-b85be66e45c2] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:54 INFO  Fetcher:583 - [Consumer clientId=consumer-64, groupId=0da38049-1162-4383-8e59-b85be66e45c2] Resetting offset for partition test101-0 to offset 409.
2020-01-07 20:01:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 45d89ee0-7d5d-4b0d-8f15-a0f147b6b536
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-65, groupId=45d89ee0-7d5d-4b0d-8f15-a0f147b6b536] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-65, groupId=45d89ee0-7d5d-4b0d-8f15-a0f147b6b536] Revoking previously assigned partitions []
2020-01-07 20:01:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-65, groupId=45d89ee0-7d5d-4b0d-8f15-a0f147b6b536] (Re-)joining group
2020-01-07 20:01:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-65, groupId=45d89ee0-7d5d-4b0d-8f15-a0f147b6b536] Successfully joined group with generation 1
2020-01-07 20:01:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-65, groupId=45d89ee0-7d5d-4b0d-8f15-a0f147b6b536] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:54 INFO  Fetcher:583 - [Consumer clientId=consumer-65, groupId=45d89ee0-7d5d-4b0d-8f15-a0f147b6b536] Resetting offset for partition test101-0 to offset 411.
2020-01-07 20:01:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4b192e4b-dc6b-41ce-9d2d-25fc22840131
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-66, groupId=4b192e4b-dc6b-41ce-9d2d-25fc22840131] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-66, groupId=4b192e4b-dc6b-41ce-9d2d-25fc22840131] Revoking previously assigned partitions []
2020-01-07 20:01:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-66, groupId=4b192e4b-dc6b-41ce-9d2d-25fc22840131] (Re-)joining group
2020-01-07 20:01:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-66, groupId=4b192e4b-dc6b-41ce-9d2d-25fc22840131] Successfully joined group with generation 1
2020-01-07 20:01:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-66, groupId=4b192e4b-dc6b-41ce-9d2d-25fc22840131] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:55 INFO  Fetcher:583 - [Consumer clientId=consumer-66, groupId=4b192e4b-dc6b-41ce-9d2d-25fc22840131] Resetting offset for partition test101-0 to offset 412.
2020-01-07 20:01:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4bac4a20-b200-45c0-ba33-5b433f6cd906
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-67, groupId=4bac4a20-b200-45c0-ba33-5b433f6cd906] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-67, groupId=4bac4a20-b200-45c0-ba33-5b433f6cd906] Revoking previously assigned partitions []
2020-01-07 20:01:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-67, groupId=4bac4a20-b200-45c0-ba33-5b433f6cd906] (Re-)joining group
2020-01-07 20:01:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-67, groupId=4bac4a20-b200-45c0-ba33-5b433f6cd906] Successfully joined group with generation 1
2020-01-07 20:01:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-67, groupId=4bac4a20-b200-45c0-ba33-5b433f6cd906] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:55 INFO  Fetcher:583 - [Consumer clientId=consumer-67, groupId=4bac4a20-b200-45c0-ba33-5b433f6cd906] Resetting offset for partition test101-0 to offset 414.
2020-01-07 20:01:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 409ad04a-b061-4103-b501-cc22e402269c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-68, groupId=409ad04a-b061-4103-b501-cc22e402269c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-68, groupId=409ad04a-b061-4103-b501-cc22e402269c] Revoking previously assigned partitions []
2020-01-07 20:01:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-68, groupId=409ad04a-b061-4103-b501-cc22e402269c] (Re-)joining group
2020-01-07 20:01:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-68, groupId=409ad04a-b061-4103-b501-cc22e402269c] Successfully joined group with generation 1
2020-01-07 20:01:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-68, groupId=409ad04a-b061-4103-b501-cc22e402269c] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:55 INFO  Fetcher:583 - [Consumer clientId=consumer-68, groupId=409ad04a-b061-4103-b501-cc22e402269c] Resetting offset for partition test101-0 to offset 415.
2020-01-07 20:01:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 366a814a-6a9f-439d-bc82-f67f1487eab1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-69, groupId=366a814a-6a9f-439d-bc82-f67f1487eab1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-69, groupId=366a814a-6a9f-439d-bc82-f67f1487eab1] Revoking previously assigned partitions []
2020-01-07 20:01:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-69, groupId=366a814a-6a9f-439d-bc82-f67f1487eab1] (Re-)joining group
2020-01-07 20:01:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-69, groupId=366a814a-6a9f-439d-bc82-f67f1487eab1] Successfully joined group with generation 1
2020-01-07 20:01:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-69, groupId=366a814a-6a9f-439d-bc82-f67f1487eab1] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:55 INFO  Fetcher:583 - [Consumer clientId=consumer-69, groupId=366a814a-6a9f-439d-bc82-f67f1487eab1] Resetting offset for partition test101-0 to offset 416.
2020-01-07 20:01:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d6093d8e-e035-456f-ba6c-ff198a44dc6a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-70, groupId=d6093d8e-e035-456f-ba6c-ff198a44dc6a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-70, groupId=d6093d8e-e035-456f-ba6c-ff198a44dc6a] Revoking previously assigned partitions []
2020-01-07 20:01:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-70, groupId=d6093d8e-e035-456f-ba6c-ff198a44dc6a] (Re-)joining group
2020-01-07 20:01:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-70, groupId=d6093d8e-e035-456f-ba6c-ff198a44dc6a] Successfully joined group with generation 1
2020-01-07 20:01:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-70, groupId=d6093d8e-e035-456f-ba6c-ff198a44dc6a] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:55 INFO  Fetcher:583 - [Consumer clientId=consumer-70, groupId=d6093d8e-e035-456f-ba6c-ff198a44dc6a] Resetting offset for partition test101-0 to offset 418.
2020-01-07 20:01:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1e6f22a9-5eaf-40d8-a5ad-f63a71408eff
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-71, groupId=1e6f22a9-5eaf-40d8-a5ad-f63a71408eff] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-71, groupId=1e6f22a9-5eaf-40d8-a5ad-f63a71408eff] Revoking previously assigned partitions []
2020-01-07 20:01:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-71, groupId=1e6f22a9-5eaf-40d8-a5ad-f63a71408eff] (Re-)joining group
2020-01-07 20:01:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-71, groupId=1e6f22a9-5eaf-40d8-a5ad-f63a71408eff] Successfully joined group with generation 1
2020-01-07 20:01:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-71, groupId=1e6f22a9-5eaf-40d8-a5ad-f63a71408eff] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:55 INFO  Fetcher:583 - [Consumer clientId=consumer-71, groupId=1e6f22a9-5eaf-40d8-a5ad-f63a71408eff] Resetting offset for partition test101-0 to offset 419.
2020-01-07 20:01:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 20359424-7ee1-4c08-8fcf-98d89fbac501
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-72, groupId=20359424-7ee1-4c08-8fcf-98d89fbac501] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-72, groupId=20359424-7ee1-4c08-8fcf-98d89fbac501] Revoking previously assigned partitions []
2020-01-07 20:01:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-72, groupId=20359424-7ee1-4c08-8fcf-98d89fbac501] (Re-)joining group
2020-01-07 20:01:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-72, groupId=20359424-7ee1-4c08-8fcf-98d89fbac501] Successfully joined group with generation 1
2020-01-07 20:01:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-72, groupId=20359424-7ee1-4c08-8fcf-98d89fbac501] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:55 INFO  Fetcher:583 - [Consumer clientId=consumer-72, groupId=20359424-7ee1-4c08-8fcf-98d89fbac501] Resetting offset for partition test101-0 to offset 420.
2020-01-07 20:01:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 901fca6f-c588-4186-bbbc-74eb93afbb4c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-73, groupId=901fca6f-c588-4186-bbbc-74eb93afbb4c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-73, groupId=901fca6f-c588-4186-bbbc-74eb93afbb4c] Revoking previously assigned partitions []
2020-01-07 20:01:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-73, groupId=901fca6f-c588-4186-bbbc-74eb93afbb4c] (Re-)joining group
2020-01-07 20:01:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-73, groupId=901fca6f-c588-4186-bbbc-74eb93afbb4c] Successfully joined group with generation 1
2020-01-07 20:01:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-73, groupId=901fca6f-c588-4186-bbbc-74eb93afbb4c] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:55 INFO  Fetcher:583 - [Consumer clientId=consumer-73, groupId=901fca6f-c588-4186-bbbc-74eb93afbb4c] Resetting offset for partition test101-0 to offset 422.
2020-01-07 20:01:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8dbea20c-f795-4eef-81cc-a35c1f072fc0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-74, groupId=8dbea20c-f795-4eef-81cc-a35c1f072fc0] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-74, groupId=8dbea20c-f795-4eef-81cc-a35c1f072fc0] Revoking previously assigned partitions []
2020-01-07 20:01:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-74, groupId=8dbea20c-f795-4eef-81cc-a35c1f072fc0] (Re-)joining group
2020-01-07 20:01:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-74, groupId=8dbea20c-f795-4eef-81cc-a35c1f072fc0] Successfully joined group with generation 1
2020-01-07 20:01:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-74, groupId=8dbea20c-f795-4eef-81cc-a35c1f072fc0] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:55 INFO  Fetcher:583 - [Consumer clientId=consumer-74, groupId=8dbea20c-f795-4eef-81cc-a35c1f072fc0] Resetting offset for partition test101-0 to offset 424.
2020-01-07 20:01:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8bf99c8a-c78d-4443-9708-623cc97e8160
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-75, groupId=8bf99c8a-c78d-4443-9708-623cc97e8160] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-75, groupId=8bf99c8a-c78d-4443-9708-623cc97e8160] Revoking previously assigned partitions []
2020-01-07 20:01:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-75, groupId=8bf99c8a-c78d-4443-9708-623cc97e8160] (Re-)joining group
2020-01-07 20:01:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-75, groupId=8bf99c8a-c78d-4443-9708-623cc97e8160] Successfully joined group with generation 1
2020-01-07 20:01:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-75, groupId=8bf99c8a-c78d-4443-9708-623cc97e8160] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:55 INFO  Fetcher:583 - [Consumer clientId=consumer-75, groupId=8bf99c8a-c78d-4443-9708-623cc97e8160] Resetting offset for partition test101-0 to offset 426.
2020-01-07 20:01:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d0cf331f-97e0-493b-bef3-309801847418
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-76, groupId=d0cf331f-97e0-493b-bef3-309801847418] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-76, groupId=d0cf331f-97e0-493b-bef3-309801847418] Revoking previously assigned partitions []
2020-01-07 20:01:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-76, groupId=d0cf331f-97e0-493b-bef3-309801847418] (Re-)joining group
2020-01-07 20:01:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-76, groupId=d0cf331f-97e0-493b-bef3-309801847418] Successfully joined group with generation 1
2020-01-07 20:01:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-76, groupId=d0cf331f-97e0-493b-bef3-309801847418] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:55 INFO  Fetcher:583 - [Consumer clientId=consumer-76, groupId=d0cf331f-97e0-493b-bef3-309801847418] Resetting offset for partition test101-0 to offset 428.
2020-01-07 20:01:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d6d0f01f-7694-4eae-ba79-12165510e35a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-77, groupId=d6d0f01f-7694-4eae-ba79-12165510e35a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-77, groupId=d6d0f01f-7694-4eae-ba79-12165510e35a] Revoking previously assigned partitions []
2020-01-07 20:01:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-77, groupId=d6d0f01f-7694-4eae-ba79-12165510e35a] (Re-)joining group
2020-01-07 20:01:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-77, groupId=d6d0f01f-7694-4eae-ba79-12165510e35a] Successfully joined group with generation 1
2020-01-07 20:01:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-77, groupId=d6d0f01f-7694-4eae-ba79-12165510e35a] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:55 INFO  Fetcher:583 - [Consumer clientId=consumer-77, groupId=d6d0f01f-7694-4eae-ba79-12165510e35a] Resetting offset for partition test101-0 to offset 430.
2020-01-07 20:01:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 70029cc9-03cf-4530-a093-f068bddcb8d0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-78, groupId=70029cc9-03cf-4530-a093-f068bddcb8d0] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-78, groupId=70029cc9-03cf-4530-a093-f068bddcb8d0] Revoking previously assigned partitions []
2020-01-07 20:01:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-78, groupId=70029cc9-03cf-4530-a093-f068bddcb8d0] (Re-)joining group
2020-01-07 20:01:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-78, groupId=70029cc9-03cf-4530-a093-f068bddcb8d0] Successfully joined group with generation 1
2020-01-07 20:01:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-78, groupId=70029cc9-03cf-4530-a093-f068bddcb8d0] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:56 INFO  Fetcher:583 - [Consumer clientId=consumer-78, groupId=70029cc9-03cf-4530-a093-f068bddcb8d0] Resetting offset for partition test101-0 to offset 432.
2020-01-07 20:01:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fffe23c4-bb6f-4a39-b73f-7c1d05c78c16
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-79, groupId=fffe23c4-bb6f-4a39-b73f-7c1d05c78c16] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-79, groupId=fffe23c4-bb6f-4a39-b73f-7c1d05c78c16] Revoking previously assigned partitions []
2020-01-07 20:01:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-79, groupId=fffe23c4-bb6f-4a39-b73f-7c1d05c78c16] (Re-)joining group
2020-01-07 20:01:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-79, groupId=fffe23c4-bb6f-4a39-b73f-7c1d05c78c16] Successfully joined group with generation 1
2020-01-07 20:01:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-79, groupId=fffe23c4-bb6f-4a39-b73f-7c1d05c78c16] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:56 INFO  Fetcher:583 - [Consumer clientId=consumer-79, groupId=fffe23c4-bb6f-4a39-b73f-7c1d05c78c16] Resetting offset for partition test101-0 to offset 433.
2020-01-07 20:01:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f5b7be6b-c5b7-46aa-9fdd-ecf65c006333
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-80, groupId=f5b7be6b-c5b7-46aa-9fdd-ecf65c006333] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-80, groupId=f5b7be6b-c5b7-46aa-9fdd-ecf65c006333] Revoking previously assigned partitions []
2020-01-07 20:01:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-80, groupId=f5b7be6b-c5b7-46aa-9fdd-ecf65c006333] (Re-)joining group
2020-01-07 20:01:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-80, groupId=f5b7be6b-c5b7-46aa-9fdd-ecf65c006333] Successfully joined group with generation 1
2020-01-07 20:01:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-80, groupId=f5b7be6b-c5b7-46aa-9fdd-ecf65c006333] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:56 INFO  Fetcher:583 - [Consumer clientId=consumer-80, groupId=f5b7be6b-c5b7-46aa-9fdd-ecf65c006333] Resetting offset for partition test101-0 to offset 434.
2020-01-07 20:01:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4001756b-65c4-4b88-a0d3-37c8ed67ccd4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-81, groupId=4001756b-65c4-4b88-a0d3-37c8ed67ccd4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-81, groupId=4001756b-65c4-4b88-a0d3-37c8ed67ccd4] Revoking previously assigned partitions []
2020-01-07 20:01:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-81, groupId=4001756b-65c4-4b88-a0d3-37c8ed67ccd4] (Re-)joining group
2020-01-07 20:01:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-81, groupId=4001756b-65c4-4b88-a0d3-37c8ed67ccd4] Successfully joined group with generation 1
2020-01-07 20:01:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-81, groupId=4001756b-65c4-4b88-a0d3-37c8ed67ccd4] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:56 INFO  Fetcher:583 - [Consumer clientId=consumer-81, groupId=4001756b-65c4-4b88-a0d3-37c8ed67ccd4] Resetting offset for partition test101-0 to offset 435.
2020-01-07 20:01:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7f919d73-3f9e-4967-bbe9-963cc8c1633c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-82, groupId=7f919d73-3f9e-4967-bbe9-963cc8c1633c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-82, groupId=7f919d73-3f9e-4967-bbe9-963cc8c1633c] Revoking previously assigned partitions []
2020-01-07 20:01:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-82, groupId=7f919d73-3f9e-4967-bbe9-963cc8c1633c] (Re-)joining group
2020-01-07 20:01:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-82, groupId=7f919d73-3f9e-4967-bbe9-963cc8c1633c] Successfully joined group with generation 1
2020-01-07 20:01:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-82, groupId=7f919d73-3f9e-4967-bbe9-963cc8c1633c] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:56 INFO  Fetcher:583 - [Consumer clientId=consumer-82, groupId=7f919d73-3f9e-4967-bbe9-963cc8c1633c] Resetting offset for partition test101-0 to offset 437.
2020-01-07 20:01:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 09b73a1f-02fd-4266-862f-9c62251ea9ff
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-83, groupId=09b73a1f-02fd-4266-862f-9c62251ea9ff] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-83, groupId=09b73a1f-02fd-4266-862f-9c62251ea9ff] Revoking previously assigned partitions []
2020-01-07 20:01:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-83, groupId=09b73a1f-02fd-4266-862f-9c62251ea9ff] (Re-)joining group
2020-01-07 20:01:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-83, groupId=09b73a1f-02fd-4266-862f-9c62251ea9ff] Successfully joined group with generation 1
2020-01-07 20:01:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-83, groupId=09b73a1f-02fd-4266-862f-9c62251ea9ff] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:56 INFO  Fetcher:583 - [Consumer clientId=consumer-83, groupId=09b73a1f-02fd-4266-862f-9c62251ea9ff] Resetting offset for partition test101-0 to offset 438.
2020-01-07 20:01:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5de6b729-5238-4a75-8794-e0fd4a738818
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-84, groupId=5de6b729-5238-4a75-8794-e0fd4a738818] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-84, groupId=5de6b729-5238-4a75-8794-e0fd4a738818] Revoking previously assigned partitions []
2020-01-07 20:01:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-84, groupId=5de6b729-5238-4a75-8794-e0fd4a738818] (Re-)joining group
2020-01-07 20:01:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-84, groupId=5de6b729-5238-4a75-8794-e0fd4a738818] Successfully joined group with generation 1
2020-01-07 20:01:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-84, groupId=5de6b729-5238-4a75-8794-e0fd4a738818] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:56 INFO  Fetcher:583 - [Consumer clientId=consumer-84, groupId=5de6b729-5238-4a75-8794-e0fd4a738818] Resetting offset for partition test101-0 to offset 439.
2020-01-07 20:01:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e479456a-ac18-471e-90bf-3bc50a7a2029
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-85, groupId=e479456a-ac18-471e-90bf-3bc50a7a2029] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-85, groupId=e479456a-ac18-471e-90bf-3bc50a7a2029] Revoking previously assigned partitions []
2020-01-07 20:01:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-85, groupId=e479456a-ac18-471e-90bf-3bc50a7a2029] (Re-)joining group
2020-01-07 20:01:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-85, groupId=e479456a-ac18-471e-90bf-3bc50a7a2029] Successfully joined group with generation 1
2020-01-07 20:01:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-85, groupId=e479456a-ac18-471e-90bf-3bc50a7a2029] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:56 INFO  Fetcher:583 - [Consumer clientId=consumer-85, groupId=e479456a-ac18-471e-90bf-3bc50a7a2029] Resetting offset for partition test101-0 to offset 440.
2020-01-07 20:01:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5d8b92f8-7502-4177-a9b4-9ed0e718fb3d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-86, groupId=5d8b92f8-7502-4177-a9b4-9ed0e718fb3d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-86, groupId=5d8b92f8-7502-4177-a9b4-9ed0e718fb3d] Revoking previously assigned partitions []
2020-01-07 20:01:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-86, groupId=5d8b92f8-7502-4177-a9b4-9ed0e718fb3d] (Re-)joining group
2020-01-07 20:01:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-86, groupId=5d8b92f8-7502-4177-a9b4-9ed0e718fb3d] Successfully joined group with generation 1
2020-01-07 20:01:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-86, groupId=5d8b92f8-7502-4177-a9b4-9ed0e718fb3d] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:56 INFO  Fetcher:583 - [Consumer clientId=consumer-86, groupId=5d8b92f8-7502-4177-a9b4-9ed0e718fb3d] Resetting offset for partition test101-0 to offset 441.
2020-01-07 20:01:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e5c00874-48ad-4411-8848-1297423a5767
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-87, groupId=e5c00874-48ad-4411-8848-1297423a5767] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-87, groupId=e5c00874-48ad-4411-8848-1297423a5767] Revoking previously assigned partitions []
2020-01-07 20:01:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-87, groupId=e5c00874-48ad-4411-8848-1297423a5767] (Re-)joining group
2020-01-07 20:01:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-87, groupId=e5c00874-48ad-4411-8848-1297423a5767] Successfully joined group with generation 1
2020-01-07 20:01:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-87, groupId=e5c00874-48ad-4411-8848-1297423a5767] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:56 INFO  Fetcher:583 - [Consumer clientId=consumer-87, groupId=e5c00874-48ad-4411-8848-1297423a5767] Resetting offset for partition test101-0 to offset 442.
2020-01-07 20:01:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 367d418c-eea3-4dd1-9241-5af467a12239
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-88, groupId=367d418c-eea3-4dd1-9241-5af467a12239] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-88, groupId=367d418c-eea3-4dd1-9241-5af467a12239] Revoking previously assigned partitions []
2020-01-07 20:01:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-88, groupId=367d418c-eea3-4dd1-9241-5af467a12239] (Re-)joining group
2020-01-07 20:01:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-88, groupId=367d418c-eea3-4dd1-9241-5af467a12239] Successfully joined group with generation 1
2020-01-07 20:01:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-88, groupId=367d418c-eea3-4dd1-9241-5af467a12239] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:56 INFO  Fetcher:583 - [Consumer clientId=consumer-88, groupId=367d418c-eea3-4dd1-9241-5af467a12239] Resetting offset for partition test101-0 to offset 443.
2020-01-07 20:01:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d678fd76-fe79-4027-938a-a9d925700ac4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-89, groupId=d678fd76-fe79-4027-938a-a9d925700ac4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-89, groupId=d678fd76-fe79-4027-938a-a9d925700ac4] Revoking previously assigned partitions []
2020-01-07 20:01:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-89, groupId=d678fd76-fe79-4027-938a-a9d925700ac4] (Re-)joining group
2020-01-07 20:01:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-89, groupId=d678fd76-fe79-4027-938a-a9d925700ac4] Successfully joined group with generation 1
2020-01-07 20:01:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-89, groupId=d678fd76-fe79-4027-938a-a9d925700ac4] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:56 INFO  Fetcher:583 - [Consumer clientId=consumer-89, groupId=d678fd76-fe79-4027-938a-a9d925700ac4] Resetting offset for partition test101-0 to offset 444.
2020-01-07 20:01:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = cf5aecf7-0aa5-4d07-91ed-55509281b78c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-90, groupId=cf5aecf7-0aa5-4d07-91ed-55509281b78c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-90, groupId=cf5aecf7-0aa5-4d07-91ed-55509281b78c] Revoking previously assigned partitions []
2020-01-07 20:01:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-90, groupId=cf5aecf7-0aa5-4d07-91ed-55509281b78c] (Re-)joining group
2020-01-07 20:01:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-90, groupId=cf5aecf7-0aa5-4d07-91ed-55509281b78c] Successfully joined group with generation 1
2020-01-07 20:01:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-90, groupId=cf5aecf7-0aa5-4d07-91ed-55509281b78c] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:56 INFO  Fetcher:583 - [Consumer clientId=consumer-90, groupId=cf5aecf7-0aa5-4d07-91ed-55509281b78c] Resetting offset for partition test101-0 to offset 445.
2020-01-07 20:01:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c04ebe5a-266f-4c24-870d-363b8bf90efc
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-91, groupId=c04ebe5a-266f-4c24-870d-363b8bf90efc] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-91, groupId=c04ebe5a-266f-4c24-870d-363b8bf90efc] Revoking previously assigned partitions []
2020-01-07 20:01:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-91, groupId=c04ebe5a-266f-4c24-870d-363b8bf90efc] (Re-)joining group
2020-01-07 20:01:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-91, groupId=c04ebe5a-266f-4c24-870d-363b8bf90efc] Successfully joined group with generation 1
2020-01-07 20:01:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-91, groupId=c04ebe5a-266f-4c24-870d-363b8bf90efc] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:56 INFO  Fetcher:583 - [Consumer clientId=consumer-91, groupId=c04ebe5a-266f-4c24-870d-363b8bf90efc] Resetting offset for partition test101-0 to offset 447.
2020-01-07 20:01:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = bf023734-fe5c-423d-87d1-41e26c572afc
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-92, groupId=bf023734-fe5c-423d-87d1-41e26c572afc] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-92, groupId=bf023734-fe5c-423d-87d1-41e26c572afc] Revoking previously assigned partitions []
2020-01-07 20:01:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-92, groupId=bf023734-fe5c-423d-87d1-41e26c572afc] (Re-)joining group
2020-01-07 20:01:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-92, groupId=bf023734-fe5c-423d-87d1-41e26c572afc] Successfully joined group with generation 1
2020-01-07 20:01:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-92, groupId=bf023734-fe5c-423d-87d1-41e26c572afc] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:57 INFO  Fetcher:583 - [Consumer clientId=consumer-92, groupId=bf023734-fe5c-423d-87d1-41e26c572afc] Resetting offset for partition test101-0 to offset 448.
2020-01-07 20:01:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f02e54d9-577b-467a-84ba-f6a944a91525
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-93, groupId=f02e54d9-577b-467a-84ba-f6a944a91525] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-93, groupId=f02e54d9-577b-467a-84ba-f6a944a91525] Revoking previously assigned partitions []
2020-01-07 20:01:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-93, groupId=f02e54d9-577b-467a-84ba-f6a944a91525] (Re-)joining group
2020-01-07 20:01:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-93, groupId=f02e54d9-577b-467a-84ba-f6a944a91525] Successfully joined group with generation 1
2020-01-07 20:01:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-93, groupId=f02e54d9-577b-467a-84ba-f6a944a91525] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:57 INFO  Fetcher:583 - [Consumer clientId=consumer-93, groupId=f02e54d9-577b-467a-84ba-f6a944a91525] Resetting offset for partition test101-0 to offset 451.
2020-01-07 20:01:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 377d93a0-16c4-4ff6-ad5e-254ebcaf4b27
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-94, groupId=377d93a0-16c4-4ff6-ad5e-254ebcaf4b27] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-94, groupId=377d93a0-16c4-4ff6-ad5e-254ebcaf4b27] Revoking previously assigned partitions []
2020-01-07 20:01:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-94, groupId=377d93a0-16c4-4ff6-ad5e-254ebcaf4b27] (Re-)joining group
2020-01-07 20:01:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-94, groupId=377d93a0-16c4-4ff6-ad5e-254ebcaf4b27] Successfully joined group with generation 1
2020-01-07 20:01:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-94, groupId=377d93a0-16c4-4ff6-ad5e-254ebcaf4b27] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:57 INFO  Fetcher:583 - [Consumer clientId=consumer-94, groupId=377d93a0-16c4-4ff6-ad5e-254ebcaf4b27] Resetting offset for partition test101-0 to offset 453.
2020-01-07 20:01:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ab332955-90a6-4348-8c4d-d9a85e74fdbc
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-95, groupId=ab332955-90a6-4348-8c4d-d9a85e74fdbc] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-95, groupId=ab332955-90a6-4348-8c4d-d9a85e74fdbc] Revoking previously assigned partitions []
2020-01-07 20:01:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-95, groupId=ab332955-90a6-4348-8c4d-d9a85e74fdbc] (Re-)joining group
2020-01-07 20:01:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-95, groupId=ab332955-90a6-4348-8c4d-d9a85e74fdbc] Successfully joined group with generation 1
2020-01-07 20:01:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-95, groupId=ab332955-90a6-4348-8c4d-d9a85e74fdbc] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:57 INFO  Fetcher:583 - [Consumer clientId=consumer-95, groupId=ab332955-90a6-4348-8c4d-d9a85e74fdbc] Resetting offset for partition test101-0 to offset 454.
2020-01-07 20:01:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3891acac-7e20-4f9c-a61c-527bf55babea
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-96, groupId=3891acac-7e20-4f9c-a61c-527bf55babea] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-96, groupId=3891acac-7e20-4f9c-a61c-527bf55babea] Revoking previously assigned partitions []
2020-01-07 20:01:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-96, groupId=3891acac-7e20-4f9c-a61c-527bf55babea] (Re-)joining group
2020-01-07 20:01:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-96, groupId=3891acac-7e20-4f9c-a61c-527bf55babea] Successfully joined group with generation 1
2020-01-07 20:01:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-96, groupId=3891acac-7e20-4f9c-a61c-527bf55babea] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:57 INFO  Fetcher:583 - [Consumer clientId=consumer-96, groupId=3891acac-7e20-4f9c-a61c-527bf55babea] Resetting offset for partition test101-0 to offset 456.
2020-01-07 20:01:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = daf7289c-d2f8-4dd7-aa8b-a72ab7939631
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-97, groupId=daf7289c-d2f8-4dd7-aa8b-a72ab7939631] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-97, groupId=daf7289c-d2f8-4dd7-aa8b-a72ab7939631] Revoking previously assigned partitions []
2020-01-07 20:01:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-97, groupId=daf7289c-d2f8-4dd7-aa8b-a72ab7939631] (Re-)joining group
2020-01-07 20:01:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-97, groupId=daf7289c-d2f8-4dd7-aa8b-a72ab7939631] Successfully joined group with generation 1
2020-01-07 20:01:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-97, groupId=daf7289c-d2f8-4dd7-aa8b-a72ab7939631] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:57 INFO  Fetcher:583 - [Consumer clientId=consumer-97, groupId=daf7289c-d2f8-4dd7-aa8b-a72ab7939631] Resetting offset for partition test101-0 to offset 459.
2020-01-07 20:01:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9aa30d7e-ea32-4e21-8f5d-e74c6426a315
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-98, groupId=9aa30d7e-ea32-4e21-8f5d-e74c6426a315] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-98, groupId=9aa30d7e-ea32-4e21-8f5d-e74c6426a315] Revoking previously assigned partitions []
2020-01-07 20:01:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-98, groupId=9aa30d7e-ea32-4e21-8f5d-e74c6426a315] (Re-)joining group
2020-01-07 20:01:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-98, groupId=9aa30d7e-ea32-4e21-8f5d-e74c6426a315] Successfully joined group with generation 1
2020-01-07 20:01:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-98, groupId=9aa30d7e-ea32-4e21-8f5d-e74c6426a315] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:57 INFO  Fetcher:583 - [Consumer clientId=consumer-98, groupId=9aa30d7e-ea32-4e21-8f5d-e74c6426a315] Resetting offset for partition test101-0 to offset 461.
2020-01-07 20:01:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d9079b9f-a24a-4b1b-83ff-8f27cfaaca09
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-99, groupId=d9079b9f-a24a-4b1b-83ff-8f27cfaaca09] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-99, groupId=d9079b9f-a24a-4b1b-83ff-8f27cfaaca09] Revoking previously assigned partitions []
2020-01-07 20:01:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-99, groupId=d9079b9f-a24a-4b1b-83ff-8f27cfaaca09] (Re-)joining group
2020-01-07 20:01:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-99, groupId=d9079b9f-a24a-4b1b-83ff-8f27cfaaca09] Successfully joined group with generation 1
2020-01-07 20:01:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-99, groupId=d9079b9f-a24a-4b1b-83ff-8f27cfaaca09] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:58 INFO  Fetcher:583 - [Consumer clientId=consumer-99, groupId=d9079b9f-a24a-4b1b-83ff-8f27cfaaca09] Resetting offset for partition test101-0 to offset 463.
2020-01-07 20:01:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 53e2d3f5-3520-4180-a497-56c3ff0bd610
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:01:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:01:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:01:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:01:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-100, groupId=53e2d3f5-3520-4180-a497-56c3ff0bd610] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:01:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-100, groupId=53e2d3f5-3520-4180-a497-56c3ff0bd610] Revoking previously assigned partitions []
2020-01-07 20:01:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-100, groupId=53e2d3f5-3520-4180-a497-56c3ff0bd610] (Re-)joining group
2020-01-07 20:01:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-100, groupId=53e2d3f5-3520-4180-a497-56c3ff0bd610] Successfully joined group with generation 1
2020-01-07 20:01:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-100, groupId=53e2d3f5-3520-4180-a497-56c3ff0bd610] Setting newly assigned partitions [test101-0]
2020-01-07 20:01:58 INFO  Fetcher:583 - [Consumer clientId=consumer-100, groupId=53e2d3f5-3520-4180-a497-56c3ff0bd610] Resetting offset for partition test101-0 to offset 465.
2020-01-07 20:25:21 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1c2058da-d386-4002-ad26-bd6cc6e97b90
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:22 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:22 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:22 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:22 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=1c2058da-d386-4002-ad26-bd6cc6e97b90] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:22 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=1c2058da-d386-4002-ad26-bd6cc6e97b90] Revoking previously assigned partitions []
2020-01-07 20:25:22 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=1c2058da-d386-4002-ad26-bd6cc6e97b90] (Re-)joining group
2020-01-07 20:25:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=1c2058da-d386-4002-ad26-bd6cc6e97b90] Successfully joined group with generation 1
2020-01-07 20:25:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=1c2058da-d386-4002-ad26-bd6cc6e97b90] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:23 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=1c2058da-d386-4002-ad26-bd6cc6e97b90] Resetting offset for partition test101-0 to offset 979.
2020-01-07 20:25:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3788c12f-f6c2-4e50-a6ff-bbe824e40621
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-2, groupId=3788c12f-f6c2-4e50-a6ff-bbe824e40621] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-2, groupId=3788c12f-f6c2-4e50-a6ff-bbe824e40621] Revoking previously assigned partitions []
2020-01-07 20:25:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-2, groupId=3788c12f-f6c2-4e50-a6ff-bbe824e40621] (Re-)joining group
2020-01-07 20:25:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-2, groupId=3788c12f-f6c2-4e50-a6ff-bbe824e40621] Successfully joined group with generation 1
2020-01-07 20:25:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-2, groupId=3788c12f-f6c2-4e50-a6ff-bbe824e40621] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:23 INFO  Fetcher:583 - [Consumer clientId=consumer-2, groupId=3788c12f-f6c2-4e50-a6ff-bbe824e40621] Resetting offset for partition test101-0 to offset 982.
2020-01-07 20:25:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 260a5b80-7b75-446c-b9cb-8f7b847aad32
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-3, groupId=260a5b80-7b75-446c-b9cb-8f7b847aad32] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-3, groupId=260a5b80-7b75-446c-b9cb-8f7b847aad32] Revoking previously assigned partitions []
2020-01-07 20:25:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-3, groupId=260a5b80-7b75-446c-b9cb-8f7b847aad32] (Re-)joining group
2020-01-07 20:25:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-3, groupId=260a5b80-7b75-446c-b9cb-8f7b847aad32] Successfully joined group with generation 1
2020-01-07 20:25:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-3, groupId=260a5b80-7b75-446c-b9cb-8f7b847aad32] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:23 INFO  Fetcher:583 - [Consumer clientId=consumer-3, groupId=260a5b80-7b75-446c-b9cb-8f7b847aad32] Resetting offset for partition test101-0 to offset 984.
2020-01-07 20:25:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b297fa0a-6765-42b8-91e3-f77a9e074e6c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-4, groupId=b297fa0a-6765-42b8-91e3-f77a9e074e6c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-4, groupId=b297fa0a-6765-42b8-91e3-f77a9e074e6c] Revoking previously assigned partitions []
2020-01-07 20:25:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-4, groupId=b297fa0a-6765-42b8-91e3-f77a9e074e6c] (Re-)joining group
2020-01-07 20:25:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-4, groupId=b297fa0a-6765-42b8-91e3-f77a9e074e6c] Successfully joined group with generation 1
2020-01-07 20:25:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-4, groupId=b297fa0a-6765-42b8-91e3-f77a9e074e6c] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:23 INFO  Fetcher:583 - [Consumer clientId=consumer-4, groupId=b297fa0a-6765-42b8-91e3-f77a9e074e6c] Resetting offset for partition test101-0 to offset 986.
2020-01-07 20:25:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ae32e0f3-ddcc-42bd-808f-bccc15159c9b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-5, groupId=ae32e0f3-ddcc-42bd-808f-bccc15159c9b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-5, groupId=ae32e0f3-ddcc-42bd-808f-bccc15159c9b] Revoking previously assigned partitions []
2020-01-07 20:25:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-5, groupId=ae32e0f3-ddcc-42bd-808f-bccc15159c9b] (Re-)joining group
2020-01-07 20:25:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-5, groupId=ae32e0f3-ddcc-42bd-808f-bccc15159c9b] Successfully joined group with generation 1
2020-01-07 20:25:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-5, groupId=ae32e0f3-ddcc-42bd-808f-bccc15159c9b] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:23 INFO  Fetcher:583 - [Consumer clientId=consumer-5, groupId=ae32e0f3-ddcc-42bd-808f-bccc15159c9b] Resetting offset for partition test101-0 to offset 987.
2020-01-07 20:25:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 65304eb9-2d6d-404c-b6cd-8a27f3121eba
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-6, groupId=65304eb9-2d6d-404c-b6cd-8a27f3121eba] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-6, groupId=65304eb9-2d6d-404c-b6cd-8a27f3121eba] Revoking previously assigned partitions []
2020-01-07 20:25:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-6, groupId=65304eb9-2d6d-404c-b6cd-8a27f3121eba] (Re-)joining group
2020-01-07 20:25:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-6, groupId=65304eb9-2d6d-404c-b6cd-8a27f3121eba] Successfully joined group with generation 1
2020-01-07 20:25:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-6, groupId=65304eb9-2d6d-404c-b6cd-8a27f3121eba] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:23 INFO  Fetcher:583 - [Consumer clientId=consumer-6, groupId=65304eb9-2d6d-404c-b6cd-8a27f3121eba] Resetting offset for partition test101-0 to offset 989.
2020-01-07 20:25:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 14d04d71-345d-42ae-9b26-3bdc9933bc31
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-7, groupId=14d04d71-345d-42ae-9b26-3bdc9933bc31] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-7, groupId=14d04d71-345d-42ae-9b26-3bdc9933bc31] Revoking previously assigned partitions []
2020-01-07 20:25:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-7, groupId=14d04d71-345d-42ae-9b26-3bdc9933bc31] (Re-)joining group
2020-01-07 20:25:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-7, groupId=14d04d71-345d-42ae-9b26-3bdc9933bc31] Successfully joined group with generation 1
2020-01-07 20:25:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-7, groupId=14d04d71-345d-42ae-9b26-3bdc9933bc31] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:23 INFO  Fetcher:583 - [Consumer clientId=consumer-7, groupId=14d04d71-345d-42ae-9b26-3bdc9933bc31] Resetting offset for partition test101-0 to offset 992.
2020-01-07 20:25:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f7959068-3381-436f-8a8c-5db8cf32e5c8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-8, groupId=f7959068-3381-436f-8a8c-5db8cf32e5c8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-8, groupId=f7959068-3381-436f-8a8c-5db8cf32e5c8] Revoking previously assigned partitions []
2020-01-07 20:25:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-8, groupId=f7959068-3381-436f-8a8c-5db8cf32e5c8] (Re-)joining group
2020-01-07 20:25:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-8, groupId=f7959068-3381-436f-8a8c-5db8cf32e5c8] Successfully joined group with generation 1
2020-01-07 20:25:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-8, groupId=f7959068-3381-436f-8a8c-5db8cf32e5c8] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:23 INFO  Fetcher:583 - [Consumer clientId=consumer-8, groupId=f7959068-3381-436f-8a8c-5db8cf32e5c8] Resetting offset for partition test101-0 to offset 994.
2020-01-07 20:25:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4c13508f-0758-41ce-b3af-ea0c24bb2517
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-9, groupId=4c13508f-0758-41ce-b3af-ea0c24bb2517] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-9, groupId=4c13508f-0758-41ce-b3af-ea0c24bb2517] Revoking previously assigned partitions []
2020-01-07 20:25:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-9, groupId=4c13508f-0758-41ce-b3af-ea0c24bb2517] (Re-)joining group
2020-01-07 20:25:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-9, groupId=4c13508f-0758-41ce-b3af-ea0c24bb2517] Successfully joined group with generation 1
2020-01-07 20:25:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-9, groupId=4c13508f-0758-41ce-b3af-ea0c24bb2517] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:23 INFO  Fetcher:583 - [Consumer clientId=consumer-9, groupId=4c13508f-0758-41ce-b3af-ea0c24bb2517] Resetting offset for partition test101-0 to offset 996.
2020-01-07 20:25:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ed65abb5-d268-4c5a-8b5b-69fb03811928
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-10, groupId=ed65abb5-d268-4c5a-8b5b-69fb03811928] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-10, groupId=ed65abb5-d268-4c5a-8b5b-69fb03811928] Revoking previously assigned partitions []
2020-01-07 20:25:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-10, groupId=ed65abb5-d268-4c5a-8b5b-69fb03811928] (Re-)joining group
2020-01-07 20:25:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-10, groupId=ed65abb5-d268-4c5a-8b5b-69fb03811928] Successfully joined group with generation 1
2020-01-07 20:25:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-10, groupId=ed65abb5-d268-4c5a-8b5b-69fb03811928] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:23 INFO  Fetcher:583 - [Consumer clientId=consumer-10, groupId=ed65abb5-d268-4c5a-8b5b-69fb03811928] Resetting offset for partition test101-0 to offset 998.
2020-01-07 20:25:23 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e61a77c8-e26b-4b44-8298-468011ea14d3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:23 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:23 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-11, groupId=e61a77c8-e26b-4b44-8298-468011ea14d3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-11, groupId=e61a77c8-e26b-4b44-8298-468011ea14d3] Revoking previously assigned partitions []
2020-01-07 20:25:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-11, groupId=e61a77c8-e26b-4b44-8298-468011ea14d3] (Re-)joining group
2020-01-07 20:25:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-11, groupId=e61a77c8-e26b-4b44-8298-468011ea14d3] Successfully joined group with generation 1
2020-01-07 20:25:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-11, groupId=e61a77c8-e26b-4b44-8298-468011ea14d3] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:24 INFO  Fetcher:583 - [Consumer clientId=consumer-11, groupId=e61a77c8-e26b-4b44-8298-468011ea14d3] Resetting offset for partition test101-0 to offset 1001.
2020-01-07 20:25:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 17ba18b6-3ddb-4f9f-a14e-889f1cab98ff
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-12, groupId=17ba18b6-3ddb-4f9f-a14e-889f1cab98ff] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-12, groupId=17ba18b6-3ddb-4f9f-a14e-889f1cab98ff] Revoking previously assigned partitions []
2020-01-07 20:25:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-12, groupId=17ba18b6-3ddb-4f9f-a14e-889f1cab98ff] (Re-)joining group
2020-01-07 20:25:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-12, groupId=17ba18b6-3ddb-4f9f-a14e-889f1cab98ff] Successfully joined group with generation 1
2020-01-07 20:25:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-12, groupId=17ba18b6-3ddb-4f9f-a14e-889f1cab98ff] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:24 INFO  Fetcher:583 - [Consumer clientId=consumer-12, groupId=17ba18b6-3ddb-4f9f-a14e-889f1cab98ff] Resetting offset for partition test101-0 to offset 1003.
2020-01-07 20:25:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 31534f97-d5bb-4fdb-8983-780c5c9a1021
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-13, groupId=31534f97-d5bb-4fdb-8983-780c5c9a1021] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-13, groupId=31534f97-d5bb-4fdb-8983-780c5c9a1021] Revoking previously assigned partitions []
2020-01-07 20:25:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-13, groupId=31534f97-d5bb-4fdb-8983-780c5c9a1021] (Re-)joining group
2020-01-07 20:25:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-13, groupId=31534f97-d5bb-4fdb-8983-780c5c9a1021] Successfully joined group with generation 1
2020-01-07 20:25:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-13, groupId=31534f97-d5bb-4fdb-8983-780c5c9a1021] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:24 INFO  Fetcher:583 - [Consumer clientId=consumer-13, groupId=31534f97-d5bb-4fdb-8983-780c5c9a1021] Resetting offset for partition test101-0 to offset 1004.
2020-01-07 20:25:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 87bf56a4-f0e2-4ad6-8aca-fc01a426aed1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-14, groupId=87bf56a4-f0e2-4ad6-8aca-fc01a426aed1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-14, groupId=87bf56a4-f0e2-4ad6-8aca-fc01a426aed1] Revoking previously assigned partitions []
2020-01-07 20:25:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-14, groupId=87bf56a4-f0e2-4ad6-8aca-fc01a426aed1] (Re-)joining group
2020-01-07 20:25:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-14, groupId=87bf56a4-f0e2-4ad6-8aca-fc01a426aed1] Successfully joined group with generation 1
2020-01-07 20:25:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-14, groupId=87bf56a4-f0e2-4ad6-8aca-fc01a426aed1] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:24 INFO  Fetcher:583 - [Consumer clientId=consumer-14, groupId=87bf56a4-f0e2-4ad6-8aca-fc01a426aed1] Resetting offset for partition test101-0 to offset 1005.
2020-01-07 20:25:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1f39ea5e-9302-4267-9524-39f1ed3c9b66
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-15, groupId=1f39ea5e-9302-4267-9524-39f1ed3c9b66] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-15, groupId=1f39ea5e-9302-4267-9524-39f1ed3c9b66] Revoking previously assigned partitions []
2020-01-07 20:25:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-15, groupId=1f39ea5e-9302-4267-9524-39f1ed3c9b66] (Re-)joining group
2020-01-07 20:25:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-15, groupId=1f39ea5e-9302-4267-9524-39f1ed3c9b66] Successfully joined group with generation 1
2020-01-07 20:25:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-15, groupId=1f39ea5e-9302-4267-9524-39f1ed3c9b66] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:24 INFO  Fetcher:583 - [Consumer clientId=consumer-15, groupId=1f39ea5e-9302-4267-9524-39f1ed3c9b66] Resetting offset for partition test101-0 to offset 1007.
2020-01-07 20:25:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4dc68a01-42f9-4287-ae6e-5dd53ee487ad
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-16, groupId=4dc68a01-42f9-4287-ae6e-5dd53ee487ad] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-16, groupId=4dc68a01-42f9-4287-ae6e-5dd53ee487ad] Revoking previously assigned partitions []
2020-01-07 20:25:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-16, groupId=4dc68a01-42f9-4287-ae6e-5dd53ee487ad] (Re-)joining group
2020-01-07 20:25:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-16, groupId=4dc68a01-42f9-4287-ae6e-5dd53ee487ad] Successfully joined group with generation 1
2020-01-07 20:25:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-16, groupId=4dc68a01-42f9-4287-ae6e-5dd53ee487ad] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:24 INFO  Fetcher:583 - [Consumer clientId=consumer-16, groupId=4dc68a01-42f9-4287-ae6e-5dd53ee487ad] Resetting offset for partition test101-0 to offset 1008.
2020-01-07 20:25:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = db283257-108b-4ac0-97dd-d665f7ea4e6a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-17, groupId=db283257-108b-4ac0-97dd-d665f7ea4e6a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-17, groupId=db283257-108b-4ac0-97dd-d665f7ea4e6a] Revoking previously assigned partitions []
2020-01-07 20:25:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-17, groupId=db283257-108b-4ac0-97dd-d665f7ea4e6a] (Re-)joining group
2020-01-07 20:25:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-17, groupId=db283257-108b-4ac0-97dd-d665f7ea4e6a] Successfully joined group with generation 1
2020-01-07 20:25:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-17, groupId=db283257-108b-4ac0-97dd-d665f7ea4e6a] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:24 INFO  Fetcher:583 - [Consumer clientId=consumer-17, groupId=db283257-108b-4ac0-97dd-d665f7ea4e6a] Resetting offset for partition test101-0 to offset 1011.
2020-01-07 20:25:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c88ea772-dfe1-4e29-a23c-a44a2a38a313
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:24 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-18, groupId=c88ea772-dfe1-4e29-a23c-a44a2a38a313] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-18, groupId=c88ea772-dfe1-4e29-a23c-a44a2a38a313] Revoking previously assigned partitions []
2020-01-07 20:25:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-18, groupId=c88ea772-dfe1-4e29-a23c-a44a2a38a313] (Re-)joining group
2020-01-07 20:25:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-18, groupId=c88ea772-dfe1-4e29-a23c-a44a2a38a313] Successfully joined group with generation 1
2020-01-07 20:25:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-18, groupId=c88ea772-dfe1-4e29-a23c-a44a2a38a313] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:24 INFO  Fetcher:583 - [Consumer clientId=consumer-18, groupId=c88ea772-dfe1-4e29-a23c-a44a2a38a313] Resetting offset for partition test101-0 to offset 1013.
2020-01-07 20:25:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 04326e65-b9bf-4138-a762-062e5c353e12
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-19, groupId=04326e65-b9bf-4138-a762-062e5c353e12] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-19, groupId=04326e65-b9bf-4138-a762-062e5c353e12] Revoking previously assigned partitions []
2020-01-07 20:25:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-19, groupId=04326e65-b9bf-4138-a762-062e5c353e12] (Re-)joining group
2020-01-07 20:25:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-19, groupId=04326e65-b9bf-4138-a762-062e5c353e12] Successfully joined group with generation 1
2020-01-07 20:25:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-19, groupId=04326e65-b9bf-4138-a762-062e5c353e12] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:25 INFO  Fetcher:583 - [Consumer clientId=consumer-19, groupId=04326e65-b9bf-4138-a762-062e5c353e12] Resetting offset for partition test101-0 to offset 1015.
2020-01-07 20:25:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c17de9db-3823-4257-b6c6-d4bed7e1fdfb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-20, groupId=c17de9db-3823-4257-b6c6-d4bed7e1fdfb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-20, groupId=c17de9db-3823-4257-b6c6-d4bed7e1fdfb] Revoking previously assigned partitions []
2020-01-07 20:25:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-20, groupId=c17de9db-3823-4257-b6c6-d4bed7e1fdfb] (Re-)joining group
2020-01-07 20:25:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-20, groupId=c17de9db-3823-4257-b6c6-d4bed7e1fdfb] Successfully joined group with generation 1
2020-01-07 20:25:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-20, groupId=c17de9db-3823-4257-b6c6-d4bed7e1fdfb] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:25 INFO  Fetcher:583 - [Consumer clientId=consumer-20, groupId=c17de9db-3823-4257-b6c6-d4bed7e1fdfb] Resetting offset for partition test101-0 to offset 1017.
2020-01-07 20:25:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = be60d302-933c-4683-ae98-d1d0bfbf7102
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-21, groupId=be60d302-933c-4683-ae98-d1d0bfbf7102] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-21, groupId=be60d302-933c-4683-ae98-d1d0bfbf7102] Revoking previously assigned partitions []
2020-01-07 20:25:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-21, groupId=be60d302-933c-4683-ae98-d1d0bfbf7102] (Re-)joining group
2020-01-07 20:25:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-21, groupId=be60d302-933c-4683-ae98-d1d0bfbf7102] Successfully joined group with generation 1
2020-01-07 20:25:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-21, groupId=be60d302-933c-4683-ae98-d1d0bfbf7102] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:25 INFO  Fetcher:583 - [Consumer clientId=consumer-21, groupId=be60d302-933c-4683-ae98-d1d0bfbf7102] Resetting offset for partition test101-0 to offset 1018.
2020-01-07 20:25:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fab706dc-c9a0-4ced-a654-c686297b417c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-22, groupId=fab706dc-c9a0-4ced-a654-c686297b417c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-22, groupId=fab706dc-c9a0-4ced-a654-c686297b417c] Revoking previously assigned partitions []
2020-01-07 20:25:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-22, groupId=fab706dc-c9a0-4ced-a654-c686297b417c] (Re-)joining group
2020-01-07 20:25:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-22, groupId=fab706dc-c9a0-4ced-a654-c686297b417c] Successfully joined group with generation 1
2020-01-07 20:25:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-22, groupId=fab706dc-c9a0-4ced-a654-c686297b417c] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:25 INFO  Fetcher:583 - [Consumer clientId=consumer-22, groupId=fab706dc-c9a0-4ced-a654-c686297b417c] Resetting offset for partition test101-0 to offset 1019.
2020-01-07 20:25:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7d36cda6-d66a-4b24-924b-1ffb771e1669
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-23, groupId=7d36cda6-d66a-4b24-924b-1ffb771e1669] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-23, groupId=7d36cda6-d66a-4b24-924b-1ffb771e1669] Revoking previously assigned partitions []
2020-01-07 20:25:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-23, groupId=7d36cda6-d66a-4b24-924b-1ffb771e1669] (Re-)joining group
2020-01-07 20:25:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-23, groupId=7d36cda6-d66a-4b24-924b-1ffb771e1669] Successfully joined group with generation 1
2020-01-07 20:25:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-23, groupId=7d36cda6-d66a-4b24-924b-1ffb771e1669] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:25 INFO  Fetcher:583 - [Consumer clientId=consumer-23, groupId=7d36cda6-d66a-4b24-924b-1ffb771e1669] Resetting offset for partition test101-0 to offset 1021.
2020-01-07 20:25:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 49939842-042c-4c29-822f-b964ba4d9b9b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-24, groupId=49939842-042c-4c29-822f-b964ba4d9b9b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-24, groupId=49939842-042c-4c29-822f-b964ba4d9b9b] Revoking previously assigned partitions []
2020-01-07 20:25:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-24, groupId=49939842-042c-4c29-822f-b964ba4d9b9b] (Re-)joining group
2020-01-07 20:25:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-24, groupId=49939842-042c-4c29-822f-b964ba4d9b9b] Successfully joined group with generation 1
2020-01-07 20:25:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-24, groupId=49939842-042c-4c29-822f-b964ba4d9b9b] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:25 INFO  Fetcher:583 - [Consumer clientId=consumer-24, groupId=49939842-042c-4c29-822f-b964ba4d9b9b] Resetting offset for partition test101-0 to offset 1023.
2020-01-07 20:25:25 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c1bf0620-2987-4dc5-a14f-426806dba1a8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:25 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:25 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:25 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:25 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-25, groupId=c1bf0620-2987-4dc5-a14f-426806dba1a8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:25 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-25, groupId=c1bf0620-2987-4dc5-a14f-426806dba1a8] Revoking previously assigned partitions []
2020-01-07 20:25:25 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-25, groupId=c1bf0620-2987-4dc5-a14f-426806dba1a8] (Re-)joining group
2020-01-07 20:25:25 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-25, groupId=c1bf0620-2987-4dc5-a14f-426806dba1a8] Successfully joined group with generation 1
2020-01-07 20:25:25 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-25, groupId=c1bf0620-2987-4dc5-a14f-426806dba1a8] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:25 INFO  Fetcher:583 - [Consumer clientId=consumer-25, groupId=c1bf0620-2987-4dc5-a14f-426806dba1a8] Resetting offset for partition test101-0 to offset 1024.
2020-01-07 20:25:26 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = cf86e8ef-350f-46f8-afdf-ce1767b02f19
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:26 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:26 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:26 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:26 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-26, groupId=cf86e8ef-350f-46f8-afdf-ce1767b02f19] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:26 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-26, groupId=cf86e8ef-350f-46f8-afdf-ce1767b02f19] Revoking previously assigned partitions []
2020-01-07 20:25:26 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-26, groupId=cf86e8ef-350f-46f8-afdf-ce1767b02f19] (Re-)joining group
2020-01-07 20:25:26 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-26, groupId=cf86e8ef-350f-46f8-afdf-ce1767b02f19] Successfully joined group with generation 1
2020-01-07 20:25:26 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-26, groupId=cf86e8ef-350f-46f8-afdf-ce1767b02f19] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:26 INFO  Fetcher:583 - [Consumer clientId=consumer-26, groupId=cf86e8ef-350f-46f8-afdf-ce1767b02f19] Resetting offset for partition test101-0 to offset 1027.
2020-01-07 20:25:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = baa39ece-00bb-4d24-9fdc-d0d3138d33ce
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-27, groupId=baa39ece-00bb-4d24-9fdc-d0d3138d33ce] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-27, groupId=baa39ece-00bb-4d24-9fdc-d0d3138d33ce] Revoking previously assigned partitions []
2020-01-07 20:25:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-27, groupId=baa39ece-00bb-4d24-9fdc-d0d3138d33ce] (Re-)joining group
2020-01-07 20:25:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-27, groupId=baa39ece-00bb-4d24-9fdc-d0d3138d33ce] Successfully joined group with generation 1
2020-01-07 20:25:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-27, groupId=baa39ece-00bb-4d24-9fdc-d0d3138d33ce] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:27 INFO  Fetcher:583 - [Consumer clientId=consumer-27, groupId=baa39ece-00bb-4d24-9fdc-d0d3138d33ce] Resetting offset for partition test101-0 to offset 1029.
2020-01-07 20:25:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c539235e-8eb0-495d-8c53-9ead874587bf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-28, groupId=c539235e-8eb0-495d-8c53-9ead874587bf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-28, groupId=c539235e-8eb0-495d-8c53-9ead874587bf] Revoking previously assigned partitions []
2020-01-07 20:25:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-28, groupId=c539235e-8eb0-495d-8c53-9ead874587bf] (Re-)joining group
2020-01-07 20:25:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-28, groupId=c539235e-8eb0-495d-8c53-9ead874587bf] Successfully joined group with generation 1
2020-01-07 20:25:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-28, groupId=c539235e-8eb0-495d-8c53-9ead874587bf] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:27 INFO  Fetcher:583 - [Consumer clientId=consumer-28, groupId=c539235e-8eb0-495d-8c53-9ead874587bf] Resetting offset for partition test101-0 to offset 1030.
2020-01-07 20:25:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4a3a8f3a-d097-4d29-ae68-4e2d9369219e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-29, groupId=4a3a8f3a-d097-4d29-ae68-4e2d9369219e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-29, groupId=4a3a8f3a-d097-4d29-ae68-4e2d9369219e] Revoking previously assigned partitions []
2020-01-07 20:25:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-29, groupId=4a3a8f3a-d097-4d29-ae68-4e2d9369219e] (Re-)joining group
2020-01-07 20:25:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-29, groupId=4a3a8f3a-d097-4d29-ae68-4e2d9369219e] Successfully joined group with generation 1
2020-01-07 20:25:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-29, groupId=4a3a8f3a-d097-4d29-ae68-4e2d9369219e] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:27 INFO  Fetcher:583 - [Consumer clientId=consumer-29, groupId=4a3a8f3a-d097-4d29-ae68-4e2d9369219e] Resetting offset for partition test101-0 to offset 1031.
2020-01-07 20:25:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dc8b3ca6-a58a-4ab1-ace0-10514c14667c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-30, groupId=dc8b3ca6-a58a-4ab1-ace0-10514c14667c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-30, groupId=dc8b3ca6-a58a-4ab1-ace0-10514c14667c] Revoking previously assigned partitions []
2020-01-07 20:25:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-30, groupId=dc8b3ca6-a58a-4ab1-ace0-10514c14667c] (Re-)joining group
2020-01-07 20:25:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-30, groupId=dc8b3ca6-a58a-4ab1-ace0-10514c14667c] Successfully joined group with generation 1
2020-01-07 20:25:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-30, groupId=dc8b3ca6-a58a-4ab1-ace0-10514c14667c] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:27 INFO  Fetcher:583 - [Consumer clientId=consumer-30, groupId=dc8b3ca6-a58a-4ab1-ace0-10514c14667c] Resetting offset for partition test101-0 to offset 1032.
2020-01-07 20:25:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6a1e2acf-8e07-4815-b84d-5cc623021cc4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-31, groupId=6a1e2acf-8e07-4815-b84d-5cc623021cc4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-31, groupId=6a1e2acf-8e07-4815-b84d-5cc623021cc4] Revoking previously assigned partitions []
2020-01-07 20:25:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-31, groupId=6a1e2acf-8e07-4815-b84d-5cc623021cc4] (Re-)joining group
2020-01-07 20:25:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-31, groupId=6a1e2acf-8e07-4815-b84d-5cc623021cc4] Successfully joined group with generation 1
2020-01-07 20:25:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-31, groupId=6a1e2acf-8e07-4815-b84d-5cc623021cc4] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:27 INFO  Fetcher:583 - [Consumer clientId=consumer-31, groupId=6a1e2acf-8e07-4815-b84d-5cc623021cc4] Resetting offset for partition test101-0 to offset 1035.
2020-01-07 20:25:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1d29f4d2-6525-4caa-8389-f7e4f1d96d41
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-32, groupId=1d29f4d2-6525-4caa-8389-f7e4f1d96d41] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-32, groupId=1d29f4d2-6525-4caa-8389-f7e4f1d96d41] Revoking previously assigned partitions []
2020-01-07 20:25:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-32, groupId=1d29f4d2-6525-4caa-8389-f7e4f1d96d41] (Re-)joining group
2020-01-07 20:25:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-32, groupId=1d29f4d2-6525-4caa-8389-f7e4f1d96d41] Successfully joined group with generation 1
2020-01-07 20:25:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-32, groupId=1d29f4d2-6525-4caa-8389-f7e4f1d96d41] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:27 INFO  Fetcher:583 - [Consumer clientId=consumer-32, groupId=1d29f4d2-6525-4caa-8389-f7e4f1d96d41] Resetting offset for partition test101-0 to offset 1037.
2020-01-07 20:25:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8d9304f6-214c-43cd-b889-d75e714ba39d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-33, groupId=8d9304f6-214c-43cd-b889-d75e714ba39d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-33, groupId=8d9304f6-214c-43cd-b889-d75e714ba39d] Revoking previously assigned partitions []
2020-01-07 20:25:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-33, groupId=8d9304f6-214c-43cd-b889-d75e714ba39d] (Re-)joining group
2020-01-07 20:25:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-33, groupId=8d9304f6-214c-43cd-b889-d75e714ba39d] Successfully joined group with generation 1
2020-01-07 20:25:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-33, groupId=8d9304f6-214c-43cd-b889-d75e714ba39d] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:27 INFO  Fetcher:583 - [Consumer clientId=consumer-33, groupId=8d9304f6-214c-43cd-b889-d75e714ba39d] Resetting offset for partition test101-0 to offset 1038.
2020-01-07 20:25:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 019445de-7704-413e-a641-f7bd6018cebc
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-34, groupId=019445de-7704-413e-a641-f7bd6018cebc] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-34, groupId=019445de-7704-413e-a641-f7bd6018cebc] Revoking previously assigned partitions []
2020-01-07 20:25:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-34, groupId=019445de-7704-413e-a641-f7bd6018cebc] (Re-)joining group
2020-01-07 20:25:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-34, groupId=019445de-7704-413e-a641-f7bd6018cebc] Successfully joined group with generation 1
2020-01-07 20:25:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-34, groupId=019445de-7704-413e-a641-f7bd6018cebc] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:27 INFO  Fetcher:583 - [Consumer clientId=consumer-34, groupId=019445de-7704-413e-a641-f7bd6018cebc] Resetting offset for partition test101-0 to offset 1039.
2020-01-07 20:25:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8da24433-99e1-4161-866e-d657a2498b85
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-35, groupId=8da24433-99e1-4161-866e-d657a2498b85] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-35, groupId=8da24433-99e1-4161-866e-d657a2498b85] Revoking previously assigned partitions []
2020-01-07 20:25:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-35, groupId=8da24433-99e1-4161-866e-d657a2498b85] (Re-)joining group
2020-01-07 20:25:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-35, groupId=8da24433-99e1-4161-866e-d657a2498b85] Successfully joined group with generation 1
2020-01-07 20:25:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-35, groupId=8da24433-99e1-4161-866e-d657a2498b85] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:27 INFO  Fetcher:583 - [Consumer clientId=consumer-35, groupId=8da24433-99e1-4161-866e-d657a2498b85] Resetting offset for partition test101-0 to offset 1040.
2020-01-07 20:25:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3d8fef1b-cc8d-42cc-beb5-3e796ac1d1fb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-36, groupId=3d8fef1b-cc8d-42cc-beb5-3e796ac1d1fb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-36, groupId=3d8fef1b-cc8d-42cc-beb5-3e796ac1d1fb] Revoking previously assigned partitions []
2020-01-07 20:25:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-36, groupId=3d8fef1b-cc8d-42cc-beb5-3e796ac1d1fb] (Re-)joining group
2020-01-07 20:25:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-36, groupId=3d8fef1b-cc8d-42cc-beb5-3e796ac1d1fb] Successfully joined group with generation 1
2020-01-07 20:25:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-36, groupId=3d8fef1b-cc8d-42cc-beb5-3e796ac1d1fb] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:27 INFO  Fetcher:583 - [Consumer clientId=consumer-36, groupId=3d8fef1b-cc8d-42cc-beb5-3e796ac1d1fb] Resetting offset for partition test101-0 to offset 1041.
2020-01-07 20:25:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d7d97991-f666-4bdb-be74-e964c90752b0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-37, groupId=d7d97991-f666-4bdb-be74-e964c90752b0] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-37, groupId=d7d97991-f666-4bdb-be74-e964c90752b0] Revoking previously assigned partitions []
2020-01-07 20:25:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-37, groupId=d7d97991-f666-4bdb-be74-e964c90752b0] (Re-)joining group
2020-01-07 20:25:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-37, groupId=d7d97991-f666-4bdb-be74-e964c90752b0] Successfully joined group with generation 1
2020-01-07 20:25:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-37, groupId=d7d97991-f666-4bdb-be74-e964c90752b0] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:27 INFO  Fetcher:583 - [Consumer clientId=consumer-37, groupId=d7d97991-f666-4bdb-be74-e964c90752b0] Resetting offset for partition test101-0 to offset 1042.
2020-01-07 20:25:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 755c4452-9851-4d34-9fa1-d1b7b223ebce
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:27 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-38, groupId=755c4452-9851-4d34-9fa1-d1b7b223ebce] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-38, groupId=755c4452-9851-4d34-9fa1-d1b7b223ebce] Revoking previously assigned partitions []
2020-01-07 20:25:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-38, groupId=755c4452-9851-4d34-9fa1-d1b7b223ebce] (Re-)joining group
2020-01-07 20:25:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-38, groupId=755c4452-9851-4d34-9fa1-d1b7b223ebce] Successfully joined group with generation 1
2020-01-07 20:25:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-38, groupId=755c4452-9851-4d34-9fa1-d1b7b223ebce] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:28 INFO  Fetcher:583 - [Consumer clientId=consumer-38, groupId=755c4452-9851-4d34-9fa1-d1b7b223ebce] Resetting offset for partition test101-0 to offset 1044.
2020-01-07 20:25:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d6f14cb2-c2ed-41e4-8e53-a95f4c7d25d7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-39, groupId=d6f14cb2-c2ed-41e4-8e53-a95f4c7d25d7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-39, groupId=d6f14cb2-c2ed-41e4-8e53-a95f4c7d25d7] Revoking previously assigned partitions []
2020-01-07 20:25:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-39, groupId=d6f14cb2-c2ed-41e4-8e53-a95f4c7d25d7] (Re-)joining group
2020-01-07 20:25:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-39, groupId=d6f14cb2-c2ed-41e4-8e53-a95f4c7d25d7] Successfully joined group with generation 1
2020-01-07 20:25:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-39, groupId=d6f14cb2-c2ed-41e4-8e53-a95f4c7d25d7] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:28 INFO  Fetcher:583 - [Consumer clientId=consumer-39, groupId=d6f14cb2-c2ed-41e4-8e53-a95f4c7d25d7] Resetting offset for partition test101-0 to offset 1046.
2020-01-07 20:25:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0ac411c6-f10f-4151-8237-5a689009e955
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-40, groupId=0ac411c6-f10f-4151-8237-5a689009e955] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-40, groupId=0ac411c6-f10f-4151-8237-5a689009e955] Revoking previously assigned partitions []
2020-01-07 20:25:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-40, groupId=0ac411c6-f10f-4151-8237-5a689009e955] (Re-)joining group
2020-01-07 20:25:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-40, groupId=0ac411c6-f10f-4151-8237-5a689009e955] Successfully joined group with generation 1
2020-01-07 20:25:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-40, groupId=0ac411c6-f10f-4151-8237-5a689009e955] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:28 INFO  Fetcher:583 - [Consumer clientId=consumer-40, groupId=0ac411c6-f10f-4151-8237-5a689009e955] Resetting offset for partition test101-0 to offset 1048.
2020-01-07 20:25:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7c687227-0b1c-45c2-bc0a-a66ce26c97e3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-41, groupId=7c687227-0b1c-45c2-bc0a-a66ce26c97e3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-41, groupId=7c687227-0b1c-45c2-bc0a-a66ce26c97e3] Revoking previously assigned partitions []
2020-01-07 20:25:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-41, groupId=7c687227-0b1c-45c2-bc0a-a66ce26c97e3] (Re-)joining group
2020-01-07 20:25:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-41, groupId=7c687227-0b1c-45c2-bc0a-a66ce26c97e3] Successfully joined group with generation 1
2020-01-07 20:25:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-41, groupId=7c687227-0b1c-45c2-bc0a-a66ce26c97e3] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:28 INFO  Fetcher:583 - [Consumer clientId=consumer-41, groupId=7c687227-0b1c-45c2-bc0a-a66ce26c97e3] Resetting offset for partition test101-0 to offset 1050.
2020-01-07 20:25:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 45d0af46-ad0b-4276-bdfd-c03c7c3e357e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-42, groupId=45d0af46-ad0b-4276-bdfd-c03c7c3e357e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-42, groupId=45d0af46-ad0b-4276-bdfd-c03c7c3e357e] Revoking previously assigned partitions []
2020-01-07 20:25:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-42, groupId=45d0af46-ad0b-4276-bdfd-c03c7c3e357e] (Re-)joining group
2020-01-07 20:25:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-42, groupId=45d0af46-ad0b-4276-bdfd-c03c7c3e357e] Successfully joined group with generation 1
2020-01-07 20:25:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-42, groupId=45d0af46-ad0b-4276-bdfd-c03c7c3e357e] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:28 INFO  Fetcher:583 - [Consumer clientId=consumer-42, groupId=45d0af46-ad0b-4276-bdfd-c03c7c3e357e] Resetting offset for partition test101-0 to offset 1051.
2020-01-07 20:25:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e6a9dd99-792c-4850-9528-891dbb0d86ed
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-43, groupId=e6a9dd99-792c-4850-9528-891dbb0d86ed] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-43, groupId=e6a9dd99-792c-4850-9528-891dbb0d86ed] Revoking previously assigned partitions []
2020-01-07 20:25:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-43, groupId=e6a9dd99-792c-4850-9528-891dbb0d86ed] (Re-)joining group
2020-01-07 20:25:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-43, groupId=e6a9dd99-792c-4850-9528-891dbb0d86ed] Successfully joined group with generation 1
2020-01-07 20:25:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-43, groupId=e6a9dd99-792c-4850-9528-891dbb0d86ed] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:28 INFO  Fetcher:583 - [Consumer clientId=consumer-43, groupId=e6a9dd99-792c-4850-9528-891dbb0d86ed] Resetting offset for partition test101-0 to offset 1052.
2020-01-07 20:25:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 10a8d5d5-1957-41a9-85dd-4f53d677c3ab
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-44, groupId=10a8d5d5-1957-41a9-85dd-4f53d677c3ab] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-44, groupId=10a8d5d5-1957-41a9-85dd-4f53d677c3ab] Revoking previously assigned partitions []
2020-01-07 20:25:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-44, groupId=10a8d5d5-1957-41a9-85dd-4f53d677c3ab] (Re-)joining group
2020-01-07 20:25:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-44, groupId=10a8d5d5-1957-41a9-85dd-4f53d677c3ab] Successfully joined group with generation 1
2020-01-07 20:25:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-44, groupId=10a8d5d5-1957-41a9-85dd-4f53d677c3ab] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:28 INFO  Fetcher:583 - [Consumer clientId=consumer-44, groupId=10a8d5d5-1957-41a9-85dd-4f53d677c3ab] Resetting offset for partition test101-0 to offset 1053.
2020-01-07 20:25:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 83234349-5ac1-43b9-8f0e-0274d19dacfd
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-45, groupId=83234349-5ac1-43b9-8f0e-0274d19dacfd] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-45, groupId=83234349-5ac1-43b9-8f0e-0274d19dacfd] Revoking previously assigned partitions []
2020-01-07 20:25:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-45, groupId=83234349-5ac1-43b9-8f0e-0274d19dacfd] (Re-)joining group
2020-01-07 20:25:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-45, groupId=83234349-5ac1-43b9-8f0e-0274d19dacfd] Successfully joined group with generation 1
2020-01-07 20:25:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-45, groupId=83234349-5ac1-43b9-8f0e-0274d19dacfd] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:28 INFO  Fetcher:583 - [Consumer clientId=consumer-45, groupId=83234349-5ac1-43b9-8f0e-0274d19dacfd] Resetting offset for partition test101-0 to offset 1055.
2020-01-07 20:25:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 52462ee4-30fa-4a11-b560-1f9a11a9722f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-46, groupId=52462ee4-30fa-4a11-b560-1f9a11a9722f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-46, groupId=52462ee4-30fa-4a11-b560-1f9a11a9722f] Revoking previously assigned partitions []
2020-01-07 20:25:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-46, groupId=52462ee4-30fa-4a11-b560-1f9a11a9722f] (Re-)joining group
2020-01-07 20:25:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-46, groupId=52462ee4-30fa-4a11-b560-1f9a11a9722f] Successfully joined group with generation 1
2020-01-07 20:25:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-46, groupId=52462ee4-30fa-4a11-b560-1f9a11a9722f] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:28 INFO  Fetcher:583 - [Consumer clientId=consumer-46, groupId=52462ee4-30fa-4a11-b560-1f9a11a9722f] Resetting offset for partition test101-0 to offset 1056.
2020-01-07 20:25:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e6192d44-d6a4-4d4f-bc6d-f31f05705fdf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-47, groupId=e6192d44-d6a4-4d4f-bc6d-f31f05705fdf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-47, groupId=e6192d44-d6a4-4d4f-bc6d-f31f05705fdf] Revoking previously assigned partitions []
2020-01-07 20:25:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-47, groupId=e6192d44-d6a4-4d4f-bc6d-f31f05705fdf] (Re-)joining group
2020-01-07 20:25:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-47, groupId=e6192d44-d6a4-4d4f-bc6d-f31f05705fdf] Successfully joined group with generation 1
2020-01-07 20:25:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-47, groupId=e6192d44-d6a4-4d4f-bc6d-f31f05705fdf] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:28 INFO  Fetcher:583 - [Consumer clientId=consumer-47, groupId=e6192d44-d6a4-4d4f-bc6d-f31f05705fdf] Resetting offset for partition test101-0 to offset 1057.
2020-01-07 20:25:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2cca6705-08d7-45e6-a105-368e488616af
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-48, groupId=2cca6705-08d7-45e6-a105-368e488616af] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-48, groupId=2cca6705-08d7-45e6-a105-368e488616af] Revoking previously assigned partitions []
2020-01-07 20:25:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-48, groupId=2cca6705-08d7-45e6-a105-368e488616af] (Re-)joining group
2020-01-07 20:25:28 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-48, groupId=2cca6705-08d7-45e6-a105-368e488616af] Successfully joined group with generation 1
2020-01-07 20:25:28 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-48, groupId=2cca6705-08d7-45e6-a105-368e488616af] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:28 INFO  Fetcher:583 - [Consumer clientId=consumer-48, groupId=2cca6705-08d7-45e6-a105-368e488616af] Resetting offset for partition test101-0 to offset 1059.
2020-01-07 20:25:28 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 663e06f6-3b9e-4d72-a907-aedfb1760f46
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:28 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:28 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:28 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:28 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-49, groupId=663e06f6-3b9e-4d72-a907-aedfb1760f46] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:28 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-49, groupId=663e06f6-3b9e-4d72-a907-aedfb1760f46] Revoking previously assigned partitions []
2020-01-07 20:25:28 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-49, groupId=663e06f6-3b9e-4d72-a907-aedfb1760f46] (Re-)joining group
2020-01-07 20:25:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-49, groupId=663e06f6-3b9e-4d72-a907-aedfb1760f46] Successfully joined group with generation 1
2020-01-07 20:25:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-49, groupId=663e06f6-3b9e-4d72-a907-aedfb1760f46] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:29 INFO  Fetcher:583 - [Consumer clientId=consumer-49, groupId=663e06f6-3b9e-4d72-a907-aedfb1760f46] Resetting offset for partition test101-0 to offset 1060.
2020-01-07 20:25:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 40df2d91-e498-414b-919c-bd22c76ce72d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-50, groupId=40df2d91-e498-414b-919c-bd22c76ce72d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-50, groupId=40df2d91-e498-414b-919c-bd22c76ce72d] Revoking previously assigned partitions []
2020-01-07 20:25:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-50, groupId=40df2d91-e498-414b-919c-bd22c76ce72d] (Re-)joining group
2020-01-07 20:25:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-50, groupId=40df2d91-e498-414b-919c-bd22c76ce72d] Successfully joined group with generation 1
2020-01-07 20:25:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-50, groupId=40df2d91-e498-414b-919c-bd22c76ce72d] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:29 INFO  Fetcher:583 - [Consumer clientId=consumer-50, groupId=40df2d91-e498-414b-919c-bd22c76ce72d] Resetting offset for partition test101-0 to offset 1062.
2020-01-07 20:25:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3160b65b-f694-43bf-a06a-ad84ebbc7eb8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-51, groupId=3160b65b-f694-43bf-a06a-ad84ebbc7eb8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-51, groupId=3160b65b-f694-43bf-a06a-ad84ebbc7eb8] Revoking previously assigned partitions []
2020-01-07 20:25:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-51, groupId=3160b65b-f694-43bf-a06a-ad84ebbc7eb8] (Re-)joining group
2020-01-07 20:25:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-51, groupId=3160b65b-f694-43bf-a06a-ad84ebbc7eb8] Successfully joined group with generation 1
2020-01-07 20:25:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-51, groupId=3160b65b-f694-43bf-a06a-ad84ebbc7eb8] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:29 INFO  Fetcher:583 - [Consumer clientId=consumer-51, groupId=3160b65b-f694-43bf-a06a-ad84ebbc7eb8] Resetting offset for partition test101-0 to offset 1063.
2020-01-07 20:25:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 671cbc6e-f067-411a-a745-b8fb6b2db9ff
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-52, groupId=671cbc6e-f067-411a-a745-b8fb6b2db9ff] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-52, groupId=671cbc6e-f067-411a-a745-b8fb6b2db9ff] Revoking previously assigned partitions []
2020-01-07 20:25:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-52, groupId=671cbc6e-f067-411a-a745-b8fb6b2db9ff] (Re-)joining group
2020-01-07 20:25:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-52, groupId=671cbc6e-f067-411a-a745-b8fb6b2db9ff] Successfully joined group with generation 1
2020-01-07 20:25:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-52, groupId=671cbc6e-f067-411a-a745-b8fb6b2db9ff] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:29 INFO  Fetcher:583 - [Consumer clientId=consumer-52, groupId=671cbc6e-f067-411a-a745-b8fb6b2db9ff] Resetting offset for partition test101-0 to offset 1067.
2020-01-07 20:25:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9e22a37f-5081-4ae6-a090-832bb6a6fcf9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-53, groupId=9e22a37f-5081-4ae6-a090-832bb6a6fcf9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-53, groupId=9e22a37f-5081-4ae6-a090-832bb6a6fcf9] Revoking previously assigned partitions []
2020-01-07 20:25:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-53, groupId=9e22a37f-5081-4ae6-a090-832bb6a6fcf9] (Re-)joining group
2020-01-07 20:25:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-53, groupId=9e22a37f-5081-4ae6-a090-832bb6a6fcf9] Successfully joined group with generation 1
2020-01-07 20:25:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-53, groupId=9e22a37f-5081-4ae6-a090-832bb6a6fcf9] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:29 INFO  Fetcher:583 - [Consumer clientId=consumer-53, groupId=9e22a37f-5081-4ae6-a090-832bb6a6fcf9] Resetting offset for partition test101-0 to offset 1068.
2020-01-07 20:25:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 68009751-92d9-47ce-82a7-b1f9e8553cc2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-54, groupId=68009751-92d9-47ce-82a7-b1f9e8553cc2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-54, groupId=68009751-92d9-47ce-82a7-b1f9e8553cc2] Revoking previously assigned partitions []
2020-01-07 20:25:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-54, groupId=68009751-92d9-47ce-82a7-b1f9e8553cc2] (Re-)joining group
2020-01-07 20:25:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-54, groupId=68009751-92d9-47ce-82a7-b1f9e8553cc2] Successfully joined group with generation 1
2020-01-07 20:25:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-54, groupId=68009751-92d9-47ce-82a7-b1f9e8553cc2] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:29 INFO  Fetcher:583 - [Consumer clientId=consumer-54, groupId=68009751-92d9-47ce-82a7-b1f9e8553cc2] Resetting offset for partition test101-0 to offset 1069.
2020-01-07 20:25:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a311e9f5-c0e6-427f-b094-acfc5638b9e3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-55, groupId=a311e9f5-c0e6-427f-b094-acfc5638b9e3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-55, groupId=a311e9f5-c0e6-427f-b094-acfc5638b9e3] Revoking previously assigned partitions []
2020-01-07 20:25:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-55, groupId=a311e9f5-c0e6-427f-b094-acfc5638b9e3] (Re-)joining group
2020-01-07 20:25:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-55, groupId=a311e9f5-c0e6-427f-b094-acfc5638b9e3] Successfully joined group with generation 1
2020-01-07 20:25:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-55, groupId=a311e9f5-c0e6-427f-b094-acfc5638b9e3] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:29 INFO  Fetcher:583 - [Consumer clientId=consumer-55, groupId=a311e9f5-c0e6-427f-b094-acfc5638b9e3] Resetting offset for partition test101-0 to offset 1071.
2020-01-07 20:25:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a52f9ddb-96d5-4726-a894-0a8bd6589ba2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-56, groupId=a52f9ddb-96d5-4726-a894-0a8bd6589ba2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-56, groupId=a52f9ddb-96d5-4726-a894-0a8bd6589ba2] Revoking previously assigned partitions []
2020-01-07 20:25:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-56, groupId=a52f9ddb-96d5-4726-a894-0a8bd6589ba2] (Re-)joining group
2020-01-07 20:25:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-56, groupId=a52f9ddb-96d5-4726-a894-0a8bd6589ba2] Successfully joined group with generation 1
2020-01-07 20:25:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-56, groupId=a52f9ddb-96d5-4726-a894-0a8bd6589ba2] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:29 INFO  Fetcher:583 - [Consumer clientId=consumer-56, groupId=a52f9ddb-96d5-4726-a894-0a8bd6589ba2] Resetting offset for partition test101-0 to offset 1072.
2020-01-07 20:25:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = bff616e2-45b6-42d2-9279-29e1546f5685
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-57, groupId=bff616e2-45b6-42d2-9279-29e1546f5685] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-57, groupId=bff616e2-45b6-42d2-9279-29e1546f5685] Revoking previously assigned partitions []
2020-01-07 20:25:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-57, groupId=bff616e2-45b6-42d2-9279-29e1546f5685] (Re-)joining group
2020-01-07 20:25:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-57, groupId=bff616e2-45b6-42d2-9279-29e1546f5685] Successfully joined group with generation 1
2020-01-07 20:25:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-57, groupId=bff616e2-45b6-42d2-9279-29e1546f5685] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:29 INFO  Fetcher:583 - [Consumer clientId=consumer-57, groupId=bff616e2-45b6-42d2-9279-29e1546f5685] Resetting offset for partition test101-0 to offset 1074.
2020-01-07 20:25:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 61b3f37f-77d2-41ef-b6ac-010f6a41e859
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-58, groupId=61b3f37f-77d2-41ef-b6ac-010f6a41e859] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-58, groupId=61b3f37f-77d2-41ef-b6ac-010f6a41e859] Revoking previously assigned partitions []
2020-01-07 20:25:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-58, groupId=61b3f37f-77d2-41ef-b6ac-010f6a41e859] (Re-)joining group
2020-01-07 20:25:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-58, groupId=61b3f37f-77d2-41ef-b6ac-010f6a41e859] Successfully joined group with generation 1
2020-01-07 20:25:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-58, groupId=61b3f37f-77d2-41ef-b6ac-010f6a41e859] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:29 INFO  Fetcher:583 - [Consumer clientId=consumer-58, groupId=61b3f37f-77d2-41ef-b6ac-010f6a41e859] Resetting offset for partition test101-0 to offset 1075.
2020-01-07 20:25:29 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = da42a787-fe3f-4098-93bf-d5fc60e61621
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:29 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:29 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:29 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-59, groupId=da42a787-fe3f-4098-93bf-d5fc60e61621] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:29 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-59, groupId=da42a787-fe3f-4098-93bf-d5fc60e61621] Revoking previously assigned partitions []
2020-01-07 20:25:29 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-59, groupId=da42a787-fe3f-4098-93bf-d5fc60e61621] (Re-)joining group
2020-01-07 20:25:29 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-59, groupId=da42a787-fe3f-4098-93bf-d5fc60e61621] Successfully joined group with generation 1
2020-01-07 20:25:29 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-59, groupId=da42a787-fe3f-4098-93bf-d5fc60e61621] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:29 INFO  Fetcher:583 - [Consumer clientId=consumer-59, groupId=da42a787-fe3f-4098-93bf-d5fc60e61621] Resetting offset for partition test101-0 to offset 1077.
2020-01-07 20:25:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0618ca82-fb71-49ee-9b64-3bdadeb16d95
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-60, groupId=0618ca82-fb71-49ee-9b64-3bdadeb16d95] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-60, groupId=0618ca82-fb71-49ee-9b64-3bdadeb16d95] Revoking previously assigned partitions []
2020-01-07 20:25:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-60, groupId=0618ca82-fb71-49ee-9b64-3bdadeb16d95] (Re-)joining group
2020-01-07 20:25:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-60, groupId=0618ca82-fb71-49ee-9b64-3bdadeb16d95] Successfully joined group with generation 1
2020-01-07 20:25:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-60, groupId=0618ca82-fb71-49ee-9b64-3bdadeb16d95] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:30 INFO  Fetcher:583 - [Consumer clientId=consumer-60, groupId=0618ca82-fb71-49ee-9b64-3bdadeb16d95] Resetting offset for partition test101-0 to offset 1080.
2020-01-07 20:25:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 24fbae4a-d913-4386-b17d-8a11172f1bdd
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-61, groupId=24fbae4a-d913-4386-b17d-8a11172f1bdd] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-61, groupId=24fbae4a-d913-4386-b17d-8a11172f1bdd] Revoking previously assigned partitions []
2020-01-07 20:25:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-61, groupId=24fbae4a-d913-4386-b17d-8a11172f1bdd] (Re-)joining group
2020-01-07 20:25:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-61, groupId=24fbae4a-d913-4386-b17d-8a11172f1bdd] Successfully joined group with generation 1
2020-01-07 20:25:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-61, groupId=24fbae4a-d913-4386-b17d-8a11172f1bdd] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:30 INFO  Fetcher:583 - [Consumer clientId=consumer-61, groupId=24fbae4a-d913-4386-b17d-8a11172f1bdd] Resetting offset for partition test101-0 to offset 1081.
2020-01-07 20:25:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f39ca0bf-eb30-4355-aa73-a342148ad0ed
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-62, groupId=f39ca0bf-eb30-4355-aa73-a342148ad0ed] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-62, groupId=f39ca0bf-eb30-4355-aa73-a342148ad0ed] Revoking previously assigned partitions []
2020-01-07 20:25:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-62, groupId=f39ca0bf-eb30-4355-aa73-a342148ad0ed] (Re-)joining group
2020-01-07 20:25:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-62, groupId=f39ca0bf-eb30-4355-aa73-a342148ad0ed] Successfully joined group with generation 1
2020-01-07 20:25:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-62, groupId=f39ca0bf-eb30-4355-aa73-a342148ad0ed] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:30 INFO  Fetcher:583 - [Consumer clientId=consumer-62, groupId=f39ca0bf-eb30-4355-aa73-a342148ad0ed] Resetting offset for partition test101-0 to offset 1083.
2020-01-07 20:25:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = aabc1f09-3abb-444b-b7e1-5a05d0101880
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-63, groupId=aabc1f09-3abb-444b-b7e1-5a05d0101880] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-63, groupId=aabc1f09-3abb-444b-b7e1-5a05d0101880] Revoking previously assigned partitions []
2020-01-07 20:25:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-63, groupId=aabc1f09-3abb-444b-b7e1-5a05d0101880] (Re-)joining group
2020-01-07 20:25:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-63, groupId=aabc1f09-3abb-444b-b7e1-5a05d0101880] Successfully joined group with generation 1
2020-01-07 20:25:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-63, groupId=aabc1f09-3abb-444b-b7e1-5a05d0101880] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:30 INFO  Fetcher:583 - [Consumer clientId=consumer-63, groupId=aabc1f09-3abb-444b-b7e1-5a05d0101880] Resetting offset for partition test101-0 to offset 1084.
2020-01-07 20:25:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 01c7ebbd-06a8-4702-9dcd-a28d2dfa882d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-64, groupId=01c7ebbd-06a8-4702-9dcd-a28d2dfa882d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-64, groupId=01c7ebbd-06a8-4702-9dcd-a28d2dfa882d] Revoking previously assigned partitions []
2020-01-07 20:25:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-64, groupId=01c7ebbd-06a8-4702-9dcd-a28d2dfa882d] (Re-)joining group
2020-01-07 20:25:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-64, groupId=01c7ebbd-06a8-4702-9dcd-a28d2dfa882d] Successfully joined group with generation 1
2020-01-07 20:25:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-64, groupId=01c7ebbd-06a8-4702-9dcd-a28d2dfa882d] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:30 INFO  Fetcher:583 - [Consumer clientId=consumer-64, groupId=01c7ebbd-06a8-4702-9dcd-a28d2dfa882d] Resetting offset for partition test101-0 to offset 1085.
2020-01-07 20:25:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 331d93b4-c357-467d-81ab-b8e68a060bdc
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-65, groupId=331d93b4-c357-467d-81ab-b8e68a060bdc] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-65, groupId=331d93b4-c357-467d-81ab-b8e68a060bdc] Revoking previously assigned partitions []
2020-01-07 20:25:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-65, groupId=331d93b4-c357-467d-81ab-b8e68a060bdc] (Re-)joining group
2020-01-07 20:25:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-65, groupId=331d93b4-c357-467d-81ab-b8e68a060bdc] Successfully joined group with generation 1
2020-01-07 20:25:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-65, groupId=331d93b4-c357-467d-81ab-b8e68a060bdc] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:30 INFO  Fetcher:583 - [Consumer clientId=consumer-65, groupId=331d93b4-c357-467d-81ab-b8e68a060bdc] Resetting offset for partition test101-0 to offset 1086.
2020-01-07 20:25:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a36e4fbf-6d21-41dc-8362-a757ad8b0461
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-66, groupId=a36e4fbf-6d21-41dc-8362-a757ad8b0461] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-66, groupId=a36e4fbf-6d21-41dc-8362-a757ad8b0461] Revoking previously assigned partitions []
2020-01-07 20:25:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-66, groupId=a36e4fbf-6d21-41dc-8362-a757ad8b0461] (Re-)joining group
2020-01-07 20:25:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-66, groupId=a36e4fbf-6d21-41dc-8362-a757ad8b0461] Successfully joined group with generation 1
2020-01-07 20:25:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-66, groupId=a36e4fbf-6d21-41dc-8362-a757ad8b0461] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:30 INFO  Fetcher:583 - [Consumer clientId=consumer-66, groupId=a36e4fbf-6d21-41dc-8362-a757ad8b0461] Resetting offset for partition test101-0 to offset 1087.
2020-01-07 20:25:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 151dca91-d940-4740-a006-99ce6770bbc3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-67, groupId=151dca91-d940-4740-a006-99ce6770bbc3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-67, groupId=151dca91-d940-4740-a006-99ce6770bbc3] Revoking previously assigned partitions []
2020-01-07 20:25:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-67, groupId=151dca91-d940-4740-a006-99ce6770bbc3] (Re-)joining group
2020-01-07 20:25:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-67, groupId=151dca91-d940-4740-a006-99ce6770bbc3] Successfully joined group with generation 1
2020-01-07 20:25:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-67, groupId=151dca91-d940-4740-a006-99ce6770bbc3] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:30 INFO  Fetcher:583 - [Consumer clientId=consumer-67, groupId=151dca91-d940-4740-a006-99ce6770bbc3] Resetting offset for partition test101-0 to offset 1090.
2020-01-07 20:25:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 659c55c0-6d9f-419d-bf3a-04780806636b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-68, groupId=659c55c0-6d9f-419d-bf3a-04780806636b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-68, groupId=659c55c0-6d9f-419d-bf3a-04780806636b] Revoking previously assigned partitions []
2020-01-07 20:25:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-68, groupId=659c55c0-6d9f-419d-bf3a-04780806636b] (Re-)joining group
2020-01-07 20:25:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-68, groupId=659c55c0-6d9f-419d-bf3a-04780806636b] Successfully joined group with generation 1
2020-01-07 20:25:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-68, groupId=659c55c0-6d9f-419d-bf3a-04780806636b] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:30 INFO  Fetcher:583 - [Consumer clientId=consumer-68, groupId=659c55c0-6d9f-419d-bf3a-04780806636b] Resetting offset for partition test101-0 to offset 1092.
2020-01-07 20:25:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f77339d4-c020-4eda-bff4-d9103e416cd2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-69, groupId=f77339d4-c020-4eda-bff4-d9103e416cd2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-69, groupId=f77339d4-c020-4eda-bff4-d9103e416cd2] Revoking previously assigned partitions []
2020-01-07 20:25:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-69, groupId=f77339d4-c020-4eda-bff4-d9103e416cd2] (Re-)joining group
2020-01-07 20:25:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-69, groupId=f77339d4-c020-4eda-bff4-d9103e416cd2] Successfully joined group with generation 1
2020-01-07 20:25:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-69, groupId=f77339d4-c020-4eda-bff4-d9103e416cd2] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:30 INFO  Fetcher:583 - [Consumer clientId=consumer-69, groupId=f77339d4-c020-4eda-bff4-d9103e416cd2] Resetting offset for partition test101-0 to offset 1094.
2020-01-07 20:25:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 094e3ddd-fa74-4457-b8e5-f273f682ea65
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-70, groupId=094e3ddd-fa74-4457-b8e5-f273f682ea65] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-70, groupId=094e3ddd-fa74-4457-b8e5-f273f682ea65] Revoking previously assigned partitions []
2020-01-07 20:25:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-70, groupId=094e3ddd-fa74-4457-b8e5-f273f682ea65] (Re-)joining group
2020-01-07 20:25:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-70, groupId=094e3ddd-fa74-4457-b8e5-f273f682ea65] Successfully joined group with generation 1
2020-01-07 20:25:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-70, groupId=094e3ddd-fa74-4457-b8e5-f273f682ea65] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:30 INFO  Fetcher:583 - [Consumer clientId=consumer-70, groupId=094e3ddd-fa74-4457-b8e5-f273f682ea65] Resetting offset for partition test101-0 to offset 1095.
2020-01-07 20:25:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1c0ed7e1-8d62-4ed4-9cab-f5ab2d4526a9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-71, groupId=1c0ed7e1-8d62-4ed4-9cab-f5ab2d4526a9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-71, groupId=1c0ed7e1-8d62-4ed4-9cab-f5ab2d4526a9] Revoking previously assigned partitions []
2020-01-07 20:25:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-71, groupId=1c0ed7e1-8d62-4ed4-9cab-f5ab2d4526a9] (Re-)joining group
2020-01-07 20:25:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-71, groupId=1c0ed7e1-8d62-4ed4-9cab-f5ab2d4526a9] Successfully joined group with generation 1
2020-01-07 20:25:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-71, groupId=1c0ed7e1-8d62-4ed4-9cab-f5ab2d4526a9] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:30 INFO  Fetcher:583 - [Consumer clientId=consumer-71, groupId=1c0ed7e1-8d62-4ed4-9cab-f5ab2d4526a9] Resetting offset for partition test101-0 to offset 1096.
2020-01-07 20:25:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 198125bf-73be-4142-82d3-ac083983e1df
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-72, groupId=198125bf-73be-4142-82d3-ac083983e1df] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-72, groupId=198125bf-73be-4142-82d3-ac083983e1df] Revoking previously assigned partitions []
2020-01-07 20:25:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-72, groupId=198125bf-73be-4142-82d3-ac083983e1df] (Re-)joining group
2020-01-07 20:25:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-72, groupId=198125bf-73be-4142-82d3-ac083983e1df] Successfully joined group with generation 1
2020-01-07 20:25:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-72, groupId=198125bf-73be-4142-82d3-ac083983e1df] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:30 INFO  Fetcher:583 - [Consumer clientId=consumer-72, groupId=198125bf-73be-4142-82d3-ac083983e1df] Resetting offset for partition test101-0 to offset 1097.
2020-01-07 20:25:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c20e7673-34d4-4bcc-ba29-4843d5de4b7d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-73, groupId=c20e7673-34d4-4bcc-ba29-4843d5de4b7d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-73, groupId=c20e7673-34d4-4bcc-ba29-4843d5de4b7d] Revoking previously assigned partitions []
2020-01-07 20:25:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-73, groupId=c20e7673-34d4-4bcc-ba29-4843d5de4b7d] (Re-)joining group
2020-01-07 20:25:30 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-73, groupId=c20e7673-34d4-4bcc-ba29-4843d5de4b7d] Successfully joined group with generation 1
2020-01-07 20:25:30 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-73, groupId=c20e7673-34d4-4bcc-ba29-4843d5de4b7d] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:30 INFO  Fetcher:583 - [Consumer clientId=consumer-73, groupId=c20e7673-34d4-4bcc-ba29-4843d5de4b7d] Resetting offset for partition test101-0 to offset 1098.
2020-01-07 20:25:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c716a476-1e2b-4ae9-a0b3-f76b97c6d6d7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:30 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:30 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-74, groupId=c716a476-1e2b-4ae9-a0b3-f76b97c6d6d7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:30 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-74, groupId=c716a476-1e2b-4ae9-a0b3-f76b97c6d6d7] Revoking previously assigned partitions []
2020-01-07 20:25:30 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-74, groupId=c716a476-1e2b-4ae9-a0b3-f76b97c6d6d7] (Re-)joining group
2020-01-07 20:25:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-74, groupId=c716a476-1e2b-4ae9-a0b3-f76b97c6d6d7] Successfully joined group with generation 1
2020-01-07 20:25:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-74, groupId=c716a476-1e2b-4ae9-a0b3-f76b97c6d6d7] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:31 INFO  Fetcher:583 - [Consumer clientId=consumer-74, groupId=c716a476-1e2b-4ae9-a0b3-f76b97c6d6d7] Resetting offset for partition test101-0 to offset 1099.
2020-01-07 20:25:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fddeb4a8-cc63-4fc0-af88-206895ead2ab
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-75, groupId=fddeb4a8-cc63-4fc0-af88-206895ead2ab] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-75, groupId=fddeb4a8-cc63-4fc0-af88-206895ead2ab] Revoking previously assigned partitions []
2020-01-07 20:25:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-75, groupId=fddeb4a8-cc63-4fc0-af88-206895ead2ab] (Re-)joining group
2020-01-07 20:25:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-75, groupId=fddeb4a8-cc63-4fc0-af88-206895ead2ab] Successfully joined group with generation 1
2020-01-07 20:25:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-75, groupId=fddeb4a8-cc63-4fc0-af88-206895ead2ab] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:31 INFO  Fetcher:583 - [Consumer clientId=consumer-75, groupId=fddeb4a8-cc63-4fc0-af88-206895ead2ab] Resetting offset for partition test101-0 to offset 1100.
2020-01-07 20:25:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 566f4914-4af6-4126-8a35-65fc3e5afb84
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-76, groupId=566f4914-4af6-4126-8a35-65fc3e5afb84] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-76, groupId=566f4914-4af6-4126-8a35-65fc3e5afb84] Revoking previously assigned partitions []
2020-01-07 20:25:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-76, groupId=566f4914-4af6-4126-8a35-65fc3e5afb84] (Re-)joining group
2020-01-07 20:25:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-76, groupId=566f4914-4af6-4126-8a35-65fc3e5afb84] Successfully joined group with generation 1
2020-01-07 20:25:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-76, groupId=566f4914-4af6-4126-8a35-65fc3e5afb84] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:31 INFO  Fetcher:583 - [Consumer clientId=consumer-76, groupId=566f4914-4af6-4126-8a35-65fc3e5afb84] Resetting offset for partition test101-0 to offset 1101.
2020-01-07 20:25:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = bcc07063-5edf-45fc-b5ef-687411b40848
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-77, groupId=bcc07063-5edf-45fc-b5ef-687411b40848] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-77, groupId=bcc07063-5edf-45fc-b5ef-687411b40848] Revoking previously assigned partitions []
2020-01-07 20:25:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-77, groupId=bcc07063-5edf-45fc-b5ef-687411b40848] (Re-)joining group
2020-01-07 20:25:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-77, groupId=bcc07063-5edf-45fc-b5ef-687411b40848] Successfully joined group with generation 1
2020-01-07 20:25:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-77, groupId=bcc07063-5edf-45fc-b5ef-687411b40848] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:31 INFO  Fetcher:583 - [Consumer clientId=consumer-77, groupId=bcc07063-5edf-45fc-b5ef-687411b40848] Resetting offset for partition test101-0 to offset 1102.
2020-01-07 20:25:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 21897953-ab05-48a9-8302-a6ad369fc26f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-78, groupId=21897953-ab05-48a9-8302-a6ad369fc26f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-78, groupId=21897953-ab05-48a9-8302-a6ad369fc26f] Revoking previously assigned partitions []
2020-01-07 20:25:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-78, groupId=21897953-ab05-48a9-8302-a6ad369fc26f] (Re-)joining group
2020-01-07 20:25:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-78, groupId=21897953-ab05-48a9-8302-a6ad369fc26f] Successfully joined group with generation 1
2020-01-07 20:25:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-78, groupId=21897953-ab05-48a9-8302-a6ad369fc26f] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:31 INFO  Fetcher:583 - [Consumer clientId=consumer-78, groupId=21897953-ab05-48a9-8302-a6ad369fc26f] Resetting offset for partition test101-0 to offset 1103.
2020-01-07 20:25:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ebf1a9af-1fdf-4944-8e2c-bf9c060c9e8a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-79, groupId=ebf1a9af-1fdf-4944-8e2c-bf9c060c9e8a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-79, groupId=ebf1a9af-1fdf-4944-8e2c-bf9c060c9e8a] Revoking previously assigned partitions []
2020-01-07 20:25:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-79, groupId=ebf1a9af-1fdf-4944-8e2c-bf9c060c9e8a] (Re-)joining group
2020-01-07 20:25:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-79, groupId=ebf1a9af-1fdf-4944-8e2c-bf9c060c9e8a] Successfully joined group with generation 1
2020-01-07 20:25:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-79, groupId=ebf1a9af-1fdf-4944-8e2c-bf9c060c9e8a] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:31 INFO  Fetcher:583 - [Consumer clientId=consumer-79, groupId=ebf1a9af-1fdf-4944-8e2c-bf9c060c9e8a] Resetting offset for partition test101-0 to offset 1104.
2020-01-07 20:25:31 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3e436307-2aef-4d63-a1b5-ffafd8580d36
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:31 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:31 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-80, groupId=3e436307-2aef-4d63-a1b5-ffafd8580d36] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-80, groupId=3e436307-2aef-4d63-a1b5-ffafd8580d36] Revoking previously assigned partitions []
2020-01-07 20:25:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-80, groupId=3e436307-2aef-4d63-a1b5-ffafd8580d36] (Re-)joining group
2020-01-07 20:25:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-80, groupId=3e436307-2aef-4d63-a1b5-ffafd8580d36] Successfully joined group with generation 1
2020-01-07 20:25:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-80, groupId=3e436307-2aef-4d63-a1b5-ffafd8580d36] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:31 INFO  Fetcher:583 - [Consumer clientId=consumer-80, groupId=3e436307-2aef-4d63-a1b5-ffafd8580d36] Resetting offset for partition test101-0 to offset 1106.
2020-01-07 20:25:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c29ed588-c538-4665-b4de-574661f36ac5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-81, groupId=c29ed588-c538-4665-b4de-574661f36ac5] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-81, groupId=c29ed588-c538-4665-b4de-574661f36ac5] Revoking previously assigned partitions []
2020-01-07 20:25:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-81, groupId=c29ed588-c538-4665-b4de-574661f36ac5] (Re-)joining group
2020-01-07 20:25:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-81, groupId=c29ed588-c538-4665-b4de-574661f36ac5] Successfully joined group with generation 1
2020-01-07 20:25:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-81, groupId=c29ed588-c538-4665-b4de-574661f36ac5] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:32 INFO  Fetcher:583 - [Consumer clientId=consumer-81, groupId=c29ed588-c538-4665-b4de-574661f36ac5] Resetting offset for partition test101-0 to offset 1109.
2020-01-07 20:25:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 39304963-888f-4d01-86dc-65c1b827e2cb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-82, groupId=39304963-888f-4d01-86dc-65c1b827e2cb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-82, groupId=39304963-888f-4d01-86dc-65c1b827e2cb] Revoking previously assigned partitions []
2020-01-07 20:25:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-82, groupId=39304963-888f-4d01-86dc-65c1b827e2cb] (Re-)joining group
2020-01-07 20:25:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-82, groupId=39304963-888f-4d01-86dc-65c1b827e2cb] Successfully joined group with generation 1
2020-01-07 20:25:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-82, groupId=39304963-888f-4d01-86dc-65c1b827e2cb] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:32 INFO  Fetcher:583 - [Consumer clientId=consumer-82, groupId=39304963-888f-4d01-86dc-65c1b827e2cb] Resetting offset for partition test101-0 to offset 1110.
2020-01-07 20:25:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 341011ab-15aa-4cda-b823-264a6325f7b1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-83, groupId=341011ab-15aa-4cda-b823-264a6325f7b1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-83, groupId=341011ab-15aa-4cda-b823-264a6325f7b1] Revoking previously assigned partitions []
2020-01-07 20:25:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-83, groupId=341011ab-15aa-4cda-b823-264a6325f7b1] (Re-)joining group
2020-01-07 20:25:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-83, groupId=341011ab-15aa-4cda-b823-264a6325f7b1] Successfully joined group with generation 1
2020-01-07 20:25:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-83, groupId=341011ab-15aa-4cda-b823-264a6325f7b1] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:32 INFO  Fetcher:583 - [Consumer clientId=consumer-83, groupId=341011ab-15aa-4cda-b823-264a6325f7b1] Resetting offset for partition test101-0 to offset 1112.
2020-01-07 20:25:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6a7495ef-844f-4c94-bb20-446a8d113765
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-84, groupId=6a7495ef-844f-4c94-bb20-446a8d113765] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-84, groupId=6a7495ef-844f-4c94-bb20-446a8d113765] Revoking previously assigned partitions []
2020-01-07 20:25:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-84, groupId=6a7495ef-844f-4c94-bb20-446a8d113765] (Re-)joining group
2020-01-07 20:25:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-84, groupId=6a7495ef-844f-4c94-bb20-446a8d113765] Successfully joined group with generation 1
2020-01-07 20:25:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-84, groupId=6a7495ef-844f-4c94-bb20-446a8d113765] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:32 INFO  Fetcher:583 - [Consumer clientId=consumer-84, groupId=6a7495ef-844f-4c94-bb20-446a8d113765] Resetting offset for partition test101-0 to offset 1113.
2020-01-07 20:25:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9521b89c-a11f-47de-bc68-57d7c88dc0e0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-85, groupId=9521b89c-a11f-47de-bc68-57d7c88dc0e0] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-85, groupId=9521b89c-a11f-47de-bc68-57d7c88dc0e0] Revoking previously assigned partitions []
2020-01-07 20:25:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-85, groupId=9521b89c-a11f-47de-bc68-57d7c88dc0e0] (Re-)joining group
2020-01-07 20:25:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-85, groupId=9521b89c-a11f-47de-bc68-57d7c88dc0e0] Successfully joined group with generation 1
2020-01-07 20:25:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-85, groupId=9521b89c-a11f-47de-bc68-57d7c88dc0e0] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:32 INFO  Fetcher:583 - [Consumer clientId=consumer-85, groupId=9521b89c-a11f-47de-bc68-57d7c88dc0e0] Resetting offset for partition test101-0 to offset 1115.
2020-01-07 20:25:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ae74b94a-57d9-4251-ba8c-c61aaa792930
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-86, groupId=ae74b94a-57d9-4251-ba8c-c61aaa792930] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-86, groupId=ae74b94a-57d9-4251-ba8c-c61aaa792930] Revoking previously assigned partitions []
2020-01-07 20:25:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-86, groupId=ae74b94a-57d9-4251-ba8c-c61aaa792930] (Re-)joining group
2020-01-07 20:25:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-86, groupId=ae74b94a-57d9-4251-ba8c-c61aaa792930] Successfully joined group with generation 1
2020-01-07 20:25:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-86, groupId=ae74b94a-57d9-4251-ba8c-c61aaa792930] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:32 INFO  Fetcher:583 - [Consumer clientId=consumer-86, groupId=ae74b94a-57d9-4251-ba8c-c61aaa792930] Resetting offset for partition test101-0 to offset 1116.
2020-01-07 20:25:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 429cb420-36be-4392-b78e-f89073226959
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-87, groupId=429cb420-36be-4392-b78e-f89073226959] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-87, groupId=429cb420-36be-4392-b78e-f89073226959] Revoking previously assigned partitions []
2020-01-07 20:25:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-87, groupId=429cb420-36be-4392-b78e-f89073226959] (Re-)joining group
2020-01-07 20:25:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-87, groupId=429cb420-36be-4392-b78e-f89073226959] Successfully joined group with generation 1
2020-01-07 20:25:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-87, groupId=429cb420-36be-4392-b78e-f89073226959] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:32 INFO  Fetcher:583 - [Consumer clientId=consumer-87, groupId=429cb420-36be-4392-b78e-f89073226959] Resetting offset for partition test101-0 to offset 1118.
2020-01-07 20:25:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 23df4c2a-3276-458c-8777-2584c08ff330
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-88, groupId=23df4c2a-3276-458c-8777-2584c08ff330] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-88, groupId=23df4c2a-3276-458c-8777-2584c08ff330] Revoking previously assigned partitions []
2020-01-07 20:25:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-88, groupId=23df4c2a-3276-458c-8777-2584c08ff330] (Re-)joining group
2020-01-07 20:25:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-88, groupId=23df4c2a-3276-458c-8777-2584c08ff330] Successfully joined group with generation 1
2020-01-07 20:25:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-88, groupId=23df4c2a-3276-458c-8777-2584c08ff330] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:32 INFO  Fetcher:583 - [Consumer clientId=consumer-88, groupId=23df4c2a-3276-458c-8777-2584c08ff330] Resetting offset for partition test101-0 to offset 1119.
2020-01-07 20:25:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6567ca0a-1364-41e3-8fed-de8ac7a83fd1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-89, groupId=6567ca0a-1364-41e3-8fed-de8ac7a83fd1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-89, groupId=6567ca0a-1364-41e3-8fed-de8ac7a83fd1] Revoking previously assigned partitions []
2020-01-07 20:25:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-89, groupId=6567ca0a-1364-41e3-8fed-de8ac7a83fd1] (Re-)joining group
2020-01-07 20:25:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-89, groupId=6567ca0a-1364-41e3-8fed-de8ac7a83fd1] Successfully joined group with generation 1
2020-01-07 20:25:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-89, groupId=6567ca0a-1364-41e3-8fed-de8ac7a83fd1] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:32 INFO  Fetcher:583 - [Consumer clientId=consumer-89, groupId=6567ca0a-1364-41e3-8fed-de8ac7a83fd1] Resetting offset for partition test101-0 to offset 1121.
2020-01-07 20:25:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d5415975-ea5f-4532-a415-7f829f7f34d7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-90, groupId=d5415975-ea5f-4532-a415-7f829f7f34d7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-90, groupId=d5415975-ea5f-4532-a415-7f829f7f34d7] Revoking previously assigned partitions []
2020-01-07 20:25:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-90, groupId=d5415975-ea5f-4532-a415-7f829f7f34d7] (Re-)joining group
2020-01-07 20:25:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-90, groupId=d5415975-ea5f-4532-a415-7f829f7f34d7] Successfully joined group with generation 1
2020-01-07 20:25:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-90, groupId=d5415975-ea5f-4532-a415-7f829f7f34d7] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:32 INFO  Fetcher:583 - [Consumer clientId=consumer-90, groupId=d5415975-ea5f-4532-a415-7f829f7f34d7] Resetting offset for partition test101-0 to offset 1122.
2020-01-07 20:25:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4e9b9129-853d-4e41-befe-33eb986b00e1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-91, groupId=4e9b9129-853d-4e41-befe-33eb986b00e1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-91, groupId=4e9b9129-853d-4e41-befe-33eb986b00e1] Revoking previously assigned partitions []
2020-01-07 20:25:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-91, groupId=4e9b9129-853d-4e41-befe-33eb986b00e1] (Re-)joining group
2020-01-07 20:25:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-91, groupId=4e9b9129-853d-4e41-befe-33eb986b00e1] Successfully joined group with generation 1
2020-01-07 20:25:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-91, groupId=4e9b9129-853d-4e41-befe-33eb986b00e1] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:32 INFO  Fetcher:583 - [Consumer clientId=consumer-91, groupId=4e9b9129-853d-4e41-befe-33eb986b00e1] Resetting offset for partition test101-0 to offset 1123.
2020-01-07 20:25:32 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 58efabcf-cc6e-44b9-abfe-9259c694a372
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:32 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:32 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:32 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:32 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-92, groupId=58efabcf-cc6e-44b9-abfe-9259c694a372] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-92, groupId=58efabcf-cc6e-44b9-abfe-9259c694a372] Revoking previously assigned partitions []
2020-01-07 20:25:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-92, groupId=58efabcf-cc6e-44b9-abfe-9259c694a372] (Re-)joining group
2020-01-07 20:25:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-92, groupId=58efabcf-cc6e-44b9-abfe-9259c694a372] Successfully joined group with generation 1
2020-01-07 20:25:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-92, groupId=58efabcf-cc6e-44b9-abfe-9259c694a372] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:33 INFO  Fetcher:583 - [Consumer clientId=consumer-92, groupId=58efabcf-cc6e-44b9-abfe-9259c694a372] Resetting offset for partition test101-0 to offset 1125.
2020-01-07 20:25:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ed05d628-1379-40d9-8672-99c8ac7f8acd
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-93, groupId=ed05d628-1379-40d9-8672-99c8ac7f8acd] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-93, groupId=ed05d628-1379-40d9-8672-99c8ac7f8acd] Revoking previously assigned partitions []
2020-01-07 20:25:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-93, groupId=ed05d628-1379-40d9-8672-99c8ac7f8acd] (Re-)joining group
2020-01-07 20:25:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-93, groupId=ed05d628-1379-40d9-8672-99c8ac7f8acd] Successfully joined group with generation 1
2020-01-07 20:25:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-93, groupId=ed05d628-1379-40d9-8672-99c8ac7f8acd] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:33 INFO  Fetcher:583 - [Consumer clientId=consumer-93, groupId=ed05d628-1379-40d9-8672-99c8ac7f8acd] Resetting offset for partition test101-0 to offset 1127.
2020-01-07 20:25:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 42dc7016-b563-43e0-874c-b401d04b9437
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-94, groupId=42dc7016-b563-43e0-874c-b401d04b9437] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-94, groupId=42dc7016-b563-43e0-874c-b401d04b9437] Revoking previously assigned partitions []
2020-01-07 20:25:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-94, groupId=42dc7016-b563-43e0-874c-b401d04b9437] (Re-)joining group
2020-01-07 20:25:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-94, groupId=42dc7016-b563-43e0-874c-b401d04b9437] Successfully joined group with generation 1
2020-01-07 20:25:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-94, groupId=42dc7016-b563-43e0-874c-b401d04b9437] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:33 INFO  Fetcher:583 - [Consumer clientId=consumer-94, groupId=42dc7016-b563-43e0-874c-b401d04b9437] Resetting offset for partition test101-0 to offset 1128.
2020-01-07 20:25:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fc98aaa1-6a7b-41b9-a4a3-2e91ec9c51f1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-95, groupId=fc98aaa1-6a7b-41b9-a4a3-2e91ec9c51f1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-95, groupId=fc98aaa1-6a7b-41b9-a4a3-2e91ec9c51f1] Revoking previously assigned partitions []
2020-01-07 20:25:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-95, groupId=fc98aaa1-6a7b-41b9-a4a3-2e91ec9c51f1] (Re-)joining group
2020-01-07 20:25:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-95, groupId=fc98aaa1-6a7b-41b9-a4a3-2e91ec9c51f1] Successfully joined group with generation 1
2020-01-07 20:25:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-95, groupId=fc98aaa1-6a7b-41b9-a4a3-2e91ec9c51f1] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:33 INFO  Fetcher:583 - [Consumer clientId=consumer-95, groupId=fc98aaa1-6a7b-41b9-a4a3-2e91ec9c51f1] Resetting offset for partition test101-0 to offset 1129.
2020-01-07 20:25:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d7c9d162-7b42-40da-8481-3a17bc998238
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-96, groupId=d7c9d162-7b42-40da-8481-3a17bc998238] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-96, groupId=d7c9d162-7b42-40da-8481-3a17bc998238] Revoking previously assigned partitions []
2020-01-07 20:25:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-96, groupId=d7c9d162-7b42-40da-8481-3a17bc998238] (Re-)joining group
2020-01-07 20:25:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-96, groupId=d7c9d162-7b42-40da-8481-3a17bc998238] Successfully joined group with generation 1
2020-01-07 20:25:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-96, groupId=d7c9d162-7b42-40da-8481-3a17bc998238] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:33 INFO  Fetcher:583 - [Consumer clientId=consumer-96, groupId=d7c9d162-7b42-40da-8481-3a17bc998238] Resetting offset for partition test101-0 to offset 1130.
2020-01-07 20:25:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 304bb3bb-4d72-4bb4-a28f-02bfbc11745a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-97, groupId=304bb3bb-4d72-4bb4-a28f-02bfbc11745a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-97, groupId=304bb3bb-4d72-4bb4-a28f-02bfbc11745a] Revoking previously assigned partitions []
2020-01-07 20:25:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-97, groupId=304bb3bb-4d72-4bb4-a28f-02bfbc11745a] (Re-)joining group
2020-01-07 20:25:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-97, groupId=304bb3bb-4d72-4bb4-a28f-02bfbc11745a] Successfully joined group with generation 1
2020-01-07 20:25:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-97, groupId=304bb3bb-4d72-4bb4-a28f-02bfbc11745a] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:33 INFO  Fetcher:583 - [Consumer clientId=consumer-97, groupId=304bb3bb-4d72-4bb4-a28f-02bfbc11745a] Resetting offset for partition test101-0 to offset 1131.
2020-01-07 20:25:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = caeeeea2-7b15-45f1-8714-019a8d065576
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-98, groupId=caeeeea2-7b15-45f1-8714-019a8d065576] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-98, groupId=caeeeea2-7b15-45f1-8714-019a8d065576] Revoking previously assigned partitions []
2020-01-07 20:25:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-98, groupId=caeeeea2-7b15-45f1-8714-019a8d065576] (Re-)joining group
2020-01-07 20:25:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-98, groupId=caeeeea2-7b15-45f1-8714-019a8d065576] Successfully joined group with generation 1
2020-01-07 20:25:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-98, groupId=caeeeea2-7b15-45f1-8714-019a8d065576] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:33 INFO  Fetcher:583 - [Consumer clientId=consumer-98, groupId=caeeeea2-7b15-45f1-8714-019a8d065576] Resetting offset for partition test101-0 to offset 1132.
2020-01-07 20:25:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f57a4cea-ba3d-454b-a843-ea2b1a4a4f19
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-99, groupId=f57a4cea-ba3d-454b-a843-ea2b1a4a4f19] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-99, groupId=f57a4cea-ba3d-454b-a843-ea2b1a4a4f19] Revoking previously assigned partitions []
2020-01-07 20:25:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-99, groupId=f57a4cea-ba3d-454b-a843-ea2b1a4a4f19] (Re-)joining group
2020-01-07 20:25:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-99, groupId=f57a4cea-ba3d-454b-a843-ea2b1a4a4f19] Successfully joined group with generation 1
2020-01-07 20:25:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-99, groupId=f57a4cea-ba3d-454b-a843-ea2b1a4a4f19] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:33 INFO  Fetcher:583 - [Consumer clientId=consumer-99, groupId=f57a4cea-ba3d-454b-a843-ea2b1a4a4f19] Resetting offset for partition test101-0 to offset 1134.
2020-01-07 20:25:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 48230828-4d4e-4c26-811a-54478c04e588
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-100, groupId=48230828-4d4e-4c26-811a-54478c04e588] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-100, groupId=48230828-4d4e-4c26-811a-54478c04e588] Revoking previously assigned partitions []
2020-01-07 20:25:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-100, groupId=48230828-4d4e-4c26-811a-54478c04e588] (Re-)joining group
2020-01-07 20:25:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-100, groupId=48230828-4d4e-4c26-811a-54478c04e588] Successfully joined group with generation 1
2020-01-07 20:25:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-100, groupId=48230828-4d4e-4c26-811a-54478c04e588] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:33 INFO  Fetcher:583 - [Consumer clientId=consumer-100, groupId=48230828-4d4e-4c26-811a-54478c04e588] Resetting offset for partition test101-0 to offset 1135.
2020-01-07 20:25:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fc5d8f80-2c26-4d48-a807-af2cebec1778
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-101, groupId=fc5d8f80-2c26-4d48-a807-af2cebec1778] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-101, groupId=fc5d8f80-2c26-4d48-a807-af2cebec1778] Revoking previously assigned partitions []
2020-01-07 20:25:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-101, groupId=fc5d8f80-2c26-4d48-a807-af2cebec1778] (Re-)joining group
2020-01-07 20:25:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-101, groupId=fc5d8f80-2c26-4d48-a807-af2cebec1778] Successfully joined group with generation 1
2020-01-07 20:25:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-101, groupId=fc5d8f80-2c26-4d48-a807-af2cebec1778] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:33 INFO  Fetcher:583 - [Consumer clientId=consumer-101, groupId=fc5d8f80-2c26-4d48-a807-af2cebec1778] Resetting offset for partition test101-0 to offset 1137.
2020-01-07 20:25:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 57ffb925-a20f-4ef8-a4ef-e6eaeb1d4c1a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-102, groupId=57ffb925-a20f-4ef8-a4ef-e6eaeb1d4c1a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-102, groupId=57ffb925-a20f-4ef8-a4ef-e6eaeb1d4c1a] Revoking previously assigned partitions []
2020-01-07 20:25:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-102, groupId=57ffb925-a20f-4ef8-a4ef-e6eaeb1d4c1a] (Re-)joining group
2020-01-07 20:25:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-102, groupId=57ffb925-a20f-4ef8-a4ef-e6eaeb1d4c1a] Successfully joined group with generation 1
2020-01-07 20:25:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-102, groupId=57ffb925-a20f-4ef8-a4ef-e6eaeb1d4c1a] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:33 INFO  Fetcher:583 - [Consumer clientId=consumer-102, groupId=57ffb925-a20f-4ef8-a4ef-e6eaeb1d4c1a] Resetting offset for partition test101-0 to offset 1139.
2020-01-07 20:25:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6fd0e143-7c50-42ad-a8e2-102125af107e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-103, groupId=6fd0e143-7c50-42ad-a8e2-102125af107e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-103, groupId=6fd0e143-7c50-42ad-a8e2-102125af107e] Revoking previously assigned partitions []
2020-01-07 20:25:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-103, groupId=6fd0e143-7c50-42ad-a8e2-102125af107e] (Re-)joining group
2020-01-07 20:25:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-103, groupId=6fd0e143-7c50-42ad-a8e2-102125af107e] Successfully joined group with generation 1
2020-01-07 20:25:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-103, groupId=6fd0e143-7c50-42ad-a8e2-102125af107e] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:33 INFO  Fetcher:583 - [Consumer clientId=consumer-103, groupId=6fd0e143-7c50-42ad-a8e2-102125af107e] Resetting offset for partition test101-0 to offset 1141.
2020-01-07 20:25:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6b491d3f-e636-4208-8f4e-5c517566c3ec
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-104, groupId=6b491d3f-e636-4208-8f4e-5c517566c3ec] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-104, groupId=6b491d3f-e636-4208-8f4e-5c517566c3ec] Revoking previously assigned partitions []
2020-01-07 20:25:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-104, groupId=6b491d3f-e636-4208-8f4e-5c517566c3ec] (Re-)joining group
2020-01-07 20:25:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-104, groupId=6b491d3f-e636-4208-8f4e-5c517566c3ec] Successfully joined group with generation 1
2020-01-07 20:25:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-104, groupId=6b491d3f-e636-4208-8f4e-5c517566c3ec] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:33 INFO  Fetcher:583 - [Consumer clientId=consumer-104, groupId=6b491d3f-e636-4208-8f4e-5c517566c3ec] Resetting offset for partition test101-0 to offset 1142.
2020-01-07 20:25:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c4588b70-e5b0-41ad-94c8-451f1a594880
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-105, groupId=c4588b70-e5b0-41ad-94c8-451f1a594880] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-105, groupId=c4588b70-e5b0-41ad-94c8-451f1a594880] Revoking previously assigned partitions []
2020-01-07 20:25:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-105, groupId=c4588b70-e5b0-41ad-94c8-451f1a594880] (Re-)joining group
2020-01-07 20:25:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-105, groupId=c4588b70-e5b0-41ad-94c8-451f1a594880] Successfully joined group with generation 1
2020-01-07 20:25:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-105, groupId=c4588b70-e5b0-41ad-94c8-451f1a594880] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:33 INFO  Fetcher:583 - [Consumer clientId=consumer-105, groupId=c4588b70-e5b0-41ad-94c8-451f1a594880] Resetting offset for partition test101-0 to offset 1143.
2020-01-07 20:25:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9c611e8b-c98a-4685-a227-1fe73f93cd0e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-106, groupId=9c611e8b-c98a-4685-a227-1fe73f93cd0e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-106, groupId=9c611e8b-c98a-4685-a227-1fe73f93cd0e] Revoking previously assigned partitions []
2020-01-07 20:25:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-106, groupId=9c611e8b-c98a-4685-a227-1fe73f93cd0e] (Re-)joining group
2020-01-07 20:25:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-106, groupId=9c611e8b-c98a-4685-a227-1fe73f93cd0e] Successfully joined group with generation 1
2020-01-07 20:25:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-106, groupId=9c611e8b-c98a-4685-a227-1fe73f93cd0e] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:33 INFO  Fetcher:583 - [Consumer clientId=consumer-106, groupId=9c611e8b-c98a-4685-a227-1fe73f93cd0e] Resetting offset for partition test101-0 to offset 1144.
2020-01-07 20:25:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 54f985d0-864a-4769-a8d3-80434d8b318d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-107, groupId=54f985d0-864a-4769-a8d3-80434d8b318d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-107, groupId=54f985d0-864a-4769-a8d3-80434d8b318d] Revoking previously assigned partitions []
2020-01-07 20:25:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-107, groupId=54f985d0-864a-4769-a8d3-80434d8b318d] (Re-)joining group
2020-01-07 20:25:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-107, groupId=54f985d0-864a-4769-a8d3-80434d8b318d] Successfully joined group with generation 1
2020-01-07 20:25:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-107, groupId=54f985d0-864a-4769-a8d3-80434d8b318d] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:33 INFO  Fetcher:583 - [Consumer clientId=consumer-107, groupId=54f985d0-864a-4769-a8d3-80434d8b318d] Resetting offset for partition test101-0 to offset 1146.
2020-01-07 20:25:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ec22db53-ec07-4a6f-9e1e-7e7d104fc2a9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:33 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:33 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-108, groupId=ec22db53-ec07-4a6f-9e1e-7e7d104fc2a9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:33 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-108, groupId=ec22db53-ec07-4a6f-9e1e-7e7d104fc2a9] Revoking previously assigned partitions []
2020-01-07 20:25:33 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-108, groupId=ec22db53-ec07-4a6f-9e1e-7e7d104fc2a9] (Re-)joining group
2020-01-07 20:25:33 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-108, groupId=ec22db53-ec07-4a6f-9e1e-7e7d104fc2a9] Successfully joined group with generation 1
2020-01-07 20:25:33 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-108, groupId=ec22db53-ec07-4a6f-9e1e-7e7d104fc2a9] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:33 INFO  Fetcher:583 - [Consumer clientId=consumer-108, groupId=ec22db53-ec07-4a6f-9e1e-7e7d104fc2a9] Resetting offset for partition test101-0 to offset 1147.
2020-01-07 20:25:33 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5b9823e1-5e50-45c2-a3ed-97e3b9718107
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:33 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:33 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-109, groupId=5b9823e1-5e50-45c2-a3ed-97e3b9718107] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-109, groupId=5b9823e1-5e50-45c2-a3ed-97e3b9718107] Revoking previously assigned partitions []
2020-01-07 20:25:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-109, groupId=5b9823e1-5e50-45c2-a3ed-97e3b9718107] (Re-)joining group
2020-01-07 20:25:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-109, groupId=5b9823e1-5e50-45c2-a3ed-97e3b9718107] Successfully joined group with generation 1
2020-01-07 20:25:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-109, groupId=5b9823e1-5e50-45c2-a3ed-97e3b9718107] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:34 INFO  Fetcher:583 - [Consumer clientId=consumer-109, groupId=5b9823e1-5e50-45c2-a3ed-97e3b9718107] Resetting offset for partition test101-0 to offset 1148.
2020-01-07 20:25:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 53a4490d-45fe-4646-8539-913296b4cab6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-110, groupId=53a4490d-45fe-4646-8539-913296b4cab6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-110, groupId=53a4490d-45fe-4646-8539-913296b4cab6] Revoking previously assigned partitions []
2020-01-07 20:25:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-110, groupId=53a4490d-45fe-4646-8539-913296b4cab6] (Re-)joining group
2020-01-07 20:25:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-110, groupId=53a4490d-45fe-4646-8539-913296b4cab6] Successfully joined group with generation 1
2020-01-07 20:25:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-110, groupId=53a4490d-45fe-4646-8539-913296b4cab6] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:34 INFO  Fetcher:583 - [Consumer clientId=consumer-110, groupId=53a4490d-45fe-4646-8539-913296b4cab6] Resetting offset for partition test101-0 to offset 1149.
2020-01-07 20:25:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fd5b4c4f-c92c-4356-9df1-d68780127630
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-111, groupId=fd5b4c4f-c92c-4356-9df1-d68780127630] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-111, groupId=fd5b4c4f-c92c-4356-9df1-d68780127630] Revoking previously assigned partitions []
2020-01-07 20:25:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-111, groupId=fd5b4c4f-c92c-4356-9df1-d68780127630] (Re-)joining group
2020-01-07 20:25:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-111, groupId=fd5b4c4f-c92c-4356-9df1-d68780127630] Successfully joined group with generation 1
2020-01-07 20:25:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-111, groupId=fd5b4c4f-c92c-4356-9df1-d68780127630] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:34 INFO  Fetcher:583 - [Consumer clientId=consumer-111, groupId=fd5b4c4f-c92c-4356-9df1-d68780127630] Resetting offset for partition test101-0 to offset 1150.
2020-01-07 20:25:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8cef6faf-102e-4d79-802d-42d97d341cfa
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-112, groupId=8cef6faf-102e-4d79-802d-42d97d341cfa] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-112, groupId=8cef6faf-102e-4d79-802d-42d97d341cfa] Revoking previously assigned partitions []
2020-01-07 20:25:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-112, groupId=8cef6faf-102e-4d79-802d-42d97d341cfa] (Re-)joining group
2020-01-07 20:25:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-112, groupId=8cef6faf-102e-4d79-802d-42d97d341cfa] Successfully joined group with generation 1
2020-01-07 20:25:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-112, groupId=8cef6faf-102e-4d79-802d-42d97d341cfa] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:34 INFO  Fetcher:583 - [Consumer clientId=consumer-112, groupId=8cef6faf-102e-4d79-802d-42d97d341cfa] Resetting offset for partition test101-0 to offset 1151.
2020-01-07 20:25:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 07e98432-c331-4941-80fd-11a9feacca06
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-113, groupId=07e98432-c331-4941-80fd-11a9feacca06] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-113, groupId=07e98432-c331-4941-80fd-11a9feacca06] Revoking previously assigned partitions []
2020-01-07 20:25:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-113, groupId=07e98432-c331-4941-80fd-11a9feacca06] (Re-)joining group
2020-01-07 20:25:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-113, groupId=07e98432-c331-4941-80fd-11a9feacca06] Successfully joined group with generation 1
2020-01-07 20:25:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-113, groupId=07e98432-c331-4941-80fd-11a9feacca06] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:34 INFO  Fetcher:583 - [Consumer clientId=consumer-113, groupId=07e98432-c331-4941-80fd-11a9feacca06] Resetting offset for partition test101-0 to offset 1153.
2020-01-07 20:25:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 81cebb7d-1f85-439d-930f-a0ba30e9f1c3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-114, groupId=81cebb7d-1f85-439d-930f-a0ba30e9f1c3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-114, groupId=81cebb7d-1f85-439d-930f-a0ba30e9f1c3] Revoking previously assigned partitions []
2020-01-07 20:25:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-114, groupId=81cebb7d-1f85-439d-930f-a0ba30e9f1c3] (Re-)joining group
2020-01-07 20:25:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-114, groupId=81cebb7d-1f85-439d-930f-a0ba30e9f1c3] Successfully joined group with generation 1
2020-01-07 20:25:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-114, groupId=81cebb7d-1f85-439d-930f-a0ba30e9f1c3] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:34 INFO  Fetcher:583 - [Consumer clientId=consumer-114, groupId=81cebb7d-1f85-439d-930f-a0ba30e9f1c3] Resetting offset for partition test101-0 to offset 1155.
2020-01-07 20:25:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0836bb06-cd96-4922-9caa-e0371e41dd22
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-115, groupId=0836bb06-cd96-4922-9caa-e0371e41dd22] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-115, groupId=0836bb06-cd96-4922-9caa-e0371e41dd22] Revoking previously assigned partitions []
2020-01-07 20:25:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-115, groupId=0836bb06-cd96-4922-9caa-e0371e41dd22] (Re-)joining group
2020-01-07 20:25:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-115, groupId=0836bb06-cd96-4922-9caa-e0371e41dd22] Successfully joined group with generation 1
2020-01-07 20:25:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-115, groupId=0836bb06-cd96-4922-9caa-e0371e41dd22] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:34 INFO  Fetcher:583 - [Consumer clientId=consumer-115, groupId=0836bb06-cd96-4922-9caa-e0371e41dd22] Resetting offset for partition test101-0 to offset 1156.
2020-01-07 20:25:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 271b224d-b3df-4a93-a2be-40cdd9d67dda
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-116, groupId=271b224d-b3df-4a93-a2be-40cdd9d67dda] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-116, groupId=271b224d-b3df-4a93-a2be-40cdd9d67dda] Revoking previously assigned partitions []
2020-01-07 20:25:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-116, groupId=271b224d-b3df-4a93-a2be-40cdd9d67dda] (Re-)joining group
2020-01-07 20:25:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-116, groupId=271b224d-b3df-4a93-a2be-40cdd9d67dda] Successfully joined group with generation 1
2020-01-07 20:25:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-116, groupId=271b224d-b3df-4a93-a2be-40cdd9d67dda] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:34 INFO  Fetcher:583 - [Consumer clientId=consumer-116, groupId=271b224d-b3df-4a93-a2be-40cdd9d67dda] Resetting offset for partition test101-0 to offset 1157.
2020-01-07 20:25:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 98080109-4488-4701-91b3-9b5ba2dbf42d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-117, groupId=98080109-4488-4701-91b3-9b5ba2dbf42d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-117, groupId=98080109-4488-4701-91b3-9b5ba2dbf42d] Revoking previously assigned partitions []
2020-01-07 20:25:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-117, groupId=98080109-4488-4701-91b3-9b5ba2dbf42d] (Re-)joining group
2020-01-07 20:25:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-117, groupId=98080109-4488-4701-91b3-9b5ba2dbf42d] Successfully joined group with generation 1
2020-01-07 20:25:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-117, groupId=98080109-4488-4701-91b3-9b5ba2dbf42d] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:34 INFO  Fetcher:583 - [Consumer clientId=consumer-117, groupId=98080109-4488-4701-91b3-9b5ba2dbf42d] Resetting offset for partition test101-0 to offset 1159.
2020-01-07 20:25:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 48eb6850-65a8-4bee-b9b2-d0cb480b0685
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-118, groupId=48eb6850-65a8-4bee-b9b2-d0cb480b0685] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-118, groupId=48eb6850-65a8-4bee-b9b2-d0cb480b0685] Revoking previously assigned partitions []
2020-01-07 20:25:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-118, groupId=48eb6850-65a8-4bee-b9b2-d0cb480b0685] (Re-)joining group
2020-01-07 20:25:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-118, groupId=48eb6850-65a8-4bee-b9b2-d0cb480b0685] Successfully joined group with generation 1
2020-01-07 20:25:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-118, groupId=48eb6850-65a8-4bee-b9b2-d0cb480b0685] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:34 INFO  Fetcher:583 - [Consumer clientId=consumer-118, groupId=48eb6850-65a8-4bee-b9b2-d0cb480b0685] Resetting offset for partition test101-0 to offset 1161.
2020-01-07 20:25:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ac7dde65-868c-462a-abdb-11af340c3117
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-119, groupId=ac7dde65-868c-462a-abdb-11af340c3117] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-119, groupId=ac7dde65-868c-462a-abdb-11af340c3117] Revoking previously assigned partitions []
2020-01-07 20:25:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-119, groupId=ac7dde65-868c-462a-abdb-11af340c3117] (Re-)joining group
2020-01-07 20:25:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-119, groupId=ac7dde65-868c-462a-abdb-11af340c3117] Successfully joined group with generation 1
2020-01-07 20:25:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-119, groupId=ac7dde65-868c-462a-abdb-11af340c3117] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:34 INFO  Fetcher:583 - [Consumer clientId=consumer-119, groupId=ac7dde65-868c-462a-abdb-11af340c3117] Resetting offset for partition test101-0 to offset 1163.
2020-01-07 20:25:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d96aba6c-b2cb-4ab8-b66a-bb22939bf638
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-120, groupId=d96aba6c-b2cb-4ab8-b66a-bb22939bf638] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-120, groupId=d96aba6c-b2cb-4ab8-b66a-bb22939bf638] Revoking previously assigned partitions []
2020-01-07 20:25:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-120, groupId=d96aba6c-b2cb-4ab8-b66a-bb22939bf638] (Re-)joining group
2020-01-07 20:25:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-120, groupId=d96aba6c-b2cb-4ab8-b66a-bb22939bf638] Successfully joined group with generation 1
2020-01-07 20:25:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-120, groupId=d96aba6c-b2cb-4ab8-b66a-bb22939bf638] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:34 INFO  Fetcher:583 - [Consumer clientId=consumer-120, groupId=d96aba6c-b2cb-4ab8-b66a-bb22939bf638] Resetting offset for partition test101-0 to offset 1165.
2020-01-07 20:25:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 36d0a552-1c6f-49bf-ae15-2085ac413157
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-121, groupId=36d0a552-1c6f-49bf-ae15-2085ac413157] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-121, groupId=36d0a552-1c6f-49bf-ae15-2085ac413157] Revoking previously assigned partitions []
2020-01-07 20:25:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-121, groupId=36d0a552-1c6f-49bf-ae15-2085ac413157] (Re-)joining group
2020-01-07 20:25:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-121, groupId=36d0a552-1c6f-49bf-ae15-2085ac413157] Successfully joined group with generation 1
2020-01-07 20:25:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-121, groupId=36d0a552-1c6f-49bf-ae15-2085ac413157] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:34 INFO  Fetcher:583 - [Consumer clientId=consumer-121, groupId=36d0a552-1c6f-49bf-ae15-2085ac413157] Resetting offset for partition test101-0 to offset 1166.
2020-01-07 20:25:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 95834deb-9e91-446e-a855-df1d84012b45
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:34 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:34 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-122, groupId=95834deb-9e91-446e-a855-df1d84012b45] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:34 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-122, groupId=95834deb-9e91-446e-a855-df1d84012b45] Revoking previously assigned partitions []
2020-01-07 20:25:34 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-122, groupId=95834deb-9e91-446e-a855-df1d84012b45] (Re-)joining group
2020-01-07 20:25:34 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-122, groupId=95834deb-9e91-446e-a855-df1d84012b45] Successfully joined group with generation 1
2020-01-07 20:25:34 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-122, groupId=95834deb-9e91-446e-a855-df1d84012b45] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:34 INFO  Fetcher:583 - [Consumer clientId=consumer-122, groupId=95834deb-9e91-446e-a855-df1d84012b45] Resetting offset for partition test101-0 to offset 1168.
2020-01-07 20:25:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ae723b29-0711-4fe9-8a3f-14cad52427a6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-123, groupId=ae723b29-0711-4fe9-8a3f-14cad52427a6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-123, groupId=ae723b29-0711-4fe9-8a3f-14cad52427a6] Revoking previously assigned partitions []
2020-01-07 20:25:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-123, groupId=ae723b29-0711-4fe9-8a3f-14cad52427a6] (Re-)joining group
2020-01-07 20:25:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-123, groupId=ae723b29-0711-4fe9-8a3f-14cad52427a6] Successfully joined group with generation 1
2020-01-07 20:25:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-123, groupId=ae723b29-0711-4fe9-8a3f-14cad52427a6] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:35 INFO  Fetcher:583 - [Consumer clientId=consumer-123, groupId=ae723b29-0711-4fe9-8a3f-14cad52427a6] Resetting offset for partition test101-0 to offset 1169.
2020-01-07 20:25:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8e4c2fbf-002d-4c2d-b2c0-0fd27e251e39
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-124, groupId=8e4c2fbf-002d-4c2d-b2c0-0fd27e251e39] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-124, groupId=8e4c2fbf-002d-4c2d-b2c0-0fd27e251e39] Revoking previously assigned partitions []
2020-01-07 20:25:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-124, groupId=8e4c2fbf-002d-4c2d-b2c0-0fd27e251e39] (Re-)joining group
2020-01-07 20:25:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-124, groupId=8e4c2fbf-002d-4c2d-b2c0-0fd27e251e39] Successfully joined group with generation 1
2020-01-07 20:25:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-124, groupId=8e4c2fbf-002d-4c2d-b2c0-0fd27e251e39] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:35 INFO  Fetcher:583 - [Consumer clientId=consumer-124, groupId=8e4c2fbf-002d-4c2d-b2c0-0fd27e251e39] Resetting offset for partition test101-0 to offset 1171.
2020-01-07 20:25:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6e04d5f1-2f3e-48c1-ba05-a137047adf4e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-125, groupId=6e04d5f1-2f3e-48c1-ba05-a137047adf4e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-125, groupId=6e04d5f1-2f3e-48c1-ba05-a137047adf4e] Revoking previously assigned partitions []
2020-01-07 20:25:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-125, groupId=6e04d5f1-2f3e-48c1-ba05-a137047adf4e] (Re-)joining group
2020-01-07 20:25:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-125, groupId=6e04d5f1-2f3e-48c1-ba05-a137047adf4e] Successfully joined group with generation 1
2020-01-07 20:25:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-125, groupId=6e04d5f1-2f3e-48c1-ba05-a137047adf4e] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:35 INFO  Fetcher:583 - [Consumer clientId=consumer-125, groupId=6e04d5f1-2f3e-48c1-ba05-a137047adf4e] Resetting offset for partition test101-0 to offset 1172.
2020-01-07 20:25:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c605e158-7ac6-436d-8f0f-674490e03f99
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-126, groupId=c605e158-7ac6-436d-8f0f-674490e03f99] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-126, groupId=c605e158-7ac6-436d-8f0f-674490e03f99] Revoking previously assigned partitions []
2020-01-07 20:25:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-126, groupId=c605e158-7ac6-436d-8f0f-674490e03f99] (Re-)joining group
2020-01-07 20:25:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-126, groupId=c605e158-7ac6-436d-8f0f-674490e03f99] Successfully joined group with generation 1
2020-01-07 20:25:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-126, groupId=c605e158-7ac6-436d-8f0f-674490e03f99] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:35 INFO  Fetcher:583 - [Consumer clientId=consumer-126, groupId=c605e158-7ac6-436d-8f0f-674490e03f99] Resetting offset for partition test101-0 to offset 1173.
2020-01-07 20:25:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a9604d8a-6003-4a83-803e-b48f5746a505
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-127, groupId=a9604d8a-6003-4a83-803e-b48f5746a505] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-127, groupId=a9604d8a-6003-4a83-803e-b48f5746a505] Revoking previously assigned partitions []
2020-01-07 20:25:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-127, groupId=a9604d8a-6003-4a83-803e-b48f5746a505] (Re-)joining group
2020-01-07 20:25:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-127, groupId=a9604d8a-6003-4a83-803e-b48f5746a505] Successfully joined group with generation 1
2020-01-07 20:25:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-127, groupId=a9604d8a-6003-4a83-803e-b48f5746a505] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:35 INFO  Fetcher:583 - [Consumer clientId=consumer-127, groupId=a9604d8a-6003-4a83-803e-b48f5746a505] Resetting offset for partition test101-0 to offset 1175.
2020-01-07 20:25:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0ff8900e-9ad3-41d8-b14f-88892f5d604a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-128, groupId=0ff8900e-9ad3-41d8-b14f-88892f5d604a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-128, groupId=0ff8900e-9ad3-41d8-b14f-88892f5d604a] Revoking previously assigned partitions []
2020-01-07 20:25:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-128, groupId=0ff8900e-9ad3-41d8-b14f-88892f5d604a] (Re-)joining group
2020-01-07 20:25:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-128, groupId=0ff8900e-9ad3-41d8-b14f-88892f5d604a] Successfully joined group with generation 1
2020-01-07 20:25:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-128, groupId=0ff8900e-9ad3-41d8-b14f-88892f5d604a] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:35 INFO  Fetcher:583 - [Consumer clientId=consumer-128, groupId=0ff8900e-9ad3-41d8-b14f-88892f5d604a] Resetting offset for partition test101-0 to offset 1176.
2020-01-07 20:25:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 22b75d9b-ca9b-43c3-9613-888f0376d7b6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-129, groupId=22b75d9b-ca9b-43c3-9613-888f0376d7b6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-129, groupId=22b75d9b-ca9b-43c3-9613-888f0376d7b6] Revoking previously assigned partitions []
2020-01-07 20:25:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-129, groupId=22b75d9b-ca9b-43c3-9613-888f0376d7b6] (Re-)joining group
2020-01-07 20:25:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-129, groupId=22b75d9b-ca9b-43c3-9613-888f0376d7b6] Successfully joined group with generation 1
2020-01-07 20:25:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-129, groupId=22b75d9b-ca9b-43c3-9613-888f0376d7b6] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:35 INFO  Fetcher:583 - [Consumer clientId=consumer-129, groupId=22b75d9b-ca9b-43c3-9613-888f0376d7b6] Resetting offset for partition test101-0 to offset 1177.
2020-01-07 20:25:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e57b68c5-2f8a-4b4b-843c-546286025f42
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-130, groupId=e57b68c5-2f8a-4b4b-843c-546286025f42] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-130, groupId=e57b68c5-2f8a-4b4b-843c-546286025f42] Revoking previously assigned partitions []
2020-01-07 20:25:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-130, groupId=e57b68c5-2f8a-4b4b-843c-546286025f42] (Re-)joining group
2020-01-07 20:25:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-130, groupId=e57b68c5-2f8a-4b4b-843c-546286025f42] Successfully joined group with generation 1
2020-01-07 20:25:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-130, groupId=e57b68c5-2f8a-4b4b-843c-546286025f42] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:35 INFO  Fetcher:583 - [Consumer clientId=consumer-130, groupId=e57b68c5-2f8a-4b4b-843c-546286025f42] Resetting offset for partition test101-0 to offset 1178.
2020-01-07 20:25:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 86f8cc76-c14c-4879-afe6-cf8d6869adc2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-131, groupId=86f8cc76-c14c-4879-afe6-cf8d6869adc2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-131, groupId=86f8cc76-c14c-4879-afe6-cf8d6869adc2] Revoking previously assigned partitions []
2020-01-07 20:25:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-131, groupId=86f8cc76-c14c-4879-afe6-cf8d6869adc2] (Re-)joining group
2020-01-07 20:25:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-131, groupId=86f8cc76-c14c-4879-afe6-cf8d6869adc2] Successfully joined group with generation 1
2020-01-07 20:25:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-131, groupId=86f8cc76-c14c-4879-afe6-cf8d6869adc2] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:35 INFO  Fetcher:583 - [Consumer clientId=consumer-131, groupId=86f8cc76-c14c-4879-afe6-cf8d6869adc2] Resetting offset for partition test101-0 to offset 1180.
2020-01-07 20:25:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1331723b-026a-4fc0-bb95-7ef3728136d4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-132, groupId=1331723b-026a-4fc0-bb95-7ef3728136d4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-132, groupId=1331723b-026a-4fc0-bb95-7ef3728136d4] Revoking previously assigned partitions []
2020-01-07 20:25:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-132, groupId=1331723b-026a-4fc0-bb95-7ef3728136d4] (Re-)joining group
2020-01-07 20:25:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-132, groupId=1331723b-026a-4fc0-bb95-7ef3728136d4] Successfully joined group with generation 1
2020-01-07 20:25:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-132, groupId=1331723b-026a-4fc0-bb95-7ef3728136d4] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:35 INFO  Fetcher:583 - [Consumer clientId=consumer-132, groupId=1331723b-026a-4fc0-bb95-7ef3728136d4] Resetting offset for partition test101-0 to offset 1181.
2020-01-07 20:25:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ce36b752-3da8-4c18-80c7-2df9d550a014
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-133, groupId=ce36b752-3da8-4c18-80c7-2df9d550a014] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-133, groupId=ce36b752-3da8-4c18-80c7-2df9d550a014] Revoking previously assigned partitions []
2020-01-07 20:25:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-133, groupId=ce36b752-3da8-4c18-80c7-2df9d550a014] (Re-)joining group
2020-01-07 20:25:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-133, groupId=ce36b752-3da8-4c18-80c7-2df9d550a014] Successfully joined group with generation 1
2020-01-07 20:25:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-133, groupId=ce36b752-3da8-4c18-80c7-2df9d550a014] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:35 INFO  Fetcher:583 - [Consumer clientId=consumer-133, groupId=ce36b752-3da8-4c18-80c7-2df9d550a014] Resetting offset for partition test101-0 to offset 1182.
2020-01-07 20:25:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 61c84e85-a84f-415c-ab9a-e152d0331375
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-134, groupId=61c84e85-a84f-415c-ab9a-e152d0331375] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-134, groupId=61c84e85-a84f-415c-ab9a-e152d0331375] Revoking previously assigned partitions []
2020-01-07 20:25:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-134, groupId=61c84e85-a84f-415c-ab9a-e152d0331375] (Re-)joining group
2020-01-07 20:25:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-134, groupId=61c84e85-a84f-415c-ab9a-e152d0331375] Successfully joined group with generation 1
2020-01-07 20:25:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-134, groupId=61c84e85-a84f-415c-ab9a-e152d0331375] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:35 INFO  Fetcher:583 - [Consumer clientId=consumer-134, groupId=61c84e85-a84f-415c-ab9a-e152d0331375] Resetting offset for partition test101-0 to offset 1183.
2020-01-07 20:25:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c9eb6129-5bdb-46e4-8c31-bd2d8cf552dd
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-135, groupId=c9eb6129-5bdb-46e4-8c31-bd2d8cf552dd] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-135, groupId=c9eb6129-5bdb-46e4-8c31-bd2d8cf552dd] Revoking previously assigned partitions []
2020-01-07 20:25:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-135, groupId=c9eb6129-5bdb-46e4-8c31-bd2d8cf552dd] (Re-)joining group
2020-01-07 20:25:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-135, groupId=c9eb6129-5bdb-46e4-8c31-bd2d8cf552dd] Successfully joined group with generation 1
2020-01-07 20:25:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-135, groupId=c9eb6129-5bdb-46e4-8c31-bd2d8cf552dd] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:35 INFO  Fetcher:583 - [Consumer clientId=consumer-135, groupId=c9eb6129-5bdb-46e4-8c31-bd2d8cf552dd] Resetting offset for partition test101-0 to offset 1185.
2020-01-07 20:25:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 23b166b6-fce8-4435-b919-dbe62ba356a9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-136, groupId=23b166b6-fce8-4435-b919-dbe62ba356a9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-136, groupId=23b166b6-fce8-4435-b919-dbe62ba356a9] Revoking previously assigned partitions []
2020-01-07 20:25:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-136, groupId=23b166b6-fce8-4435-b919-dbe62ba356a9] (Re-)joining group
2020-01-07 20:25:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-136, groupId=23b166b6-fce8-4435-b919-dbe62ba356a9] Successfully joined group with generation 1
2020-01-07 20:25:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-136, groupId=23b166b6-fce8-4435-b919-dbe62ba356a9] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:35 INFO  Fetcher:583 - [Consumer clientId=consumer-136, groupId=23b166b6-fce8-4435-b919-dbe62ba356a9] Resetting offset for partition test101-0 to offset 1187.
2020-01-07 20:25:35 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1971c11a-8ad0-4a7b-902d-196462c25eee
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:35 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:35 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:35 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-137, groupId=1971c11a-8ad0-4a7b-902d-196462c25eee] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-137, groupId=1971c11a-8ad0-4a7b-902d-196462c25eee] Revoking previously assigned partitions []
2020-01-07 20:25:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-137, groupId=1971c11a-8ad0-4a7b-902d-196462c25eee] (Re-)joining group
2020-01-07 20:25:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-137, groupId=1971c11a-8ad0-4a7b-902d-196462c25eee] Successfully joined group with generation 1
2020-01-07 20:25:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-137, groupId=1971c11a-8ad0-4a7b-902d-196462c25eee] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:36 INFO  Fetcher:583 - [Consumer clientId=consumer-137, groupId=1971c11a-8ad0-4a7b-902d-196462c25eee] Resetting offset for partition test101-0 to offset 1188.
2020-01-07 20:25:36 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 827b9ca7-46b8-4163-a270-dad4156eea96
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:36 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:36 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:36 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:36 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-138, groupId=827b9ca7-46b8-4163-a270-dad4156eea96] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:36 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-138, groupId=827b9ca7-46b8-4163-a270-dad4156eea96] Revoking previously assigned partitions []
2020-01-07 20:25:36 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-138, groupId=827b9ca7-46b8-4163-a270-dad4156eea96] (Re-)joining group
2020-01-07 20:25:36 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-138, groupId=827b9ca7-46b8-4163-a270-dad4156eea96] Successfully joined group with generation 1
2020-01-07 20:25:36 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-138, groupId=827b9ca7-46b8-4163-a270-dad4156eea96] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:36 INFO  Fetcher:583 - [Consumer clientId=consumer-138, groupId=827b9ca7-46b8-4163-a270-dad4156eea96] Resetting offset for partition test101-0 to offset 1189.
2020-01-07 20:25:36 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a4eb2484-c5f8-4cf3-a235-681cae534876
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:36 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:36 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:36 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:36 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-139, groupId=a4eb2484-c5f8-4cf3-a235-681cae534876] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:36 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-139, groupId=a4eb2484-c5f8-4cf3-a235-681cae534876] Revoking previously assigned partitions []
2020-01-07 20:25:36 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-139, groupId=a4eb2484-c5f8-4cf3-a235-681cae534876] (Re-)joining group
2020-01-07 20:25:36 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-139, groupId=a4eb2484-c5f8-4cf3-a235-681cae534876] Successfully joined group with generation 1
2020-01-07 20:25:36 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-139, groupId=a4eb2484-c5f8-4cf3-a235-681cae534876] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:36 INFO  Fetcher:583 - [Consumer clientId=consumer-139, groupId=a4eb2484-c5f8-4cf3-a235-681cae534876] Resetting offset for partition test101-0 to offset 1190.
2020-01-07 20:25:36 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 57608e69-dc8a-42d4-96b9-7042797a0f6b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:36 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:36 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:36 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:36 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-140, groupId=57608e69-dc8a-42d4-96b9-7042797a0f6b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:36 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-140, groupId=57608e69-dc8a-42d4-96b9-7042797a0f6b] Revoking previously assigned partitions []
2020-01-07 20:25:36 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-140, groupId=57608e69-dc8a-42d4-96b9-7042797a0f6b] (Re-)joining group
2020-01-07 20:25:36 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-140, groupId=57608e69-dc8a-42d4-96b9-7042797a0f6b] Successfully joined group with generation 1
2020-01-07 20:25:36 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-140, groupId=57608e69-dc8a-42d4-96b9-7042797a0f6b] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:36 INFO  Fetcher:583 - [Consumer clientId=consumer-140, groupId=57608e69-dc8a-42d4-96b9-7042797a0f6b] Resetting offset for partition test101-0 to offset 1191.
2020-01-07 20:25:36 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8e47704b-d5bb-4e5d-bdb0-f8a7b129f64c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:36 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:36 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:36 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:36 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-141, groupId=8e47704b-d5bb-4e5d-bdb0-f8a7b129f64c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:36 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-141, groupId=8e47704b-d5bb-4e5d-bdb0-f8a7b129f64c] Revoking previously assigned partitions []
2020-01-07 20:25:36 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-141, groupId=8e47704b-d5bb-4e5d-bdb0-f8a7b129f64c] (Re-)joining group
2020-01-07 20:25:36 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-141, groupId=8e47704b-d5bb-4e5d-bdb0-f8a7b129f64c] Successfully joined group with generation 1
2020-01-07 20:25:36 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-141, groupId=8e47704b-d5bb-4e5d-bdb0-f8a7b129f64c] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:36 INFO  Fetcher:583 - [Consumer clientId=consumer-141, groupId=8e47704b-d5bb-4e5d-bdb0-f8a7b129f64c] Resetting offset for partition test101-0 to offset 1192.
2020-01-07 20:25:36 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c7df5c3a-047a-4e77-a862-f9addd38339f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:36 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:36 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:36 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:36 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-142, groupId=c7df5c3a-047a-4e77-a862-f9addd38339f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:36 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-142, groupId=c7df5c3a-047a-4e77-a862-f9addd38339f] Revoking previously assigned partitions []
2020-01-07 20:25:36 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-142, groupId=c7df5c3a-047a-4e77-a862-f9addd38339f] (Re-)joining group
2020-01-07 20:25:36 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-142, groupId=c7df5c3a-047a-4e77-a862-f9addd38339f] Successfully joined group with generation 1
2020-01-07 20:25:36 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-142, groupId=c7df5c3a-047a-4e77-a862-f9addd38339f] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:36 INFO  Fetcher:583 - [Consumer clientId=consumer-142, groupId=c7df5c3a-047a-4e77-a862-f9addd38339f] Resetting offset for partition test101-0 to offset 1194.
2020-01-07 20:25:36 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = da4afce5-17bb-4853-af87-766eec8cc842
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:36 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:36 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:36 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:36 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-143, groupId=da4afce5-17bb-4853-af87-766eec8cc842] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:36 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-143, groupId=da4afce5-17bb-4853-af87-766eec8cc842] Revoking previously assigned partitions []
2020-01-07 20:25:36 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-143, groupId=da4afce5-17bb-4853-af87-766eec8cc842] (Re-)joining group
2020-01-07 20:25:36 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-143, groupId=da4afce5-17bb-4853-af87-766eec8cc842] Successfully joined group with generation 1
2020-01-07 20:25:36 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-143, groupId=da4afce5-17bb-4853-af87-766eec8cc842] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:36 INFO  Fetcher:583 - [Consumer clientId=consumer-143, groupId=da4afce5-17bb-4853-af87-766eec8cc842] Resetting offset for partition test101-0 to offset 1196.
2020-01-07 20:25:36 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6033c493-43bd-498a-aa94-c93b18b21079
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:36 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:36 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:36 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:36 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-144, groupId=6033c493-43bd-498a-aa94-c93b18b21079] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:36 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-144, groupId=6033c493-43bd-498a-aa94-c93b18b21079] Revoking previously assigned partitions []
2020-01-07 20:25:36 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-144, groupId=6033c493-43bd-498a-aa94-c93b18b21079] (Re-)joining group
2020-01-07 20:25:36 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-144, groupId=6033c493-43bd-498a-aa94-c93b18b21079] Successfully joined group with generation 1
2020-01-07 20:25:36 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-144, groupId=6033c493-43bd-498a-aa94-c93b18b21079] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:36 INFO  Fetcher:583 - [Consumer clientId=consumer-144, groupId=6033c493-43bd-498a-aa94-c93b18b21079] Resetting offset for partition test101-0 to offset 1197.
2020-01-07 20:25:36 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ba93cad3-5738-4888-b275-ce6a29906fe4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:36 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:36 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:36 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:36 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-145, groupId=ba93cad3-5738-4888-b275-ce6a29906fe4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:36 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-145, groupId=ba93cad3-5738-4888-b275-ce6a29906fe4] Revoking previously assigned partitions []
2020-01-07 20:25:36 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-145, groupId=ba93cad3-5738-4888-b275-ce6a29906fe4] (Re-)joining group
2020-01-07 20:25:36 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-145, groupId=ba93cad3-5738-4888-b275-ce6a29906fe4] Successfully joined group with generation 1
2020-01-07 20:25:36 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-145, groupId=ba93cad3-5738-4888-b275-ce6a29906fe4] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:36 INFO  Fetcher:583 - [Consumer clientId=consumer-145, groupId=ba93cad3-5738-4888-b275-ce6a29906fe4] Resetting offset for partition test101-0 to offset 1199.
2020-01-07 20:25:36 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f53672f6-fb70-4a45-98f3-51ccce235c19
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:36 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:36 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:36 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:36 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-146, groupId=f53672f6-fb70-4a45-98f3-51ccce235c19] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:36 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-146, groupId=f53672f6-fb70-4a45-98f3-51ccce235c19] Revoking previously assigned partitions []
2020-01-07 20:25:36 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-146, groupId=f53672f6-fb70-4a45-98f3-51ccce235c19] (Re-)joining group
2020-01-07 20:25:36 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-146, groupId=f53672f6-fb70-4a45-98f3-51ccce235c19] Successfully joined group with generation 1
2020-01-07 20:25:36 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-146, groupId=f53672f6-fb70-4a45-98f3-51ccce235c19] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:36 INFO  Fetcher:583 - [Consumer clientId=consumer-146, groupId=f53672f6-fb70-4a45-98f3-51ccce235c19] Resetting offset for partition test101-0 to offset 1201.
2020-01-07 20:25:36 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = bcd02e31-373a-4bf9-8ea6-982558b65e45
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:36 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:36 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:36 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:36 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-147, groupId=bcd02e31-373a-4bf9-8ea6-982558b65e45] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:36 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-147, groupId=bcd02e31-373a-4bf9-8ea6-982558b65e45] Revoking previously assigned partitions []
2020-01-07 20:25:36 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-147, groupId=bcd02e31-373a-4bf9-8ea6-982558b65e45] (Re-)joining group
2020-01-07 20:25:36 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-147, groupId=bcd02e31-373a-4bf9-8ea6-982558b65e45] Successfully joined group with generation 1
2020-01-07 20:25:36 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-147, groupId=bcd02e31-373a-4bf9-8ea6-982558b65e45] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:36 INFO  Fetcher:583 - [Consumer clientId=consumer-147, groupId=bcd02e31-373a-4bf9-8ea6-982558b65e45] Resetting offset for partition test101-0 to offset 1203.
2020-01-07 20:25:36 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 01659f5a-cc65-4462-8f65-16cbe33b9fa2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:36 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:36 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:36 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:36 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-148, groupId=01659f5a-cc65-4462-8f65-16cbe33b9fa2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:36 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-148, groupId=01659f5a-cc65-4462-8f65-16cbe33b9fa2] Revoking previously assigned partitions []
2020-01-07 20:25:36 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-148, groupId=01659f5a-cc65-4462-8f65-16cbe33b9fa2] (Re-)joining group
2020-01-07 20:25:36 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-148, groupId=01659f5a-cc65-4462-8f65-16cbe33b9fa2] Successfully joined group with generation 1
2020-01-07 20:25:36 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-148, groupId=01659f5a-cc65-4462-8f65-16cbe33b9fa2] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:36 INFO  Fetcher:583 - [Consumer clientId=consumer-148, groupId=01659f5a-cc65-4462-8f65-16cbe33b9fa2] Resetting offset for partition test101-0 to offset 1205.
2020-01-07 20:25:36 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ca9a9bb3-bec7-4388-83f2-7781d778fee0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:36 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:36 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:36 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:36 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-149, groupId=ca9a9bb3-bec7-4388-83f2-7781d778fee0] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:36 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-149, groupId=ca9a9bb3-bec7-4388-83f2-7781d778fee0] Revoking previously assigned partitions []
2020-01-07 20:25:36 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-149, groupId=ca9a9bb3-bec7-4388-83f2-7781d778fee0] (Re-)joining group
2020-01-07 20:25:36 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-149, groupId=ca9a9bb3-bec7-4388-83f2-7781d778fee0] Successfully joined group with generation 1
2020-01-07 20:25:36 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-149, groupId=ca9a9bb3-bec7-4388-83f2-7781d778fee0] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:36 INFO  Fetcher:583 - [Consumer clientId=consumer-149, groupId=ca9a9bb3-bec7-4388-83f2-7781d778fee0] Resetting offset for partition test101-0 to offset 1207.
2020-01-07 20:25:36 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e17d52b0-df49-4288-80fc-ca34c7d28070
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:36 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:36 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:36 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:36 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-150, groupId=e17d52b0-df49-4288-80fc-ca34c7d28070] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:36 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-150, groupId=e17d52b0-df49-4288-80fc-ca34c7d28070] Revoking previously assigned partitions []
2020-01-07 20:25:36 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-150, groupId=e17d52b0-df49-4288-80fc-ca34c7d28070] (Re-)joining group
2020-01-07 20:25:36 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-150, groupId=e17d52b0-df49-4288-80fc-ca34c7d28070] Successfully joined group with generation 1
2020-01-07 20:25:36 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-150, groupId=e17d52b0-df49-4288-80fc-ca34c7d28070] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:36 INFO  Fetcher:583 - [Consumer clientId=consumer-150, groupId=e17d52b0-df49-4288-80fc-ca34c7d28070] Resetting offset for partition test101-0 to offset 1208.
2020-01-07 20:25:36 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 185b12e2-9d30-4646-9135-57c2ae929b93
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:36 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:36 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:36 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:36 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-151, groupId=185b12e2-9d30-4646-9135-57c2ae929b93] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:36 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-151, groupId=185b12e2-9d30-4646-9135-57c2ae929b93] Revoking previously assigned partitions []
2020-01-07 20:25:36 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-151, groupId=185b12e2-9d30-4646-9135-57c2ae929b93] (Re-)joining group
2020-01-07 20:25:36 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-151, groupId=185b12e2-9d30-4646-9135-57c2ae929b93] Successfully joined group with generation 1
2020-01-07 20:25:36 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-151, groupId=185b12e2-9d30-4646-9135-57c2ae929b93] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:36 INFO  Fetcher:583 - [Consumer clientId=consumer-151, groupId=185b12e2-9d30-4646-9135-57c2ae929b93] Resetting offset for partition test101-0 to offset 1210.
2020-01-07 20:25:36 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9244707e-c93c-4674-8505-a2aef4b197df
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:36 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:36 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:36 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:36 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-152, groupId=9244707e-c93c-4674-8505-a2aef4b197df] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:36 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-152, groupId=9244707e-c93c-4674-8505-a2aef4b197df] Revoking previously assigned partitions []
2020-01-07 20:25:36 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-152, groupId=9244707e-c93c-4674-8505-a2aef4b197df] (Re-)joining group
2020-01-07 20:25:36 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-152, groupId=9244707e-c93c-4674-8505-a2aef4b197df] Successfully joined group with generation 1
2020-01-07 20:25:36 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-152, groupId=9244707e-c93c-4674-8505-a2aef4b197df] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:36 INFO  Fetcher:583 - [Consumer clientId=consumer-152, groupId=9244707e-c93c-4674-8505-a2aef4b197df] Resetting offset for partition test101-0 to offset 1211.
2020-01-07 20:25:36 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f44225b4-ea9d-4537-9504-afa8144dd879
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:36 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:36 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:36 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:36 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-153, groupId=f44225b4-ea9d-4537-9504-afa8144dd879] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:36 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-153, groupId=f44225b4-ea9d-4537-9504-afa8144dd879] Revoking previously assigned partitions []
2020-01-07 20:25:36 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-153, groupId=f44225b4-ea9d-4537-9504-afa8144dd879] (Re-)joining group
2020-01-07 20:25:36 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-153, groupId=f44225b4-ea9d-4537-9504-afa8144dd879] Successfully joined group with generation 1
2020-01-07 20:25:36 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-153, groupId=f44225b4-ea9d-4537-9504-afa8144dd879] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:36 INFO  Fetcher:583 - [Consumer clientId=consumer-153, groupId=f44225b4-ea9d-4537-9504-afa8144dd879] Resetting offset for partition test101-0 to offset 1213.
2020-01-07 20:25:36 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 20fbb702-fdcc-4c86-9ab0-fba9eb3fc287
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:36 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:36 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:36 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:36 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-154, groupId=20fbb702-fdcc-4c86-9ab0-fba9eb3fc287] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:36 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-154, groupId=20fbb702-fdcc-4c86-9ab0-fba9eb3fc287] Revoking previously assigned partitions []
2020-01-07 20:25:36 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-154, groupId=20fbb702-fdcc-4c86-9ab0-fba9eb3fc287] (Re-)joining group
2020-01-07 20:25:36 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-154, groupId=20fbb702-fdcc-4c86-9ab0-fba9eb3fc287] Successfully joined group with generation 1
2020-01-07 20:25:36 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-154, groupId=20fbb702-fdcc-4c86-9ab0-fba9eb3fc287] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:37 INFO  Fetcher:583 - [Consumer clientId=consumer-154, groupId=20fbb702-fdcc-4c86-9ab0-fba9eb3fc287] Resetting offset for partition test101-0 to offset 1214.
2020-01-07 20:25:37 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 451dfd55-c68c-4a84-a4c4-12183d95cdd5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:37 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:37 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:37 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:37 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-155, groupId=451dfd55-c68c-4a84-a4c4-12183d95cdd5] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:37 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-155, groupId=451dfd55-c68c-4a84-a4c4-12183d95cdd5] Revoking previously assigned partitions []
2020-01-07 20:25:37 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-155, groupId=451dfd55-c68c-4a84-a4c4-12183d95cdd5] (Re-)joining group
2020-01-07 20:25:37 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-155, groupId=451dfd55-c68c-4a84-a4c4-12183d95cdd5] Successfully joined group with generation 1
2020-01-07 20:25:37 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-155, groupId=451dfd55-c68c-4a84-a4c4-12183d95cdd5] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:37 INFO  Fetcher:583 - [Consumer clientId=consumer-155, groupId=451dfd55-c68c-4a84-a4c4-12183d95cdd5] Resetting offset for partition test101-0 to offset 1215.
2020-01-07 20:25:37 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = abbcd050-21a1-4e19-986b-d601d6443418
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:37 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:37 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:37 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:37 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-156, groupId=abbcd050-21a1-4e19-986b-d601d6443418] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:37 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-156, groupId=abbcd050-21a1-4e19-986b-d601d6443418] Revoking previously assigned partitions []
2020-01-07 20:25:37 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-156, groupId=abbcd050-21a1-4e19-986b-d601d6443418] (Re-)joining group
2020-01-07 20:25:37 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-156, groupId=abbcd050-21a1-4e19-986b-d601d6443418] Successfully joined group with generation 1
2020-01-07 20:25:37 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-156, groupId=abbcd050-21a1-4e19-986b-d601d6443418] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:37 INFO  Fetcher:583 - [Consumer clientId=consumer-156, groupId=abbcd050-21a1-4e19-986b-d601d6443418] Resetting offset for partition test101-0 to offset 1216.
2020-01-07 20:25:37 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = bcbf643b-fcdb-4a39-b3ea-2831b9ac8589
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:37 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:37 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:37 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:37 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-157, groupId=bcbf643b-fcdb-4a39-b3ea-2831b9ac8589] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:37 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-157, groupId=bcbf643b-fcdb-4a39-b3ea-2831b9ac8589] Revoking previously assigned partitions []
2020-01-07 20:25:37 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-157, groupId=bcbf643b-fcdb-4a39-b3ea-2831b9ac8589] (Re-)joining group
2020-01-07 20:25:37 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-157, groupId=bcbf643b-fcdb-4a39-b3ea-2831b9ac8589] Successfully joined group with generation 1
2020-01-07 20:25:37 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-157, groupId=bcbf643b-fcdb-4a39-b3ea-2831b9ac8589] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:37 INFO  Fetcher:583 - [Consumer clientId=consumer-157, groupId=bcbf643b-fcdb-4a39-b3ea-2831b9ac8589] Resetting offset for partition test101-0 to offset 1217.
2020-01-07 20:25:37 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ad2e46b2-5637-40aa-8a8c-b5427c69f3f8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:37 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:37 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:37 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:37 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-158, groupId=ad2e46b2-5637-40aa-8a8c-b5427c69f3f8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:37 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-158, groupId=ad2e46b2-5637-40aa-8a8c-b5427c69f3f8] Revoking previously assigned partitions []
2020-01-07 20:25:37 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-158, groupId=ad2e46b2-5637-40aa-8a8c-b5427c69f3f8] (Re-)joining group
2020-01-07 20:25:37 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-158, groupId=ad2e46b2-5637-40aa-8a8c-b5427c69f3f8] Successfully joined group with generation 1
2020-01-07 20:25:37 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-158, groupId=ad2e46b2-5637-40aa-8a8c-b5427c69f3f8] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:37 INFO  Fetcher:583 - [Consumer clientId=consumer-158, groupId=ad2e46b2-5637-40aa-8a8c-b5427c69f3f8] Resetting offset for partition test101-0 to offset 1219.
2020-01-07 20:25:37 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3a8ce97f-d10b-41d4-aa16-8d691808ceed
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:37 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:37 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:37 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:37 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-159, groupId=3a8ce97f-d10b-41d4-aa16-8d691808ceed] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:37 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-159, groupId=3a8ce97f-d10b-41d4-aa16-8d691808ceed] Revoking previously assigned partitions []
2020-01-07 20:25:37 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-159, groupId=3a8ce97f-d10b-41d4-aa16-8d691808ceed] (Re-)joining group
2020-01-07 20:25:37 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-159, groupId=3a8ce97f-d10b-41d4-aa16-8d691808ceed] Successfully joined group with generation 1
2020-01-07 20:25:37 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-159, groupId=3a8ce97f-d10b-41d4-aa16-8d691808ceed] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:37 INFO  Fetcher:583 - [Consumer clientId=consumer-159, groupId=3a8ce97f-d10b-41d4-aa16-8d691808ceed] Resetting offset for partition test101-0 to offset 1221.
2020-01-07 20:25:37 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2e813bf1-3fd2-4536-9fa9-a71233626d91
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:37 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:37 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:37 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:37 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-160, groupId=2e813bf1-3fd2-4536-9fa9-a71233626d91] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:37 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-160, groupId=2e813bf1-3fd2-4536-9fa9-a71233626d91] Revoking previously assigned partitions []
2020-01-07 20:25:37 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-160, groupId=2e813bf1-3fd2-4536-9fa9-a71233626d91] (Re-)joining group
2020-01-07 20:25:37 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-160, groupId=2e813bf1-3fd2-4536-9fa9-a71233626d91] Successfully joined group with generation 1
2020-01-07 20:25:37 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-160, groupId=2e813bf1-3fd2-4536-9fa9-a71233626d91] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:37 INFO  Fetcher:583 - [Consumer clientId=consumer-160, groupId=2e813bf1-3fd2-4536-9fa9-a71233626d91] Resetting offset for partition test101-0 to offset 1222.
2020-01-07 20:25:37 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 31193963-50c7-4a8b-a027-48c6aead4954
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:37 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:37 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:37 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:37 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-161, groupId=31193963-50c7-4a8b-a027-48c6aead4954] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:37 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-161, groupId=31193963-50c7-4a8b-a027-48c6aead4954] Revoking previously assigned partitions []
2020-01-07 20:25:37 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-161, groupId=31193963-50c7-4a8b-a027-48c6aead4954] (Re-)joining group
2020-01-07 20:25:37 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-161, groupId=31193963-50c7-4a8b-a027-48c6aead4954] Successfully joined group with generation 1
2020-01-07 20:25:37 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-161, groupId=31193963-50c7-4a8b-a027-48c6aead4954] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:37 INFO  Fetcher:583 - [Consumer clientId=consumer-161, groupId=31193963-50c7-4a8b-a027-48c6aead4954] Resetting offset for partition test101-0 to offset 1223.
2020-01-07 20:25:37 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 78683b46-ee84-464a-86bf-1f181b189b40
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:37 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:37 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:37 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:37 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-162, groupId=78683b46-ee84-464a-86bf-1f181b189b40] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:37 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-162, groupId=78683b46-ee84-464a-86bf-1f181b189b40] Revoking previously assigned partitions []
2020-01-07 20:25:37 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-162, groupId=78683b46-ee84-464a-86bf-1f181b189b40] (Re-)joining group
2020-01-07 20:25:37 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-162, groupId=78683b46-ee84-464a-86bf-1f181b189b40] Successfully joined group with generation 1
2020-01-07 20:25:37 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-162, groupId=78683b46-ee84-464a-86bf-1f181b189b40] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:37 INFO  Fetcher:583 - [Consumer clientId=consumer-162, groupId=78683b46-ee84-464a-86bf-1f181b189b40] Resetting offset for partition test101-0 to offset 1225.
2020-01-07 20:25:37 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7a07eab2-191a-4bdb-8503-4272f1e38900
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:37 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:37 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:37 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:37 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-163, groupId=7a07eab2-191a-4bdb-8503-4272f1e38900] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:37 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-163, groupId=7a07eab2-191a-4bdb-8503-4272f1e38900] Revoking previously assigned partitions []
2020-01-07 20:25:37 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-163, groupId=7a07eab2-191a-4bdb-8503-4272f1e38900] (Re-)joining group
2020-01-07 20:25:37 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-163, groupId=7a07eab2-191a-4bdb-8503-4272f1e38900] Successfully joined group with generation 1
2020-01-07 20:25:37 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-163, groupId=7a07eab2-191a-4bdb-8503-4272f1e38900] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:37 INFO  Fetcher:583 - [Consumer clientId=consumer-163, groupId=7a07eab2-191a-4bdb-8503-4272f1e38900] Resetting offset for partition test101-0 to offset 1226.
2020-01-07 20:25:37 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f2dc4a75-e0a6-469c-b63a-849e1f156552
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:37 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:37 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:37 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:37 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-164, groupId=f2dc4a75-e0a6-469c-b63a-849e1f156552] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:37 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-164, groupId=f2dc4a75-e0a6-469c-b63a-849e1f156552] Revoking previously assigned partitions []
2020-01-07 20:25:37 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-164, groupId=f2dc4a75-e0a6-469c-b63a-849e1f156552] (Re-)joining group
2020-01-07 20:25:37 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-164, groupId=f2dc4a75-e0a6-469c-b63a-849e1f156552] Successfully joined group with generation 1
2020-01-07 20:25:37 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-164, groupId=f2dc4a75-e0a6-469c-b63a-849e1f156552] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:37 INFO  Fetcher:583 - [Consumer clientId=consumer-164, groupId=f2dc4a75-e0a6-469c-b63a-849e1f156552] Resetting offset for partition test101-0 to offset 1227.
2020-01-07 20:25:37 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9a3c71ef-fab6-4a29-9bd5-7aca58ddcfcf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:37 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:37 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:37 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:37 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-165, groupId=9a3c71ef-fab6-4a29-9bd5-7aca58ddcfcf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:37 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-165, groupId=9a3c71ef-fab6-4a29-9bd5-7aca58ddcfcf] Revoking previously assigned partitions []
2020-01-07 20:25:37 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-165, groupId=9a3c71ef-fab6-4a29-9bd5-7aca58ddcfcf] (Re-)joining group
2020-01-07 20:25:37 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-165, groupId=9a3c71ef-fab6-4a29-9bd5-7aca58ddcfcf] Successfully joined group with generation 1
2020-01-07 20:25:37 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-165, groupId=9a3c71ef-fab6-4a29-9bd5-7aca58ddcfcf] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:37 INFO  Fetcher:583 - [Consumer clientId=consumer-165, groupId=9a3c71ef-fab6-4a29-9bd5-7aca58ddcfcf] Resetting offset for partition test101-0 to offset 1228.
2020-01-07 20:25:37 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6d38dc6b-b5e5-4db1-b5e1-e493d5c35263
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:37 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:37 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:37 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:37 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-166, groupId=6d38dc6b-b5e5-4db1-b5e1-e493d5c35263] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:37 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-166, groupId=6d38dc6b-b5e5-4db1-b5e1-e493d5c35263] Revoking previously assigned partitions []
2020-01-07 20:25:37 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-166, groupId=6d38dc6b-b5e5-4db1-b5e1-e493d5c35263] (Re-)joining group
2020-01-07 20:25:37 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-166, groupId=6d38dc6b-b5e5-4db1-b5e1-e493d5c35263] Successfully joined group with generation 1
2020-01-07 20:25:37 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-166, groupId=6d38dc6b-b5e5-4db1-b5e1-e493d5c35263] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:37 INFO  Fetcher:583 - [Consumer clientId=consumer-166, groupId=6d38dc6b-b5e5-4db1-b5e1-e493d5c35263] Resetting offset for partition test101-0 to offset 1229.
2020-01-07 20:25:37 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a61a1de2-af13-45cb-a4bd-0ee8b927cd0e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:37 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:37 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:37 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:37 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-167, groupId=a61a1de2-af13-45cb-a4bd-0ee8b927cd0e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:37 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-167, groupId=a61a1de2-af13-45cb-a4bd-0ee8b927cd0e] Revoking previously assigned partitions []
2020-01-07 20:25:37 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-167, groupId=a61a1de2-af13-45cb-a4bd-0ee8b927cd0e] (Re-)joining group
2020-01-07 20:25:37 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-167, groupId=a61a1de2-af13-45cb-a4bd-0ee8b927cd0e] Successfully joined group with generation 1
2020-01-07 20:25:37 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-167, groupId=a61a1de2-af13-45cb-a4bd-0ee8b927cd0e] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:37 INFO  Fetcher:583 - [Consumer clientId=consumer-167, groupId=a61a1de2-af13-45cb-a4bd-0ee8b927cd0e] Resetting offset for partition test101-0 to offset 1231.
2020-01-07 20:25:37 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 07ffd1a7-2cfa-4018-b41b-f0125bc75466
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:37 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:37 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:37 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:37 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-168, groupId=07ffd1a7-2cfa-4018-b41b-f0125bc75466] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:37 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-168, groupId=07ffd1a7-2cfa-4018-b41b-f0125bc75466] Revoking previously assigned partitions []
2020-01-07 20:25:37 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-168, groupId=07ffd1a7-2cfa-4018-b41b-f0125bc75466] (Re-)joining group
2020-01-07 20:25:38 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-168, groupId=07ffd1a7-2cfa-4018-b41b-f0125bc75466] Successfully joined group with generation 1
2020-01-07 20:25:38 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-168, groupId=07ffd1a7-2cfa-4018-b41b-f0125bc75466] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:38 INFO  Fetcher:583 - [Consumer clientId=consumer-168, groupId=07ffd1a7-2cfa-4018-b41b-f0125bc75466] Resetting offset for partition test101-0 to offset 1233.
2020-01-07 20:25:38 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a0681931-7a01-4927-a721-445a1ce06a8f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:38 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:38 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:38 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:38 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-169, groupId=a0681931-7a01-4927-a721-445a1ce06a8f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:38 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-169, groupId=a0681931-7a01-4927-a721-445a1ce06a8f] Revoking previously assigned partitions []
2020-01-07 20:25:38 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-169, groupId=a0681931-7a01-4927-a721-445a1ce06a8f] (Re-)joining group
2020-01-07 20:25:38 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-169, groupId=a0681931-7a01-4927-a721-445a1ce06a8f] Successfully joined group with generation 1
2020-01-07 20:25:38 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-169, groupId=a0681931-7a01-4927-a721-445a1ce06a8f] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:38 INFO  Fetcher:583 - [Consumer clientId=consumer-169, groupId=a0681931-7a01-4927-a721-445a1ce06a8f] Resetting offset for partition test101-0 to offset 1235.
2020-01-07 20:25:38 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3eccdac3-5e2f-4eb1-b91f-c2007e72746e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:38 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:38 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:38 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:38 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-170, groupId=3eccdac3-5e2f-4eb1-b91f-c2007e72746e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:38 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-170, groupId=3eccdac3-5e2f-4eb1-b91f-c2007e72746e] Revoking previously assigned partitions []
2020-01-07 20:25:38 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-170, groupId=3eccdac3-5e2f-4eb1-b91f-c2007e72746e] (Re-)joining group
2020-01-07 20:25:38 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-170, groupId=3eccdac3-5e2f-4eb1-b91f-c2007e72746e] Successfully joined group with generation 1
2020-01-07 20:25:38 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-170, groupId=3eccdac3-5e2f-4eb1-b91f-c2007e72746e] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:38 INFO  Fetcher:583 - [Consumer clientId=consumer-170, groupId=3eccdac3-5e2f-4eb1-b91f-c2007e72746e] Resetting offset for partition test101-0 to offset 1237.
2020-01-07 20:25:38 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e17a298b-0589-4b41-bbc2-1ff4163fc25b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:38 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:38 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:38 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:38 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-171, groupId=e17a298b-0589-4b41-bbc2-1ff4163fc25b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:38 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-171, groupId=e17a298b-0589-4b41-bbc2-1ff4163fc25b] Revoking previously assigned partitions []
2020-01-07 20:25:38 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-171, groupId=e17a298b-0589-4b41-bbc2-1ff4163fc25b] (Re-)joining group
2020-01-07 20:25:38 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-171, groupId=e17a298b-0589-4b41-bbc2-1ff4163fc25b] Successfully joined group with generation 1
2020-01-07 20:25:38 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-171, groupId=e17a298b-0589-4b41-bbc2-1ff4163fc25b] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:38 INFO  Fetcher:583 - [Consumer clientId=consumer-171, groupId=e17a298b-0589-4b41-bbc2-1ff4163fc25b] Resetting offset for partition test101-0 to offset 1239.
2020-01-07 20:25:38 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d4c162e7-500f-4264-ab40-1f7009947d53
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:38 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:38 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:38 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:38 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-172, groupId=d4c162e7-500f-4264-ab40-1f7009947d53] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:38 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-172, groupId=d4c162e7-500f-4264-ab40-1f7009947d53] Revoking previously assigned partitions []
2020-01-07 20:25:38 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-172, groupId=d4c162e7-500f-4264-ab40-1f7009947d53] (Re-)joining group
2020-01-07 20:25:38 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-172, groupId=d4c162e7-500f-4264-ab40-1f7009947d53] Successfully joined group with generation 1
2020-01-07 20:25:38 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-172, groupId=d4c162e7-500f-4264-ab40-1f7009947d53] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:38 INFO  Fetcher:583 - [Consumer clientId=consumer-172, groupId=d4c162e7-500f-4264-ab40-1f7009947d53] Resetting offset for partition test101-0 to offset 1241.
2020-01-07 20:25:38 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 76a83666-8b71-47bd-8767-9eb0c1af351c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:38 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:38 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:38 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:38 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-173, groupId=76a83666-8b71-47bd-8767-9eb0c1af351c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:38 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-173, groupId=76a83666-8b71-47bd-8767-9eb0c1af351c] Revoking previously assigned partitions []
2020-01-07 20:25:38 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-173, groupId=76a83666-8b71-47bd-8767-9eb0c1af351c] (Re-)joining group
2020-01-07 20:25:38 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-173, groupId=76a83666-8b71-47bd-8767-9eb0c1af351c] Successfully joined group with generation 1
2020-01-07 20:25:38 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-173, groupId=76a83666-8b71-47bd-8767-9eb0c1af351c] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:38 INFO  Fetcher:583 - [Consumer clientId=consumer-173, groupId=76a83666-8b71-47bd-8767-9eb0c1af351c] Resetting offset for partition test101-0 to offset 1244.
2020-01-07 20:25:38 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dd37d189-d6a6-4579-bc46-695f475b2ac8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:38 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:38 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:38 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:38 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-174, groupId=dd37d189-d6a6-4579-bc46-695f475b2ac8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:38 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-174, groupId=dd37d189-d6a6-4579-bc46-695f475b2ac8] Revoking previously assigned partitions []
2020-01-07 20:25:38 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-174, groupId=dd37d189-d6a6-4579-bc46-695f475b2ac8] (Re-)joining group
2020-01-07 20:25:38 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-174, groupId=dd37d189-d6a6-4579-bc46-695f475b2ac8] Successfully joined group with generation 1
2020-01-07 20:25:38 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-174, groupId=dd37d189-d6a6-4579-bc46-695f475b2ac8] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:38 INFO  Fetcher:583 - [Consumer clientId=consumer-174, groupId=dd37d189-d6a6-4579-bc46-695f475b2ac8] Resetting offset for partition test101-0 to offset 1245.
2020-01-07 20:25:38 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 81087202-b7c4-4312-af68-f52a01ab044f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:38 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:38 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:38 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:38 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-175, groupId=81087202-b7c4-4312-af68-f52a01ab044f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:38 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-175, groupId=81087202-b7c4-4312-af68-f52a01ab044f] Revoking previously assigned partitions []
2020-01-07 20:25:38 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-175, groupId=81087202-b7c4-4312-af68-f52a01ab044f] (Re-)joining group
2020-01-07 20:25:38 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-175, groupId=81087202-b7c4-4312-af68-f52a01ab044f] Successfully joined group with generation 1
2020-01-07 20:25:38 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-175, groupId=81087202-b7c4-4312-af68-f52a01ab044f] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:38 INFO  Fetcher:583 - [Consumer clientId=consumer-175, groupId=81087202-b7c4-4312-af68-f52a01ab044f] Resetting offset for partition test101-0 to offset 1247.
2020-01-07 20:25:38 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a72d8ef1-2cc0-418f-a48b-caf420796c74
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:38 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:38 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:38 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:38 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-176, groupId=a72d8ef1-2cc0-418f-a48b-caf420796c74] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:38 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-176, groupId=a72d8ef1-2cc0-418f-a48b-caf420796c74] Revoking previously assigned partitions []
2020-01-07 20:25:38 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-176, groupId=a72d8ef1-2cc0-418f-a48b-caf420796c74] (Re-)joining group
2020-01-07 20:25:38 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-176, groupId=a72d8ef1-2cc0-418f-a48b-caf420796c74] Successfully joined group with generation 1
2020-01-07 20:25:38 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-176, groupId=a72d8ef1-2cc0-418f-a48b-caf420796c74] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:38 INFO  Fetcher:583 - [Consumer clientId=consumer-176, groupId=a72d8ef1-2cc0-418f-a48b-caf420796c74] Resetting offset for partition test101-0 to offset 1248.
2020-01-07 20:25:38 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e9f60b06-dbae-46a4-874c-35ec46b11d92
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:38 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:38 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:38 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:38 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-177, groupId=e9f60b06-dbae-46a4-874c-35ec46b11d92] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:38 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-177, groupId=e9f60b06-dbae-46a4-874c-35ec46b11d92] Revoking previously assigned partitions []
2020-01-07 20:25:38 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-177, groupId=e9f60b06-dbae-46a4-874c-35ec46b11d92] (Re-)joining group
2020-01-07 20:25:38 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-177, groupId=e9f60b06-dbae-46a4-874c-35ec46b11d92] Successfully joined group with generation 1
2020-01-07 20:25:38 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-177, groupId=e9f60b06-dbae-46a4-874c-35ec46b11d92] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:38 INFO  Fetcher:583 - [Consumer clientId=consumer-177, groupId=e9f60b06-dbae-46a4-874c-35ec46b11d92] Resetting offset for partition test101-0 to offset 1249.
2020-01-07 20:25:38 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fee2115a-8da0-468d-ae17-4cc40dfcf7df
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:38 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:38 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:38 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:38 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-178, groupId=fee2115a-8da0-468d-ae17-4cc40dfcf7df] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:38 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-178, groupId=fee2115a-8da0-468d-ae17-4cc40dfcf7df] Revoking previously assigned partitions []
2020-01-07 20:25:38 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-178, groupId=fee2115a-8da0-468d-ae17-4cc40dfcf7df] (Re-)joining group
2020-01-07 20:25:38 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-178, groupId=fee2115a-8da0-468d-ae17-4cc40dfcf7df] Successfully joined group with generation 1
2020-01-07 20:25:38 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-178, groupId=fee2115a-8da0-468d-ae17-4cc40dfcf7df] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:38 INFO  Fetcher:583 - [Consumer clientId=consumer-178, groupId=fee2115a-8da0-468d-ae17-4cc40dfcf7df] Resetting offset for partition test101-0 to offset 1252.
2020-01-07 20:25:38 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a30c06f6-aa50-41e1-90f1-9841c04301cf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:38 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:38 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:38 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:38 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-179, groupId=a30c06f6-aa50-41e1-90f1-9841c04301cf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:38 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-179, groupId=a30c06f6-aa50-41e1-90f1-9841c04301cf] Revoking previously assigned partitions []
2020-01-07 20:25:38 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-179, groupId=a30c06f6-aa50-41e1-90f1-9841c04301cf] (Re-)joining group
2020-01-07 20:25:38 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-179, groupId=a30c06f6-aa50-41e1-90f1-9841c04301cf] Successfully joined group with generation 1
2020-01-07 20:25:38 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-179, groupId=a30c06f6-aa50-41e1-90f1-9841c04301cf] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:38 INFO  Fetcher:583 - [Consumer clientId=consumer-179, groupId=a30c06f6-aa50-41e1-90f1-9841c04301cf] Resetting offset for partition test101-0 to offset 1254.
2020-01-07 20:25:38 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 40dab833-05a7-40c0-b67d-6ce32094e34c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:38 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:38 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:38 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:38 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-180, groupId=40dab833-05a7-40c0-b67d-6ce32094e34c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:38 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-180, groupId=40dab833-05a7-40c0-b67d-6ce32094e34c] Revoking previously assigned partitions []
2020-01-07 20:25:38 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-180, groupId=40dab833-05a7-40c0-b67d-6ce32094e34c] (Re-)joining group
2020-01-07 20:25:38 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-180, groupId=40dab833-05a7-40c0-b67d-6ce32094e34c] Successfully joined group with generation 1
2020-01-07 20:25:38 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-180, groupId=40dab833-05a7-40c0-b67d-6ce32094e34c] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:38 INFO  Fetcher:583 - [Consumer clientId=consumer-180, groupId=40dab833-05a7-40c0-b67d-6ce32094e34c] Resetting offset for partition test101-0 to offset 1256.
2020-01-07 20:25:38 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = db764c97-ccf2-4fcb-ae79-ad034b56379b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:38 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:38 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:38 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:38 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-181, groupId=db764c97-ccf2-4fcb-ae79-ad034b56379b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:38 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-181, groupId=db764c97-ccf2-4fcb-ae79-ad034b56379b] Revoking previously assigned partitions []
2020-01-07 20:25:38 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-181, groupId=db764c97-ccf2-4fcb-ae79-ad034b56379b] (Re-)joining group
2020-01-07 20:25:38 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-181, groupId=db764c97-ccf2-4fcb-ae79-ad034b56379b] Successfully joined group with generation 1
2020-01-07 20:25:38 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-181, groupId=db764c97-ccf2-4fcb-ae79-ad034b56379b] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:38 INFO  Fetcher:583 - [Consumer clientId=consumer-181, groupId=db764c97-ccf2-4fcb-ae79-ad034b56379b] Resetting offset for partition test101-0 to offset 1257.
2020-01-07 20:25:39 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 74ec4112-3ad8-433f-b101-7bfffcc87155
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:39 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:39 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:39 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:39 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-182, groupId=74ec4112-3ad8-433f-b101-7bfffcc87155] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:39 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-182, groupId=74ec4112-3ad8-433f-b101-7bfffcc87155] Revoking previously assigned partitions []
2020-01-07 20:25:39 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-182, groupId=74ec4112-3ad8-433f-b101-7bfffcc87155] (Re-)joining group
2020-01-07 20:25:39 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-182, groupId=74ec4112-3ad8-433f-b101-7bfffcc87155] Successfully joined group with generation 1
2020-01-07 20:25:39 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-182, groupId=74ec4112-3ad8-433f-b101-7bfffcc87155] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:39 INFO  Fetcher:583 - [Consumer clientId=consumer-182, groupId=74ec4112-3ad8-433f-b101-7bfffcc87155] Resetting offset for partition test101-0 to offset 1259.
2020-01-07 20:25:39 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ce11c986-c33c-40d4-b559-4cda767cf0e5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:39 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:39 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:39 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:39 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-183, groupId=ce11c986-c33c-40d4-b559-4cda767cf0e5] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:39 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-183, groupId=ce11c986-c33c-40d4-b559-4cda767cf0e5] Revoking previously assigned partitions []
2020-01-07 20:25:39 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-183, groupId=ce11c986-c33c-40d4-b559-4cda767cf0e5] (Re-)joining group
2020-01-07 20:25:39 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-183, groupId=ce11c986-c33c-40d4-b559-4cda767cf0e5] Successfully joined group with generation 1
2020-01-07 20:25:39 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-183, groupId=ce11c986-c33c-40d4-b559-4cda767cf0e5] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:39 INFO  Fetcher:583 - [Consumer clientId=consumer-183, groupId=ce11c986-c33c-40d4-b559-4cda767cf0e5] Resetting offset for partition test101-0 to offset 1260.
2020-01-07 20:25:39 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9b902bed-7765-4514-9eb9-f564107d5e0c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:39 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:39 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:39 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:39 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-184, groupId=9b902bed-7765-4514-9eb9-f564107d5e0c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:39 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-184, groupId=9b902bed-7765-4514-9eb9-f564107d5e0c] Revoking previously assigned partitions []
2020-01-07 20:25:39 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-184, groupId=9b902bed-7765-4514-9eb9-f564107d5e0c] (Re-)joining group
2020-01-07 20:25:39 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-184, groupId=9b902bed-7765-4514-9eb9-f564107d5e0c] Successfully joined group with generation 1
2020-01-07 20:25:39 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-184, groupId=9b902bed-7765-4514-9eb9-f564107d5e0c] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:39 INFO  Fetcher:583 - [Consumer clientId=consumer-184, groupId=9b902bed-7765-4514-9eb9-f564107d5e0c] Resetting offset for partition test101-0 to offset 1262.
2020-01-07 20:25:39 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 76cbf669-340b-4089-9875-ef56c61f4821
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:39 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:39 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:39 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:39 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-185, groupId=76cbf669-340b-4089-9875-ef56c61f4821] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:39 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-185, groupId=76cbf669-340b-4089-9875-ef56c61f4821] Revoking previously assigned partitions []
2020-01-07 20:25:39 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-185, groupId=76cbf669-340b-4089-9875-ef56c61f4821] (Re-)joining group
2020-01-07 20:25:39 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-185, groupId=76cbf669-340b-4089-9875-ef56c61f4821] Successfully joined group with generation 1
2020-01-07 20:25:39 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-185, groupId=76cbf669-340b-4089-9875-ef56c61f4821] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:39 INFO  Fetcher:583 - [Consumer clientId=consumer-185, groupId=76cbf669-340b-4089-9875-ef56c61f4821] Resetting offset for partition test101-0 to offset 1264.
2020-01-07 20:25:39 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1dd5e315-f79b-4340-9393-c2c853d8aad4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:39 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:39 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:39 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:39 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-186, groupId=1dd5e315-f79b-4340-9393-c2c853d8aad4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:39 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-186, groupId=1dd5e315-f79b-4340-9393-c2c853d8aad4] Revoking previously assigned partitions []
2020-01-07 20:25:39 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-186, groupId=1dd5e315-f79b-4340-9393-c2c853d8aad4] (Re-)joining group
2020-01-07 20:25:39 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-186, groupId=1dd5e315-f79b-4340-9393-c2c853d8aad4] Successfully joined group with generation 1
2020-01-07 20:25:39 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-186, groupId=1dd5e315-f79b-4340-9393-c2c853d8aad4] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:39 INFO  Fetcher:583 - [Consumer clientId=consumer-186, groupId=1dd5e315-f79b-4340-9393-c2c853d8aad4] Resetting offset for partition test101-0 to offset 1266.
2020-01-07 20:25:39 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0f717b2b-7b7d-47aa-9678-328950b82e37
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:39 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:39 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:39 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:39 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-187, groupId=0f717b2b-7b7d-47aa-9678-328950b82e37] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:39 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-187, groupId=0f717b2b-7b7d-47aa-9678-328950b82e37] Revoking previously assigned partitions []
2020-01-07 20:25:39 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-187, groupId=0f717b2b-7b7d-47aa-9678-328950b82e37] (Re-)joining group
2020-01-07 20:25:39 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-187, groupId=0f717b2b-7b7d-47aa-9678-328950b82e37] Successfully joined group with generation 1
2020-01-07 20:25:39 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-187, groupId=0f717b2b-7b7d-47aa-9678-328950b82e37] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:39 INFO  Fetcher:583 - [Consumer clientId=consumer-187, groupId=0f717b2b-7b7d-47aa-9678-328950b82e37] Resetting offset for partition test101-0 to offset 1268.
2020-01-07 20:25:39 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = cc667ca8-f9ef-4f18-9716-fb6c01425bc4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:39 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:39 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:39 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:39 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-188, groupId=cc667ca8-f9ef-4f18-9716-fb6c01425bc4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:39 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-188, groupId=cc667ca8-f9ef-4f18-9716-fb6c01425bc4] Revoking previously assigned partitions []
2020-01-07 20:25:39 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-188, groupId=cc667ca8-f9ef-4f18-9716-fb6c01425bc4] (Re-)joining group
2020-01-07 20:25:39 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-188, groupId=cc667ca8-f9ef-4f18-9716-fb6c01425bc4] Successfully joined group with generation 1
2020-01-07 20:25:39 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-188, groupId=cc667ca8-f9ef-4f18-9716-fb6c01425bc4] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:39 INFO  Fetcher:583 - [Consumer clientId=consumer-188, groupId=cc667ca8-f9ef-4f18-9716-fb6c01425bc4] Resetting offset for partition test101-0 to offset 1269.
2020-01-07 20:25:39 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5c96064e-55fb-4f59-8c3d-f509138f4299
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:39 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:39 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:39 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:39 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-189, groupId=5c96064e-55fb-4f59-8c3d-f509138f4299] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:39 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-189, groupId=5c96064e-55fb-4f59-8c3d-f509138f4299] Revoking previously assigned partitions []
2020-01-07 20:25:39 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-189, groupId=5c96064e-55fb-4f59-8c3d-f509138f4299] (Re-)joining group
2020-01-07 20:25:39 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-189, groupId=5c96064e-55fb-4f59-8c3d-f509138f4299] Successfully joined group with generation 1
2020-01-07 20:25:39 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-189, groupId=5c96064e-55fb-4f59-8c3d-f509138f4299] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:39 INFO  Fetcher:583 - [Consumer clientId=consumer-189, groupId=5c96064e-55fb-4f59-8c3d-f509138f4299] Resetting offset for partition test101-0 to offset 1271.
2020-01-07 20:25:39 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f0e8d0ea-d5d1-4285-94ba-a5097521d1cf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:39 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:39 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:39 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:39 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-190, groupId=f0e8d0ea-d5d1-4285-94ba-a5097521d1cf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:39 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-190, groupId=f0e8d0ea-d5d1-4285-94ba-a5097521d1cf] Revoking previously assigned partitions []
2020-01-07 20:25:39 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-190, groupId=f0e8d0ea-d5d1-4285-94ba-a5097521d1cf] (Re-)joining group
2020-01-07 20:25:39 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-190, groupId=f0e8d0ea-d5d1-4285-94ba-a5097521d1cf] Successfully joined group with generation 1
2020-01-07 20:25:39 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-190, groupId=f0e8d0ea-d5d1-4285-94ba-a5097521d1cf] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:39 INFO  Fetcher:583 - [Consumer clientId=consumer-190, groupId=f0e8d0ea-d5d1-4285-94ba-a5097521d1cf] Resetting offset for partition test101-0 to offset 1272.
2020-01-07 20:25:39 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 163024b3-161d-40da-a346-f9a376fb43e3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:39 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:39 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:39 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:39 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-191, groupId=163024b3-161d-40da-a346-f9a376fb43e3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:39 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-191, groupId=163024b3-161d-40da-a346-f9a376fb43e3] Revoking previously assigned partitions []
2020-01-07 20:25:39 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-191, groupId=163024b3-161d-40da-a346-f9a376fb43e3] (Re-)joining group
2020-01-07 20:25:39 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-191, groupId=163024b3-161d-40da-a346-f9a376fb43e3] Successfully joined group with generation 1
2020-01-07 20:25:39 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-191, groupId=163024b3-161d-40da-a346-f9a376fb43e3] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:39 INFO  Fetcher:583 - [Consumer clientId=consumer-191, groupId=163024b3-161d-40da-a346-f9a376fb43e3] Resetting offset for partition test101-0 to offset 1275.
2020-01-07 20:25:39 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 98c48a13-b67e-4165-aec1-c408a5af8853
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:39 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:39 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:39 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:39 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-192, groupId=98c48a13-b67e-4165-aec1-c408a5af8853] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:39 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-192, groupId=98c48a13-b67e-4165-aec1-c408a5af8853] Revoking previously assigned partitions []
2020-01-07 20:25:39 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-192, groupId=98c48a13-b67e-4165-aec1-c408a5af8853] (Re-)joining group
2020-01-07 20:25:39 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-192, groupId=98c48a13-b67e-4165-aec1-c408a5af8853] Successfully joined group with generation 1
2020-01-07 20:25:39 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-192, groupId=98c48a13-b67e-4165-aec1-c408a5af8853] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:39 INFO  Fetcher:583 - [Consumer clientId=consumer-192, groupId=98c48a13-b67e-4165-aec1-c408a5af8853] Resetting offset for partition test101-0 to offset 1276.
2020-01-07 20:25:39 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 351470f4-0187-49f3-b512-a3048bb10146
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:39 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:39 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:39 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:39 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-193, groupId=351470f4-0187-49f3-b512-a3048bb10146] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:39 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-193, groupId=351470f4-0187-49f3-b512-a3048bb10146] Revoking previously assigned partitions []
2020-01-07 20:25:39 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-193, groupId=351470f4-0187-49f3-b512-a3048bb10146] (Re-)joining group
2020-01-07 20:25:39 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-193, groupId=351470f4-0187-49f3-b512-a3048bb10146] Successfully joined group with generation 1
2020-01-07 20:25:39 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-193, groupId=351470f4-0187-49f3-b512-a3048bb10146] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:39 INFO  Fetcher:583 - [Consumer clientId=consumer-193, groupId=351470f4-0187-49f3-b512-a3048bb10146] Resetting offset for partition test101-0 to offset 1279.
2020-01-07 20:25:39 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7ce22382-a1e3-4c92-a9c1-079ad16feea1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:39 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:39 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:40 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:40 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-194, groupId=7ce22382-a1e3-4c92-a9c1-079ad16feea1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:40 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-194, groupId=7ce22382-a1e3-4c92-a9c1-079ad16feea1] Revoking previously assigned partitions []
2020-01-07 20:25:40 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-194, groupId=7ce22382-a1e3-4c92-a9c1-079ad16feea1] (Re-)joining group
2020-01-07 20:25:40 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-194, groupId=7ce22382-a1e3-4c92-a9c1-079ad16feea1] Successfully joined group with generation 1
2020-01-07 20:25:40 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-194, groupId=7ce22382-a1e3-4c92-a9c1-079ad16feea1] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:40 INFO  Fetcher:583 - [Consumer clientId=consumer-194, groupId=7ce22382-a1e3-4c92-a9c1-079ad16feea1] Resetting offset for partition test101-0 to offset 1283.
2020-01-07 20:25:40 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = df1fd1e0-c7dc-40bd-9fc5-b4f17c0b9cc9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:40 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:40 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:40 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:40 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-195, groupId=df1fd1e0-c7dc-40bd-9fc5-b4f17c0b9cc9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:40 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-195, groupId=df1fd1e0-c7dc-40bd-9fc5-b4f17c0b9cc9] Revoking previously assigned partitions []
2020-01-07 20:25:40 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-195, groupId=df1fd1e0-c7dc-40bd-9fc5-b4f17c0b9cc9] (Re-)joining group
2020-01-07 20:25:40 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-195, groupId=df1fd1e0-c7dc-40bd-9fc5-b4f17c0b9cc9] Successfully joined group with generation 1
2020-01-07 20:25:40 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-195, groupId=df1fd1e0-c7dc-40bd-9fc5-b4f17c0b9cc9] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:40 INFO  Fetcher:583 - [Consumer clientId=consumer-195, groupId=df1fd1e0-c7dc-40bd-9fc5-b4f17c0b9cc9] Resetting offset for partition test101-0 to offset 1284.
2020-01-07 20:25:40 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1fe4f474-5c08-4d71-ad34-55461b5da6b2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:40 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:40 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:40 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:40 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-196, groupId=1fe4f474-5c08-4d71-ad34-55461b5da6b2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:40 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-196, groupId=1fe4f474-5c08-4d71-ad34-55461b5da6b2] Revoking previously assigned partitions []
2020-01-07 20:25:40 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-196, groupId=1fe4f474-5c08-4d71-ad34-55461b5da6b2] (Re-)joining group
2020-01-07 20:25:40 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-196, groupId=1fe4f474-5c08-4d71-ad34-55461b5da6b2] Successfully joined group with generation 1
2020-01-07 20:25:40 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-196, groupId=1fe4f474-5c08-4d71-ad34-55461b5da6b2] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:40 INFO  Fetcher:583 - [Consumer clientId=consumer-196, groupId=1fe4f474-5c08-4d71-ad34-55461b5da6b2] Resetting offset for partition test101-0 to offset 1286.
2020-01-07 20:25:40 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0e6002ab-9371-46f3-bcff-f5f486d50745
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:40 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:40 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:40 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:40 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-197, groupId=0e6002ab-9371-46f3-bcff-f5f486d50745] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:40 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-197, groupId=0e6002ab-9371-46f3-bcff-f5f486d50745] Revoking previously assigned partitions []
2020-01-07 20:25:40 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-197, groupId=0e6002ab-9371-46f3-bcff-f5f486d50745] (Re-)joining group
2020-01-07 20:25:40 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-197, groupId=0e6002ab-9371-46f3-bcff-f5f486d50745] Successfully joined group with generation 1
2020-01-07 20:25:40 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-197, groupId=0e6002ab-9371-46f3-bcff-f5f486d50745] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:40 INFO  Fetcher:583 - [Consumer clientId=consumer-197, groupId=0e6002ab-9371-46f3-bcff-f5f486d50745] Resetting offset for partition test101-0 to offset 1287.
2020-01-07 20:25:40 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c6493528-8962-4464-86a1-6be8a4ad7014
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:40 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:40 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:40 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:40 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-198, groupId=c6493528-8962-4464-86a1-6be8a4ad7014] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:40 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-198, groupId=c6493528-8962-4464-86a1-6be8a4ad7014] Revoking previously assigned partitions []
2020-01-07 20:25:40 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-198, groupId=c6493528-8962-4464-86a1-6be8a4ad7014] (Re-)joining group
2020-01-07 20:25:40 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-198, groupId=c6493528-8962-4464-86a1-6be8a4ad7014] Successfully joined group with generation 1
2020-01-07 20:25:40 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-198, groupId=c6493528-8962-4464-86a1-6be8a4ad7014] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:40 INFO  Fetcher:583 - [Consumer clientId=consumer-198, groupId=c6493528-8962-4464-86a1-6be8a4ad7014] Resetting offset for partition test101-0 to offset 1290.
2020-01-07 20:25:40 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 13a207ed-378c-4b1d-9dc6-07461daf66e7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:40 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:40 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:40 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:40 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-199, groupId=13a207ed-378c-4b1d-9dc6-07461daf66e7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:40 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-199, groupId=13a207ed-378c-4b1d-9dc6-07461daf66e7] Revoking previously assigned partitions []
2020-01-07 20:25:40 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-199, groupId=13a207ed-378c-4b1d-9dc6-07461daf66e7] (Re-)joining group
2020-01-07 20:25:40 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-199, groupId=13a207ed-378c-4b1d-9dc6-07461daf66e7] Successfully joined group with generation 1
2020-01-07 20:25:40 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-199, groupId=13a207ed-378c-4b1d-9dc6-07461daf66e7] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:40 INFO  Fetcher:583 - [Consumer clientId=consumer-199, groupId=13a207ed-378c-4b1d-9dc6-07461daf66e7] Resetting offset for partition test101-0 to offset 1291.
2020-01-07 20:25:40 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0f1c6f91-0477-45c0-a91e-b18b2e99d922
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:40 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:40 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:40 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:40 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-200, groupId=0f1c6f91-0477-45c0-a91e-b18b2e99d922] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:40 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-200, groupId=0f1c6f91-0477-45c0-a91e-b18b2e99d922] Revoking previously assigned partitions []
2020-01-07 20:25:40 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-200, groupId=0f1c6f91-0477-45c0-a91e-b18b2e99d922] (Re-)joining group
2020-01-07 20:25:40 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-200, groupId=0f1c6f91-0477-45c0-a91e-b18b2e99d922] Successfully joined group with generation 1
2020-01-07 20:25:40 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-200, groupId=0f1c6f91-0477-45c0-a91e-b18b2e99d922] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:40 INFO  Fetcher:583 - [Consumer clientId=consumer-200, groupId=0f1c6f91-0477-45c0-a91e-b18b2e99d922] Resetting offset for partition test101-0 to offset 1294.
2020-01-07 20:25:40 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9eb86765-b1a6-4736-b024-b858772a83ac
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-01-07 20:25:40 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 20:25:40 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 20:25:40 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 20:25:40 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-201, groupId=9eb86765-b1a6-4736-b024-b858772a83ac] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 20:25:40 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-201, groupId=9eb86765-b1a6-4736-b024-b858772a83ac] Revoking previously assigned partitions []
2020-01-07 20:25:40 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-201, groupId=9eb86765-b1a6-4736-b024-b858772a83ac] (Re-)joining group
2020-01-07 20:25:40 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-201, groupId=9eb86765-b1a6-4736-b024-b858772a83ac] Successfully joined group with generation 1
2020-01-07 20:25:40 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-201, groupId=9eb86765-b1a6-4736-b024-b858772a83ac] Setting newly assigned partitions [test101-0]
2020-01-07 20:25:40 INFO  Fetcher:583 - [Consumer clientId=consumer-201, groupId=9eb86765-b1a6-4736-b024-b858772a83ac] Resetting offset for partition test101-0 to offset 1295.
2020-01-07 23:32:22 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = aad5df4e-3e6b-4e2f-88a7-ecb17a0bd35b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-07 23:32:22 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 23:32:22 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 23:32:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 23:32:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=aad5df4e-3e6b-4e2f-88a7-ecb17a0bd35b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 23:32:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=aad5df4e-3e6b-4e2f-88a7-ecb17a0bd35b] Revoking previously assigned partitions []
2020-01-07 23:32:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=aad5df4e-3e6b-4e2f-88a7-ecb17a0bd35b] (Re-)joining group
2020-01-07 23:32:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=aad5df4e-3e6b-4e2f-88a7-ecb17a0bd35b] Successfully joined group with generation 1
2020-01-07 23:32:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=aad5df4e-3e6b-4e2f-88a7-ecb17a0bd35b] Setting newly assigned partitions [testOne-0]
2020-01-07 23:32:23 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=aad5df4e-3e6b-4e2f-88a7-ecb17a0bd35b] Resetting offset for partition testOne-0 to offset 0.
2020-01-07 23:33:39 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 55890da0-0d69-4659-9836-322caaaa9621
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-07 23:33:40 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-07 23:33:40 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-07 23:33:40 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-07 23:33:40 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=55890da0-0d69-4659-9836-322caaaa9621] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-07 23:33:40 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=55890da0-0d69-4659-9836-322caaaa9621] Revoking previously assigned partitions []
2020-01-07 23:33:40 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=55890da0-0d69-4659-9836-322caaaa9621] (Re-)joining group
2020-01-07 23:33:40 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=55890da0-0d69-4659-9836-322caaaa9621] Successfully joined group with generation 1
2020-01-07 23:33:40 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=55890da0-0d69-4659-9836-322caaaa9621] Setting newly assigned partitions [testOne-0]
2020-01-07 23:33:40 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=55890da0-0d69-4659-9836-322caaaa9621] Resetting offset for partition testOne-0 to offset 0.
2020-01-08 01:15:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8977844f-f2c3-43c5-a944-972319979059
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 01:15:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 01:15:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 01:15:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 01:15:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=8977844f-f2c3-43c5-a944-972319979059] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 01:15:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=8977844f-f2c3-43c5-a944-972319979059] Revoking previously assigned partitions []
2020-01-08 01:15:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=8977844f-f2c3-43c5-a944-972319979059] (Re-)joining group
2020-01-08 01:15:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=8977844f-f2c3-43c5-a944-972319979059] Successfully joined group with generation 1
2020-01-08 01:15:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=8977844f-f2c3-43c5-a944-972319979059] Setting newly assigned partitions [testOne-0]
2020-01-08 01:15:09 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=8977844f-f2c3-43c5-a944-972319979059] Resetting offset for partition testOne-0 to offset 0.
2020-01-08 01:24:30 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 287919aa-b7d8-4084-b082-8dc00385dc84
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 01:24:30 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 01:24:30 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 01:24:31 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 01:24:31 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=287919aa-b7d8-4084-b082-8dc00385dc84] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 01:24:31 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=287919aa-b7d8-4084-b082-8dc00385dc84] Revoking previously assigned partitions []
2020-01-08 01:24:31 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=287919aa-b7d8-4084-b082-8dc00385dc84] (Re-)joining group
2020-01-08 01:24:31 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=287919aa-b7d8-4084-b082-8dc00385dc84] Successfully joined group with generation 1
2020-01-08 01:24:31 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=287919aa-b7d8-4084-b082-8dc00385dc84] Setting newly assigned partitions [testOne-0]
2020-01-08 01:24:31 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=287919aa-b7d8-4084-b082-8dc00385dc84] Resetting offset for partition testOne-0 to offset 0.
2020-01-08 01:28:21 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 60c1270b-142c-47c9-8d75-1b94d926822f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 01:28:21 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 01:28:21 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 01:28:22 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 01:28:22 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=60c1270b-142c-47c9-8d75-1b94d926822f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 01:28:22 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=60c1270b-142c-47c9-8d75-1b94d926822f] Revoking previously assigned partitions []
2020-01-08 01:28:22 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=60c1270b-142c-47c9-8d75-1b94d926822f] (Re-)joining group
2020-01-08 01:28:22 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=60c1270b-142c-47c9-8d75-1b94d926822f] Successfully joined group with generation 1
2020-01-08 01:28:22 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=60c1270b-142c-47c9-8d75-1b94d926822f] Setting newly assigned partitions [testOne-0]
2020-01-08 01:28:22 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=60c1270b-142c-47c9-8d75-1b94d926822f] Resetting offset for partition testOne-0 to offset 0.
2020-01-08 01:32:43 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d43ed724-3b35-4c62-9300-74d4a3eabf2e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 01:32:43 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 01:32:43 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 01:32:44 WARN  NetworkClient:968 - [Consumer clientId=consumer-1, groupId=d43ed724-3b35-4c62-9300-74d4a3eabf2e] Error while fetching metadata with correlation id 2 : {stream19=LEADER_NOT_AVAILABLE}
2020-01-08 01:32:44 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 01:32:44 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=d43ed724-3b35-4c62-9300-74d4a3eabf2e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 01:32:44 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=d43ed724-3b35-4c62-9300-74d4a3eabf2e] Revoking previously assigned partitions []
2020-01-08 01:32:44 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=d43ed724-3b35-4c62-9300-74d4a3eabf2e] (Re-)joining group
2020-01-08 01:32:44 WARN  NetworkClient:968 - [Consumer clientId=consumer-1, groupId=d43ed724-3b35-4c62-9300-74d4a3eabf2e] Error while fetching metadata with correlation id 6 : {stream19=LEADER_NOT_AVAILABLE}
2020-01-08 01:32:44 WARN  NetworkClient:968 - [Consumer clientId=consumer-1, groupId=d43ed724-3b35-4c62-9300-74d4a3eabf2e] Error while fetching metadata with correlation id 7 : {stream19=LEADER_NOT_AVAILABLE}
2020-01-08 01:32:44 WARN  ConsumerCoordinator:427 - [Consumer clientId=consumer-1, groupId=d43ed724-3b35-4c62-9300-74d4a3eabf2e] The following subscribed topics are not assigned to any members: [stream19] 
2020-01-08 01:32:44 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=d43ed724-3b35-4c62-9300-74d4a3eabf2e] Successfully joined group with generation 1
2020-01-08 01:32:44 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=d43ed724-3b35-4c62-9300-74d4a3eabf2e] Setting newly assigned partitions []
2020-01-08 01:32:44 WARN  NetworkClient:968 - [Consumer clientId=consumer-1, groupId=d43ed724-3b35-4c62-9300-74d4a3eabf2e] Error while fetching metadata with correlation id 9 : {stream19=LEADER_NOT_AVAILABLE}
2020-01-08 01:32:44 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=d43ed724-3b35-4c62-9300-74d4a3eabf2e] Revoking previously assigned partitions []
2020-01-08 01:32:44 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=d43ed724-3b35-4c62-9300-74d4a3eabf2e] (Re-)joining group
2020-01-08 01:32:44 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=d43ed724-3b35-4c62-9300-74d4a3eabf2e] Successfully joined group with generation 2
2020-01-08 01:32:44 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=d43ed724-3b35-4c62-9300-74d4a3eabf2e] Setting newly assigned partitions [stream19-0]
2020-01-08 01:32:44 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=d43ed724-3b35-4c62-9300-74d4a3eabf2e] Resetting offset for partition stream19-0 to offset 0.
2020-01-08 02:30:47 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f09b34df-6192-4894-a698-1a3d09ec71bd
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 02:30:47 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 02:30:47 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 02:30:47 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 02:30:47 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=f09b34df-6192-4894-a698-1a3d09ec71bd] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 02:30:47 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=f09b34df-6192-4894-a698-1a3d09ec71bd] Revoking previously assigned partitions []
2020-01-08 02:30:47 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=f09b34df-6192-4894-a698-1a3d09ec71bd] (Re-)joining group
2020-01-08 02:30:48 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=f09b34df-6192-4894-a698-1a3d09ec71bd] Successfully joined group with generation 1
2020-01-08 02:30:48 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=f09b34df-6192-4894-a698-1a3d09ec71bd] Setting newly assigned partitions [stream19-0]
2020-01-08 02:30:48 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=f09b34df-6192-4894-a698-1a3d09ec71bd] Resetting offset for partition stream19-0 to offset 0.
2020-01-08 02:35:18 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0debd5f2-56bb-4480-840f-6ca2eaab44cf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 02:35:18 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 02:35:18 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 02:35:19 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 02:35:19 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=0debd5f2-56bb-4480-840f-6ca2eaab44cf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 02:35:19 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=0debd5f2-56bb-4480-840f-6ca2eaab44cf] Revoking previously assigned partitions []
2020-01-08 02:35:19 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=0debd5f2-56bb-4480-840f-6ca2eaab44cf] (Re-)joining group
2020-01-08 02:35:19 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=0debd5f2-56bb-4480-840f-6ca2eaab44cf] Successfully joined group with generation 1
2020-01-08 02:35:19 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=0debd5f2-56bb-4480-840f-6ca2eaab44cf] Setting newly assigned partitions [test111-0]
2020-01-08 02:35:19 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=0debd5f2-56bb-4480-840f-6ca2eaab44cf] Resetting offset for partition test111-0 to offset 37.
2020-01-08 02:56:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = da13a3dc-5977-47db-9ef2-3d455fe8fb74
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 02:56:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 02:56:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 02:56:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 02:56:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=da13a3dc-5977-47db-9ef2-3d455fe8fb74] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 02:56:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=da13a3dc-5977-47db-9ef2-3d455fe8fb74] Revoking previously assigned partitions []
2020-01-08 02:56:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=da13a3dc-5977-47db-9ef2-3d455fe8fb74] (Re-)joining group
2020-01-08 02:56:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=da13a3dc-5977-47db-9ef2-3d455fe8fb74] Successfully joined group with generation 1
2020-01-08 02:56:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=da13a3dc-5977-47db-9ef2-3d455fe8fb74] Setting newly assigned partitions [test112-0]
2020-01-08 02:56:56 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=da13a3dc-5977-47db-9ef2-3d455fe8fb74] Resetting offset for partition test112-0 to offset 270.
2020-01-08 03:06:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d5c8845c-0e81-4c14-9b39-a84e8008f6f5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:06:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:06:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:06:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:06:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=d5c8845c-0e81-4c14-9b39-a84e8008f6f5] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:06:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=d5c8845c-0e81-4c14-9b39-a84e8008f6f5] Revoking previously assigned partitions []
2020-01-08 03:06:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=d5c8845c-0e81-4c14-9b39-a84e8008f6f5] (Re-)joining group
2020-01-08 03:06:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=d5c8845c-0e81-4c14-9b39-a84e8008f6f5] Successfully joined group with generation 1
2020-01-08 03:06:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=d5c8845c-0e81-4c14-9b39-a84e8008f6f5] Setting newly assigned partitions [stream19-0]
2020-01-08 03:06:56 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=d5c8845c-0e81-4c14-9b39-a84e8008f6f5] Resetting offset for partition stream19-0 to offset 0.
2020-01-08 03:08:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 795bb787-01c5-42fb-8094-8f777b02f03d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:08:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:08:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:08:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:08:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=795bb787-01c5-42fb-8094-8f777b02f03d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:08:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=795bb787-01c5-42fb-8094-8f777b02f03d] Revoking previously assigned partitions []
2020-01-08 03:08:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=795bb787-01c5-42fb-8094-8f777b02f03d] (Re-)joining group
2020-01-08 03:08:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=795bb787-01c5-42fb-8094-8f777b02f03d] Successfully joined group with generation 1
2020-01-08 03:08:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=795bb787-01c5-42fb-8094-8f777b02f03d] Setting newly assigned partitions [stream19-0]
2020-01-08 03:08:09 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=795bb787-01c5-42fb-8094-8f777b02f03d] Resetting offset for partition stream19-0 to offset 0.
2020-01-08 03:09:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b7ac8fa9-7e0e-4be5-9647-d986dd60cdf4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:09:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:09:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:09:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:09:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=b7ac8fa9-7e0e-4be5-9647-d986dd60cdf4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:09:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=b7ac8fa9-7e0e-4be5-9647-d986dd60cdf4] Revoking previously assigned partitions []
2020-01-08 03:09:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=b7ac8fa9-7e0e-4be5-9647-d986dd60cdf4] (Re-)joining group
2020-01-08 03:09:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=b7ac8fa9-7e0e-4be5-9647-d986dd60cdf4] Successfully joined group with generation 1
2020-01-08 03:09:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=b7ac8fa9-7e0e-4be5-9647-d986dd60cdf4] Setting newly assigned partitions [test113-0]
2020-01-08 03:09:58 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=b7ac8fa9-7e0e-4be5-9647-d986dd60cdf4] Resetting offset for partition test113-0 to offset 208.
2020-01-08 03:12:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 76eb4f04-8ea3-499e-aa57-484a3b31ab28
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:12:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:12:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:12:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:12:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=76eb4f04-8ea3-499e-aa57-484a3b31ab28] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:12:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=76eb4f04-8ea3-499e-aa57-484a3b31ab28] Revoking previously assigned partitions []
2020-01-08 03:12:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=76eb4f04-8ea3-499e-aa57-484a3b31ab28] (Re-)joining group
2020-01-08 03:12:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=76eb4f04-8ea3-499e-aa57-484a3b31ab28] Successfully joined group with generation 1
2020-01-08 03:12:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=76eb4f04-8ea3-499e-aa57-484a3b31ab28] Setting newly assigned partitions [test113-0]
2020-01-08 03:12:58 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=76eb4f04-8ea3-499e-aa57-484a3b31ab28] Resetting offset for partition test113-0 to offset 395.
2020-01-08 03:14:47 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 888b7eb4-f6ff-4dde-99f9-4325746db3f8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:47 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:47 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:48 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:48 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=888b7eb4-f6ff-4dde-99f9-4325746db3f8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:48 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=888b7eb4-f6ff-4dde-99f9-4325746db3f8] Revoking previously assigned partitions []
2020-01-08 03:14:48 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=888b7eb4-f6ff-4dde-99f9-4325746db3f8] (Re-)joining group
2020-01-08 03:14:48 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=888b7eb4-f6ff-4dde-99f9-4325746db3f8] Successfully joined group with generation 1
2020-01-08 03:14:48 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=888b7eb4-f6ff-4dde-99f9-4325746db3f8] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:48 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=888b7eb4-f6ff-4dde-99f9-4325746db3f8] Resetting offset for partition test113-0 to offset 854.
2020-01-08 03:14:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 46f90bc9-71f7-4fc3-8df2-768d4d32928e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-2, groupId=46f90bc9-71f7-4fc3-8df2-768d4d32928e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-2, groupId=46f90bc9-71f7-4fc3-8df2-768d4d32928e] Revoking previously assigned partitions []
2020-01-08 03:14:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-2, groupId=46f90bc9-71f7-4fc3-8df2-768d4d32928e] (Re-)joining group
2020-01-08 03:14:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-2, groupId=46f90bc9-71f7-4fc3-8df2-768d4d32928e] Successfully joined group with generation 1
2020-01-08 03:14:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-2, groupId=46f90bc9-71f7-4fc3-8df2-768d4d32928e] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:53 INFO  Fetcher:583 - [Consumer clientId=consumer-2, groupId=46f90bc9-71f7-4fc3-8df2-768d4d32928e] Resetting offset for partition test113-0 to offset 857.
2020-01-08 03:14:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e16bd86a-3b03-4634-ae37-aabfc69308c7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-3, groupId=e16bd86a-3b03-4634-ae37-aabfc69308c7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-3, groupId=e16bd86a-3b03-4634-ae37-aabfc69308c7] Revoking previously assigned partitions []
2020-01-08 03:14:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-3, groupId=e16bd86a-3b03-4634-ae37-aabfc69308c7] (Re-)joining group
2020-01-08 03:14:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-3, groupId=e16bd86a-3b03-4634-ae37-aabfc69308c7] Successfully joined group with generation 1
2020-01-08 03:14:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-3, groupId=e16bd86a-3b03-4634-ae37-aabfc69308c7] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:53 INFO  Fetcher:583 - [Consumer clientId=consumer-3, groupId=e16bd86a-3b03-4634-ae37-aabfc69308c7] Resetting offset for partition test113-0 to offset 859.
2020-01-08 03:14:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fdc0d10c-1823-4685-a92a-556f1166b47f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-4, groupId=fdc0d10c-1823-4685-a92a-556f1166b47f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-4, groupId=fdc0d10c-1823-4685-a92a-556f1166b47f] Revoking previously assigned partitions []
2020-01-08 03:14:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-4, groupId=fdc0d10c-1823-4685-a92a-556f1166b47f] (Re-)joining group
2020-01-08 03:14:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-4, groupId=fdc0d10c-1823-4685-a92a-556f1166b47f] Successfully joined group with generation 1
2020-01-08 03:14:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-4, groupId=fdc0d10c-1823-4685-a92a-556f1166b47f] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:53 INFO  Fetcher:583 - [Consumer clientId=consumer-4, groupId=fdc0d10c-1823-4685-a92a-556f1166b47f] Resetting offset for partition test113-0 to offset 860.
2020-01-08 03:14:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f7cf7e49-ef51-4379-8c6b-0ca306a42521
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:53 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:53 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-5, groupId=f7cf7e49-ef51-4379-8c6b-0ca306a42521] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:53 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-5, groupId=f7cf7e49-ef51-4379-8c6b-0ca306a42521] Revoking previously assigned partitions []
2020-01-08 03:14:53 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-5, groupId=f7cf7e49-ef51-4379-8c6b-0ca306a42521] (Re-)joining group
2020-01-08 03:14:53 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-5, groupId=f7cf7e49-ef51-4379-8c6b-0ca306a42521] Successfully joined group with generation 1
2020-01-08 03:14:53 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-5, groupId=f7cf7e49-ef51-4379-8c6b-0ca306a42521] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:53 INFO  Fetcher:583 - [Consumer clientId=consumer-5, groupId=f7cf7e49-ef51-4379-8c6b-0ca306a42521] Resetting offset for partition test113-0 to offset 862.
2020-01-08 03:14:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b2a8d846-2d56-4d51-b4ef-f191b75a169e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-6, groupId=b2a8d846-2d56-4d51-b4ef-f191b75a169e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-6, groupId=b2a8d846-2d56-4d51-b4ef-f191b75a169e] Revoking previously assigned partitions []
2020-01-08 03:14:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-6, groupId=b2a8d846-2d56-4d51-b4ef-f191b75a169e] (Re-)joining group
2020-01-08 03:14:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-6, groupId=b2a8d846-2d56-4d51-b4ef-f191b75a169e] Successfully joined group with generation 1
2020-01-08 03:14:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-6, groupId=b2a8d846-2d56-4d51-b4ef-f191b75a169e] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:54 INFO  Fetcher:583 - [Consumer clientId=consumer-6, groupId=b2a8d846-2d56-4d51-b4ef-f191b75a169e] Resetting offset for partition test113-0 to offset 864.
2020-01-08 03:14:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8a328939-f278-4990-94f3-971a22a75f03
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-7, groupId=8a328939-f278-4990-94f3-971a22a75f03] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-7, groupId=8a328939-f278-4990-94f3-971a22a75f03] Revoking previously assigned partitions []
2020-01-08 03:14:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-7, groupId=8a328939-f278-4990-94f3-971a22a75f03] (Re-)joining group
2020-01-08 03:14:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-7, groupId=8a328939-f278-4990-94f3-971a22a75f03] Successfully joined group with generation 1
2020-01-08 03:14:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-7, groupId=8a328939-f278-4990-94f3-971a22a75f03] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:54 INFO  Fetcher:583 - [Consumer clientId=consumer-7, groupId=8a328939-f278-4990-94f3-971a22a75f03] Resetting offset for partition test113-0 to offset 866.
2020-01-08 03:14:54 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7be40e60-dbc5-4902-8abc-1409e2a056d2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:54 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:54 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-8, groupId=7be40e60-dbc5-4902-8abc-1409e2a056d2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-8, groupId=7be40e60-dbc5-4902-8abc-1409e2a056d2] Revoking previously assigned partitions []
2020-01-08 03:14:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-8, groupId=7be40e60-dbc5-4902-8abc-1409e2a056d2] (Re-)joining group
2020-01-08 03:14:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-8, groupId=7be40e60-dbc5-4902-8abc-1409e2a056d2] Successfully joined group with generation 1
2020-01-08 03:14:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-8, groupId=7be40e60-dbc5-4902-8abc-1409e2a056d2] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:54 INFO  Fetcher:583 - [Consumer clientId=consumer-8, groupId=7be40e60-dbc5-4902-8abc-1409e2a056d2] Resetting offset for partition test113-0 to offset 868.
2020-01-08 03:14:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e67ba9e0-9b6e-42be-b9b0-3485b9e10118
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-9, groupId=e67ba9e0-9b6e-42be-b9b0-3485b9e10118] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-9, groupId=e67ba9e0-9b6e-42be-b9b0-3485b9e10118] Revoking previously assigned partitions []
2020-01-08 03:14:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-9, groupId=e67ba9e0-9b6e-42be-b9b0-3485b9e10118] (Re-)joining group
2020-01-08 03:14:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-9, groupId=e67ba9e0-9b6e-42be-b9b0-3485b9e10118] Successfully joined group with generation 1
2020-01-08 03:14:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-9, groupId=e67ba9e0-9b6e-42be-b9b0-3485b9e10118] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:55 INFO  Fetcher:583 - [Consumer clientId=consumer-9, groupId=e67ba9e0-9b6e-42be-b9b0-3485b9e10118] Resetting offset for partition test113-0 to offset 869.
2020-01-08 03:14:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e4059d8e-f119-49ad-b5af-f26339eaa951
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-10, groupId=e4059d8e-f119-49ad-b5af-f26339eaa951] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-10, groupId=e4059d8e-f119-49ad-b5af-f26339eaa951] Revoking previously assigned partitions []
2020-01-08 03:14:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-10, groupId=e4059d8e-f119-49ad-b5af-f26339eaa951] (Re-)joining group
2020-01-08 03:14:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-10, groupId=e4059d8e-f119-49ad-b5af-f26339eaa951] Successfully joined group with generation 1
2020-01-08 03:14:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-10, groupId=e4059d8e-f119-49ad-b5af-f26339eaa951] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:55 INFO  Fetcher:583 - [Consumer clientId=consumer-10, groupId=e4059d8e-f119-49ad-b5af-f26339eaa951] Resetting offset for partition test113-0 to offset 871.
2020-01-08 03:14:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4470b74d-01c4-4aec-9c68-efbd9b43157d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-11, groupId=4470b74d-01c4-4aec-9c68-efbd9b43157d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-11, groupId=4470b74d-01c4-4aec-9c68-efbd9b43157d] Revoking previously assigned partitions []
2020-01-08 03:14:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-11, groupId=4470b74d-01c4-4aec-9c68-efbd9b43157d] (Re-)joining group
2020-01-08 03:14:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-11, groupId=4470b74d-01c4-4aec-9c68-efbd9b43157d] Successfully joined group with generation 1
2020-01-08 03:14:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-11, groupId=4470b74d-01c4-4aec-9c68-efbd9b43157d] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:55 INFO  Fetcher:583 - [Consumer clientId=consumer-11, groupId=4470b74d-01c4-4aec-9c68-efbd9b43157d] Resetting offset for partition test113-0 to offset 872.
2020-01-08 03:14:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0f32c323-39e9-41f7-b3fa-579f7ae09453
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-12, groupId=0f32c323-39e9-41f7-b3fa-579f7ae09453] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-12, groupId=0f32c323-39e9-41f7-b3fa-579f7ae09453] Revoking previously assigned partitions []
2020-01-08 03:14:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-12, groupId=0f32c323-39e9-41f7-b3fa-579f7ae09453] (Re-)joining group
2020-01-08 03:14:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-12, groupId=0f32c323-39e9-41f7-b3fa-579f7ae09453] Successfully joined group with generation 1
2020-01-08 03:14:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-12, groupId=0f32c323-39e9-41f7-b3fa-579f7ae09453] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:55 INFO  Fetcher:583 - [Consumer clientId=consumer-12, groupId=0f32c323-39e9-41f7-b3fa-579f7ae09453] Resetting offset for partition test113-0 to offset 873.
2020-01-08 03:14:55 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5fd34ced-f019-4768-8d93-a8a94bda1261
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:55 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:55 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:55 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:55 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-13, groupId=5fd34ced-f019-4768-8d93-a8a94bda1261] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:55 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-13, groupId=5fd34ced-f019-4768-8d93-a8a94bda1261] Revoking previously assigned partitions []
2020-01-08 03:14:55 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-13, groupId=5fd34ced-f019-4768-8d93-a8a94bda1261] (Re-)joining group
2020-01-08 03:14:55 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-13, groupId=5fd34ced-f019-4768-8d93-a8a94bda1261] Successfully joined group with generation 1
2020-01-08 03:14:55 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-13, groupId=5fd34ced-f019-4768-8d93-a8a94bda1261] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:55 INFO  Fetcher:583 - [Consumer clientId=consumer-13, groupId=5fd34ced-f019-4768-8d93-a8a94bda1261] Resetting offset for partition test113-0 to offset 874.
2020-01-08 03:14:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d5a201a7-cdaf-48ba-b922-d9470f9905d8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-14, groupId=d5a201a7-cdaf-48ba-b922-d9470f9905d8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-14, groupId=d5a201a7-cdaf-48ba-b922-d9470f9905d8] Revoking previously assigned partitions []
2020-01-08 03:14:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-14, groupId=d5a201a7-cdaf-48ba-b922-d9470f9905d8] (Re-)joining group
2020-01-08 03:14:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-14, groupId=d5a201a7-cdaf-48ba-b922-d9470f9905d8] Successfully joined group with generation 1
2020-01-08 03:14:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-14, groupId=d5a201a7-cdaf-48ba-b922-d9470f9905d8] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:56 INFO  Fetcher:583 - [Consumer clientId=consumer-14, groupId=d5a201a7-cdaf-48ba-b922-d9470f9905d8] Resetting offset for partition test113-0 to offset 875.
2020-01-08 03:14:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6ebecd29-0070-458f-a279-5bc0c84b0b07
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-15, groupId=6ebecd29-0070-458f-a279-5bc0c84b0b07] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-15, groupId=6ebecd29-0070-458f-a279-5bc0c84b0b07] Revoking previously assigned partitions []
2020-01-08 03:14:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-15, groupId=6ebecd29-0070-458f-a279-5bc0c84b0b07] (Re-)joining group
2020-01-08 03:14:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-15, groupId=6ebecd29-0070-458f-a279-5bc0c84b0b07] Successfully joined group with generation 1
2020-01-08 03:14:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-15, groupId=6ebecd29-0070-458f-a279-5bc0c84b0b07] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:56 INFO  Fetcher:583 - [Consumer clientId=consumer-15, groupId=6ebecd29-0070-458f-a279-5bc0c84b0b07] Resetting offset for partition test113-0 to offset 876.
2020-01-08 03:14:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 66e934be-05bc-4724-879c-7a5993b2e7a1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-16, groupId=66e934be-05bc-4724-879c-7a5993b2e7a1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-16, groupId=66e934be-05bc-4724-879c-7a5993b2e7a1] Revoking previously assigned partitions []
2020-01-08 03:14:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-16, groupId=66e934be-05bc-4724-879c-7a5993b2e7a1] (Re-)joining group
2020-01-08 03:14:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-16, groupId=66e934be-05bc-4724-879c-7a5993b2e7a1] Successfully joined group with generation 1
2020-01-08 03:14:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-16, groupId=66e934be-05bc-4724-879c-7a5993b2e7a1] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:56 INFO  Fetcher:583 - [Consumer clientId=consumer-16, groupId=66e934be-05bc-4724-879c-7a5993b2e7a1] Resetting offset for partition test113-0 to offset 877.
2020-01-08 03:14:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ffaa1950-f3c7-40d6-8dba-10ac19bc7297
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-17, groupId=ffaa1950-f3c7-40d6-8dba-10ac19bc7297] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-17, groupId=ffaa1950-f3c7-40d6-8dba-10ac19bc7297] Revoking previously assigned partitions []
2020-01-08 03:14:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-17, groupId=ffaa1950-f3c7-40d6-8dba-10ac19bc7297] (Re-)joining group
2020-01-08 03:14:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-17, groupId=ffaa1950-f3c7-40d6-8dba-10ac19bc7297] Successfully joined group with generation 1
2020-01-08 03:14:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-17, groupId=ffaa1950-f3c7-40d6-8dba-10ac19bc7297] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:56 INFO  Fetcher:583 - [Consumer clientId=consumer-17, groupId=ffaa1950-f3c7-40d6-8dba-10ac19bc7297] Resetting offset for partition test113-0 to offset 878.
2020-01-08 03:14:56 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1ce0f288-d8e0-4a4e-a329-7515947193e3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:56 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:56 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:56 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:56 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-18, groupId=1ce0f288-d8e0-4a4e-a329-7515947193e3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:56 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-18, groupId=1ce0f288-d8e0-4a4e-a329-7515947193e3] Revoking previously assigned partitions []
2020-01-08 03:14:56 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-18, groupId=1ce0f288-d8e0-4a4e-a329-7515947193e3] (Re-)joining group
2020-01-08 03:14:56 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-18, groupId=1ce0f288-d8e0-4a4e-a329-7515947193e3] Successfully joined group with generation 1
2020-01-08 03:14:56 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-18, groupId=1ce0f288-d8e0-4a4e-a329-7515947193e3] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:56 INFO  Fetcher:583 - [Consumer clientId=consumer-18, groupId=1ce0f288-d8e0-4a4e-a329-7515947193e3] Resetting offset for partition test113-0 to offset 879.
2020-01-08 03:14:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = eb2d2e76-f372-4e0d-8139-ffb101f73e0f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-19, groupId=eb2d2e76-f372-4e0d-8139-ffb101f73e0f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-19, groupId=eb2d2e76-f372-4e0d-8139-ffb101f73e0f] Revoking previously assigned partitions []
2020-01-08 03:14:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-19, groupId=eb2d2e76-f372-4e0d-8139-ffb101f73e0f] (Re-)joining group
2020-01-08 03:14:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-19, groupId=eb2d2e76-f372-4e0d-8139-ffb101f73e0f] Successfully joined group with generation 1
2020-01-08 03:14:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-19, groupId=eb2d2e76-f372-4e0d-8139-ffb101f73e0f] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:57 INFO  Fetcher:583 - [Consumer clientId=consumer-19, groupId=eb2d2e76-f372-4e0d-8139-ffb101f73e0f] Resetting offset for partition test113-0 to offset 880.
2020-01-08 03:14:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0eaa9f18-a8ee-4dc9-b3c1-ef4968a606c0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-20, groupId=0eaa9f18-a8ee-4dc9-b3c1-ef4968a606c0] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-20, groupId=0eaa9f18-a8ee-4dc9-b3c1-ef4968a606c0] Revoking previously assigned partitions []
2020-01-08 03:14:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-20, groupId=0eaa9f18-a8ee-4dc9-b3c1-ef4968a606c0] (Re-)joining group
2020-01-08 03:14:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-20, groupId=0eaa9f18-a8ee-4dc9-b3c1-ef4968a606c0] Successfully joined group with generation 1
2020-01-08 03:14:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-20, groupId=0eaa9f18-a8ee-4dc9-b3c1-ef4968a606c0] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:57 INFO  Fetcher:583 - [Consumer clientId=consumer-20, groupId=0eaa9f18-a8ee-4dc9-b3c1-ef4968a606c0] Resetting offset for partition test113-0 to offset 881.
2020-01-08 03:14:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 93f95dfa-7cc2-4465-8c50-bbf1f013e2b3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-21, groupId=93f95dfa-7cc2-4465-8c50-bbf1f013e2b3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-21, groupId=93f95dfa-7cc2-4465-8c50-bbf1f013e2b3] Revoking previously assigned partitions []
2020-01-08 03:14:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-21, groupId=93f95dfa-7cc2-4465-8c50-bbf1f013e2b3] (Re-)joining group
2020-01-08 03:14:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-21, groupId=93f95dfa-7cc2-4465-8c50-bbf1f013e2b3] Successfully joined group with generation 1
2020-01-08 03:14:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-21, groupId=93f95dfa-7cc2-4465-8c50-bbf1f013e2b3] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:57 INFO  Fetcher:583 - [Consumer clientId=consumer-21, groupId=93f95dfa-7cc2-4465-8c50-bbf1f013e2b3] Resetting offset for partition test113-0 to offset 882.
2020-01-08 03:14:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8010fcdb-91af-4f8f-9eaa-c6a76caadbf2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-22, groupId=8010fcdb-91af-4f8f-9eaa-c6a76caadbf2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-22, groupId=8010fcdb-91af-4f8f-9eaa-c6a76caadbf2] Revoking previously assigned partitions []
2020-01-08 03:14:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-22, groupId=8010fcdb-91af-4f8f-9eaa-c6a76caadbf2] (Re-)joining group
2020-01-08 03:14:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-22, groupId=8010fcdb-91af-4f8f-9eaa-c6a76caadbf2] Successfully joined group with generation 1
2020-01-08 03:14:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-22, groupId=8010fcdb-91af-4f8f-9eaa-c6a76caadbf2] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:57 INFO  Fetcher:583 - [Consumer clientId=consumer-22, groupId=8010fcdb-91af-4f8f-9eaa-c6a76caadbf2] Resetting offset for partition test113-0 to offset 883.
2020-01-08 03:14:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 160a56a7-6861-4947-ba90-a69e4ec7b862
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-23, groupId=160a56a7-6861-4947-ba90-a69e4ec7b862] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-23, groupId=160a56a7-6861-4947-ba90-a69e4ec7b862] Revoking previously assigned partitions []
2020-01-08 03:14:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-23, groupId=160a56a7-6861-4947-ba90-a69e4ec7b862] (Re-)joining group
2020-01-08 03:14:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-23, groupId=160a56a7-6861-4947-ba90-a69e4ec7b862] Successfully joined group with generation 1
2020-01-08 03:14:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-23, groupId=160a56a7-6861-4947-ba90-a69e4ec7b862] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:57 INFO  Fetcher:583 - [Consumer clientId=consumer-23, groupId=160a56a7-6861-4947-ba90-a69e4ec7b862] Resetting offset for partition test113-0 to offset 884.
2020-01-08 03:14:57 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a871b715-24a5-4d9a-8f12-1bd56b707c0d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:57 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:57 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:57 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:57 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-24, groupId=a871b715-24a5-4d9a-8f12-1bd56b707c0d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:57 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-24, groupId=a871b715-24a5-4d9a-8f12-1bd56b707c0d] Revoking previously assigned partitions []
2020-01-08 03:14:57 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-24, groupId=a871b715-24a5-4d9a-8f12-1bd56b707c0d] (Re-)joining group
2020-01-08 03:14:57 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-24, groupId=a871b715-24a5-4d9a-8f12-1bd56b707c0d] Successfully joined group with generation 1
2020-01-08 03:14:57 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-24, groupId=a871b715-24a5-4d9a-8f12-1bd56b707c0d] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:57 INFO  Fetcher:583 - [Consumer clientId=consumer-24, groupId=a871b715-24a5-4d9a-8f12-1bd56b707c0d] Resetting offset for partition test113-0 to offset 885.
2020-01-08 03:14:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3337e899-a238-4b98-8bfb-21899386d24d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-25, groupId=3337e899-a238-4b98-8bfb-21899386d24d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-25, groupId=3337e899-a238-4b98-8bfb-21899386d24d] Revoking previously assigned partitions []
2020-01-08 03:14:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-25, groupId=3337e899-a238-4b98-8bfb-21899386d24d] (Re-)joining group
2020-01-08 03:14:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-25, groupId=3337e899-a238-4b98-8bfb-21899386d24d] Successfully joined group with generation 1
2020-01-08 03:14:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-25, groupId=3337e899-a238-4b98-8bfb-21899386d24d] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:58 INFO  Fetcher:583 - [Consumer clientId=consumer-25, groupId=3337e899-a238-4b98-8bfb-21899386d24d] Resetting offset for partition test113-0 to offset 886.
2020-01-08 03:14:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d390241a-4779-4756-8e1e-25b765b8c45a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-26, groupId=d390241a-4779-4756-8e1e-25b765b8c45a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-26, groupId=d390241a-4779-4756-8e1e-25b765b8c45a] Revoking previously assigned partitions []
2020-01-08 03:14:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-26, groupId=d390241a-4779-4756-8e1e-25b765b8c45a] (Re-)joining group
2020-01-08 03:14:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-26, groupId=d390241a-4779-4756-8e1e-25b765b8c45a] Successfully joined group with generation 1
2020-01-08 03:14:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-26, groupId=d390241a-4779-4756-8e1e-25b765b8c45a] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:58 INFO  Fetcher:583 - [Consumer clientId=consumer-26, groupId=d390241a-4779-4756-8e1e-25b765b8c45a] Resetting offset for partition test113-0 to offset 887.
2020-01-08 03:14:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4d663051-bdcc-49aa-9281-00482fb1c7fa
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-27, groupId=4d663051-bdcc-49aa-9281-00482fb1c7fa] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-27, groupId=4d663051-bdcc-49aa-9281-00482fb1c7fa] Revoking previously assigned partitions []
2020-01-08 03:14:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-27, groupId=4d663051-bdcc-49aa-9281-00482fb1c7fa] (Re-)joining group
2020-01-08 03:14:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-27, groupId=4d663051-bdcc-49aa-9281-00482fb1c7fa] Successfully joined group with generation 1
2020-01-08 03:14:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-27, groupId=4d663051-bdcc-49aa-9281-00482fb1c7fa] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:58 INFO  Fetcher:583 - [Consumer clientId=consumer-27, groupId=4d663051-bdcc-49aa-9281-00482fb1c7fa] Resetting offset for partition test113-0 to offset 889.
2020-01-08 03:14:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0574eab0-83f0-408d-8ad0-42927c684a9e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-28, groupId=0574eab0-83f0-408d-8ad0-42927c684a9e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-28, groupId=0574eab0-83f0-408d-8ad0-42927c684a9e] Revoking previously assigned partitions []
2020-01-08 03:14:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-28, groupId=0574eab0-83f0-408d-8ad0-42927c684a9e] (Re-)joining group
2020-01-08 03:14:58 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-28, groupId=0574eab0-83f0-408d-8ad0-42927c684a9e] Successfully joined group with generation 1
2020-01-08 03:14:58 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-28, groupId=0574eab0-83f0-408d-8ad0-42927c684a9e] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:58 INFO  Fetcher:583 - [Consumer clientId=consumer-28, groupId=0574eab0-83f0-408d-8ad0-42927c684a9e] Resetting offset for partition test113-0 to offset 890.
2020-01-08 03:14:58 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8118180a-2b54-4caf-b228-9a2a34d209e3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:58 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:58 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:58 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:58 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-29, groupId=8118180a-2b54-4caf-b228-9a2a34d209e3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:58 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-29, groupId=8118180a-2b54-4caf-b228-9a2a34d209e3] Revoking previously assigned partitions []
2020-01-08 03:14:58 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-29, groupId=8118180a-2b54-4caf-b228-9a2a34d209e3] (Re-)joining group
2020-01-08 03:14:59 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-29, groupId=8118180a-2b54-4caf-b228-9a2a34d209e3] Successfully joined group with generation 1
2020-01-08 03:14:59 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-29, groupId=8118180a-2b54-4caf-b228-9a2a34d209e3] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:59 INFO  Fetcher:583 - [Consumer clientId=consumer-29, groupId=8118180a-2b54-4caf-b228-9a2a34d209e3] Resetting offset for partition test113-0 to offset 892.
2020-01-08 03:14:59 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f0f601c7-577f-4e16-9ff2-902b2bb5879b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:59 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:59 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:59 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:59 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-30, groupId=f0f601c7-577f-4e16-9ff2-902b2bb5879b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:59 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-30, groupId=f0f601c7-577f-4e16-9ff2-902b2bb5879b] Revoking previously assigned partitions []
2020-01-08 03:14:59 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-30, groupId=f0f601c7-577f-4e16-9ff2-902b2bb5879b] (Re-)joining group
2020-01-08 03:14:59 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-30, groupId=f0f601c7-577f-4e16-9ff2-902b2bb5879b] Successfully joined group with generation 1
2020-01-08 03:14:59 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-30, groupId=f0f601c7-577f-4e16-9ff2-902b2bb5879b] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:59 INFO  Fetcher:583 - [Consumer clientId=consumer-30, groupId=f0f601c7-577f-4e16-9ff2-902b2bb5879b] Resetting offset for partition test113-0 to offset 893.
2020-01-08 03:14:59 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2fe08578-254a-4875-9e30-33f55811879d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:59 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:59 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:59 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:59 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-31, groupId=2fe08578-254a-4875-9e30-33f55811879d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:59 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-31, groupId=2fe08578-254a-4875-9e30-33f55811879d] Revoking previously assigned partitions []
2020-01-08 03:14:59 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-31, groupId=2fe08578-254a-4875-9e30-33f55811879d] (Re-)joining group
2020-01-08 03:14:59 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-31, groupId=2fe08578-254a-4875-9e30-33f55811879d] Successfully joined group with generation 1
2020-01-08 03:14:59 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-31, groupId=2fe08578-254a-4875-9e30-33f55811879d] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:59 INFO  Fetcher:583 - [Consumer clientId=consumer-31, groupId=2fe08578-254a-4875-9e30-33f55811879d] Resetting offset for partition test113-0 to offset 894.
2020-01-08 03:14:59 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8ff2e4b2-a85e-4ce1-97f6-37b3cbb8e5ae
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:59 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:59 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:59 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:59 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-32, groupId=8ff2e4b2-a85e-4ce1-97f6-37b3cbb8e5ae] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:59 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-32, groupId=8ff2e4b2-a85e-4ce1-97f6-37b3cbb8e5ae] Revoking previously assigned partitions []
2020-01-08 03:14:59 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-32, groupId=8ff2e4b2-a85e-4ce1-97f6-37b3cbb8e5ae] (Re-)joining group
2020-01-08 03:14:59 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-32, groupId=8ff2e4b2-a85e-4ce1-97f6-37b3cbb8e5ae] Successfully joined group with generation 1
2020-01-08 03:14:59 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-32, groupId=8ff2e4b2-a85e-4ce1-97f6-37b3cbb8e5ae] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:59 INFO  Fetcher:583 - [Consumer clientId=consumer-32, groupId=8ff2e4b2-a85e-4ce1-97f6-37b3cbb8e5ae] Resetting offset for partition test113-0 to offset 895.
2020-01-08 03:14:59 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6a67dadb-7e41-4d04-9922-973841bfcef3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:59 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:59 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:59 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:59 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-33, groupId=6a67dadb-7e41-4d04-9922-973841bfcef3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:59 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-33, groupId=6a67dadb-7e41-4d04-9922-973841bfcef3] Revoking previously assigned partitions []
2020-01-08 03:14:59 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-33, groupId=6a67dadb-7e41-4d04-9922-973841bfcef3] (Re-)joining group
2020-01-08 03:14:59 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-33, groupId=6a67dadb-7e41-4d04-9922-973841bfcef3] Successfully joined group with generation 1
2020-01-08 03:14:59 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-33, groupId=6a67dadb-7e41-4d04-9922-973841bfcef3] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:59 INFO  Fetcher:583 - [Consumer clientId=consumer-33, groupId=6a67dadb-7e41-4d04-9922-973841bfcef3] Resetting offset for partition test113-0 to offset 897.
2020-01-08 03:14:59 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2afa4c2b-425e-4495-a9a0-315311b547db
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:14:59 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:14:59 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:14:59 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:14:59 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-34, groupId=2afa4c2b-425e-4495-a9a0-315311b547db] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:14:59 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-34, groupId=2afa4c2b-425e-4495-a9a0-315311b547db] Revoking previously assigned partitions []
2020-01-08 03:14:59 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-34, groupId=2afa4c2b-425e-4495-a9a0-315311b547db] (Re-)joining group
2020-01-08 03:14:59 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-34, groupId=2afa4c2b-425e-4495-a9a0-315311b547db] Successfully joined group with generation 1
2020-01-08 03:14:59 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-34, groupId=2afa4c2b-425e-4495-a9a0-315311b547db] Setting newly assigned partitions [test113-0]
2020-01-08 03:14:59 INFO  Fetcher:583 - [Consumer clientId=consumer-34, groupId=2afa4c2b-425e-4495-a9a0-315311b547db] Resetting offset for partition test113-0 to offset 898.
2020-01-08 03:15:00 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2014a98b-a573-4569-a687-41dd790cfa93
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:00 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:00 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:00 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:00 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-35, groupId=2014a98b-a573-4569-a687-41dd790cfa93] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:00 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-35, groupId=2014a98b-a573-4569-a687-41dd790cfa93] Revoking previously assigned partitions []
2020-01-08 03:15:00 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-35, groupId=2014a98b-a573-4569-a687-41dd790cfa93] (Re-)joining group
2020-01-08 03:15:00 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-35, groupId=2014a98b-a573-4569-a687-41dd790cfa93] Successfully joined group with generation 1
2020-01-08 03:15:00 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-35, groupId=2014a98b-a573-4569-a687-41dd790cfa93] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:00 INFO  Fetcher:583 - [Consumer clientId=consumer-35, groupId=2014a98b-a573-4569-a687-41dd790cfa93] Resetting offset for partition test113-0 to offset 899.
2020-01-08 03:15:00 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 70adefa4-349f-4b75-bbb5-014e21f98ae6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:00 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:00 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:00 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:00 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-36, groupId=70adefa4-349f-4b75-bbb5-014e21f98ae6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:00 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-36, groupId=70adefa4-349f-4b75-bbb5-014e21f98ae6] Revoking previously assigned partitions []
2020-01-08 03:15:00 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-36, groupId=70adefa4-349f-4b75-bbb5-014e21f98ae6] (Re-)joining group
2020-01-08 03:15:00 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-36, groupId=70adefa4-349f-4b75-bbb5-014e21f98ae6] Successfully joined group with generation 1
2020-01-08 03:15:00 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-36, groupId=70adefa4-349f-4b75-bbb5-014e21f98ae6] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:00 INFO  Fetcher:583 - [Consumer clientId=consumer-36, groupId=70adefa4-349f-4b75-bbb5-014e21f98ae6] Resetting offset for partition test113-0 to offset 900.
2020-01-08 03:15:00 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e601778a-65a6-400c-aa8b-70020e886ede
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:00 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:00 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:00 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:00 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-37, groupId=e601778a-65a6-400c-aa8b-70020e886ede] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:00 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-37, groupId=e601778a-65a6-400c-aa8b-70020e886ede] Revoking previously assigned partitions []
2020-01-08 03:15:00 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-37, groupId=e601778a-65a6-400c-aa8b-70020e886ede] (Re-)joining group
2020-01-08 03:15:00 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-37, groupId=e601778a-65a6-400c-aa8b-70020e886ede] Successfully joined group with generation 1
2020-01-08 03:15:00 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-37, groupId=e601778a-65a6-400c-aa8b-70020e886ede] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:00 INFO  Fetcher:583 - [Consumer clientId=consumer-37, groupId=e601778a-65a6-400c-aa8b-70020e886ede] Resetting offset for partition test113-0 to offset 901.
2020-01-08 03:15:00 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 72f31e7f-7069-4eff-af2d-055d15276dea
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:00 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:00 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:00 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:00 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-38, groupId=72f31e7f-7069-4eff-af2d-055d15276dea] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:00 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-38, groupId=72f31e7f-7069-4eff-af2d-055d15276dea] Revoking previously assigned partitions []
2020-01-08 03:15:00 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-38, groupId=72f31e7f-7069-4eff-af2d-055d15276dea] (Re-)joining group
2020-01-08 03:15:00 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-38, groupId=72f31e7f-7069-4eff-af2d-055d15276dea] Successfully joined group with generation 1
2020-01-08 03:15:00 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-38, groupId=72f31e7f-7069-4eff-af2d-055d15276dea] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:00 INFO  Fetcher:583 - [Consumer clientId=consumer-38, groupId=72f31e7f-7069-4eff-af2d-055d15276dea] Resetting offset for partition test113-0 to offset 902.
2020-01-08 03:15:00 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = eb8ca974-bcfb-4fec-a1a2-78e24eba08a9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:00 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:00 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:00 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:00 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-39, groupId=eb8ca974-bcfb-4fec-a1a2-78e24eba08a9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:00 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-39, groupId=eb8ca974-bcfb-4fec-a1a2-78e24eba08a9] Revoking previously assigned partitions []
2020-01-08 03:15:00 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-39, groupId=eb8ca974-bcfb-4fec-a1a2-78e24eba08a9] (Re-)joining group
2020-01-08 03:15:00 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-39, groupId=eb8ca974-bcfb-4fec-a1a2-78e24eba08a9] Successfully joined group with generation 1
2020-01-08 03:15:00 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-39, groupId=eb8ca974-bcfb-4fec-a1a2-78e24eba08a9] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:00 INFO  Fetcher:583 - [Consumer clientId=consumer-39, groupId=eb8ca974-bcfb-4fec-a1a2-78e24eba08a9] Resetting offset for partition test113-0 to offset 903.
2020-01-08 03:15:00 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d1a07f91-91f7-4e2a-a9a5-1bc8d5eda05a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:00 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:00 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:00 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:00 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-40, groupId=d1a07f91-91f7-4e2a-a9a5-1bc8d5eda05a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:00 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-40, groupId=d1a07f91-91f7-4e2a-a9a5-1bc8d5eda05a] Revoking previously assigned partitions []
2020-01-08 03:15:00 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-40, groupId=d1a07f91-91f7-4e2a-a9a5-1bc8d5eda05a] (Re-)joining group
2020-01-08 03:15:00 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-40, groupId=d1a07f91-91f7-4e2a-a9a5-1bc8d5eda05a] Successfully joined group with generation 1
2020-01-08 03:15:00 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-40, groupId=d1a07f91-91f7-4e2a-a9a5-1bc8d5eda05a] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:00 INFO  Fetcher:583 - [Consumer clientId=consumer-40, groupId=d1a07f91-91f7-4e2a-a9a5-1bc8d5eda05a] Resetting offset for partition test113-0 to offset 905.
2020-01-08 03:15:00 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 236d6a73-51d3-4b6e-bf44-a68a99ea871f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:00 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:00 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:00 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:00 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-41, groupId=236d6a73-51d3-4b6e-bf44-a68a99ea871f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:00 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-41, groupId=236d6a73-51d3-4b6e-bf44-a68a99ea871f] Revoking previously assigned partitions []
2020-01-08 03:15:00 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-41, groupId=236d6a73-51d3-4b6e-bf44-a68a99ea871f] (Re-)joining group
2020-01-08 03:15:01 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-41, groupId=236d6a73-51d3-4b6e-bf44-a68a99ea871f] Successfully joined group with generation 1
2020-01-08 03:15:01 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-41, groupId=236d6a73-51d3-4b6e-bf44-a68a99ea871f] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:01 INFO  Fetcher:583 - [Consumer clientId=consumer-41, groupId=236d6a73-51d3-4b6e-bf44-a68a99ea871f] Resetting offset for partition test113-0 to offset 907.
2020-01-08 03:15:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = be71b764-f9cd-4f57-8cc6-cc16d3cd8b62
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:01 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:01 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-42, groupId=be71b764-f9cd-4f57-8cc6-cc16d3cd8b62] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:01 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-42, groupId=be71b764-f9cd-4f57-8cc6-cc16d3cd8b62] Revoking previously assigned partitions []
2020-01-08 03:15:01 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-42, groupId=be71b764-f9cd-4f57-8cc6-cc16d3cd8b62] (Re-)joining group
2020-01-08 03:15:01 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-42, groupId=be71b764-f9cd-4f57-8cc6-cc16d3cd8b62] Successfully joined group with generation 1
2020-01-08 03:15:01 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-42, groupId=be71b764-f9cd-4f57-8cc6-cc16d3cd8b62] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:01 INFO  Fetcher:583 - [Consumer clientId=consumer-42, groupId=be71b764-f9cd-4f57-8cc6-cc16d3cd8b62] Resetting offset for partition test113-0 to offset 908.
2020-01-08 03:15:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3d63e47e-6b56-465f-a7d8-18a376f39a7b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:01 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:01 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-43, groupId=3d63e47e-6b56-465f-a7d8-18a376f39a7b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:01 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-43, groupId=3d63e47e-6b56-465f-a7d8-18a376f39a7b] Revoking previously assigned partitions []
2020-01-08 03:15:01 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-43, groupId=3d63e47e-6b56-465f-a7d8-18a376f39a7b] (Re-)joining group
2020-01-08 03:15:01 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-43, groupId=3d63e47e-6b56-465f-a7d8-18a376f39a7b] Successfully joined group with generation 1
2020-01-08 03:15:01 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-43, groupId=3d63e47e-6b56-465f-a7d8-18a376f39a7b] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:01 INFO  Fetcher:583 - [Consumer clientId=consumer-43, groupId=3d63e47e-6b56-465f-a7d8-18a376f39a7b] Resetting offset for partition test113-0 to offset 910.
2020-01-08 03:15:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1ee3a335-a201-4e5b-aa4e-d941687cb0f4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:01 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:01 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-44, groupId=1ee3a335-a201-4e5b-aa4e-d941687cb0f4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:01 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-44, groupId=1ee3a335-a201-4e5b-aa4e-d941687cb0f4] Revoking previously assigned partitions []
2020-01-08 03:15:01 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-44, groupId=1ee3a335-a201-4e5b-aa4e-d941687cb0f4] (Re-)joining group
2020-01-08 03:15:01 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-44, groupId=1ee3a335-a201-4e5b-aa4e-d941687cb0f4] Successfully joined group with generation 1
2020-01-08 03:15:01 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-44, groupId=1ee3a335-a201-4e5b-aa4e-d941687cb0f4] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:01 INFO  Fetcher:583 - [Consumer clientId=consumer-44, groupId=1ee3a335-a201-4e5b-aa4e-d941687cb0f4] Resetting offset for partition test113-0 to offset 911.
2020-01-08 03:15:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0f8b2fcd-6e2b-4917-94c6-22af6ee90d92
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:01 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:01 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-45, groupId=0f8b2fcd-6e2b-4917-94c6-22af6ee90d92] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:01 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-45, groupId=0f8b2fcd-6e2b-4917-94c6-22af6ee90d92] Revoking previously assigned partitions []
2020-01-08 03:15:01 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-45, groupId=0f8b2fcd-6e2b-4917-94c6-22af6ee90d92] (Re-)joining group
2020-01-08 03:15:01 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-45, groupId=0f8b2fcd-6e2b-4917-94c6-22af6ee90d92] Successfully joined group with generation 1
2020-01-08 03:15:01 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-45, groupId=0f8b2fcd-6e2b-4917-94c6-22af6ee90d92] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:01 INFO  Fetcher:583 - [Consumer clientId=consumer-45, groupId=0f8b2fcd-6e2b-4917-94c6-22af6ee90d92] Resetting offset for partition test113-0 to offset 912.
2020-01-08 03:15:01 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5809a3de-8856-4d9f-ba71-8b50ad397d4e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:01 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:01 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:01 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:01 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-46, groupId=5809a3de-8856-4d9f-ba71-8b50ad397d4e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:01 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-46, groupId=5809a3de-8856-4d9f-ba71-8b50ad397d4e] Revoking previously assigned partitions []
2020-01-08 03:15:01 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-46, groupId=5809a3de-8856-4d9f-ba71-8b50ad397d4e] (Re-)joining group
2020-01-08 03:15:01 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-46, groupId=5809a3de-8856-4d9f-ba71-8b50ad397d4e] Successfully joined group with generation 1
2020-01-08 03:15:01 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-46, groupId=5809a3de-8856-4d9f-ba71-8b50ad397d4e] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:01 INFO  Fetcher:583 - [Consumer clientId=consumer-46, groupId=5809a3de-8856-4d9f-ba71-8b50ad397d4e] Resetting offset for partition test113-0 to offset 913.
2020-01-08 03:15:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3b60a6c8-ddc0-42ff-8983-6c241ea4ca30
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-47, groupId=3b60a6c8-ddc0-42ff-8983-6c241ea4ca30] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-47, groupId=3b60a6c8-ddc0-42ff-8983-6c241ea4ca30] Revoking previously assigned partitions []
2020-01-08 03:15:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-47, groupId=3b60a6c8-ddc0-42ff-8983-6c241ea4ca30] (Re-)joining group
2020-01-08 03:15:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-47, groupId=3b60a6c8-ddc0-42ff-8983-6c241ea4ca30] Successfully joined group with generation 1
2020-01-08 03:15:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-47, groupId=3b60a6c8-ddc0-42ff-8983-6c241ea4ca30] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:02 INFO  Fetcher:583 - [Consumer clientId=consumer-47, groupId=3b60a6c8-ddc0-42ff-8983-6c241ea4ca30] Resetting offset for partition test113-0 to offset 914.
2020-01-08 03:15:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e1fdb6cc-fdba-49f9-b0c1-4e67e3591894
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-48, groupId=e1fdb6cc-fdba-49f9-b0c1-4e67e3591894] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-48, groupId=e1fdb6cc-fdba-49f9-b0c1-4e67e3591894] Revoking previously assigned partitions []
2020-01-08 03:15:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-48, groupId=e1fdb6cc-fdba-49f9-b0c1-4e67e3591894] (Re-)joining group
2020-01-08 03:15:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-48, groupId=e1fdb6cc-fdba-49f9-b0c1-4e67e3591894] Successfully joined group with generation 1
2020-01-08 03:15:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-48, groupId=e1fdb6cc-fdba-49f9-b0c1-4e67e3591894] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:02 INFO  Fetcher:583 - [Consumer clientId=consumer-48, groupId=e1fdb6cc-fdba-49f9-b0c1-4e67e3591894] Resetting offset for partition test113-0 to offset 916.
2020-01-08 03:15:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 609c7aa9-75e5-4c6a-be6d-c2297668ff77
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-49, groupId=609c7aa9-75e5-4c6a-be6d-c2297668ff77] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-49, groupId=609c7aa9-75e5-4c6a-be6d-c2297668ff77] Revoking previously assigned partitions []
2020-01-08 03:15:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-49, groupId=609c7aa9-75e5-4c6a-be6d-c2297668ff77] (Re-)joining group
2020-01-08 03:15:02 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-49, groupId=609c7aa9-75e5-4c6a-be6d-c2297668ff77] Successfully joined group with generation 1
2020-01-08 03:15:02 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-49, groupId=609c7aa9-75e5-4c6a-be6d-c2297668ff77] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:02 INFO  Fetcher:583 - [Consumer clientId=consumer-49, groupId=609c7aa9-75e5-4c6a-be6d-c2297668ff77] Resetting offset for partition test113-0 to offset 918.
2020-01-08 03:15:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 87778247-867f-4681-a985-9e12829bebba
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:02 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:02 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:02 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:02 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-50, groupId=87778247-867f-4681-a985-9e12829bebba] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:02 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-50, groupId=87778247-867f-4681-a985-9e12829bebba] Revoking previously assigned partitions []
2020-01-08 03:15:02 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-50, groupId=87778247-867f-4681-a985-9e12829bebba] (Re-)joining group
2020-01-08 03:15:03 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-50, groupId=87778247-867f-4681-a985-9e12829bebba] Successfully joined group with generation 1
2020-01-08 03:15:03 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-50, groupId=87778247-867f-4681-a985-9e12829bebba] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:03 INFO  Fetcher:583 - [Consumer clientId=consumer-50, groupId=87778247-867f-4681-a985-9e12829bebba] Resetting offset for partition test113-0 to offset 920.
2020-01-08 03:15:03 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 43439385-c905-486d-b1ad-f417a9db4671
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:03 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:03 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:03 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:03 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-51, groupId=43439385-c905-486d-b1ad-f417a9db4671] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:03 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-51, groupId=43439385-c905-486d-b1ad-f417a9db4671] Revoking previously assigned partitions []
2020-01-08 03:15:03 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-51, groupId=43439385-c905-486d-b1ad-f417a9db4671] (Re-)joining group
2020-01-08 03:15:03 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-51, groupId=43439385-c905-486d-b1ad-f417a9db4671] Successfully joined group with generation 1
2020-01-08 03:15:03 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-51, groupId=43439385-c905-486d-b1ad-f417a9db4671] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:03 INFO  Fetcher:583 - [Consumer clientId=consumer-51, groupId=43439385-c905-486d-b1ad-f417a9db4671] Resetting offset for partition test113-0 to offset 921.
2020-01-08 03:15:03 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e8d9ae96-5f6e-4481-a916-2019c98026ea
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:03 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:03 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:03 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:03 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-52, groupId=e8d9ae96-5f6e-4481-a916-2019c98026ea] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:03 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-52, groupId=e8d9ae96-5f6e-4481-a916-2019c98026ea] Revoking previously assigned partitions []
2020-01-08 03:15:03 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-52, groupId=e8d9ae96-5f6e-4481-a916-2019c98026ea] (Re-)joining group
2020-01-08 03:15:03 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-52, groupId=e8d9ae96-5f6e-4481-a916-2019c98026ea] Successfully joined group with generation 1
2020-01-08 03:15:03 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-52, groupId=e8d9ae96-5f6e-4481-a916-2019c98026ea] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:03 INFO  Fetcher:583 - [Consumer clientId=consumer-52, groupId=e8d9ae96-5f6e-4481-a916-2019c98026ea] Resetting offset for partition test113-0 to offset 923.
2020-01-08 03:15:03 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a5e8a2e2-5457-429c-bb3e-a9fdd022a78d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:03 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:03 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:03 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:03 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-53, groupId=a5e8a2e2-5457-429c-bb3e-a9fdd022a78d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:03 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-53, groupId=a5e8a2e2-5457-429c-bb3e-a9fdd022a78d] Revoking previously assigned partitions []
2020-01-08 03:15:03 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-53, groupId=a5e8a2e2-5457-429c-bb3e-a9fdd022a78d] (Re-)joining group
2020-01-08 03:15:03 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-53, groupId=a5e8a2e2-5457-429c-bb3e-a9fdd022a78d] Successfully joined group with generation 1
2020-01-08 03:15:03 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-53, groupId=a5e8a2e2-5457-429c-bb3e-a9fdd022a78d] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:03 INFO  Fetcher:583 - [Consumer clientId=consumer-53, groupId=a5e8a2e2-5457-429c-bb3e-a9fdd022a78d] Resetting offset for partition test113-0 to offset 924.
2020-01-08 03:15:03 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = de942e31-d341-4d06-893c-4b18c55a37cf
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:03 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:03 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:03 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:03 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-54, groupId=de942e31-d341-4d06-893c-4b18c55a37cf] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:03 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-54, groupId=de942e31-d341-4d06-893c-4b18c55a37cf] Revoking previously assigned partitions []
2020-01-08 03:15:03 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-54, groupId=de942e31-d341-4d06-893c-4b18c55a37cf] (Re-)joining group
2020-01-08 03:15:03 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-54, groupId=de942e31-d341-4d06-893c-4b18c55a37cf] Successfully joined group with generation 1
2020-01-08 03:15:03 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-54, groupId=de942e31-d341-4d06-893c-4b18c55a37cf] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:03 INFO  Fetcher:583 - [Consumer clientId=consumer-54, groupId=de942e31-d341-4d06-893c-4b18c55a37cf] Resetting offset for partition test113-0 to offset 925.
2020-01-08 03:15:03 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 69765533-11e4-418b-bbba-aaa098ad85ba
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:03 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:03 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:03 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:03 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-55, groupId=69765533-11e4-418b-bbba-aaa098ad85ba] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:03 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-55, groupId=69765533-11e4-418b-bbba-aaa098ad85ba] Revoking previously assigned partitions []
2020-01-08 03:15:03 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-55, groupId=69765533-11e4-418b-bbba-aaa098ad85ba] (Re-)joining group
2020-01-08 03:15:03 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-55, groupId=69765533-11e4-418b-bbba-aaa098ad85ba] Successfully joined group with generation 1
2020-01-08 03:15:03 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-55, groupId=69765533-11e4-418b-bbba-aaa098ad85ba] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:03 INFO  Fetcher:583 - [Consumer clientId=consumer-55, groupId=69765533-11e4-418b-bbba-aaa098ad85ba] Resetting offset for partition test113-0 to offset 926.
2020-01-08 03:15:04 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = df6c732e-9257-4683-bb83-685c01e09a33
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:04 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:04 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:04 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:04 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-56, groupId=df6c732e-9257-4683-bb83-685c01e09a33] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:04 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-56, groupId=df6c732e-9257-4683-bb83-685c01e09a33] Revoking previously assigned partitions []
2020-01-08 03:15:04 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-56, groupId=df6c732e-9257-4683-bb83-685c01e09a33] (Re-)joining group
2020-01-08 03:15:04 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-56, groupId=df6c732e-9257-4683-bb83-685c01e09a33] Successfully joined group with generation 1
2020-01-08 03:15:04 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-56, groupId=df6c732e-9257-4683-bb83-685c01e09a33] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:04 INFO  Fetcher:583 - [Consumer clientId=consumer-56, groupId=df6c732e-9257-4683-bb83-685c01e09a33] Resetting offset for partition test113-0 to offset 927.
2020-01-08 03:15:04 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c36d5115-9820-443f-a788-8b145c87f84c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:04 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:04 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:04 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:04 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-57, groupId=c36d5115-9820-443f-a788-8b145c87f84c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:04 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-57, groupId=c36d5115-9820-443f-a788-8b145c87f84c] Revoking previously assigned partitions []
2020-01-08 03:15:04 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-57, groupId=c36d5115-9820-443f-a788-8b145c87f84c] (Re-)joining group
2020-01-08 03:15:04 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-57, groupId=c36d5115-9820-443f-a788-8b145c87f84c] Successfully joined group with generation 1
2020-01-08 03:15:04 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-57, groupId=c36d5115-9820-443f-a788-8b145c87f84c] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:04 INFO  Fetcher:583 - [Consumer clientId=consumer-57, groupId=c36d5115-9820-443f-a788-8b145c87f84c] Resetting offset for partition test113-0 to offset 929.
2020-01-08 03:15:04 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b45f419e-20a7-4612-a664-d26da16df74d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:04 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:04 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:04 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:04 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-58, groupId=b45f419e-20a7-4612-a664-d26da16df74d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:04 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-58, groupId=b45f419e-20a7-4612-a664-d26da16df74d] Revoking previously assigned partitions []
2020-01-08 03:15:04 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-58, groupId=b45f419e-20a7-4612-a664-d26da16df74d] (Re-)joining group
2020-01-08 03:15:04 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-58, groupId=b45f419e-20a7-4612-a664-d26da16df74d] Successfully joined group with generation 1
2020-01-08 03:15:04 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-58, groupId=b45f419e-20a7-4612-a664-d26da16df74d] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:04 INFO  Fetcher:583 - [Consumer clientId=consumer-58, groupId=b45f419e-20a7-4612-a664-d26da16df74d] Resetting offset for partition test113-0 to offset 931.
2020-01-08 03:15:04 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a2459d93-6f36-426e-b501-2a072aba40b1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:04 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:04 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:04 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:04 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-59, groupId=a2459d93-6f36-426e-b501-2a072aba40b1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:04 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-59, groupId=a2459d93-6f36-426e-b501-2a072aba40b1] Revoking previously assigned partitions []
2020-01-08 03:15:04 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-59, groupId=a2459d93-6f36-426e-b501-2a072aba40b1] (Re-)joining group
2020-01-08 03:15:04 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-59, groupId=a2459d93-6f36-426e-b501-2a072aba40b1] Successfully joined group with generation 1
2020-01-08 03:15:04 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-59, groupId=a2459d93-6f36-426e-b501-2a072aba40b1] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:04 INFO  Fetcher:583 - [Consumer clientId=consumer-59, groupId=a2459d93-6f36-426e-b501-2a072aba40b1] Resetting offset for partition test113-0 to offset 932.
2020-01-08 03:15:05 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4546c60a-4243-41a6-9db4-1252492dc16f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:05 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:05 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:05 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:05 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-60, groupId=4546c60a-4243-41a6-9db4-1252492dc16f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:05 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-60, groupId=4546c60a-4243-41a6-9db4-1252492dc16f] Revoking previously assigned partitions []
2020-01-08 03:15:05 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-60, groupId=4546c60a-4243-41a6-9db4-1252492dc16f] (Re-)joining group
2020-01-08 03:15:05 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-60, groupId=4546c60a-4243-41a6-9db4-1252492dc16f] Successfully joined group with generation 1
2020-01-08 03:15:05 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-60, groupId=4546c60a-4243-41a6-9db4-1252492dc16f] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:05 INFO  Fetcher:583 - [Consumer clientId=consumer-60, groupId=4546c60a-4243-41a6-9db4-1252492dc16f] Resetting offset for partition test113-0 to offset 933.
2020-01-08 03:15:05 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e91877e4-e475-4c9a-9b30-a8c0a1da6332
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:05 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:05 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:05 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:05 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-61, groupId=e91877e4-e475-4c9a-9b30-a8c0a1da6332] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:05 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-61, groupId=e91877e4-e475-4c9a-9b30-a8c0a1da6332] Revoking previously assigned partitions []
2020-01-08 03:15:05 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-61, groupId=e91877e4-e475-4c9a-9b30-a8c0a1da6332] (Re-)joining group
2020-01-08 03:15:05 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-61, groupId=e91877e4-e475-4c9a-9b30-a8c0a1da6332] Successfully joined group with generation 1
2020-01-08 03:15:05 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-61, groupId=e91877e4-e475-4c9a-9b30-a8c0a1da6332] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:05 INFO  Fetcher:583 - [Consumer clientId=consumer-61, groupId=e91877e4-e475-4c9a-9b30-a8c0a1da6332] Resetting offset for partition test113-0 to offset 934.
2020-01-08 03:15:05 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56dd785f-83e5-43df-8651-abb38deaad78
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:05 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:05 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:05 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:05 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-62, groupId=56dd785f-83e5-43df-8651-abb38deaad78] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:05 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-62, groupId=56dd785f-83e5-43df-8651-abb38deaad78] Revoking previously assigned partitions []
2020-01-08 03:15:05 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-62, groupId=56dd785f-83e5-43df-8651-abb38deaad78] (Re-)joining group
2020-01-08 03:15:05 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-62, groupId=56dd785f-83e5-43df-8651-abb38deaad78] Successfully joined group with generation 1
2020-01-08 03:15:05 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-62, groupId=56dd785f-83e5-43df-8651-abb38deaad78] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:05 INFO  Fetcher:583 - [Consumer clientId=consumer-62, groupId=56dd785f-83e5-43df-8651-abb38deaad78] Resetting offset for partition test113-0 to offset 935.
2020-01-08 03:15:05 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 95a35a0a-1695-44a6-8362-9703bead9387
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:05 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:05 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:05 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:05 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-63, groupId=95a35a0a-1695-44a6-8362-9703bead9387] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:05 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-63, groupId=95a35a0a-1695-44a6-8362-9703bead9387] Revoking previously assigned partitions []
2020-01-08 03:15:05 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-63, groupId=95a35a0a-1695-44a6-8362-9703bead9387] (Re-)joining group
2020-01-08 03:15:05 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-63, groupId=95a35a0a-1695-44a6-8362-9703bead9387] Successfully joined group with generation 1
2020-01-08 03:15:05 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-63, groupId=95a35a0a-1695-44a6-8362-9703bead9387] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:05 INFO  Fetcher:583 - [Consumer clientId=consumer-63, groupId=95a35a0a-1695-44a6-8362-9703bead9387] Resetting offset for partition test113-0 to offset 937.
2020-01-08 03:15:05 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = dcdb42fb-731d-422d-aac5-61c4e8e43912
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:05 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:05 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:05 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:05 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-64, groupId=dcdb42fb-731d-422d-aac5-61c4e8e43912] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:05 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-64, groupId=dcdb42fb-731d-422d-aac5-61c4e8e43912] Revoking previously assigned partitions []
2020-01-08 03:15:05 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-64, groupId=dcdb42fb-731d-422d-aac5-61c4e8e43912] (Re-)joining group
2020-01-08 03:15:05 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-64, groupId=dcdb42fb-731d-422d-aac5-61c4e8e43912] Successfully joined group with generation 1
2020-01-08 03:15:05 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-64, groupId=dcdb42fb-731d-422d-aac5-61c4e8e43912] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:05 INFO  Fetcher:583 - [Consumer clientId=consumer-64, groupId=dcdb42fb-731d-422d-aac5-61c4e8e43912] Resetting offset for partition test113-0 to offset 938.
2020-01-08 03:15:05 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 12a4fe1c-8403-4d89-b965-68976ca07cb3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:05 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:05 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:05 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:05 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-65, groupId=12a4fe1c-8403-4d89-b965-68976ca07cb3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:05 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-65, groupId=12a4fe1c-8403-4d89-b965-68976ca07cb3] Revoking previously assigned partitions []
2020-01-08 03:15:05 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-65, groupId=12a4fe1c-8403-4d89-b965-68976ca07cb3] (Re-)joining group
2020-01-08 03:15:05 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-65, groupId=12a4fe1c-8403-4d89-b965-68976ca07cb3] Successfully joined group with generation 1
2020-01-08 03:15:05 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-65, groupId=12a4fe1c-8403-4d89-b965-68976ca07cb3] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:05 INFO  Fetcher:583 - [Consumer clientId=consumer-65, groupId=12a4fe1c-8403-4d89-b965-68976ca07cb3] Resetting offset for partition test113-0 to offset 940.
2020-01-08 03:15:06 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d1e8e4e3-e636-4865-84ff-614c18729892
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:06 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:06 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:06 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:06 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-66, groupId=d1e8e4e3-e636-4865-84ff-614c18729892] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:06 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-66, groupId=d1e8e4e3-e636-4865-84ff-614c18729892] Revoking previously assigned partitions []
2020-01-08 03:15:06 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-66, groupId=d1e8e4e3-e636-4865-84ff-614c18729892] (Re-)joining group
2020-01-08 03:15:06 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-66, groupId=d1e8e4e3-e636-4865-84ff-614c18729892] Successfully joined group with generation 1
2020-01-08 03:15:06 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-66, groupId=d1e8e4e3-e636-4865-84ff-614c18729892] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:06 INFO  Fetcher:583 - [Consumer clientId=consumer-66, groupId=d1e8e4e3-e636-4865-84ff-614c18729892] Resetting offset for partition test113-0 to offset 941.
2020-01-08 03:15:06 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 59d9e06b-0085-464a-acae-c5a7c35ea93c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:06 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:06 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:06 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:06 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-67, groupId=59d9e06b-0085-464a-acae-c5a7c35ea93c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:06 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-67, groupId=59d9e06b-0085-464a-acae-c5a7c35ea93c] Revoking previously assigned partitions []
2020-01-08 03:15:06 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-67, groupId=59d9e06b-0085-464a-acae-c5a7c35ea93c] (Re-)joining group
2020-01-08 03:15:06 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-67, groupId=59d9e06b-0085-464a-acae-c5a7c35ea93c] Successfully joined group with generation 1
2020-01-08 03:15:06 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-67, groupId=59d9e06b-0085-464a-acae-c5a7c35ea93c] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:06 INFO  Fetcher:583 - [Consumer clientId=consumer-67, groupId=59d9e06b-0085-464a-acae-c5a7c35ea93c] Resetting offset for partition test113-0 to offset 942.
2020-01-08 03:15:06 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d11cdd79-d2d2-4e9d-9b90-a1faf2587144
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:06 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:06 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:06 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:06 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-68, groupId=d11cdd79-d2d2-4e9d-9b90-a1faf2587144] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:06 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-68, groupId=d11cdd79-d2d2-4e9d-9b90-a1faf2587144] Revoking previously assigned partitions []
2020-01-08 03:15:06 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-68, groupId=d11cdd79-d2d2-4e9d-9b90-a1faf2587144] (Re-)joining group
2020-01-08 03:15:06 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-68, groupId=d11cdd79-d2d2-4e9d-9b90-a1faf2587144] Successfully joined group with generation 1
2020-01-08 03:15:06 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-68, groupId=d11cdd79-d2d2-4e9d-9b90-a1faf2587144] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:06 INFO  Fetcher:583 - [Consumer clientId=consumer-68, groupId=d11cdd79-d2d2-4e9d-9b90-a1faf2587144] Resetting offset for partition test113-0 to offset 943.
2020-01-08 03:15:06 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e509b213-0986-42a0-b4dd-c00ec985d47b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:06 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:06 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:06 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:06 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-69, groupId=e509b213-0986-42a0-b4dd-c00ec985d47b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:06 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-69, groupId=e509b213-0986-42a0-b4dd-c00ec985d47b] Revoking previously assigned partitions []
2020-01-08 03:15:06 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-69, groupId=e509b213-0986-42a0-b4dd-c00ec985d47b] (Re-)joining group
2020-01-08 03:15:06 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-69, groupId=e509b213-0986-42a0-b4dd-c00ec985d47b] Successfully joined group with generation 1
2020-01-08 03:15:06 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-69, groupId=e509b213-0986-42a0-b4dd-c00ec985d47b] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:06 INFO  Fetcher:583 - [Consumer clientId=consumer-69, groupId=e509b213-0986-42a0-b4dd-c00ec985d47b] Resetting offset for partition test113-0 to offset 944.
2020-01-08 03:15:06 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f0912f21-f046-401c-95ad-908b7c6cff7e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:06 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:06 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:06 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:06 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-70, groupId=f0912f21-f046-401c-95ad-908b7c6cff7e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:06 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-70, groupId=f0912f21-f046-401c-95ad-908b7c6cff7e] Revoking previously assigned partitions []
2020-01-08 03:15:06 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-70, groupId=f0912f21-f046-401c-95ad-908b7c6cff7e] (Re-)joining group
2020-01-08 03:15:06 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-70, groupId=f0912f21-f046-401c-95ad-908b7c6cff7e] Successfully joined group with generation 1
2020-01-08 03:15:06 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-70, groupId=f0912f21-f046-401c-95ad-908b7c6cff7e] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:06 INFO  Fetcher:583 - [Consumer clientId=consumer-70, groupId=f0912f21-f046-401c-95ad-908b7c6cff7e] Resetting offset for partition test113-0 to offset 945.
2020-01-08 03:15:06 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b2b91236-2b71-48f6-afe2-2bfd3509e58a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:06 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:06 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:06 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:06 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-71, groupId=b2b91236-2b71-48f6-afe2-2bfd3509e58a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:06 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-71, groupId=b2b91236-2b71-48f6-afe2-2bfd3509e58a] Revoking previously assigned partitions []
2020-01-08 03:15:06 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-71, groupId=b2b91236-2b71-48f6-afe2-2bfd3509e58a] (Re-)joining group
2020-01-08 03:15:06 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-71, groupId=b2b91236-2b71-48f6-afe2-2bfd3509e58a] Successfully joined group with generation 1
2020-01-08 03:15:06 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-71, groupId=b2b91236-2b71-48f6-afe2-2bfd3509e58a] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:06 INFO  Fetcher:583 - [Consumer clientId=consumer-71, groupId=b2b91236-2b71-48f6-afe2-2bfd3509e58a] Resetting offset for partition test113-0 to offset 947.
2020-01-08 03:15:07 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 197bcbe1-7db7-4f1e-9c6b-f3dad8d090f2
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:07 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:07 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:07 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:07 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-72, groupId=197bcbe1-7db7-4f1e-9c6b-f3dad8d090f2] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:07 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-72, groupId=197bcbe1-7db7-4f1e-9c6b-f3dad8d090f2] Revoking previously assigned partitions []
2020-01-08 03:15:07 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-72, groupId=197bcbe1-7db7-4f1e-9c6b-f3dad8d090f2] (Re-)joining group
2020-01-08 03:15:07 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-72, groupId=197bcbe1-7db7-4f1e-9c6b-f3dad8d090f2] Successfully joined group with generation 1
2020-01-08 03:15:07 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-72, groupId=197bcbe1-7db7-4f1e-9c6b-f3dad8d090f2] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:07 INFO  Fetcher:583 - [Consumer clientId=consumer-72, groupId=197bcbe1-7db7-4f1e-9c6b-f3dad8d090f2] Resetting offset for partition test113-0 to offset 948.
2020-01-08 03:15:07 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0e70d7a7-a1e1-47a2-a2c4-4c381f674b83
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:07 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:07 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:07 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:07 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-73, groupId=0e70d7a7-a1e1-47a2-a2c4-4c381f674b83] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:07 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-73, groupId=0e70d7a7-a1e1-47a2-a2c4-4c381f674b83] Revoking previously assigned partitions []
2020-01-08 03:15:07 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-73, groupId=0e70d7a7-a1e1-47a2-a2c4-4c381f674b83] (Re-)joining group
2020-01-08 03:15:07 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-73, groupId=0e70d7a7-a1e1-47a2-a2c4-4c381f674b83] Successfully joined group with generation 1
2020-01-08 03:15:07 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-73, groupId=0e70d7a7-a1e1-47a2-a2c4-4c381f674b83] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:07 INFO  Fetcher:583 - [Consumer clientId=consumer-73, groupId=0e70d7a7-a1e1-47a2-a2c4-4c381f674b83] Resetting offset for partition test113-0 to offset 949.
2020-01-08 03:15:07 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = bc4d3edf-0408-434f-940a-23924c629c7a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:07 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:07 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:07 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:07 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-74, groupId=bc4d3edf-0408-434f-940a-23924c629c7a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:07 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-74, groupId=bc4d3edf-0408-434f-940a-23924c629c7a] Revoking previously assigned partitions []
2020-01-08 03:15:07 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-74, groupId=bc4d3edf-0408-434f-940a-23924c629c7a] (Re-)joining group
2020-01-08 03:15:07 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-74, groupId=bc4d3edf-0408-434f-940a-23924c629c7a] Successfully joined group with generation 1
2020-01-08 03:15:07 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-74, groupId=bc4d3edf-0408-434f-940a-23924c629c7a] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:07 INFO  Fetcher:583 - [Consumer clientId=consumer-74, groupId=bc4d3edf-0408-434f-940a-23924c629c7a] Resetting offset for partition test113-0 to offset 951.
2020-01-08 03:15:07 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c6022dd5-1dd1-4613-a609-f7ffc8a4d83a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:07 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:07 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:07 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:07 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-75, groupId=c6022dd5-1dd1-4613-a609-f7ffc8a4d83a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:07 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-75, groupId=c6022dd5-1dd1-4613-a609-f7ffc8a4d83a] Revoking previously assigned partitions []
2020-01-08 03:15:07 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-75, groupId=c6022dd5-1dd1-4613-a609-f7ffc8a4d83a] (Re-)joining group
2020-01-08 03:15:07 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-75, groupId=c6022dd5-1dd1-4613-a609-f7ffc8a4d83a] Successfully joined group with generation 1
2020-01-08 03:15:07 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-75, groupId=c6022dd5-1dd1-4613-a609-f7ffc8a4d83a] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:07 INFO  Fetcher:583 - [Consumer clientId=consumer-75, groupId=c6022dd5-1dd1-4613-a609-f7ffc8a4d83a] Resetting offset for partition test113-0 to offset 952.
2020-01-08 03:15:07 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 089af2b1-c7eb-41a1-8c69-a4a89c331338
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:07 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:07 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:07 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:07 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-76, groupId=089af2b1-c7eb-41a1-8c69-a4a89c331338] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:07 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-76, groupId=089af2b1-c7eb-41a1-8c69-a4a89c331338] Revoking previously assigned partitions []
2020-01-08 03:15:07 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-76, groupId=089af2b1-c7eb-41a1-8c69-a4a89c331338] (Re-)joining group
2020-01-08 03:15:07 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-76, groupId=089af2b1-c7eb-41a1-8c69-a4a89c331338] Successfully joined group with generation 1
2020-01-08 03:15:07 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-76, groupId=089af2b1-c7eb-41a1-8c69-a4a89c331338] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:07 INFO  Fetcher:583 - [Consumer clientId=consumer-76, groupId=089af2b1-c7eb-41a1-8c69-a4a89c331338] Resetting offset for partition test113-0 to offset 953.
2020-01-08 03:15:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2e4f6046-1f3e-4682-8e03-ed7d4fc7414d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-77, groupId=2e4f6046-1f3e-4682-8e03-ed7d4fc7414d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:08 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-77, groupId=2e4f6046-1f3e-4682-8e03-ed7d4fc7414d] Revoking previously assigned partitions []
2020-01-08 03:15:08 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-77, groupId=2e4f6046-1f3e-4682-8e03-ed7d4fc7414d] (Re-)joining group
2020-01-08 03:15:08 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-77, groupId=2e4f6046-1f3e-4682-8e03-ed7d4fc7414d] Successfully joined group with generation 1
2020-01-08 03:15:08 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-77, groupId=2e4f6046-1f3e-4682-8e03-ed7d4fc7414d] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:08 INFO  Fetcher:583 - [Consumer clientId=consumer-77, groupId=2e4f6046-1f3e-4682-8e03-ed7d4fc7414d] Resetting offset for partition test113-0 to offset 955.
2020-01-08 03:15:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a88abbbd-24bc-43b6-9c65-68e3d7c96827
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-78, groupId=a88abbbd-24bc-43b6-9c65-68e3d7c96827] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:08 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-78, groupId=a88abbbd-24bc-43b6-9c65-68e3d7c96827] Revoking previously assigned partitions []
2020-01-08 03:15:08 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-78, groupId=a88abbbd-24bc-43b6-9c65-68e3d7c96827] (Re-)joining group
2020-01-08 03:15:08 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-78, groupId=a88abbbd-24bc-43b6-9c65-68e3d7c96827] Successfully joined group with generation 1
2020-01-08 03:15:08 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-78, groupId=a88abbbd-24bc-43b6-9c65-68e3d7c96827] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:08 INFO  Fetcher:583 - [Consumer clientId=consumer-78, groupId=a88abbbd-24bc-43b6-9c65-68e3d7c96827] Resetting offset for partition test113-0 to offset 956.
2020-01-08 03:15:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9edb9793-3788-4953-a781-30d2e5e162cd
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-79, groupId=9edb9793-3788-4953-a781-30d2e5e162cd] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:08 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-79, groupId=9edb9793-3788-4953-a781-30d2e5e162cd] Revoking previously assigned partitions []
2020-01-08 03:15:08 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-79, groupId=9edb9793-3788-4953-a781-30d2e5e162cd] (Re-)joining group
2020-01-08 03:15:08 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-79, groupId=9edb9793-3788-4953-a781-30d2e5e162cd] Successfully joined group with generation 1
2020-01-08 03:15:08 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-79, groupId=9edb9793-3788-4953-a781-30d2e5e162cd] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:08 INFO  Fetcher:583 - [Consumer clientId=consumer-79, groupId=9edb9793-3788-4953-a781-30d2e5e162cd] Resetting offset for partition test113-0 to offset 957.
2020-01-08 03:15:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9521ab85-a779-437f-9664-45bb7fb8b41a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-80, groupId=9521ab85-a779-437f-9664-45bb7fb8b41a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:08 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-80, groupId=9521ab85-a779-437f-9664-45bb7fb8b41a] Revoking previously assigned partitions []
2020-01-08 03:15:08 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-80, groupId=9521ab85-a779-437f-9664-45bb7fb8b41a] (Re-)joining group
2020-01-08 03:15:08 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-80, groupId=9521ab85-a779-437f-9664-45bb7fb8b41a] Successfully joined group with generation 1
2020-01-08 03:15:08 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-80, groupId=9521ab85-a779-437f-9664-45bb7fb8b41a] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:08 INFO  Fetcher:583 - [Consumer clientId=consumer-80, groupId=9521ab85-a779-437f-9664-45bb7fb8b41a] Resetting offset for partition test113-0 to offset 958.
2020-01-08 03:15:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 7d5cade3-96f3-4f22-a0e3-391ffedc9023
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-81, groupId=7d5cade3-96f3-4f22-a0e3-391ffedc9023] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:08 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-81, groupId=7d5cade3-96f3-4f22-a0e3-391ffedc9023] Revoking previously assigned partitions []
2020-01-08 03:15:08 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-81, groupId=7d5cade3-96f3-4f22-a0e3-391ffedc9023] (Re-)joining group
2020-01-08 03:15:08 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-81, groupId=7d5cade3-96f3-4f22-a0e3-391ffedc9023] Successfully joined group with generation 1
2020-01-08 03:15:08 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-81, groupId=7d5cade3-96f3-4f22-a0e3-391ffedc9023] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:08 INFO  Fetcher:583 - [Consumer clientId=consumer-81, groupId=7d5cade3-96f3-4f22-a0e3-391ffedc9023] Resetting offset for partition test113-0 to offset 960.
2020-01-08 03:15:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5799e85c-cb89-4023-84d1-93e2c68eb574
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-82, groupId=5799e85c-cb89-4023-84d1-93e2c68eb574] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:08 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-82, groupId=5799e85c-cb89-4023-84d1-93e2c68eb574] Revoking previously assigned partitions []
2020-01-08 03:15:08 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-82, groupId=5799e85c-cb89-4023-84d1-93e2c68eb574] (Re-)joining group
2020-01-08 03:15:08 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-82, groupId=5799e85c-cb89-4023-84d1-93e2c68eb574] Successfully joined group with generation 1
2020-01-08 03:15:08 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-82, groupId=5799e85c-cb89-4023-84d1-93e2c68eb574] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:08 INFO  Fetcher:583 - [Consumer clientId=consumer-82, groupId=5799e85c-cb89-4023-84d1-93e2c68eb574] Resetting offset for partition test113-0 to offset 961.
2020-01-08 03:15:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5f103eac-2bc5-43b5-a42b-2fb0333670dc
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:08 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:08 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:08 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:08 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-83, groupId=5f103eac-2bc5-43b5-a42b-2fb0333670dc] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:08 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-83, groupId=5f103eac-2bc5-43b5-a42b-2fb0333670dc] Revoking previously assigned partitions []
2020-01-08 03:15:08 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-83, groupId=5f103eac-2bc5-43b5-a42b-2fb0333670dc] (Re-)joining group
2020-01-08 03:15:08 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-83, groupId=5f103eac-2bc5-43b5-a42b-2fb0333670dc] Successfully joined group with generation 1
2020-01-08 03:15:08 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-83, groupId=5f103eac-2bc5-43b5-a42b-2fb0333670dc] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:09 INFO  Fetcher:583 - [Consumer clientId=consumer-83, groupId=5f103eac-2bc5-43b5-a42b-2fb0333670dc] Resetting offset for partition test113-0 to offset 962.
2020-01-08 03:15:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 145a90e2-32fa-4f36-a5f5-a1c271c6968c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:09 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:09 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-84, groupId=145a90e2-32fa-4f36-a5f5-a1c271c6968c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-84, groupId=145a90e2-32fa-4f36-a5f5-a1c271c6968c] Revoking previously assigned partitions []
2020-01-08 03:15:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-84, groupId=145a90e2-32fa-4f36-a5f5-a1c271c6968c] (Re-)joining group
2020-01-08 03:15:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-84, groupId=145a90e2-32fa-4f36-a5f5-a1c271c6968c] Successfully joined group with generation 1
2020-01-08 03:15:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-84, groupId=145a90e2-32fa-4f36-a5f5-a1c271c6968c] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:09 INFO  Fetcher:583 - [Consumer clientId=consumer-84, groupId=145a90e2-32fa-4f36-a5f5-a1c271c6968c] Resetting offset for partition test113-0 to offset 963.
2020-01-08 03:15:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8aafed83-e65c-489f-8427-2a0b0ac1f6fd
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:09 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:09 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-85, groupId=8aafed83-e65c-489f-8427-2a0b0ac1f6fd] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-85, groupId=8aafed83-e65c-489f-8427-2a0b0ac1f6fd] Revoking previously assigned partitions []
2020-01-08 03:15:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-85, groupId=8aafed83-e65c-489f-8427-2a0b0ac1f6fd] (Re-)joining group
2020-01-08 03:15:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-85, groupId=8aafed83-e65c-489f-8427-2a0b0ac1f6fd] Successfully joined group with generation 1
2020-01-08 03:15:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-85, groupId=8aafed83-e65c-489f-8427-2a0b0ac1f6fd] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:09 INFO  Fetcher:583 - [Consumer clientId=consumer-85, groupId=8aafed83-e65c-489f-8427-2a0b0ac1f6fd] Resetting offset for partition test113-0 to offset 965.
2020-01-08 03:15:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c4e3e22f-a915-4fff-ae8e-8234add1640a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:09 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:09 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-86, groupId=c4e3e22f-a915-4fff-ae8e-8234add1640a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-86, groupId=c4e3e22f-a915-4fff-ae8e-8234add1640a] Revoking previously assigned partitions []
2020-01-08 03:15:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-86, groupId=c4e3e22f-a915-4fff-ae8e-8234add1640a] (Re-)joining group
2020-01-08 03:15:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-86, groupId=c4e3e22f-a915-4fff-ae8e-8234add1640a] Successfully joined group with generation 1
2020-01-08 03:15:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-86, groupId=c4e3e22f-a915-4fff-ae8e-8234add1640a] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:09 INFO  Fetcher:583 - [Consumer clientId=consumer-86, groupId=c4e3e22f-a915-4fff-ae8e-8234add1640a] Resetting offset for partition test113-0 to offset 966.
2020-01-08 03:15:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8304669c-a37d-4baf-b12d-8d5ed2db32ec
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:09 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:09 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-87, groupId=8304669c-a37d-4baf-b12d-8d5ed2db32ec] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-87, groupId=8304669c-a37d-4baf-b12d-8d5ed2db32ec] Revoking previously assigned partitions []
2020-01-08 03:15:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-87, groupId=8304669c-a37d-4baf-b12d-8d5ed2db32ec] (Re-)joining group
2020-01-08 03:15:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-87, groupId=8304669c-a37d-4baf-b12d-8d5ed2db32ec] Successfully joined group with generation 1
2020-01-08 03:15:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-87, groupId=8304669c-a37d-4baf-b12d-8d5ed2db32ec] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:09 INFO  Fetcher:583 - [Consumer clientId=consumer-87, groupId=8304669c-a37d-4baf-b12d-8d5ed2db32ec] Resetting offset for partition test113-0 to offset 967.
2020-01-08 03:15:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ac900cde-9d3f-4026-913a-58c7dc7a9501
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:09 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:09 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-88, groupId=ac900cde-9d3f-4026-913a-58c7dc7a9501] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-88, groupId=ac900cde-9d3f-4026-913a-58c7dc7a9501] Revoking previously assigned partitions []
2020-01-08 03:15:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-88, groupId=ac900cde-9d3f-4026-913a-58c7dc7a9501] (Re-)joining group
2020-01-08 03:15:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-88, groupId=ac900cde-9d3f-4026-913a-58c7dc7a9501] Successfully joined group with generation 1
2020-01-08 03:15:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-88, groupId=ac900cde-9d3f-4026-913a-58c7dc7a9501] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:09 INFO  Fetcher:583 - [Consumer clientId=consumer-88, groupId=ac900cde-9d3f-4026-913a-58c7dc7a9501] Resetting offset for partition test113-0 to offset 968.
2020-01-08 03:15:10 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0f43d346-0a85-4c4b-aaf2-0e1787e69ad4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:10 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:10 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:10 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:10 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-89, groupId=0f43d346-0a85-4c4b-aaf2-0e1787e69ad4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:10 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-89, groupId=0f43d346-0a85-4c4b-aaf2-0e1787e69ad4] Revoking previously assigned partitions []
2020-01-08 03:15:10 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-89, groupId=0f43d346-0a85-4c4b-aaf2-0e1787e69ad4] (Re-)joining group
2020-01-08 03:15:10 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-89, groupId=0f43d346-0a85-4c4b-aaf2-0e1787e69ad4] Successfully joined group with generation 1
2020-01-08 03:15:10 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-89, groupId=0f43d346-0a85-4c4b-aaf2-0e1787e69ad4] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:10 INFO  Fetcher:583 - [Consumer clientId=consumer-89, groupId=0f43d346-0a85-4c4b-aaf2-0e1787e69ad4] Resetting offset for partition test113-0 to offset 970.
2020-01-08 03:15:10 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 38169156-c6c2-4126-908d-6e0f9b4edeca
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:10 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:10 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:10 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:10 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-90, groupId=38169156-c6c2-4126-908d-6e0f9b4edeca] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:10 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-90, groupId=38169156-c6c2-4126-908d-6e0f9b4edeca] Revoking previously assigned partitions []
2020-01-08 03:15:10 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-90, groupId=38169156-c6c2-4126-908d-6e0f9b4edeca] (Re-)joining group
2020-01-08 03:15:10 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-90, groupId=38169156-c6c2-4126-908d-6e0f9b4edeca] Successfully joined group with generation 1
2020-01-08 03:15:10 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-90, groupId=38169156-c6c2-4126-908d-6e0f9b4edeca] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:10 INFO  Fetcher:583 - [Consumer clientId=consumer-90, groupId=38169156-c6c2-4126-908d-6e0f9b4edeca] Resetting offset for partition test113-0 to offset 972.
2020-01-08 03:15:10 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4e3bb1e8-30c4-4068-b4d3-cd03e0c95cd8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:10 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:10 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:10 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:10 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-91, groupId=4e3bb1e8-30c4-4068-b4d3-cd03e0c95cd8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:10 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-91, groupId=4e3bb1e8-30c4-4068-b4d3-cd03e0c95cd8] Revoking previously assigned partitions []
2020-01-08 03:15:10 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-91, groupId=4e3bb1e8-30c4-4068-b4d3-cd03e0c95cd8] (Re-)joining group
2020-01-08 03:15:10 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-91, groupId=4e3bb1e8-30c4-4068-b4d3-cd03e0c95cd8] Successfully joined group with generation 1
2020-01-08 03:15:10 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-91, groupId=4e3bb1e8-30c4-4068-b4d3-cd03e0c95cd8] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:10 INFO  Fetcher:583 - [Consumer clientId=consumer-91, groupId=4e3bb1e8-30c4-4068-b4d3-cd03e0c95cd8] Resetting offset for partition test113-0 to offset 974.
2020-01-08 03:15:11 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = be932e52-f129-49fe-9f60-e37a870c472e
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:11 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:11 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:11 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:11 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-92, groupId=be932e52-f129-49fe-9f60-e37a870c472e] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:11 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-92, groupId=be932e52-f129-49fe-9f60-e37a870c472e] Revoking previously assigned partitions []
2020-01-08 03:15:11 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-92, groupId=be932e52-f129-49fe-9f60-e37a870c472e] (Re-)joining group
2020-01-08 03:15:11 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-92, groupId=be932e52-f129-49fe-9f60-e37a870c472e] Successfully joined group with generation 1
2020-01-08 03:15:11 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-92, groupId=be932e52-f129-49fe-9f60-e37a870c472e] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:11 INFO  Fetcher:583 - [Consumer clientId=consumer-92, groupId=be932e52-f129-49fe-9f60-e37a870c472e] Resetting offset for partition test113-0 to offset 976.
2020-01-08 03:15:11 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a1663dc7-f3c5-4bdf-9420-5187235be370
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:11 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:11 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:11 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:11 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-93, groupId=a1663dc7-f3c5-4bdf-9420-5187235be370] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:11 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-93, groupId=a1663dc7-f3c5-4bdf-9420-5187235be370] Revoking previously assigned partitions []
2020-01-08 03:15:11 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-93, groupId=a1663dc7-f3c5-4bdf-9420-5187235be370] (Re-)joining group
2020-01-08 03:15:11 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-93, groupId=a1663dc7-f3c5-4bdf-9420-5187235be370] Successfully joined group with generation 1
2020-01-08 03:15:11 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-93, groupId=a1663dc7-f3c5-4bdf-9420-5187235be370] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:11 INFO  Fetcher:583 - [Consumer clientId=consumer-93, groupId=a1663dc7-f3c5-4bdf-9420-5187235be370] Resetting offset for partition test113-0 to offset 977.
2020-01-08 03:15:11 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5e18f57e-2036-4930-9121-287aa38e87d5
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:11 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:11 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:11 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:11 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-94, groupId=5e18f57e-2036-4930-9121-287aa38e87d5] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:11 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-94, groupId=5e18f57e-2036-4930-9121-287aa38e87d5] Revoking previously assigned partitions []
2020-01-08 03:15:11 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-94, groupId=5e18f57e-2036-4930-9121-287aa38e87d5] (Re-)joining group
2020-01-08 03:15:11 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-94, groupId=5e18f57e-2036-4930-9121-287aa38e87d5] Successfully joined group with generation 1
2020-01-08 03:15:11 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-94, groupId=5e18f57e-2036-4930-9121-287aa38e87d5] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:11 INFO  Fetcher:583 - [Consumer clientId=consumer-94, groupId=5e18f57e-2036-4930-9121-287aa38e87d5] Resetting offset for partition test113-0 to offset 979.
2020-01-08 03:15:12 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 5d97c874-336f-4139-b40a-466e2db3097b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:12 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:12 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:12 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:12 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-95, groupId=5d97c874-336f-4139-b40a-466e2db3097b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:12 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-95, groupId=5d97c874-336f-4139-b40a-466e2db3097b] Revoking previously assigned partitions []
2020-01-08 03:15:12 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-95, groupId=5d97c874-336f-4139-b40a-466e2db3097b] (Re-)joining group
2020-01-08 03:15:12 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-95, groupId=5d97c874-336f-4139-b40a-466e2db3097b] Successfully joined group with generation 1
2020-01-08 03:15:12 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-95, groupId=5d97c874-336f-4139-b40a-466e2db3097b] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:12 INFO  Fetcher:583 - [Consumer clientId=consumer-95, groupId=5d97c874-336f-4139-b40a-466e2db3097b] Resetting offset for partition test113-0 to offset 981.
2020-01-08 03:15:12 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 3835a6de-541d-4896-be3b-fe30e2ecab1f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:12 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:12 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:12 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:12 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-96, groupId=3835a6de-541d-4896-be3b-fe30e2ecab1f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:12 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-96, groupId=3835a6de-541d-4896-be3b-fe30e2ecab1f] Revoking previously assigned partitions []
2020-01-08 03:15:12 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-96, groupId=3835a6de-541d-4896-be3b-fe30e2ecab1f] (Re-)joining group
2020-01-08 03:15:12 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-96, groupId=3835a6de-541d-4896-be3b-fe30e2ecab1f] Successfully joined group with generation 1
2020-01-08 03:15:12 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-96, groupId=3835a6de-541d-4896-be3b-fe30e2ecab1f] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:12 INFO  Fetcher:583 - [Consumer clientId=consumer-96, groupId=3835a6de-541d-4896-be3b-fe30e2ecab1f] Resetting offset for partition test113-0 to offset 982.
2020-01-08 03:15:12 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e65c607d-03f0-4715-a45d-015368a473b9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:12 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:12 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:12 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:12 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-97, groupId=e65c607d-03f0-4715-a45d-015368a473b9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:12 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-97, groupId=e65c607d-03f0-4715-a45d-015368a473b9] Revoking previously assigned partitions []
2020-01-08 03:15:12 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-97, groupId=e65c607d-03f0-4715-a45d-015368a473b9] (Re-)joining group
2020-01-08 03:15:12 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-97, groupId=e65c607d-03f0-4715-a45d-015368a473b9] Successfully joined group with generation 1
2020-01-08 03:15:12 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-97, groupId=e65c607d-03f0-4715-a45d-015368a473b9] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:12 INFO  Fetcher:583 - [Consumer clientId=consumer-97, groupId=e65c607d-03f0-4715-a45d-015368a473b9] Resetting offset for partition test113-0 to offset 984.
2020-01-08 03:15:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 01b8cef5-3bf2-4594-a94b-c69763c5945d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:13 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-98, groupId=01b8cef5-3bf2-4594-a94b-c69763c5945d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-98, groupId=01b8cef5-3bf2-4594-a94b-c69763c5945d] Revoking previously assigned partitions []
2020-01-08 03:15:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-98, groupId=01b8cef5-3bf2-4594-a94b-c69763c5945d] (Re-)joining group
2020-01-08 03:15:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-98, groupId=01b8cef5-3bf2-4594-a94b-c69763c5945d] Successfully joined group with generation 1
2020-01-08 03:15:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-98, groupId=01b8cef5-3bf2-4594-a94b-c69763c5945d] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:13 INFO  Fetcher:583 - [Consumer clientId=consumer-98, groupId=01b8cef5-3bf2-4594-a94b-c69763c5945d] Resetting offset for partition test113-0 to offset 986.
2020-01-08 03:15:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fedad866-0151-4bcf-a7ea-82fb4c11ab6f
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:13 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-99, groupId=fedad866-0151-4bcf-a7ea-82fb4c11ab6f] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-99, groupId=fedad866-0151-4bcf-a7ea-82fb4c11ab6f] Revoking previously assigned partitions []
2020-01-08 03:15:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-99, groupId=fedad866-0151-4bcf-a7ea-82fb4c11ab6f] (Re-)joining group
2020-01-08 03:15:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-99, groupId=fedad866-0151-4bcf-a7ea-82fb4c11ab6f] Successfully joined group with generation 1
2020-01-08 03:15:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-99, groupId=fedad866-0151-4bcf-a7ea-82fb4c11ab6f] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:13 INFO  Fetcher:583 - [Consumer clientId=consumer-99, groupId=fedad866-0151-4bcf-a7ea-82fb4c11ab6f] Resetting offset for partition test113-0 to offset 987.
2020-01-08 03:15:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 20bd0c33-3d7d-42cb-94e1-f0aef1254750
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:13 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-100, groupId=20bd0c33-3d7d-42cb-94e1-f0aef1254750] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-100, groupId=20bd0c33-3d7d-42cb-94e1-f0aef1254750] Revoking previously assigned partitions []
2020-01-08 03:15:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-100, groupId=20bd0c33-3d7d-42cb-94e1-f0aef1254750] (Re-)joining group
2020-01-08 03:15:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-100, groupId=20bd0c33-3d7d-42cb-94e1-f0aef1254750] Successfully joined group with generation 1
2020-01-08 03:15:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-100, groupId=20bd0c33-3d7d-42cb-94e1-f0aef1254750] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:13 INFO  Fetcher:583 - [Consumer clientId=consumer-100, groupId=20bd0c33-3d7d-42cb-94e1-f0aef1254750] Resetting offset for partition test113-0 to offset 988.
2020-01-08 03:15:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c5d65094-87f1-4ffe-b107-45d5b93a0092
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:13 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-101, groupId=c5d65094-87f1-4ffe-b107-45d5b93a0092] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-101, groupId=c5d65094-87f1-4ffe-b107-45d5b93a0092] Revoking previously assigned partitions []
2020-01-08 03:15:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-101, groupId=c5d65094-87f1-4ffe-b107-45d5b93a0092] (Re-)joining group
2020-01-08 03:15:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-101, groupId=c5d65094-87f1-4ffe-b107-45d5b93a0092] Successfully joined group with generation 1
2020-01-08 03:15:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-101, groupId=c5d65094-87f1-4ffe-b107-45d5b93a0092] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:13 INFO  Fetcher:583 - [Consumer clientId=consumer-101, groupId=c5d65094-87f1-4ffe-b107-45d5b93a0092] Resetting offset for partition test113-0 to offset 989.
2020-01-08 03:15:13 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a80d1abf-9094-40a4-8e4c-9fc5d2837434
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:13 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:13 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:13 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:13 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-102, groupId=a80d1abf-9094-40a4-8e4c-9fc5d2837434] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:13 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-102, groupId=a80d1abf-9094-40a4-8e4c-9fc5d2837434] Revoking previously assigned partitions []
2020-01-08 03:15:13 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-102, groupId=a80d1abf-9094-40a4-8e4c-9fc5d2837434] (Re-)joining group
2020-01-08 03:15:13 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-102, groupId=a80d1abf-9094-40a4-8e4c-9fc5d2837434] Successfully joined group with generation 1
2020-01-08 03:15:13 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-102, groupId=a80d1abf-9094-40a4-8e4c-9fc5d2837434] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:13 INFO  Fetcher:583 - [Consumer clientId=consumer-102, groupId=a80d1abf-9094-40a4-8e4c-9fc5d2837434] Resetting offset for partition test113-0 to offset 991.
2020-01-08 03:15:14 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 33499fea-150b-4ce7-97c3-182a619e4d96
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:14 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:14 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:14 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:14 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-103, groupId=33499fea-150b-4ce7-97c3-182a619e4d96] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:14 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-103, groupId=33499fea-150b-4ce7-97c3-182a619e4d96] Revoking previously assigned partitions []
2020-01-08 03:15:14 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-103, groupId=33499fea-150b-4ce7-97c3-182a619e4d96] (Re-)joining group
2020-01-08 03:15:14 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-103, groupId=33499fea-150b-4ce7-97c3-182a619e4d96] Successfully joined group with generation 1
2020-01-08 03:15:14 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-103, groupId=33499fea-150b-4ce7-97c3-182a619e4d96] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:14 INFO  Fetcher:583 - [Consumer clientId=consumer-103, groupId=33499fea-150b-4ce7-97c3-182a619e4d96] Resetting offset for partition test113-0 to offset 992.
2020-01-08 03:15:14 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 632627d6-aab4-4c33-887a-0c9d7f072cf6
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:14 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:14 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:14 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:14 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-104, groupId=632627d6-aab4-4c33-887a-0c9d7f072cf6] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:14 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-104, groupId=632627d6-aab4-4c33-887a-0c9d7f072cf6] Revoking previously assigned partitions []
2020-01-08 03:15:14 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-104, groupId=632627d6-aab4-4c33-887a-0c9d7f072cf6] (Re-)joining group
2020-01-08 03:15:14 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-104, groupId=632627d6-aab4-4c33-887a-0c9d7f072cf6] Successfully joined group with generation 1
2020-01-08 03:15:14 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-104, groupId=632627d6-aab4-4c33-887a-0c9d7f072cf6] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:14 INFO  Fetcher:583 - [Consumer clientId=consumer-104, groupId=632627d6-aab4-4c33-887a-0c9d7f072cf6] Resetting offset for partition test113-0 to offset 994.
2020-01-08 03:15:14 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a3b08aa7-9546-40da-a415-c76bc83d93d7
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:14 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:14 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:14 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:14 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-105, groupId=a3b08aa7-9546-40da-a415-c76bc83d93d7] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:14 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-105, groupId=a3b08aa7-9546-40da-a415-c76bc83d93d7] Revoking previously assigned partitions []
2020-01-08 03:15:14 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-105, groupId=a3b08aa7-9546-40da-a415-c76bc83d93d7] (Re-)joining group
2020-01-08 03:15:14 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-105, groupId=a3b08aa7-9546-40da-a415-c76bc83d93d7] Successfully joined group with generation 1
2020-01-08 03:15:14 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-105, groupId=a3b08aa7-9546-40da-a415-c76bc83d93d7] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:14 INFO  Fetcher:583 - [Consumer clientId=consumer-105, groupId=a3b08aa7-9546-40da-a415-c76bc83d93d7] Resetting offset for partition test113-0 to offset 996.
2020-01-08 03:15:15 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b5f22794-0960-488b-9de9-621b5422ea74
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:15 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:15 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:15 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:15 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-106, groupId=b5f22794-0960-488b-9de9-621b5422ea74] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:15 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-106, groupId=b5f22794-0960-488b-9de9-621b5422ea74] Revoking previously assigned partitions []
2020-01-08 03:15:15 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-106, groupId=b5f22794-0960-488b-9de9-621b5422ea74] (Re-)joining group
2020-01-08 03:15:15 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-106, groupId=b5f22794-0960-488b-9de9-621b5422ea74] Successfully joined group with generation 1
2020-01-08 03:15:15 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-106, groupId=b5f22794-0960-488b-9de9-621b5422ea74] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:15 INFO  Fetcher:583 - [Consumer clientId=consumer-106, groupId=b5f22794-0960-488b-9de9-621b5422ea74] Resetting offset for partition test113-0 to offset 1000.
2020-01-08 03:15:16 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 36186e97-b500-49d8-afe7-c7ef68bb6921
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:16 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:16 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:16 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:16 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-107, groupId=36186e97-b500-49d8-afe7-c7ef68bb6921] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:16 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-107, groupId=36186e97-b500-49d8-afe7-c7ef68bb6921] Revoking previously assigned partitions []
2020-01-08 03:15:16 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-107, groupId=36186e97-b500-49d8-afe7-c7ef68bb6921] (Re-)joining group
2020-01-08 03:15:16 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-107, groupId=36186e97-b500-49d8-afe7-c7ef68bb6921] Successfully joined group with generation 1
2020-01-08 03:15:16 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-107, groupId=36186e97-b500-49d8-afe7-c7ef68bb6921] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:16 INFO  Fetcher:583 - [Consumer clientId=consumer-107, groupId=36186e97-b500-49d8-afe7-c7ef68bb6921] Resetting offset for partition test113-0 to offset 1002.
2020-01-08 03:15:16 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 967b98ea-26da-4639-95d7-c521ea681f2c
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:16 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:16 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:16 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:16 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-108, groupId=967b98ea-26da-4639-95d7-c521ea681f2c] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:16 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-108, groupId=967b98ea-26da-4639-95d7-c521ea681f2c] Revoking previously assigned partitions []
2020-01-08 03:15:16 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-108, groupId=967b98ea-26da-4639-95d7-c521ea681f2c] (Re-)joining group
2020-01-08 03:15:16 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-108, groupId=967b98ea-26da-4639-95d7-c521ea681f2c] Successfully joined group with generation 1
2020-01-08 03:15:16 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-108, groupId=967b98ea-26da-4639-95d7-c521ea681f2c] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:16 INFO  Fetcher:583 - [Consumer clientId=consumer-108, groupId=967b98ea-26da-4639-95d7-c521ea681f2c] Resetting offset for partition test113-0 to offset 1004.
2020-01-08 03:15:17 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = cd4de2f4-6789-4b5f-936e-79e676a34f70
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:17 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:17 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:17 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:17 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-109, groupId=cd4de2f4-6789-4b5f-936e-79e676a34f70] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:17 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-109, groupId=cd4de2f4-6789-4b5f-936e-79e676a34f70] Revoking previously assigned partitions []
2020-01-08 03:15:17 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-109, groupId=cd4de2f4-6789-4b5f-936e-79e676a34f70] (Re-)joining group
2020-01-08 03:15:17 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-109, groupId=cd4de2f4-6789-4b5f-936e-79e676a34f70] Successfully joined group with generation 1
2020-01-08 03:15:17 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-109, groupId=cd4de2f4-6789-4b5f-936e-79e676a34f70] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:17 INFO  Fetcher:583 - [Consumer clientId=consumer-109, groupId=cd4de2f4-6789-4b5f-936e-79e676a34f70] Resetting offset for partition test113-0 to offset 1005.
2020-01-08 03:15:17 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1a6b59b1-2072-404c-80a0-d15dc065dc56
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:17 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:17 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:17 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:17 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-110, groupId=1a6b59b1-2072-404c-80a0-d15dc065dc56] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:17 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-110, groupId=1a6b59b1-2072-404c-80a0-d15dc065dc56] Revoking previously assigned partitions []
2020-01-08 03:15:17 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-110, groupId=1a6b59b1-2072-404c-80a0-d15dc065dc56] (Re-)joining group
2020-01-08 03:15:17 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-110, groupId=1a6b59b1-2072-404c-80a0-d15dc065dc56] Successfully joined group with generation 1
2020-01-08 03:15:17 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-110, groupId=1a6b59b1-2072-404c-80a0-d15dc065dc56] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:17 INFO  Fetcher:583 - [Consumer clientId=consumer-110, groupId=1a6b59b1-2072-404c-80a0-d15dc065dc56] Resetting offset for partition test113-0 to offset 1007.
2020-01-08 03:15:18 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 47e99496-8b80-433f-8288-7303103a95fe
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:18 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:18 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:18 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:18 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-111, groupId=47e99496-8b80-433f-8288-7303103a95fe] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:18 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-111, groupId=47e99496-8b80-433f-8288-7303103a95fe] Revoking previously assigned partitions []
2020-01-08 03:15:18 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-111, groupId=47e99496-8b80-433f-8288-7303103a95fe] (Re-)joining group
2020-01-08 03:15:18 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-111, groupId=47e99496-8b80-433f-8288-7303103a95fe] Successfully joined group with generation 1
2020-01-08 03:15:18 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-111, groupId=47e99496-8b80-433f-8288-7303103a95fe] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:18 INFO  Fetcher:583 - [Consumer clientId=consumer-111, groupId=47e99496-8b80-433f-8288-7303103a95fe] Resetting offset for partition test113-0 to offset 1009.
2020-01-08 03:15:18 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4e5f5d33-141e-4719-9aae-5fe8fb4970db
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:18 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:18 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:18 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:18 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-112, groupId=4e5f5d33-141e-4719-9aae-5fe8fb4970db] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:18 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-112, groupId=4e5f5d33-141e-4719-9aae-5fe8fb4970db] Revoking previously assigned partitions []
2020-01-08 03:15:18 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-112, groupId=4e5f5d33-141e-4719-9aae-5fe8fb4970db] (Re-)joining group
2020-01-08 03:15:18 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-112, groupId=4e5f5d33-141e-4719-9aae-5fe8fb4970db] Successfully joined group with generation 1
2020-01-08 03:15:18 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-112, groupId=4e5f5d33-141e-4719-9aae-5fe8fb4970db] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:18 INFO  Fetcher:583 - [Consumer clientId=consumer-112, groupId=4e5f5d33-141e-4719-9aae-5fe8fb4970db] Resetting offset for partition test113-0 to offset 1010.
2020-01-08 03:15:18 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = c302d379-65d4-4537-be59-38a75ca03ec3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:18 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:18 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:18 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:18 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-113, groupId=c302d379-65d4-4537-be59-38a75ca03ec3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:18 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-113, groupId=c302d379-65d4-4537-be59-38a75ca03ec3] Revoking previously assigned partitions []
2020-01-08 03:15:18 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-113, groupId=c302d379-65d4-4537-be59-38a75ca03ec3] (Re-)joining group
2020-01-08 03:15:18 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-113, groupId=c302d379-65d4-4537-be59-38a75ca03ec3] Successfully joined group with generation 1
2020-01-08 03:15:18 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-113, groupId=c302d379-65d4-4537-be59-38a75ca03ec3] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:18 INFO  Fetcher:583 - [Consumer clientId=consumer-113, groupId=c302d379-65d4-4537-be59-38a75ca03ec3] Resetting offset for partition test113-0 to offset 1011.
2020-01-08 03:15:18 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 6caa8f4b-8dc4-4a20-a455-526e21334ca0
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:18 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:18 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:18 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:18 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-114, groupId=6caa8f4b-8dc4-4a20-a455-526e21334ca0] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:18 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-114, groupId=6caa8f4b-8dc4-4a20-a455-526e21334ca0] Revoking previously assigned partitions []
2020-01-08 03:15:18 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-114, groupId=6caa8f4b-8dc4-4a20-a455-526e21334ca0] (Re-)joining group
2020-01-08 03:15:18 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-114, groupId=6caa8f4b-8dc4-4a20-a455-526e21334ca0] Successfully joined group with generation 1
2020-01-08 03:15:18 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-114, groupId=6caa8f4b-8dc4-4a20-a455-526e21334ca0] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:18 INFO  Fetcher:583 - [Consumer clientId=consumer-114, groupId=6caa8f4b-8dc4-4a20-a455-526e21334ca0] Resetting offset for partition test113-0 to offset 1013.
2020-01-08 03:15:19 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 573b844d-f907-4def-ab3f-d2959bab5427
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:19 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:19 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:19 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:19 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-115, groupId=573b844d-f907-4def-ab3f-d2959bab5427] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:19 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-115, groupId=573b844d-f907-4def-ab3f-d2959bab5427] Revoking previously assigned partitions []
2020-01-08 03:15:19 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-115, groupId=573b844d-f907-4def-ab3f-d2959bab5427] (Re-)joining group
2020-01-08 03:15:19 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-115, groupId=573b844d-f907-4def-ab3f-d2959bab5427] Successfully joined group with generation 1
2020-01-08 03:15:19 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-115, groupId=573b844d-f907-4def-ab3f-d2959bab5427] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:19 INFO  Fetcher:583 - [Consumer clientId=consumer-115, groupId=573b844d-f907-4def-ab3f-d2959bab5427] Resetting offset for partition test113-0 to offset 1014.
2020-01-08 03:15:19 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ea8035fe-3f64-45f1-82b8-27118bacb9ae
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:19 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:19 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:19 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:19 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-116, groupId=ea8035fe-3f64-45f1-82b8-27118bacb9ae] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:19 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-116, groupId=ea8035fe-3f64-45f1-82b8-27118bacb9ae] Revoking previously assigned partitions []
2020-01-08 03:15:19 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-116, groupId=ea8035fe-3f64-45f1-82b8-27118bacb9ae] (Re-)joining group
2020-01-08 03:15:19 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-116, groupId=ea8035fe-3f64-45f1-82b8-27118bacb9ae] Successfully joined group with generation 1
2020-01-08 03:15:19 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-116, groupId=ea8035fe-3f64-45f1-82b8-27118bacb9ae] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:19 INFO  Fetcher:583 - [Consumer clientId=consumer-116, groupId=ea8035fe-3f64-45f1-82b8-27118bacb9ae] Resetting offset for partition test113-0 to offset 1015.
2020-01-08 03:15:19 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d190c869-797b-43a0-ae8f-4b0e940fc25d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:19 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:19 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:19 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:19 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-117, groupId=d190c869-797b-43a0-ae8f-4b0e940fc25d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:19 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-117, groupId=d190c869-797b-43a0-ae8f-4b0e940fc25d] Revoking previously assigned partitions []
2020-01-08 03:15:19 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-117, groupId=d190c869-797b-43a0-ae8f-4b0e940fc25d] (Re-)joining group
2020-01-08 03:15:19 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-117, groupId=d190c869-797b-43a0-ae8f-4b0e940fc25d] Successfully joined group with generation 1
2020-01-08 03:15:19 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-117, groupId=d190c869-797b-43a0-ae8f-4b0e940fc25d] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:19 INFO  Fetcher:583 - [Consumer clientId=consumer-117, groupId=d190c869-797b-43a0-ae8f-4b0e940fc25d] Resetting offset for partition test113-0 to offset 1017.
2020-01-08 03:15:19 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a62ad9b6-9133-46e2-85f0-1efa63beb3ce
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:19 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:19 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:20 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:20 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-118, groupId=a62ad9b6-9133-46e2-85f0-1efa63beb3ce] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:20 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-118, groupId=a62ad9b6-9133-46e2-85f0-1efa63beb3ce] Revoking previously assigned partitions []
2020-01-08 03:15:20 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-118, groupId=a62ad9b6-9133-46e2-85f0-1efa63beb3ce] (Re-)joining group
2020-01-08 03:15:20 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-118, groupId=a62ad9b6-9133-46e2-85f0-1efa63beb3ce] Successfully joined group with generation 1
2020-01-08 03:15:20 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-118, groupId=a62ad9b6-9133-46e2-85f0-1efa63beb3ce] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:20 INFO  Fetcher:583 - [Consumer clientId=consumer-118, groupId=a62ad9b6-9133-46e2-85f0-1efa63beb3ce] Resetting offset for partition test113-0 to offset 1019.
2020-01-08 03:15:20 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 65bd1c96-6ad3-43bf-b81d-b90cf3e80359
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:15:20 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:15:20 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:15:20 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:15:20 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-119, groupId=65bd1c96-6ad3-43bf-b81d-b90cf3e80359] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:15:20 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-119, groupId=65bd1c96-6ad3-43bf-b81d-b90cf3e80359] Revoking previously assigned partitions []
2020-01-08 03:15:20 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-119, groupId=65bd1c96-6ad3-43bf-b81d-b90cf3e80359] (Re-)joining group
2020-01-08 03:15:20 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-119, groupId=65bd1c96-6ad3-43bf-b81d-b90cf3e80359] Successfully joined group with generation 1
2020-01-08 03:15:20 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-119, groupId=65bd1c96-6ad3-43bf-b81d-b90cf3e80359] Setting newly assigned partitions [test113-0]
2020-01-08 03:15:20 INFO  Fetcher:583 - [Consumer clientId=consumer-119, groupId=65bd1c96-6ad3-43bf-b81d-b90cf3e80359] Resetting offset for partition test113-0 to offset 1020.
2020-01-08 03:52:15 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f588f9a0-fa2a-44f8-adb2-cea25332a9d4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:52:15 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:52:15 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:52:16 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 832acb50-b51d-4f91-9c27-9f1edf56503a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:52:16 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:52:16 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:52:16 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:52:16 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:52:16 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-2, groupId=832acb50-b51d-4f91-9c27-9f1edf56503a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:52:16 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-2, groupId=832acb50-b51d-4f91-9c27-9f1edf56503a] Revoking previously assigned partitions []
2020-01-08 03:52:16 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-2, groupId=832acb50-b51d-4f91-9c27-9f1edf56503a] (Re-)joining group
2020-01-08 03:52:16 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=f588f9a0-fa2a-44f8-adb2-cea25332a9d4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:52:16 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=f588f9a0-fa2a-44f8-adb2-cea25332a9d4] Revoking previously assigned partitions []
2020-01-08 03:52:16 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=f588f9a0-fa2a-44f8-adb2-cea25332a9d4] (Re-)joining group
2020-01-08 03:52:16 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-2, groupId=832acb50-b51d-4f91-9c27-9f1edf56503a] Successfully joined group with generation 1
2020-01-08 03:52:16 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-2, groupId=832acb50-b51d-4f91-9c27-9f1edf56503a] Setting newly assigned partitions [test113-0]
2020-01-08 03:52:16 INFO  Fetcher:583 - [Consumer clientId=consumer-2, groupId=832acb50-b51d-4f91-9c27-9f1edf56503a] Resetting offset for partition test113-0 to offset 1061.
2020-01-08 03:52:16 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=f588f9a0-fa2a-44f8-adb2-cea25332a9d4] Successfully joined group with generation 1
2020-01-08 03:52:16 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=f588f9a0-fa2a-44f8-adb2-cea25332a9d4] Setting newly assigned partitions [test113-0]
2020-01-08 03:52:16 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=f588f9a0-fa2a-44f8-adb2-cea25332a9d4] Resetting offset for partition test113-0 to offset 1061.
2020-01-08 03:54:59 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1c5fd3cf-a053-4181-9f44-e90f6f3504eb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:55:00 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:55:00 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:55:00 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:55:00 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=1c5fd3cf-a053-4181-9f44-e90f6f3504eb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:55:00 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=1c5fd3cf-a053-4181-9f44-e90f6f3504eb] Revoking previously assigned partitions []
2020-01-08 03:55:00 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=1c5fd3cf-a053-4181-9f44-e90f6f3504eb] (Re-)joining group
2020-01-08 03:55:00 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=1c5fd3cf-a053-4181-9f44-e90f6f3504eb] Successfully joined group with generation 1
2020-01-08 03:55:00 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=1c5fd3cf-a053-4181-9f44-e90f6f3504eb] Setting newly assigned partitions [test113-0]
2020-01-08 03:55:00 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=1c5fd3cf-a053-4181-9f44-e90f6f3504eb] Resetting offset for partition test113-0 to offset 1061.
2020-01-08 03:56:22 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 92c0f690-ade8-44d5-981a-053b650ea69b
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:56:22 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:56:22 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:56:23 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:56:23 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=92c0f690-ade8-44d5-981a-053b650ea69b] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:56:23 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=92c0f690-ade8-44d5-981a-053b650ea69b] Revoking previously assigned partitions []
2020-01-08 03:56:23 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=92c0f690-ade8-44d5-981a-053b650ea69b] (Re-)joining group
2020-01-08 03:56:23 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=92c0f690-ade8-44d5-981a-053b650ea69b] Successfully joined group with generation 1
2020-01-08 03:56:23 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=92c0f690-ade8-44d5-981a-053b650ea69b] Setting newly assigned partitions [test113-0]
2020-01-08 03:56:23 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=92c0f690-ade8-44d5-981a-053b650ea69b] Resetting offset for partition test113-0 to offset 1061.
2020-01-08 03:58:02 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 55c32b8e-4864-4b60-a029-94689b546c18
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:58:03 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:58:03 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:58:03 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:58:03 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=55c32b8e-4864-4b60-a029-94689b546c18] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:58:03 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=55c32b8e-4864-4b60-a029-94689b546c18] Revoking previously assigned partitions []
2020-01-08 03:58:03 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=55c32b8e-4864-4b60-a029-94689b546c18] (Re-)joining group
2020-01-08 03:58:03 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=55c32b8e-4864-4b60-a029-94689b546c18] Successfully joined group with generation 1
2020-01-08 03:58:03 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=55c32b8e-4864-4b60-a029-94689b546c18] Setting newly assigned partitions [test124-0]
2020-01-08 03:58:03 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=55c32b8e-4864-4b60-a029-94689b546c18] Resetting offset for partition test124-0 to offset 75.
2020-01-08 03:58:53 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e767ee38-e9e3-4a1c-8459-37160f7caf04
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 03:58:53 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 03:58:53 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 03:58:54 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 03:58:54 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=e767ee38-e9e3-4a1c-8459-37160f7caf04] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 03:58:54 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=e767ee38-e9e3-4a1c-8459-37160f7caf04] Revoking previously assigned partitions []
2020-01-08 03:58:54 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=e767ee38-e9e3-4a1c-8459-37160f7caf04] (Re-)joining group
2020-01-08 03:58:54 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=e767ee38-e9e3-4a1c-8459-37160f7caf04] Successfully joined group with generation 1
2020-01-08 03:58:54 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=e767ee38-e9e3-4a1c-8459-37160f7caf04] Setting newly assigned partitions [test124-0]
2020-01-08 03:58:54 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=e767ee38-e9e3-4a1c-8459-37160f7caf04] Resetting offset for partition test124-0 to offset 246.
2020-01-08 04:00:45 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 75bbe55d-fc0e-4bf9-8cd0-3fe2822cd634
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 04:00:45 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 04:00:45 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 04:00:45 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 04:00:45 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-2, groupId=75bbe55d-fc0e-4bf9-8cd0-3fe2822cd634] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 04:00:45 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-2, groupId=75bbe55d-fc0e-4bf9-8cd0-3fe2822cd634] Revoking previously assigned partitions []
2020-01-08 04:00:45 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-2, groupId=75bbe55d-fc0e-4bf9-8cd0-3fe2822cd634] (Re-)joining group
2020-01-08 04:00:45 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-2, groupId=75bbe55d-fc0e-4bf9-8cd0-3fe2822cd634] Successfully joined group with generation 1
2020-01-08 04:00:45 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-2, groupId=75bbe55d-fc0e-4bf9-8cd0-3fe2822cd634] Setting newly assigned partitions [test124-0]
2020-01-08 04:00:45 INFO  Fetcher:583 - [Consumer clientId=consumer-2, groupId=75bbe55d-fc0e-4bf9-8cd0-3fe2822cd634] Resetting offset for partition test124-0 to offset 1032.
2020-01-08 04:00:46 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 14bf58c9-d036-44fb-8a92-840d48396aa4
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-08 04:00:46 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-08 04:00:46 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-08 04:00:46 INFO  Metadata:273 - Cluster ID: 6CUD959dTOGbirk77ZAm2A
2020-01-08 04:00:46 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-3, groupId=14bf58c9-d036-44fb-8a92-840d48396aa4] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-08 04:00:46 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-3, groupId=14bf58c9-d036-44fb-8a92-840d48396aa4] Revoking previously assigned partitions []
2020-01-08 04:00:46 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-3, groupId=14bf58c9-d036-44fb-8a92-840d48396aa4] (Re-)joining group
2020-01-08 04:00:46 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-3, groupId=14bf58c9-d036-44fb-8a92-840d48396aa4] Successfully joined group with generation 1
2020-01-08 04:00:46 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-3, groupId=14bf58c9-d036-44fb-8a92-840d48396aa4] Setting newly assigned partitions [test124-0]
2020-01-08 04:00:46 INFO  Fetcher:583 - [Consumer clientId=consumer-3, groupId=14bf58c9-d036-44fb-8a92-840d48396aa4] Resetting offset for partition test124-0 to offset 1035.
2020-01-10 14:18:42 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 31c0c422-ffcf-48da-b284-215c9ea0f1f1
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-10 14:18:42 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-10 14:18:42 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-10 14:18:43 INFO  Metadata:273 - Cluster ID: LJZV1KQ_Tz6WGtEeuzsaUw
2020-01-10 14:18:43 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=31c0c422-ffcf-48da-b284-215c9ea0f1f1] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-10 14:18:43 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=31c0c422-ffcf-48da-b284-215c9ea0f1f1] Revoking previously assigned partitions []
2020-01-10 14:18:43 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=31c0c422-ffcf-48da-b284-215c9ea0f1f1] (Re-)joining group
2020-01-10 14:18:43 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=31c0c422-ffcf-48da-b284-215c9ea0f1f1] Successfully joined group with generation 1
2020-01-10 14:18:43 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=31c0c422-ffcf-48da-b284-215c9ea0f1f1] Setting newly assigned partitions [test124-0]
2020-01-10 14:18:43 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=31c0c422-ffcf-48da-b284-215c9ea0f1f1] Resetting offset for partition test124-0 to offset 41.
2020-01-10 14:20:17 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1afeaf63-ac60-4094-8fb5-0c6bc9dcf9ff
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-10 14:20:18 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-10 14:20:18 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-10 14:20:18 INFO  Metadata:273 - Cluster ID: LJZV1KQ_Tz6WGtEeuzsaUw
2020-01-10 14:20:18 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=1afeaf63-ac60-4094-8fb5-0c6bc9dcf9ff] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-10 14:20:18 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=1afeaf63-ac60-4094-8fb5-0c6bc9dcf9ff] Revoking previously assigned partitions []
2020-01-10 14:20:18 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=1afeaf63-ac60-4094-8fb5-0c6bc9dcf9ff] (Re-)joining group
2020-01-10 14:20:18 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=1afeaf63-ac60-4094-8fb5-0c6bc9dcf9ff] Successfully joined group with generation 1
2020-01-10 14:20:18 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=1afeaf63-ac60-4094-8fb5-0c6bc9dcf9ff] Setting newly assigned partitions [test124-0]
2020-01-10 14:20:18 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=1afeaf63-ac60-4094-8fb5-0c6bc9dcf9ff] Resetting offset for partition test124-0 to offset 303.
2020-01-14 20:28:34 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 0972a57a-83fc-4d39-a08c-7895a2332a3d
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-14 20:28:34 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-14 20:28:34 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-14 20:28:35 INFO  Metadata:273 - Cluster ID: LJZV1KQ_Tz6WGtEeuzsaUw
2020-01-14 20:28:35 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-14 20:28:35 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Revoking previously assigned partitions []
2020-01-14 20:28:35 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] (Re-)joining group
2020-01-14 20:28:35 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Successfully joined group with generation 1
2020-01-14 20:28:35 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Setting newly assigned partitions [test124-0]
2020-01-14 20:28:35 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Resetting offset for partition test124-0 to offset 853.
2020-01-15 00:17:14 INFO  FetchSessionHandler:440 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Error sending fetch request (sessionId=1786933429, epoch=23742) to node 0: org.apache.kafka.common.errors.DisconnectException.
2020-01-15 00:17:14 INFO  AbstractCoordinator:729 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-01-15 00:17:14 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-15 00:17:17 INFO  AbstractCoordinator:863 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Attempt to heartbeat failed for since member id consumer-1-dfc88845-e86f-4a71-9574-2150785bbeaa is not valid.
2020-01-15 00:17:17 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Revoking previously assigned partitions [test124-0]
2020-01-15 00:17:17 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] (Re-)joining group
2020-01-15 00:17:17 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Successfully joined group with generation 3
2020-01-15 00:17:17 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Setting newly assigned partitions [test124-0]
2020-01-15 01:33:28 INFO  FetchSessionHandler:440 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Error sending fetch request (sessionId=360643170, epoch=8332) to node 0: org.apache.kafka.common.errors.DisconnectException.
2020-01-15 01:33:28 INFO  AbstractCoordinator:729 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-01-15 01:33:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-15 01:33:29 INFO  AbstractCoordinator:729 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-01-15 01:33:29 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-15 01:33:32 INFO  AbstractCoordinator:863 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Attempt to heartbeat failed for since member id consumer-1-5dcc6f17-af0b-4329-a896-acc92e11ef38 is not valid.
2020-01-15 01:33:32 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Revoking previously assigned partitions [test124-0]
2020-01-15 01:33:32 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] (Re-)joining group
2020-01-15 01:33:32 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Successfully joined group with generation 5
2020-01-15 01:33:32 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=0972a57a-83fc-4d39-a08c-7895a2332a3d] Setting newly assigned partitions [test124-0]
2020-01-16 22:29:19 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 48397f88-c46e-49ee-acec-5876a7c21419
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-16 22:29:20 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-16 22:29:20 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-16 22:29:20 INFO  Metadata:273 - Cluster ID: xvh3BcnsTfmeg4fEH_PyqA
2020-01-16 22:29:20 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=48397f88-c46e-49ee-acec-5876a7c21419] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-16 22:29:20 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=48397f88-c46e-49ee-acec-5876a7c21419] Revoking previously assigned partitions []
2020-01-16 22:29:20 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=48397f88-c46e-49ee-acec-5876a7c21419] (Re-)joining group
2020-01-16 22:29:20 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=48397f88-c46e-49ee-acec-5876a7c21419] Successfully joined group with generation 1
2020-01-16 22:29:20 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=48397f88-c46e-49ee-acec-5876a7c21419] Setting newly assigned partitions [live3-0]
2020-01-16 22:29:20 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=48397f88-c46e-49ee-acec-5876a7c21419] Resetting offset for partition live3-0 to offset 335.
2020-01-16 22:29:39 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9b044498-162e-4c74-8b37-708dd1184aa8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-16 22:29:39 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-16 22:29:39 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-16 22:29:39 INFO  Metadata:273 - Cluster ID: xvh3BcnsTfmeg4fEH_PyqA
2020-01-16 22:29:39 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-2, groupId=9b044498-162e-4c74-8b37-708dd1184aa8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-16 22:29:39 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-2, groupId=9b044498-162e-4c74-8b37-708dd1184aa8] Revoking previously assigned partitions []
2020-01-16 22:29:39 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-2, groupId=9b044498-162e-4c74-8b37-708dd1184aa8] (Re-)joining group
2020-01-16 22:29:40 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-2, groupId=9b044498-162e-4c74-8b37-708dd1184aa8] Successfully joined group with generation 1
2020-01-16 22:29:40 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-2, groupId=9b044498-162e-4c74-8b37-708dd1184aa8] Setting newly assigned partitions [live3-0]
2020-01-16 22:29:40 INFO  Fetcher:583 - [Consumer clientId=consumer-2, groupId=9b044498-162e-4c74-8b37-708dd1184aa8] Resetting offset for partition live3-0 to offset 450.
2020-01-16 22:30:21 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d6fccac9-6924-41e5-94b4-ff6b0d1d7254
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-16 22:30:21 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-16 22:30:21 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-16 22:30:21 INFO  Metadata:273 - Cluster ID: xvh3BcnsTfmeg4fEH_PyqA
2020-01-16 22:30:21 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=d6fccac9-6924-41e5-94b4-ff6b0d1d7254] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-16 22:30:21 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=d6fccac9-6924-41e5-94b4-ff6b0d1d7254] Revoking previously assigned partitions []
2020-01-16 22:30:21 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=d6fccac9-6924-41e5-94b4-ff6b0d1d7254] (Re-)joining group
2020-01-16 22:30:21 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=d6fccac9-6924-41e5-94b4-ff6b0d1d7254] Successfully joined group with generation 1
2020-01-16 22:30:21 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=d6fccac9-6924-41e5-94b4-ff6b0d1d7254] Setting newly assigned partitions [live3-0]
2020-01-16 22:30:21 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=d6fccac9-6924-41e5-94b4-ff6b0d1d7254] Resetting offset for partition live3-0 to offset 719.
2020-01-17 08:05:09 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = a4fcf723-75c5-40d6-9df3-5090461e4749
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-17 08:05:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-17 08:05:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-17 08:05:09 INFO  Metadata:273 - Cluster ID: xvh3BcnsTfmeg4fEH_PyqA
2020-01-17 08:05:09 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=a4fcf723-75c5-40d6-9df3-5090461e4749] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-17 08:05:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=a4fcf723-75c5-40d6-9df3-5090461e4749] Revoking previously assigned partitions []
2020-01-17 08:05:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=a4fcf723-75c5-40d6-9df3-5090461e4749] (Re-)joining group
2020-01-17 08:05:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=a4fcf723-75c5-40d6-9df3-5090461e4749] Successfully joined group with generation 1
2020-01-17 08:05:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=a4fcf723-75c5-40d6-9df3-5090461e4749] Setting newly assigned partitions [live3-0]
2020-01-17 08:05:09 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=a4fcf723-75c5-40d6-9df3-5090461e4749] Resetting offset for partition live3-0 to offset 1076.
2020-01-17 08:05:24 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2bc9da88-7725-49f1-b086-32c5b0bed7d8
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-17 08:05:24 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-17 08:05:24 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-17 08:05:24 INFO  Metadata:273 - Cluster ID: xvh3BcnsTfmeg4fEH_PyqA
2020-01-17 08:05:24 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-2, groupId=2bc9da88-7725-49f1-b086-32c5b0bed7d8] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-17 08:05:24 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-2, groupId=2bc9da88-7725-49f1-b086-32c5b0bed7d8] Revoking previously assigned partitions []
2020-01-17 08:05:24 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-2, groupId=2bc9da88-7725-49f1-b086-32c5b0bed7d8] (Re-)joining group
2020-01-17 08:05:24 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-2, groupId=2bc9da88-7725-49f1-b086-32c5b0bed7d8] Successfully joined group with generation 1
2020-01-17 08:05:24 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-2, groupId=2bc9da88-7725-49f1-b086-32c5b0bed7d8] Setting newly assigned partitions [live3-0]
2020-01-17 08:05:24 INFO  Fetcher:583 - [Consumer clientId=consumer-2, groupId=2bc9da88-7725-49f1-b086-32c5b0bed7d8] Resetting offset for partition live3-0 to offset 1190.
2020-01-17 08:06:19 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fed10739-90e1-4ccd-bc08-1a4ed6a94e81
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-17 08:06:19 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-17 08:06:19 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-17 08:06:20 INFO  Metadata:273 - Cluster ID: xvh3BcnsTfmeg4fEH_PyqA
2020-01-17 08:06:20 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=fed10739-90e1-4ccd-bc08-1a4ed6a94e81] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-17 08:06:20 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=fed10739-90e1-4ccd-bc08-1a4ed6a94e81] Revoking previously assigned partitions []
2020-01-17 08:06:20 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=fed10739-90e1-4ccd-bc08-1a4ed6a94e81] (Re-)joining group
2020-01-17 08:06:20 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=fed10739-90e1-4ccd-bc08-1a4ed6a94e81] Successfully joined group with generation 1
2020-01-17 08:06:20 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=fed10739-90e1-4ccd-bc08-1a4ed6a94e81] Setting newly assigned partitions [live3-0]
2020-01-17 08:06:20 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=fed10739-90e1-4ccd-bc08-1a4ed6a94e81] Resetting offset for partition live3-0 to offset 1488.
2020-01-17 11:46:48 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f8abe87c-d375-4ef1-aa55-3badcd974155
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-17 11:46:48 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-17 11:46:48 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-17 11:46:49 INFO  Metadata:273 - Cluster ID: qeuCXMCYRlOsbWtVMBy9Yw
2020-01-17 11:46:49 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=f8abe87c-d375-4ef1-aa55-3badcd974155] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-17 11:46:49 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=f8abe87c-d375-4ef1-aa55-3badcd974155] Revoking previously assigned partitions []
2020-01-17 11:46:49 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=f8abe87c-d375-4ef1-aa55-3badcd974155] (Re-)joining group
2020-01-17 11:46:49 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=f8abe87c-d375-4ef1-aa55-3badcd974155] Successfully joined group with generation 1
2020-01-17 11:46:49 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=f8abe87c-d375-4ef1-aa55-3badcd974155] Setting newly assigned partitions [live3-0]
2020-01-17 11:46:49 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=f8abe87c-d375-4ef1-aa55-3badcd974155] Resetting offset for partition live3-0 to offset 188.
2020-01-17 13:37:27 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = e3bfe28a-7581-46be-a953-0c15cca921f3
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-17 13:37:27 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-17 13:37:27 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-17 13:37:27 INFO  Metadata:273 - Cluster ID: qeuCXMCYRlOsbWtVMBy9Yw
2020-01-17 13:37:27 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=e3bfe28a-7581-46be-a953-0c15cca921f3] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-17 13:37:27 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=e3bfe28a-7581-46be-a953-0c15cca921f3] Revoking previously assigned partitions []
2020-01-17 13:37:27 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=e3bfe28a-7581-46be-a953-0c15cca921f3] (Re-)joining group
2020-01-17 13:37:27 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=e3bfe28a-7581-46be-a953-0c15cca921f3] Successfully joined group with generation 1
2020-01-17 13:37:27 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=e3bfe28a-7581-46be-a953-0c15cca921f3] Setting newly assigned partitions [live3-0]
2020-01-17 13:37:27 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=e3bfe28a-7581-46be-a953-0c15cca921f3] Resetting offset for partition live3-0 to offset 350.
2020-01-21 18:42:40 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 574942db-d735-4fd8-a5fe-0688610154cb
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-21 18:42:40 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-21 18:42:40 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-21 18:42:41 INFO  Metadata:273 - Cluster ID: qeuCXMCYRlOsbWtVMBy9Yw
2020-01-21 18:42:41 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=574942db-d735-4fd8-a5fe-0688610154cb] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-21 18:42:41 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=574942db-d735-4fd8-a5fe-0688610154cb] Revoking previously assigned partitions []
2020-01-21 18:42:41 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=574942db-d735-4fd8-a5fe-0688610154cb] (Re-)joining group
2020-01-21 18:42:41 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=574942db-d735-4fd8-a5fe-0688610154cb] Successfully joined group with generation 1
2020-01-21 18:42:41 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=574942db-d735-4fd8-a5fe-0688610154cb] Setting newly assigned partitions [live-0]
2020-01-21 18:42:41 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=574942db-d735-4fd8-a5fe-0688610154cb] Resetting offset for partition live-0 to offset 5399.
2020-01-22 22:56:40 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d7d7677c-1870-4dd6-9751-cc6510672962
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-22 22:56:40 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-22 22:56:40 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-22 22:56:41 INFO  Metadata:273 - Cluster ID: ZGSS2MwxTGi1DqMgMEP_4g
2020-01-22 22:56:41 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=d7d7677c-1870-4dd6-9751-cc6510672962] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-22 22:56:41 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=d7d7677c-1870-4dd6-9751-cc6510672962] Revoking previously assigned partitions []
2020-01-22 22:56:41 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=d7d7677c-1870-4dd6-9751-cc6510672962] (Re-)joining group
2020-01-22 22:56:41 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=d7d7677c-1870-4dd6-9751-cc6510672962] Successfully joined group with generation 1
2020-01-22 22:56:41 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=d7d7677c-1870-4dd6-9751-cc6510672962] Setting newly assigned partitions [live-0]
2020-01-22 22:56:41 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=d7d7677c-1870-4dd6-9751-cc6510672962] Resetting offset for partition live-0 to offset 1319.
2020-01-22 22:59:45 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f0ec0be6-e996-4219-bce4-cec463e1e7e9
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-22 22:59:45 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-22 22:59:45 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-22 22:59:46 INFO  Metadata:273 - Cluster ID: ZGSS2MwxTGi1DqMgMEP_4g
2020-01-22 22:59:46 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=f0ec0be6-e996-4219-bce4-cec463e1e7e9] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-22 22:59:46 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=f0ec0be6-e996-4219-bce4-cec463e1e7e9] Revoking previously assigned partitions []
2020-01-22 22:59:46 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=f0ec0be6-e996-4219-bce4-cec463e1e7e9] (Re-)joining group
2020-01-22 22:59:46 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=f0ec0be6-e996-4219-bce4-cec463e1e7e9] Successfully joined group with generation 1
2020-01-22 22:59:46 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=f0ec0be6-e996-4219-bce4-cec463e1e7e9] Setting newly assigned partitions [live-0]
2020-01-22 22:59:46 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=f0ec0be6-e996-4219-bce4-cec463e1e7e9] Resetting offset for partition live-0 to offset 1763.
2020-01-22 23:07:08 INFO  ConsumerConfig:279 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 63437309-e032-46e2-a96a-99858d21fc7a
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 10485760
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-01-22 23:07:09 INFO  AppInfoParser:109 - Kafka version : 2.0.0
2020-01-22 23:07:09 INFO  AppInfoParser:110 - Kafka commitId : 3402a8361b734732
2020-01-22 23:07:09 INFO  Metadata:273 - Cluster ID: ZGSS2MwxTGi1DqMgMEP_4g
2020-01-22 23:07:09 INFO  AbstractCoordinator:677 - [Consumer clientId=consumer-1, groupId=63437309-e032-46e2-a96a-99858d21fc7a] Discovered group coordinator DESKTOP-6VN4BTC:9092 (id: 2147483647 rack: null)
2020-01-22 23:07:09 INFO  ConsumerCoordinator:462 - [Consumer clientId=consumer-1, groupId=63437309-e032-46e2-a96a-99858d21fc7a] Revoking previously assigned partitions []
2020-01-22 23:07:09 INFO  AbstractCoordinator:509 - [Consumer clientId=consumer-1, groupId=63437309-e032-46e2-a96a-99858d21fc7a] (Re-)joining group
2020-01-22 23:07:09 INFO  AbstractCoordinator:473 - [Consumer clientId=consumer-1, groupId=63437309-e032-46e2-a96a-99858d21fc7a] Successfully joined group with generation 1
2020-01-22 23:07:09 INFO  ConsumerCoordinator:280 - [Consumer clientId=consumer-1, groupId=63437309-e032-46e2-a96a-99858d21fc7a] Setting newly assigned partitions [live-0]
2020-01-22 23:07:09 INFO  Fetcher:583 - [Consumer clientId=consumer-1, groupId=63437309-e032-46e2-a96a-99858d21fc7a] Resetting offset for partition live-0 to offset 2413.
